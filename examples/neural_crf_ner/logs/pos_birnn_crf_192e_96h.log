--*-*-*-*
Namespace(batch_size=1, data_dir='data/processed_data/', debug=False, emb_size=192, hidden_size=96, min_frequency=2, mode='train', model_name='pos_birnn_crf_192e_96h', model_type='birnn_crf', num_epochs=12, optimizer_type='ADAM', print_batch_freq=100, save_epoch_freq=1, saved_model_path=None, start_tag='start_tag', stop_tag='stop_tag', task='pos')
====================================================================================================
Creating Data Handler object
split_lens =  {'test': 0, 'train': 14986, 'val': 3465}
tag_dct =  {'PRP$': 0, 'VBG': 1, 'VBD': 2, 'start_tag': 3, 'VBN': 4, ',': 5, "''": 6, 'VBP': 7, 'WDT': 8, 'JJ': 9, 'WP': 10, 'VBZ': 11, 'DT': 12, '"': 13, 'RP': 14, '$': 15, 'NN': 16, ')': 17, '(': 18, 'FW': 19, 'POS': 20, '.': 21, 'TO': 22, '-X-': 23, 'LS': 24, 'RB': 25, ':': 26, 'NNS': 27, 'PRP': 28, 'VB': 29, 'WRB': 30, 'CC': 31, 'PDT': 32, 'RBS': 33, 'RBR': 34, 'CD': 35, 'EX': 36, 'IN': 37, 'WP$': 38, 'NN|SYM': 39, 'MD': 40, 'NNPS': 41, 'JJS': 42, 'JJR': 43, 'SYM': 44, 'UH': 45, 'stop_tag': 46, 'NNP': 47}
:---- create model birnn_crf
RNNEncoder:  ['embeddings', 'encoder']
RNNEncoder:  ['embeddings', 'encoder']
BiRNNModel:  ['encoder', 'revcoder']
NeuralCRF modules:  []
BiRNNCRF:  ['rnn_model', 'W', 'neural_crf']

 ------------- Epoch = 0---------------------

=================================
fscore(z) =  [30.693518] || goldscore = [1.6926088]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-1.48	-1.14	0.85	-0.17	-0.26	-0.62	2.25	-1.54	0.35	0.12	-0.87	0.17	0.85	0.16	0.12	0.64	-1.46	-0.67	-0.12	1.08	-1.74	-1.27	1.25	-0.79	-0.55	-1.93	-0.61	0.69	1.86	0.39	0.49	1.32	-1.12	0.32	0.90	-0.06	-1.08	-1.10	-1.73	-0.14	-0.01	1.16	-0.83	1.06	1.44	-1.23	-100000000.00	-1.08	
VBG 	-1.44	-1.12	0.61	0.00	0.18	-0.46	0.11	-0.83	1.08	0.44	-0.66	1.17	1.05	-0.59	-0.22	-1.98	0.03	-0.16	0.27	-0.33	0.77	-0.06	1.28	1.43	0.43	-0.77	-0.46	1.43	-0.29	-0.07	-0.37	0.60	-0.96	1.11	2.31	0.99	0.26	-0.06	-0.29	0.37	2.34	0.30	0.54	-0.36	0.40	-2.07	-100000000.00	-0.48	
VBD 	-0.27	-2.16	0.85	1.07	1.04	1.35	0.68	0.73	1.88	-0.73	-0.93	1.32	0.17	0.76	1.84	-0.01	-1.10	1.13	1.19	-0.39	1.92	0.43	-0.24	-0.15	-0.16	-0.68	0.71	-0.59	0.10	-0.41	0.81	-0.91	0.08	0.11	3.28	0.27	-1.29	0.50	1.37	-1.06	0.09	0.56	0.69	0.10	-0.29	-0.17	-100000000.00	-1.11	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	0.44	-1.99	-1.24	0.37	1.01	-0.68	-1.88	0.27	-0.03	0.47	-0.48	0.97	-0.57	0.97	-1.51	-1.24	-1.29	0.62	0.03	2.32	-0.97	-0.40	0.37	0.74	0.06	1.41	-0.82	-0.00	0.67	0.02	-0.88	-0.15	-0.79	-0.45	-2.83	-1.46	-1.62	-1.59	-0.31	1.49	0.38	-0.88	0.60	0.07	1.25	-0.23	-100000000.00	-0.20	
, 	0.40	-1.68	1.11	-0.81	-1.11	0.54	1.48	-0.95	2.16	1.36	-0.20	-1.24	0.31	-0.51	-1.20	0.23	0.69	1.41	-0.04	-0.23	-1.39	-0.60	1.03	1.27	0.46	0.90	0.09	-0.09	0.08	-0.24	0.01	0.65	-0.18	-1.93	0.51	1.09	-0.67	0.45	-0.57	-1.71	1.12	-0.08	-0.41	0.28	-0.21	-0.62	-100000000.00	0.52	
'' 	-2.88	1.23	-0.13	1.06	-1.30	-2.25	0.55	-0.83	1.43	0.57	-0.83	1.37	-0.87	-2.23	1.53	0.99	-1.27	-0.71	1.19	-0.10	0.80	0.31	-0.86	1.32	-0.57	1.41	1.70	-1.67	0.63	1.06	-1.33	0.51	0.77	-1.15	3.28	0.89	0.22	-0.60	0.66	-0.99	0.64	-0.50	-0.82	-1.07	-1.20	-0.43	-100000000.00	2.18	
VBP 	-0.78	-0.77	0.55	-0.73	2.00	-0.37	0.95	1.66	-0.78	-0.17	-0.06	2.18	-1.10	-1.53	-1.62	-1.12	0.50	0.67	-0.06	-1.01	0.10	0.41	-0.20	-0.48	-0.58	-0.98	-0.51	0.59	0.28	-0.04	0.22	1.44	1.46	-0.11	2.31	0.72	0.61	1.26	0.06	0.69	-1.48	0.53	0.44	-1.43	-0.55	-0.92	-100000000.00	0.62	
WDT 	-0.78	-1.37	-1.18	-0.36	-0.57	-1.52	-2.28	0.48	0.29	-0.45	-1.65	0.26	2.06	-2.27	-0.23	-1.68	-0.73	-0.19	-1.48	-0.82	-0.18	0.14	0.42	-0.53	-0.35	0.18	1.82	0.66	0.42	-0.16	-0.45	-1.17	0.97	-1.37	-0.38	-0.68	1.31	1.61	1.39	-0.28	1.25	-0.40	0.03	0.32	0.29	-0.44	-100000000.00	-0.02	
JJ 	0.44	-0.74	0.06	-1.41	1.12	-0.87	0.32	0.14	-0.66	0.79	-0.02	0.58	2.45	0.70	-1.32	1.41	-1.87	-1.61	0.14	-0.31	-0.88	-0.94	0.71	0.55	-1.24	-0.80	1.65	0.01	1.25	-0.07	0.06	0.08	-2.20	-0.24	-0.32	-0.03	-0.29	1.07	0.25	-0.57	-0.60	0.73	-0.08	-0.01	0.07	-0.97	-100000000.00	-1.07	
WP 	-0.25	-1.44	-1.02	-1.90	0.71	0.67	1.06	1.25	1.04	-0.76	0.74	0.89	-0.06	-0.82	0.11	-0.72	1.03	1.18	2.08	0.91	-0.36	-1.48	1.80	-1.79	0.52	2.02	1.12	-0.54	0.11	0.68	-0.35	1.63	-0.83	0.04	-1.04	-0.40	0.08	0.26	-1.12	1.23	-0.69	-0.01	-0.73	0.63	0.74	0.24	-100000000.00	-1.77	
VBZ 	1.27	0.77	0.85	0.91	-0.08	0.80	0.27	0.85	2.03	0.09	-1.77	0.29	1.15	2.28	0.68	0.20	0.41	0.56	0.42	-1.81	-0.33	0.02	-0.27	-0.51	1.06	0.43	1.62	-1.18	1.29	2.00	2.62	-0.23	-0.90	-1.11	0.05	0.34	-0.25	1.42	-0.27	0.45	-0.52	-0.14	1.15	0.08	-0.19	-0.07	-100000000.00	-1.07	
DT 	0.11	-2.15	-1.02	0.81	-0.47	0.84	-0.42	-1.00	-0.88	0.80	-1.03	-0.04	-0.09	-0.47	0.21	-0.58	1.99	0.51	0.98	0.31	-0.49	1.19	1.01	-0.86	-0.09	-0.68	-0.04	-0.52	-0.76	1.44	0.45	1.44	-0.73	1.38	0.57	-2.41	1.50	1.28	2.32	-0.23	0.48	1.37	0.51	1.15	-0.49	-0.76	-100000000.00	1.20	
" 	0.81	1.03	-1.55	0.74	-0.70	-0.12	0.24	0.65	-0.37	-0.48	0.34	0.25	0.95	0.50	1.42	-0.98	1.27	0.31	-1.64	-0.18	1.43	0.30	-1.21	0.51	1.02	0.17	0.68	-1.24	-0.61	-1.19	-1.29	0.09	-0.17	-0.99	0.54	0.54	-0.62	-0.78	-0.15	-2.91	-0.73	-1.00	0.51	2.27	0.19	-1.04	-100000000.00	0.34	
RP 	-0.85	0.49	-0.15	0.17	0.94	0.68	-1.49	1.16	0.44	1.18	-1.22	0.33	1.62	0.30	-0.33	0.52	-0.96	0.19	-0.07	-0.06	0.91	0.67	0.77	-0.51	0.26	-0.99	1.05	0.41	1.62	-0.66	0.29	-1.51	-0.67	-0.03	1.48	2.57	-3.92	0.31	0.16	0.02	-0.93	-2.14	-0.52	0.54	-0.22	-2.18	-100000000.00	-0.46	
$ 	-1.44	-0.30	0.15	-1.66	0.22	-0.73	0.17	1.42	0.81	0.71	-0.36	0.51	-1.25	0.27	0.33	2.55	1.41	0.06	-0.27	-3.16	-0.36	-0.17	1.72	-0.33	2.57	-0.80	0.62	0.62	-0.43	1.40	0.24	0.01	-0.66	1.03	-0.78	-0.39	0.29	0.03	-1.34	-1.98	1.42	-0.61	0.55	-0.29	-1.52	-0.28	-100000000.00	1.23	
NN 	0.76	0.51	0.31	0.86	2.12	1.39	1.01	-0.38	-0.13	-1.28	1.80	-0.12	0.39	-0.46	-0.86	-0.19	0.03	0.03	-0.75	1.08	1.41	1.89	-1.40	-0.26	-1.28	-1.58	1.36	-2.34	-1.77	-0.78	-1.73	-2.00	0.69	-2.01	1.22	0.05	-0.16	0.58	2.38	-1.64	-2.23	0.55	0.82	0.87	-1.60	-0.28	-100000000.00	0.38	
) 	-0.51	0.22	-0.13	-0.13	-0.27	-1.31	-0.75	-2.14	-1.52	-0.82	-0.40	-0.28	-1.22	-0.02	0.51	0.12	-1.01	0.65	0.63	-0.02	0.20	-2.12	-1.00	1.23	-0.05	-0.43	0.25	-1.98	-0.97	0.20	-1.16	0.23	-1.16	1.16	0.84	1.46	0.78	0.96	-0.63	-2.43	1.18	-0.12	-2.11	0.21	-0.62	0.52	-100000000.00	0.02	
( 	1.99	-3.17	0.51	-0.32	-2.39	-1.02	-0.54	0.29	0.79	-1.20	0.28	0.08	0.23	0.70	0.69	-1.30	0.53	0.11	-0.69	-0.41	0.12	0.61	0.99	0.62	0.67	-1.15	0.28	-0.69	-0.59	-0.33	-0.96	0.25	-1.93	-1.01	-0.16	1.05	-0.17	-1.66	-0.71	-0.01	0.62	-0.84	0.64	-0.68	-0.36	1.97	-100000000.00	1.91	
FW 	-0.03	0.08	-0.70	0.25	-0.42	0.15	-0.34	1.09	1.16	-0.31	0.30	-1.12	0.40	-1.28	-1.19	0.36	0.03	-0.63	-2.23	-0.09	1.24	-0.05	0.62	-0.08	1.36	0.29	-0.48	-1.03	0.20	0.04	2.25	0.63	0.45	-0.31	0.33	0.04	-0.16	-1.90	0.94	-0.69	1.67	0.70	-0.36	0.69	0.91	1.94	-100000000.00	-0.76	
POS 	0.77	0.10	0.85	0.28	1.83	-0.34	-0.05	-0.19	2.49	2.30	-3.59	0.20	0.72	1.64	-1.01	-0.63	2.49	-0.43	0.51	-1.47	-0.45	-0.83	0.30	-1.52	-2.64	1.20	2.30	-0.35	0.88	-1.18	0.61	-0.72	0.60	2.21	0.51	0.19	0.60	-0.85	-1.63	-1.25	0.52	-2.13	-0.43	1.50	-0.39	-0.87	-100000000.00	1.18	
. 	-0.86	0.62	-1.36	-0.36	-0.27	-2.55	-0.41	0.87	0.19	0.64	0.35	1.30	0.96	0.23	0.23	-1.52	-0.48	-0.33	-0.15	0.53	0.29	1.03	1.93	0.51	-0.35	-0.51	0.85	1.10	-0.13	-1.39	2.36	-0.29	0.57	1.02	-0.85	0.83	1.17	-0.53	0.02	-0.47	0.43	-0.32	-0.69	0.33	-0.16	-1.13	-100000000.00	1.62	
TO 	-0.52	-1.88	-0.05	0.38	-0.75	0.49	0.67	0.24	1.00	-0.01	0.99	1.21	-1.61	-0.78	0.20	-1.11	-0.67	-0.07	0.43	-0.05	0.03	-0.09	1.14	0.06	0.03	0.19	-0.74	-0.63	-0.30	-1.51	1.30	0.65	-0.13	0.59	-0.25	1.73	-0.97	0.06	0.83	0.82	-0.72	-2.30	1.74	0.61	-0.29	-1.54	-100000000.00	-1.99	
-X- 	0.10	1.48	-0.78	-1.52	-0.22	-0.29	-1.40	-0.45	-0.43	-0.15	-2.12	-1.58	-0.55	-1.57	0.95	-2.03	1.48	-0.25	-1.57	0.06	-1.02	0.01	-1.24	2.06	-1.09	-0.70	-0.80	0.71	-0.84	-0.26	0.53	1.19	2.03	-0.12	0.07	0.07	0.74	-0.61	0.94	1.31	1.74	-1.10	-1.61	2.69	-0.06	0.79	-100000000.00	-2.22	
LS 	0.31	1.62	-0.66	0.71	0.29	0.81	0.32	-1.37	0.54	0.26	1.73	0.92	-0.20	-1.12	-1.57	-2.69	-0.42	0.74	-0.63	-0.49	1.09	0.89	0.27	-1.44	-1.24	-0.63	0.27	-0.95	-0.10	0.48	2.24	-0.66	0.62	0.50	-0.36	1.55	-1.01	1.60	-0.45	-0.26	-0.46	-1.16	0.17	-1.47	0.49	0.09	-100000000.00	0.96	
RB 	0.46	0.31	1.72	-0.92	-1.38	-0.79	1.06	0.85	-1.11	-0.66	-0.95	0.63	0.56	1.19	1.79	0.43	-1.31	0.89	2.07	0.72	-0.13	-1.15	1.58	0.15	0.32	0.83	1.28	-0.11	0.12	-1.11	0.91	-1.29	-1.26	-0.94	-0.72	-0.55	-0.45	0.49	-0.05	1.31	0.74	-0.77	0.28	-0.49	-0.45	-0.70	-100000000.00	1.21	
: 	-1.65	-0.80	0.63	-0.44	-0.01	-0.07	-1.08	0.11	0.19	1.16	1.21	0.90	-0.50	-1.13	-1.67	0.36	0.21	-2.62	-0.57	-1.35	1.22	-0.78	-1.95	-1.15	-0.27	-0.75	0.67	-3.12	1.18	0.77	-0.44	-1.31	0.66	0.45	-0.58	0.37	0.77	2.19	-0.97	-0.87	-0.84	2.24	-0.57	0.99	-1.84	0.42	-100000000.00	0.11	
NNS 	2.73	0.64	0.69	-0.05	0.23	-1.76	-1.01	-1.26	-0.66	-0.31	0.71	-0.24	-1.23	-0.76	-1.03	-0.79	-0.20	-1.02	0.61	-1.74	0.24	-0.06	-1.29	-0.40	0.07	-0.30	0.98	-0.90	1.25	1.18	1.63	1.47	-0.32	-0.51	1.42	-1.97	1.30	-0.96	1.05	-1.20	1.47	-0.20	-0.62	0.18	-1.26	-0.36	-100000000.00	0.27	
PRP 	0.48	-0.96	-1.73	0.23	1.61	0.04	0.95	-1.32	1.05	0.17	1.14	-0.44	-1.12	0.33	-0.14	-0.43	1.02	0.64	-0.60	-1.30	0.15	1.08	0.34	1.17	-0.15	-0.76	1.02	0.25	-1.10	1.52	-0.06	-1.04	1.11	0.36	0.79	-0.29	0.85	0.68	-0.82	-0.08	0.17	-0.54	0.62	0.31	-0.30	-0.21	-100000000.00	1.09	
VB 	0.96	0.46	-2.08	0.17	-2.61	1.16	-0.69	0.41	1.86	0.09	0.30	-0.29	1.34	0.65	-0.65	3.16	-0.29	0.22	0.23	0.64	-2.25	0.75	0.10	-0.07	-0.21	-0.09	0.11	0.40	1.11	1.47	-0.09	0.75	1.88	0.38	1.03	1.83	-0.45	0.55	-1.23	0.82	0.04	0.22	1.10	1.41	-0.36	0.54	-100000000.00	0.44	
WRB 	-1.01	0.83	-1.24	-0.27	-0.92	0.43	-0.17	0.81	-0.88	1.14	0.09	0.60	-1.89	0.70	0.62	0.19	-0.56	-0.20	0.58	-0.24	-1.23	0.53	0.72	0.34	0.03	-0.66	-0.68	-0.92	0.03	-1.00	-1.01	0.39	-1.55	0.18	-1.87	-0.30	-1.20	-0.84	1.40	-0.25	0.14	-1.80	-0.05	0.86	-0.59	1.36	-100000000.00	0.10	
CC 	-2.15	0.10	-1.12	0.24	-0.26	0.49	-0.52	0.96	0.21	1.34	-0.04	-0.61	-2.56	-0.91	-0.03	0.71	-0.56	-1.07	-0.55	-0.03	0.37	0.96	1.33	-1.70	0.57	-0.10	1.46	-1.34	0.82	1.46	0.58	-1.22	0.74	-1.81	0.71	1.04	0.13	-1.11	0.25	-0.12	0.20	0.73	0.73	0.47	-0.99	-1.24	-100000000.00	0.28	
PDT 	-0.83	2.21	-2.06	0.02	0.54	-0.43	-1.31	0.23	-2.03	0.30	-1.74	1.01	-0.62	-0.79	0.01	-0.98	-1.14	0.28	0.70	0.15	1.89	0.04	-2.29	0.24	0.13	-0.58	0.12	0.84	-0.34	-1.38	0.58	-0.20	0.82	2.07	-0.54	-0.31	0.98	1.13	-0.14	-0.62	0.84	0.05	-0.83	0.18	-2.18	-0.36	-100000000.00	1.03	
RBS 	-0.52	0.01	-0.15	0.54	-0.07	0.03	0.89	0.22	-2.89	1.52	2.16	-0.47	-1.13	0.59	-0.49	0.04	0.48	-0.60	0.05	-0.51	-0.31	0.40	1.47	2.02	-1.37	1.36	0.05	-3.19	-0.94	-0.55	-2.10	2.09	-0.65	0.59	0.05	0.75	0.17	1.42	-0.46	1.00	-0.19	0.01	-1.55	-2.11	-0.38	-0.09	-100000000.00	-1.14	
RBR 	-0.34	-0.67	0.19	0.32	0.68	-1.12	0.69	-1.02	1.47	0.36	2.12	0.96	-0.12	-1.42	-0.16	0.02	-0.27	1.06	0.51	-1.67	0.37	-0.47	-0.31	0.88	1.98	0.27	0.37	0.21	-0.91	1.03	-1.00	-0.12	0.71	0.78	-1.46	-0.16	-2.24	-0.02	0.02	1.11	2.27	-0.27	1.08	0.19	0.77	1.12	-100000000.00	0.38	
CD 	-0.02	-0.61	-1.69	-1.00	-0.88	0.03	0.06	-0.78	0.32	1.06	1.84	-0.65	-1.73	-0.71	-1.94	1.44	-0.25	-0.59	-0.74	0.27	0.87	-0.41	0.37	-0.39	-0.55	-0.50	-0.00	-0.94	1.22	0.47	1.79	-0.15	1.03	-0.98	-1.72	-0.28	-1.31	-0.61	0.48	0.24	0.58	-1.24	-0.91	-0.51	-1.24	-0.11	-100000000.00	0.21	
EX 	0.48	-0.25	0.30	2.22	-0.32	-2.53	-0.69	-0.76	0.08	0.90	0.94	0.81	1.51	-0.53	-1.05	-0.99	-0.02	-0.47	-0.50	-1.89	0.17	-1.56	-1.05	-0.91	-0.26	-0.69	0.70	-1.49	0.53	0.23	0.01	0.68	-0.10	-0.73	1.59	-0.54	-0.66	-2.06	-0.05	0.23	0.53	-0.48	0.53	-1.12	-1.56	0.11	-100000000.00	-0.16	
IN 	-0.69	-0.27	-1.46	0.13	-0.06	0.48	0.15	1.87	1.40	-0.63	-0.79	-0.50	-0.39	0.97	-1.49	0.68	0.10	-0.06	-0.25	0.94	0.84	-0.28	-0.05	-0.19	-0.50	-2.04	-1.24	-0.03	-2.20	0.50	-0.65	0.85	-0.31	-0.52	1.48	-0.92	-0.17	0.94	-0.82	3.38	-1.32	-1.85	1.49	0.13	0.12	-0.11	-100000000.00	-0.28	
WP$ 	0.73	-0.01	0.44	-0.55	-0.32	0.60	-0.35	-1.55	0.38	0.25	1.92	-0.68	0.99	0.65	-0.33	1.62	0.44	0.81	-0.56	0.06	1.44	-2.09	-0.33	0.45	-0.42	-0.51	-0.45	-0.68	0.76	-1.35	-1.83	-0.47	0.07	0.85	0.93	-0.66	-0.07	0.46	-1.69	0.27	1.01	0.24	-1.28	-0.41	-0.42	0.82	-100000000.00	-0.65	
NN|SYM 	1.27	-0.51	1.12	0.64	-0.20	1.92	-0.80	-1.40	2.17	1.81	0.03	-0.13	0.28	-1.36	-0.45	-1.13	-1.20	-0.36	1.03	-0.10	0.97	1.84	-1.21	0.57	0.21	1.34	-0.39	-0.17	-0.04	-0.28	-0.41	-0.71	0.96	1.82	-0.95	0.48	0.90	0.56	0.18	-0.40	-0.05	1.18	-1.05	-0.35	-1.31	-0.29	-100000000.00	1.25	
MD 	1.38	-0.33	-0.30	0.36	-0.10	-1.22	0.28	-1.46	0.10	1.11	0.60	-0.45	-0.93	0.07	0.86	-0.69	-0.83	-0.28	0.19	-1.48	-0.04	1.20	0.39	-0.35	0.14	-0.32	0.12	-0.27	-0.08	-1.02	-0.07	0.68	0.34	-0.11	-0.85	-0.00	-0.23	-0.08	-1.15	1.70	-0.04	0.74	-0.77	-0.97	-0.94	0.64	-100000000.00	0.03	
NNPS 	-0.96	-0.25	-0.71	-0.67	1.02	0.50	-0.46	0.71	-0.28	1.16	-0.48	0.22	-0.78	0.33	-1.08	-0.39	-1.19	2.25	-0.45	-0.17	-0.10	0.09	0.43	-0.06	0.67	1.00	-0.10	-0.43	0.16	0.44	0.14	-1.79	-0.02	0.54	-0.94	-0.30	-0.26	-1.79	-0.12	-1.31	-0.08	0.79	0.37	0.82	0.33	-1.21	-100000000.00	0.15	
JJS 	-0.55	-0.32	0.59	-0.24	1.32	-1.58	0.15	1.63	-1.55	1.12	0.74	-0.81	-1.36	1.57	-0.81	-0.49	0.54	0.07	-0.21	0.31	-1.33	0.05	0.63	-2.18	-0.64	-0.20	0.42	-0.49	0.57	0.36	-1.00	-0.83	0.94	0.84	-0.39	1.41	1.06	0.29	0.46	0.61	0.16	-0.29	-0.13	-1.67	-0.41	1.29	-100000000.00	0.67	
JJR 	-0.00	-1.14	-0.15	0.27	1.34	-1.18	0.33	-0.38	-0.52	0.49	-0.84	0.06	-1.57	0.35	-0.66	0.72	-0.94	-0.55	0.97	0.70	-0.87	0.31	-0.25	0.44	-0.12	1.06	-0.30	1.07	0.72	1.46	-0.14	-1.76	-1.20	-1.47	-0.30	-0.93	0.26	-0.89	-0.57	1.61	0.90	-0.61	-0.11	-1.42	-0.74	-0.98	-100000000.00	0.30	
SYM 	1.74	1.99	-0.85	-1.70	-1.91	-1.06	0.54	1.68	-1.06	1.44	-1.10	-0.44	0.47	2.12	-1.21	1.39	-1.22	0.57	0.55	0.54	0.45	0.69	-1.80	-0.67	-0.60	0.07	-0.41	0.22	0.56	-0.30	-1.31	0.16	0.80	-0.19	-0.85	0.08	-1.43	-1.02	0.60	-0.12	-0.93	-1.40	0.50	1.16	-0.52	0.69	-100000000.00	-1.09	
UH 	0.52	1.07	0.89	-0.25	-0.33	-0.42	2.26	1.67	-1.62	1.38	1.51	-0.72	-1.07	0.67	-0.90	-1.49	-0.27	-1.99	0.27	0.15	-1.72	-1.59	-0.52	-0.34	1.17	2.26	0.05	-0.94	-0.89	0.20	0.34	1.25	1.22	-0.85	-1.30	-1.95	-1.99	0.33	-1.00	2.01	-0.47	-1.38	-0.29	0.39	0.42	-1.60	-100000000.00	-0.90	
stop_tag 	0.66	0.42	-0.25	-0.88	0.11	-0.66	-2.00	-1.03	-1.17	0.91	0.45	1.73	-0.40	0.18	1.86	0.86	0.32	0.44	-1.06	1.14	1.78	-0.23	-0.92	-0.53	-0.35	1.24	-0.32	-0.52	-1.41	0.44	-0.66	1.47	-1.38	-0.56	-0.01	2.30	0.36	-0.95	0.57	0.24	1.12	-0.14	-0.67	0.56	-0.24	-0.80	-100000000.00	-0.87	
NNP 	-0.66	-1.41	-0.09	0.66	-1.64	-1.10	0.47	0.39	0.18	-0.36	1.05	0.03	-0.83	-0.80	0.74	-0.35	-0.45	-0.27	-0.51	0.10	1.65	1.16	-1.49	1.85	-0.05	-1.21	0.18	0.06	0.32	-0.36	-0.58	0.75	-0.20	-1.36	2.32	-0.89	1.17	-1.21	-0.32	-0.78	-0.28	-0.34	-0.12	1.68	-0.85	1.36	-100000000.00	0.74	
Mean train loss after  0 batches of 0  epochs =4.14298684256
Mean train loss after  100 batches of 0  epochs =3.41162598861
Mean train loss after  200 batches of 0  epochs =2.767439246
Mean train loss after  300 batches of 0  epochs =2.4286087065
Mean train loss after  400 batches of 0  epochs =2.20937793553
Mean train loss after  500 batches of 0  epochs =2.06916830018
Mean train loss after  600 batches of 0  epochs =1.94348822198
Mean train loss after  700 batches of 0  epochs =1.81976975175
Mean train loss after  800 batches of 0  epochs =1.73503818128
Mean train loss after  900 batches of 0  epochs =1.64787190568
Mean train loss after  1000 batches of 0  epochs =1.5829892675
Mean train loss after  1100 batches of 0  epochs =1.51774561641
Mean train loss after  1200 batches of 0  epochs =1.46658264252
Mean train loss after  1300 batches of 0  epochs =1.42685059227
Mean train loss after  1400 batches of 0  epochs =1.39169311377
Mean train loss after  1500 batches of 0  epochs =1.36390545669
Mean train loss after  1600 batches of 0  epochs =1.33850654782
Mean train loss after  1700 batches of 0  epochs =1.31473001126
Mean train loss after  1800 batches of 0  epochs =1.28608998431
Mean train loss after  1900 batches of 0  epochs =1.26119008053
Mean train loss after  2000 batches of 0  epochs =1.23249009233
Mean train loss after  2100 batches of 0  epochs =1.20709652857
Mean train loss after  2200 batches of 0  epochs =1.18550156212
Mean train loss after  2300 batches of 0  epochs =1.16161830812
Mean train loss after  2400 batches of 0  epochs =1.13761441033
Mean train loss after  2500 batches of 0  epochs =1.12046896884
Mean train loss after  2600 batches of 0  epochs =1.10418431534
Mean train loss after  2700 batches of 0  epochs =1.08811261852
Mean train loss after  2800 batches of 0  epochs =1.07217648337
Mean train loss after  2900 batches of 0  epochs =1.05527782068
Mean train loss after  3000 batches of 0  epochs =1.04026730727
Mean train loss after  3100 batches of 0  epochs =1.02687361112
Mean train loss after  3200 batches of 0  epochs =1.01278836272
Mean train loss after  3300 batches of 0  epochs =0.999371377792
Mean train loss after  3400 batches of 0  epochs =0.985186573672
Mean train loss after  3500 batches of 0  epochs =0.972965799598
Mean train loss after  3600 batches of 0  epochs =0.960582010871
Mean train loss after  3700 batches of 0  epochs =0.951068978125
Mean train loss after  3800 batches of 0  epochs =0.939991570892
Mean train loss after  3900 batches of 0  epochs =0.929895078913
Mean train loss after  4000 batches of 0  epochs =0.91786618885
Mean train loss after  4100 batches of 0  epochs =0.905241198117
Mean train loss after  4200 batches of 0  epochs =0.895301515832
Mean train loss after  4300 batches of 0  epochs =0.885877589779
Mean train loss after  4400 batches of 0  epochs =0.875976413895
Mean train loss after  4500 batches of 0  epochs =0.868999796678
Mean train loss after  4600 batches of 0  epochs =0.859833289686
Mean train loss after  4700 batches of 0  epochs =0.851988528662
Mean train loss after  4800 batches of 0  epochs =0.844693438642
Mean train loss after  4900 batches of 0  epochs =0.838314506192
Mean train loss after  5000 batches of 0  epochs =0.83047038881
Mean train loss after  5100 batches of 0  epochs =0.823035804665
Mean train loss after  5200 batches of 0  epochs =0.815516722983
Mean train loss after  5300 batches of 0  epochs =0.809976599493
Mean train loss after  5400 batches of 0  epochs =0.804329489395
Mean train loss after  5500 batches of 0  epochs =0.797994060507
Mean train loss after  5600 batches of 0  epochs =0.791626560373
Mean train loss after  5700 batches of 0  epochs =0.787642842318
Mean train loss after  5800 batches of 0  epochs =0.781032246186
Mean train loss after  5900 batches of 0  epochs =0.775898939112
Mean train loss after  6000 batches of 0  epochs =0.769936173875
Mean train loss after  6100 batches of 0  epochs =0.765226267553
Mean train loss after  6200 batches of 0  epochs =0.758821177589
Mean train loss after  6300 batches of 0  epochs =0.753924540411
Mean train loss after  6400 batches of 0  epochs =0.747637392231
Mean train loss after  6500 batches of 0  epochs =0.743171081188
Mean train loss after  6600 batches of 0  epochs =0.738811309251
Mean train loss after  6700 batches of 0  epochs =0.733506887556
Mean train loss after  6800 batches of 0  epochs =0.730049853957
Mean train loss after  6900 batches of 0  epochs =0.725187210169
Mean train loss after  7000 batches of 0  epochs =0.721133106084
Mean train loss after  7100 batches of 0  epochs =0.7163984827
Mean train loss after  7200 batches of 0  epochs =0.711629318289
Mean train loss after  7300 batches of 0  epochs =0.708165910373
Mean train loss after  7400 batches of 0  epochs =0.704160041875
Mean train loss after  7500 batches of 0  epochs =0.699711592119
Mean train loss after  7600 batches of 0  epochs =0.695638166895
Mean train loss after  7700 batches of 0  epochs =0.691895653449
Mean train loss after  7800 batches of 0  epochs =0.687598001551
Mean train loss after  7900 batches of 0  epochs =0.684259952945
Mean train loss after  8000 batches of 0  epochs =0.681192787202
Mean train loss after  8100 batches of 0  epochs =0.677028828722
Mean train loss after  8200 batches of 0  epochs =0.673279765524
Mean train loss after  8300 batches of 0  epochs =0.670067553662
Mean train loss after  8400 batches of 0  epochs =0.667007241674
Mean train loss after  8500 batches of 0  epochs =0.662927309269
Mean train loss after  8600 batches of 0  epochs =0.65922023681
Mean train loss after  8700 batches of 0  epochs =0.656281666275
Mean train loss after  8800 batches of 0  epochs =0.653353806268
Mean train loss after  8900 batches of 0  epochs =0.649611496467
Mean train loss after  9000 batches of 0  epochs =0.646450339095
Mean train loss after  9100 batches of 0  epochs =0.643393975879
Mean train loss after  9200 batches of 0  epochs =0.640313997949
Mean train loss after  9300 batches of 0  epochs =0.636756159778
Mean train loss after  9400 batches of 0  epochs =0.633580057709
Mean train loss after  9500 batches of 0  epochs =0.630459996622
Mean train loss after  9600 batches of 0  epochs =0.627836723931
Mean train loss after  9700 batches of 0  epochs =0.624620357872
Mean train loss after  9800 batches of 0  epochs =0.622387921143
Mean train loss after  9900 batches of 0  epochs =0.619170641757
Mean train loss after  10000 batches of 0  epochs =0.616450408766
Mean train loss after  10100 batches of 0  epochs =0.613270076078
Mean train loss after  10200 batches of 0  epochs =0.610170593374
Mean train loss after  10300 batches of 0  epochs =0.607058451493
Mean train loss after  10400 batches of 0  epochs =0.604909276903
Mean train loss after  10500 batches of 0  epochs =0.602532331982
Mean train loss after  10600 batches of 0  epochs =0.600120756751
Mean train loss after  10700 batches of 0  epochs =0.598082144442
Mean train loss after  10800 batches of 0  epochs =0.595251852748
Mean train loss after  10900 batches of 0  epochs =0.592524749238
Mean train loss after  11000 batches of 0  epochs =0.590478163613
Mean train loss after  11100 batches of 0  epochs =0.588280430812
Mean train loss after  11200 batches of 0  epochs =0.585465242833
Mean train loss after  11300 batches of 0  epochs =0.583520912781
Mean train loss after  11400 batches of 0  epochs =0.581606302782
Mean train loss after  11500 batches of 0  epochs =0.578969348089
Mean train loss after  11600 batches of 0  epochs =0.576967681103
Mean train loss after  11700 batches of 0  epochs =0.575014900899
Mean train loss after  11800 batches of 0  epochs =0.572582726173
Mean train loss after  11900 batches of 0  epochs =0.570486294424
Mean train loss after  12000 batches of 0  epochs =0.56785578402
Mean train loss after  12100 batches of 0  epochs =0.565904552281
Mean train loss after  12200 batches of 0  epochs =0.563676719639
Mean train loss after  12300 batches of 0  epochs =0.561334596342
Mean train loss after  12400 batches of 0  epochs =0.559044645939
Mean train loss after  12500 batches of 0  epochs =0.557407992897
Mean train loss after  12600 batches of 0  epochs =0.555520659141
Mean train loss after  12700 batches of 0  epochs =0.553654997912
Mean train loss after  12800 batches of 0  epochs =0.551744223484
Mean train loss after  12900 batches of 0  epochs =0.550270210661
Mean train loss after  13000 batches of 0  epochs =0.548502711997
Mean train loss after  13100 batches of 0  epochs =0.546715003509
Mean train loss after  13200 batches of 0  epochs =0.545046495939
Mean train loss after  13300 batches of 0  epochs =0.543059046792
Mean train loss after  13400 batches of 0  epochs =0.541883396945
Mean train loss after  13500 batches of 0  epochs =0.540223107548
Mean train loss after  13600 batches of 0  epochs =0.538681185511
Mean train loss after  13700 batches of 0  epochs =0.537411174409
Mean train loss after  13800 batches of 0  epochs =0.535911434266
Mean train loss after  13900 batches of 0  epochs =0.533883140447
Mean train loss after  14000 batches of 0  epochs =0.532362319821
Mean train loss after  14100 batches of 0  epochs =0.530080214647
Mean train loss after  14200 batches of 0  epochs =0.528763440549
Mean train loss after  14300 batches of 0  epochs =0.526909763972
Mean train loss after  14400 batches of 0  epochs =0.525308472229
Mean train loss after  14500 batches of 0  epochs =0.523782330894
Mean train loss after  14600 batches of 0  epochs =0.522060441332
Mean train loss after  14700 batches of 0  epochs =0.520531026157
Mean train loss after  14800 batches of 0  epochs =0.519457796741
Mean train loss after  14900 batches of 0  epochs =0.517682860447
Epoch 0 : Mean train epoch loss =0.516217834514
Epoch 0 Epoch val loss = 14575.1456096
Epoch 0 Epoch val perplexity = 1.3461460056799543
SCORES =  (91.0, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 1---------------------

=================================
fscore(z) =  [219.67653] || goldscore = [217.59232]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-2.66	-0.71	0.46	-0.38	-0.07	-1.52	1.77	-1.41	0.05	-0.82	-1.71	0.09	0.20	-0.12	-0.11	-0.27	-1.72	-1.78	-1.06	-0.09	-2.57	-1.76	0.89	-1.08	-1.33	-2.14	-1.72	-0.81	0.53	0.52	-0.05	0.88	-1.30	-0.51	0.46	-1.58	-1.86	-0.39	-2.25	-0.52	-1.32	-0.30	-2.02	-0.20	0.45	-2.07	-100000000.00	-1.87	
VBG 	-1.68	-1.72	0.38	0.22	0.25	-0.17	-0.52	-0.38	-0.08	-0.91	-1.58	0.97	0.54	-0.62	-0.84	-2.71	-0.02	-1.13	-1.52	-2.38	0.12	-0.53	0.51	1.15	-1.34	-0.52	-0.74	0.60	-1.83	0.13	-1.03	0.48	-1.78	0.39	1.44	-0.33	-0.90	0.47	-0.64	-0.16	0.69	-0.27	0.02	-1.43	-0.69	-3.64	-100000000.00	-0.75	
VBD 	-1.52	-3.21	-1.57	-0.95	-0.39	0.88	-0.01	-0.37	1.88	-1.64	-0.44	-0.39	-0.95	0.03	0.07	-0.89	-0.39	0.83	-0.09	-0.93	0.50	-0.58	-1.85	-0.67	-2.18	-0.19	-0.40	-0.12	0.83	-1.41	-0.18	-0.72	-1.01	-0.60	2.09	-1.05	-1.02	-1.58	0.68	-1.94	-1.46	0.02	0.17	-0.41	-2.36	-1.04	-100000000.00	0.06	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-0.71	-1.55	-0.45	-0.29	-0.14	-0.72	-2.52	0.62	-0.45	-1.08	-1.28	1.05	-0.34	0.26	-1.48	-2.15	-0.90	-0.52	-0.31	0.72	-1.35	-1.05	-0.85	0.39	-1.29	0.82	-1.09	-0.05	-0.52	0.10	-1.50	-0.56	-1.38	-0.79	-3.02	-1.92	-2.71	-1.46	-0.65	0.95	-1.27	-1.36	-0.68	-0.91	0.54	-1.90	-100000000.00	-1.65	
, 	-0.68	-1.74	0.29	-2.18	-0.66	-0.30	0.78	-1.25	1.69	0.77	-1.01	-1.42	-0.37	-0.79	-1.11	-1.46	0.64	1.02	-1.10	-0.69	-2.06	-1.48	-0.46	0.80	-1.75	0.79	-1.10	0.07	0.01	-0.46	-1.65	-0.07	-1.67	-2.17	0.57	1.08	-1.32	-0.11	-1.48	-2.50	-0.35	-0.14	-0.68	0.11	-2.15	-0.61	-100000000.00	0.60	
'' 	-3.36	0.63	-0.51	0.80	-1.75	-2.08	0.31	-1.40	1.02	-0.35	-1.13	0.80	-1.51	-2.91	1.17	0.65	-1.60	-1.53	0.70	-0.47	0.47	0.34	-1.60	1.15	-0.81	0.78	1.64	-2.45	-0.12	0.39	-1.68	-0.12	0.58	-1.50	3.01	0.12	0.06	-0.84	0.48	-1.19	0.04	-1.01	-1.25	-1.46	-1.82	-0.65	-100000000.00	1.09	
VBP 	-2.61	-1.28	-1.49	-2.29	0.31	-0.67	0.70	0.11	-0.36	-1.43	0.23	0.41	-1.02	-2.42	-2.18	-1.90	-0.41	0.18	-0.84	-2.49	-1.46	-0.09	-1.62	-0.69	-1.90	-0.96	-1.21	1.21	0.89	-1.36	-0.67	0.29	0.71	-0.69	1.53	0.03	0.66	-0.86	-0.38	0.32	-2.64	0.83	-0.77	-2.52	-1.05	-2.00	-100000000.00	0.06	
WDT 	-1.59	-2.33	-2.11	-1.04	-1.41	-1.30	-2.59	-0.23	-0.33	-1.42	-2.32	-0.60	1.18	-2.58	-0.70	-2.17	-0.06	-0.35	-2.26	-1.63	-0.99	-0.09	-0.02	-0.62	-0.76	-0.79	1.45	0.66	-0.70	-0.72	-1.09	-1.47	0.58	-1.78	-0.96	-1.27	0.86	0.89	1.14	-0.41	0.32	-1.28	-0.82	-0.56	-0.60	-0.83	-100000000.00	-0.33	
JJ 	0.87	-0.42	0.16	-0.39	0.51	-0.67	-0.37	0.23	-0.94	0.23	-1.18	0.41	1.84	0.35	-1.58	0.89	-1.51	-1.45	0.04	-1.26	-0.25	-1.59	0.31	0.09	-3.56	-0.20	1.19	-1.08	-0.22	0.13	-0.01	-0.09	-3.43	-0.01	0.15	-0.02	-1.70	0.81	-0.18	-1.47	-1.96	-1.05	-0.34	-0.34	-0.80	-1.87	-100000000.00	-0.85	
WP 	-1.00	-2.23	-1.70	-2.54	0.04	0.21	0.91	0.71	0.25	-1.08	0.04	0.40	-0.31	-0.82	-0.57	-1.26	0.60	0.27	1.22	0.19	-1.21	-1.79	1.44	-1.91	-0.05	0.92	0.06	-0.29	-0.62	0.47	-0.85	0.33	-1.19	-0.54	-1.46	-1.24	-0.31	0.34	-1.41	1.03	-1.35	-0.29	-1.34	0.14	0.00	-0.26	-100000000.00	-1.51	
VBZ 	-0.09	-0.98	-1.71	-1.77	-1.13	0.58	-0.53	0.38	2.26	-0.65	-1.24	-0.59	0.31	1.26	-0.70	-0.66	0.57	-0.18	-0.28	-2.54	-1.24	-0.34	-1.15	-0.77	-0.51	0.43	0.73	-1.44	1.61	-0.09	1.53	-0.12	-1.63	-1.76	-0.99	-0.25	0.03	-0.96	-0.81	-0.11	-1.77	-1.36	0.08	-0.94	-1.42	-1.60	-100000000.00	-0.00	
DT 	-1.04	-1.57	-0.73	0.64	-0.29	0.55	-0.73	-0.58	-1.20	-0.15	-1.41	0.21	-0.76	-0.19	0.25	-2.20	0.71	0.06	0.68	-0.32	-0.88	0.26	0.80	-1.47	-1.57	-0.66	-0.02	-0.83	-1.11	1.42	0.43	1.43	-0.49	0.05	0.74	-2.31	0.53	1.43	1.37	-0.96	-0.73	-0.34	-0.62	-0.48	-0.83	-2.31	-100000000.00	0.19	
" 	0.35	0.44	-1.76	0.11	-0.88	-0.17	0.30	-0.07	-0.71	-0.55	-0.22	-0.11	0.45	-0.16	0.78	-1.63	0.79	-0.23	-1.86	-0.98	1.14	0.48	-1.33	0.26	0.46	-0.41	0.52	-1.39	-1.34	-1.10	-1.56	-0.45	-0.82	-1.62	-0.03	-0.19	-1.19	-0.95	-0.46	-3.11	-1.39	-1.25	-0.22	1.47	-0.62	-1.72	-100000000.00	0.06	
RP 	-2.02	0.49	0.40	-1.34	0.96	-0.24	-1.90	1.12	-0.37	0.08	-1.92	-0.00	0.90	-0.84	-0.71	-0.37	-1.08	-0.35	-1.37	-1.19	0.05	0.38	-0.78	-0.70	-0.67	-1.09	-0.11	-0.86	0.83	-0.09	-0.67	-2.48	-1.10	-0.75	0.77	0.74	-4.61	-0.78	-0.20	-0.25	-2.31	-2.68	-1.52	-0.22	-1.20	-2.79	-100000000.00	-1.83	
$ 	-1.82	-0.76	-0.12	-2.85	-0.08	-1.29	-0.19	0.73	0.11	0.39	-0.71	0.12	-1.14	-0.52	-0.04	2.11	0.92	-0.56	-0.24	-3.79	-0.48	-0.41	1.32	-0.47	2.10	-0.74	0.19	-0.34	-0.99	0.84	-0.41	-0.18	-1.11	0.67	-1.26	-0.71	-0.19	0.13	-1.57	-2.20	0.63	-1.36	-0.11	-0.97	-2.29	-0.69	-100000000.00	0.47	
NN 	1.00	-0.16	-0.47	0.47	0.59	0.82	0.04	-0.64	-0.97	0.65	0.67	-0.19	0.53	-0.55	-0.95	-1.45	-0.42	-0.32	-0.81	0.18	1.26	0.99	-1.36	-1.00	-4.25	-2.11	0.82	-1.99	-2.45	-0.34	-1.83	-1.53	-0.47	-2.90	0.59	-0.28	-1.38	0.18	1.88	-2.61	-3.66	-0.73	0.81	0.91	-1.32	-3.21	-100000000.00	-0.43	
) 	-1.36	-0.64	-1.21	-1.78	-0.64	-2.13	-1.63	-2.99	-2.52	-0.67	-1.61	-0.54	-1.60	-0.75	0.42	-0.93	-0.83	-0.40	-0.04	-0.73	-0.07	-2.68	-1.87	0.92	0.01	-1.29	-0.64	-1.94	-2.28	-0.42	-2.19	-1.04	-2.17	0.14	-0.19	1.28	0.27	0.09	-1.27	-3.07	-0.13	-0.41	-3.47	-1.79	-1.90	-0.79	-100000000.00	-0.02	
( 	1.59	-3.32	-0.19	-0.39	-2.98	-1.58	-1.16	-1.41	-0.24	-0.90	0.02	-0.44	-0.21	0.05	-0.37	-2.33	0.48	-0.87	-1.79	-0.45	-0.15	-0.42	0.22	0.30	-0.52	-1.56	-0.44	-0.52	-0.61	-0.71	-1.26	-0.93	-2.99	-1.98	-1.25	0.81	-0.96	-2.10	-1.27	-0.56	-0.52	-0.75	0.01	-1.36	-2.11	0.81	-100000000.00	1.53	
FW 	-1.59	-1.56	-2.56	-0.38	-2.10	-0.41	-0.84	-0.04	0.20	-1.59	-0.52	-2.84	-1.32	-2.70	-2.21	-0.27	-0.62	-0.97	-2.75	0.05	-0.39	-0.32	-1.57	-0.25	0.43	-1.74	-1.23	-2.57	-1.44	-1.81	1.49	-0.54	-0.16	-0.89	-0.48	-0.96	-0.88	-4.88	0.64	-1.02	0.33	-0.22	-1.59	-0.64	-0.10	1.07	-100000000.00	-0.45	
POS 	-0.11	-1.55	-0.14	-0.81	0.90	-0.85	0.07	-1.26	2.12	1.09	-4.11	-1.17	-0.08	1.01	-1.64	-1.18	1.98	-1.39	-0.37	-2.58	-0.89	-1.04	-0.66	-1.73	-3.32	0.12	1.84	0.08	0.10	-1.63	-0.01	-1.57	0.08	1.65	-0.16	-0.61	0.16	-1.34	-1.81	-1.46	-0.64	-2.15	-1.60	0.54	-1.27	-1.54	-100000000.00	1.76	
. 	-1.81	-0.12	-1.16	-1.94	-0.28	-3.39	-1.16	0.22	-0.47	0.22	-0.75	0.79	0.56	0.06	0.08	-2.87	-0.21	-0.46	-1.27	-0.95	-0.11	0.36	0.61	0.03	-0.05	-0.32	-0.10	0.98	-0.13	-0.94	1.08	-1.42	-0.38	-0.62	-0.79	0.73	0.71	-0.94	-0.78	-1.10	-1.22	-0.29	-1.62	0.05	-2.21	-2.21	-100000000.00	1.30	
TO 	-0.98	-1.51	-0.23	0.18	-0.62	-0.71	-0.14	0.01	-0.51	-0.38	-0.32	0.95	-2.04	-1.07	-0.08	-2.33	-0.66	-0.46	-0.36	-1.22	-1.22	-1.07	-0.22	-0.41	-1.27	-0.27	-1.28	-0.73	-0.67	-1.11	0.48	-0.99	-1.52	-0.48	-0.34	1.10	-1.48	-0.03	0.02	0.32	-2.09	-2.32	0.66	-0.08	-1.98	-3.19	-100000000.00	-1.62	
-X- 	-0.11	0.97	-1.34	-1.51	-0.72	-1.07	-1.53	-0.74	-0.60	-0.81	-2.31	-1.94	-0.90	-1.89	0.78	-2.15	0.66	-0.87	-1.95	-0.14	-1.26	-0.13	-1.63	2.01	-1.20	-1.38	-1.30	-0.07	-1.26	-0.68	0.38	0.74	1.95	-0.20	-0.01	-0.98	0.61	-1.24	0.88	1.26	1.45	-1.54	-1.73	2.50	-0.45	0.70	-100000000.00	-3.31	
LS 	-0.22	0.07	-1.96	-0.23	-1.02	-0.58	0.09	-2.13	0.11	-1.94	1.24	-0.12	-2.04	-1.93	-2.25	-3.17	-2.41	-0.56	-1.22	-1.05	0.37	0.73	-0.97	-1.52	-1.73	-2.33	0.63	-3.00	-1.03	-0.60	1.88	-2.06	0.42	0.30	-0.74	-1.14	-1.34	-0.45	-0.60	-0.39	-1.38	-2.34	-0.32	-2.20	-0.12	-0.34	-100000000.00	-1.39	
RB 	-0.27	-0.03	0.85	-0.39	-0.54	-0.50	0.38	0.73	-1.19	-1.23	-0.94	0.79	0.14	0.82	0.78	-0.65	-0.65	0.66	0.97	-1.23	-0.88	-1.63	0.79	-0.23	-1.48	-0.06	0.19	-0.10	0.19	-0.35	0.60	-0.85	-2.30	-1.51	-0.72	-0.57	-0.99	-0.04	-0.47	0.74	0.99	-1.71	-0.41	-1.47	-1.18	-2.21	-100000000.00	-0.31	
: 	-2.75	-0.72	-0.20	-1.00	-0.50	-1.10	-1.75	-0.30	-0.40	0.37	0.57	0.25	-1.36	-1.39	-2.60	-0.54	0.17	-2.36	-1.14	-3.09	0.76	-1.30	-3.22	-1.45	-1.51	-1.02	-0.47	-2.23	-0.29	0.50	-1.80	-2.61	-0.24	-0.45	-1.08	0.30	-0.19	0.92	-1.48	-1.35	-2.12	0.74	-2.14	0.45	-3.05	-0.88	-100000000.00	0.07	
NNS 	1.88	-0.18	-0.39	0.23	0.04	-1.57	-1.78	-0.97	-0.83	0.58	-0.27	-0.89	-0.68	-1.08	-1.24	-1.81	-0.15	-1.32	-0.36	-1.85	0.38	-0.96	-1.51	-1.16	-2.85	-2.08	0.26	-2.16	-0.35	0.16	0.58	0.72	-1.37	-1.44	0.41	-0.41	-0.04	-0.95	0.98	-2.32	-0.18	-1.68	-0.42	0.40	-1.57	-3.01	-100000000.00	-0.90	
PRP 	-0.75	-0.85	-0.80	0.12	0.89	-0.49	0.72	-1.02	0.36	-0.81	1.06	-0.25	-1.65	0.23	-1.01	-1.49	0.16	-0.35	-1.60	-2.55	-0.05	0.51	0.26	0.84	-1.15	-0.86	0.86	-0.53	-2.12	1.21	0.20	-0.91	0.05	-0.57	-0.07	-1.49	0.29	0.77	-1.51	-0.46	-0.69	-2.11	-0.50	-1.17	-1.00	-1.09	-100000000.00	-0.32	
VB 	-0.68	-0.58	-2.97	-0.08	-3.71	0.53	-1.25	-0.62	0.77	-1.17	-0.09	-0.93	0.10	-0.10	-1.63	2.27	-0.66	0.41	-0.81	-0.25	-3.46	0.31	0.49	-0.34	-1.52	0.53	0.49	-0.68	0.42	-0.18	-0.97	0.87	1.35	-0.33	0.79	-0.30	-1.30	-1.02	-1.61	0.41	1.11	-1.19	0.02	0.66	-1.68	-0.31	-100000000.00	-0.70	
WRB 	-1.51	-0.07	-1.45	-0.57	-0.83	0.15	-0.49	-0.09	-1.17	0.40	-0.42	0.62	-3.13	0.09	0.09	-0.44	-0.37	-0.84	-0.21	-1.06	-1.66	0.29	-0.34	0.24	-0.47	-1.10	-1.62	-1.01	-0.36	-0.97	-1.73	-0.47	-2.02	-0.31	-2.54	-0.91	-1.56	-1.26	1.21	-0.40	-1.03	-2.96	-0.77	0.07	-1.40	0.85	-100000000.00	-0.15	
CC 	-2.79	-0.96	-1.40	-0.17	-0.18	0.35	-1.27	0.05	-0.44	0.81	-1.08	-0.85	-3.03	-1.04	-0.46	-0.63	-0.19	-1.37	-1.75	-1.90	-0.74	0.59	0.00	-1.99	-1.01	-0.25	1.16	-0.99	0.06	0.66	-0.72	-2.05	-0.42	-2.44	0.19	0.49	-0.22	-1.12	-0.47	-0.54	-1.31	0.49	0.02	0.35	-1.23	-2.62	-100000000.00	0.22	
PDT 	-1.50	1.50	-2.52	-1.60	0.31	-1.32	-1.54	-0.23	-2.39	-0.83	-2.27	0.40	-1.66	-1.60	-0.25	-1.28	-2.23	-0.64	0.40	-0.25	1.28	-0.10	-3.31	0.19	-0.26	-0.65	-0.35	-0.10	-1.12	-1.64	0.37	-0.72	0.57	1.73	-0.83	-1.58	0.72	1.06	-0.26	-0.69	0.43	-0.65	-1.23	-0.19	-2.85	-0.52	-100000000.00	0.48	
RBS 	-0.50	-0.60	-0.51	-1.27	-0.56	-0.58	0.59	-0.44	-3.13	0.10	1.74	-0.64	-0.87	-0.14	-0.84	-0.29	-0.50	-1.36	-0.94	-0.90	-0.43	0.26	0.45	1.96	-1.68	0.80	-0.69	-4.56	-1.86	-0.93	-2.41	1.15	-0.92	0.26	-0.22	-0.27	-0.15	0.93	-0.56	0.91	-0.97	-0.73	-2.09	-2.60	-1.11	-0.31	-100000000.00	-2.95	
RBR 	-1.38	-1.06	0.19	-0.14	0.27	-1.77	0.34	-1.23	0.92	-0.63	1.42	0.42	-0.21	-1.77	-0.28	-0.57	-0.24	-0.02	-0.36	-2.39	-0.61	-0.73	-0.69	0.79	1.58	0.26	-0.07	0.17	-1.25	0.47	-1.54	-0.68	0.30	0.37	-2.01	-1.03	-2.72	-0.34	-0.19	0.98	1.34	-1.22	0.33	-0.52	-0.24	0.66	-100000000.00	-0.39	
CD 	-0.46	-0.58	-0.73	-0.73	-0.90	-0.30	-0.75	-1.01	-0.66	-0.47	0.39	-0.54	-1.07	-0.99	-2.40	1.99	-0.55	-0.46	-0.68	-0.56	0.67	-1.65	0.29	-1.33	-4.09	-0.59	-0.07	-1.41	-0.40	0.10	0.56	-0.39	-0.26	-2.69	-3.73	-0.20	-3.09	-0.31	-0.23	-0.15	-1.46	-1.06	-0.92	-0.77	-1.46	-0.50	-100000000.00	0.02	
EX 	-0.13	-0.74	0.22	0.76	-0.93	-2.88	-0.95	-0.80	-0.17	0.06	0.60	0.29	0.89	-0.40	-1.40	-1.29	-0.30	-1.41	-1.30	-2.36	-0.70	-1.78	-1.79	-1.02	-0.51	-1.30	0.02	-1.98	-0.32	-0.22	-0.18	0.68	-0.34	-1.04	1.32	-1.45	-1.02	-1.95	-0.26	0.09	-0.09	-1.05	0.13	-1.49	-1.99	-0.13	-100000000.00	-0.74	
IN 	-1.71	-0.62	-0.98	0.09	0.23	0.21	-0.94	0.77	0.33	-0.84	-1.99	-0.20	-0.75	0.93	-1.18	-0.36	0.13	-0.21	-0.74	-1.22	0.05	-1.25	-0.47	-0.96	-3.30	-1.37	-1.23	0.05	-1.59	-0.03	-1.26	0.06	-1.78	-1.30	1.28	-0.81	-0.78	0.10	-1.72	2.52	-2.34	-1.83	0.78	0.29	-1.21	-2.70	-100000000.00	-0.43	
WP$ 	0.17	-0.85	-0.38	-2.51	-1.09	0.54	-0.51	-2.05	0.08	-0.70	1.55	-1.28	0.19	-0.08	-0.71	1.37	-0.60	0.02	-1.19	-0.32	0.86	-2.26	-1.24	0.39	-0.64	-1.02	-1.21	-0.77	-0.07	-1.87	-2.16	-1.52	-0.07	0.61	0.71	-1.55	-0.35	-0.80	-1.82	0.19	0.42	-0.19	-1.55	-0.69	-1.05	0.62	-100000000.00	-1.66	
NN|SYM 	0.96	-1.17	0.59	-0.73	-0.79	1.29	-0.90	-1.75	2.02	0.89	-0.17	-0.56	-0.25	-1.70	-0.68	-1.32	-2.23	-0.44	0.78	-0.31	0.65	1.70	-1.62	0.52	0.05	0.58	-0.89	-0.94	-0.56	-0.83	-0.56	-1.16	0.89	1.70	-1.09	-0.65	0.77	-0.09	0.13	-0.46	-0.41	0.58	-1.23	-0.59	-1.64	-0.41	-100000000.00	0.10	
MD 	0.17	-1.28	-1.21	-1.74	-1.55	-1.20	-0.19	-1.89	0.42	-0.25	0.20	-1.12	-1.15	-0.63	0.32	-1.50	-0.48	-0.49	-1.06	-2.58	-0.68	0.92	-0.95	-0.53	-0.53	-1.05	-0.55	-0.09	0.20	-1.29	-0.37	-0.39	-0.21	-0.56	-1.68	-0.92	-0.37	-1.10	-1.52	1.41	-1.39	-0.25	-1.78	-2.14	-2.06	-0.07	-100000000.00	-0.09	
NNPS 	-2.72	-1.81	-1.39	-1.19	-0.34	-0.94	-1.18	0.11	-1.24	-0.43	-1.32	-1.18	-0.60	-0.85	-2.37	-1.25	-2.39	1.05	-0.72	-2.10	-1.62	-0.48	-1.19	-0.32	-0.96	-2.30	-0.53	-2.87	-1.63	-0.67	-0.91	-1.86	-0.97	-0.10	-2.07	-0.63	-1.04	-1.45	-0.41	-1.91	-1.63	-0.29	-1.39	-0.99	-0.80	-3.03	-100000000.00	0.54	
JJS 	-0.34	-2.31	-0.28	-0.31	0.07	-1.74	-0.11	0.41	-2.15	0.17	-0.15	-1.92	-1.06	0.68	-1.79	-1.02	-1.80	-1.18	-1.20	-0.91	-1.12	-0.20	-0.57	-2.33	-1.25	-2.04	-0.94	-3.07	-1.06	-1.06	-1.50	-1.45	0.54	0.35	-1.02	-0.42	0.57	0.26	0.18	0.43	-1.14	-2.18	-0.98	-2.57	-1.42	0.77	-100000000.00	-2.45	
JJR 	-0.69	-1.29	-0.03	-0.03	0.24	-1.60	-0.20	-0.67	-1.43	-0.59	-1.82	-0.03	-1.25	-0.56	-1.14	-0.02	-1.20	-2.13	0.69	-0.50	-2.61	-0.02	-0.77	0.28	-0.87	0.53	-0.92	0.00	-0.60	0.93	-0.28	-1.59	-1.75	-2.03	-0.92	-1.11	-0.45	-0.76	-0.87	1.35	-0.40	-1.55	-1.33	-2.28	-1.32	-1.77	-100000000.00	-1.19	
SYM 	0.80	0.40	-2.66	-1.29	-3.34	-3.09	-0.04	0.70	-1.98	0.60	-1.92	-1.79	-1.46	0.99	-2.16	0.47	-1.40	-0.20	-0.96	-0.57	-0.71	0.27	-3.38	-0.92	-1.43	-1.40	-1.34	-0.54	-0.34	-1.77	-2.01	-0.36	0.00	-0.94	-1.59	-0.14	-2.00	-2.26	0.21	-0.57	-2.24	-2.79	-0.42	0.05	-1.61	0.16	-100000000.00	-0.62	
UH 	-0.33	-0.76	-0.88	-0.47	-1.87	-0.43	1.96	0.73	-2.22	-1.30	1.01	-2.08	-3.19	0.42	-1.62	-2.01	-3.15	-3.12	-1.40	-0.76	-2.61	-1.77	-1.56	-0.41	0.33	0.35	-1.52	-3.09	-1.63	-1.43	-0.09	-0.37	0.85	-1.17	-1.78	-4.88	-2.40	-0.68	-1.15	1.86	-1.37	-2.72	-1.15	-0.22	-0.63	-2.07	-100000000.00	-2.39	
stop_tag 	-0.61	-2.02	-1.27	-0.88	-0.97	-1.58	-1.98	-2.16	-2.78	0.73	-1.00	0.08	-0.84	-0.24	0.46	-0.91	0.21	0.29	-2.47	-0.08	0.89	-0.18	-2.05	-0.52	-2.73	-0.30	-0.20	-0.22	-2.43	-0.48	-2.50	-0.10	-3.07	-2.22	-1.83	1.78	-0.47	-1.05	-0.60	-0.90	-0.67	-1.10	-2.93	-1.66	0.06	-2.50	-100000000.00	0.30	
NNP 	-0.71	-1.18	-0.44	0.37	-0.94	-0.95	-0.22	-0.75	-0.34	-0.81	-0.18	-0.22	-0.71	-0.57	-0.49	-1.21	-0.87	-0.44	-0.34	0.10	1.21	0.03	-1.17	0.93	-3.12	-2.25	0.35	-1.74	-1.33	-0.14	-0.38	0.53	-2.46	-2.49	0.63	-0.59	-0.62	-0.47	-1.09	-2.08	-1.39	-0.62	-1.93	0.26	-0.82	0.58	-100000000.00	1.05	
Mean train loss after  0 batches of 1  epochs =0.0906179676885
Mean train loss after  100 batches of 1  epochs =0.201185523855
Mean train loss after  200 batches of 1  epochs =0.201293484287
Mean train loss after  300 batches of 1  epochs =0.19302970177
Mean train loss after  400 batches of 1  epochs =0.190092104435
Mean train loss after  500 batches of 1  epochs =0.191324463067
Mean train loss after  600 batches of 1  epochs =0.187144789342
Mean train loss after  700 batches of 1  epochs =0.192533584905
Mean train loss after  800 batches of 1  epochs =0.190802362245
Mean train loss after  900 batches of 1  epochs =0.193159528584
Mean train loss after  1000 batches of 1  epochs =0.189731553288
Mean train loss after  1100 batches of 1  epochs =0.191830060608
Mean train loss after  1200 batches of 1  epochs =0.190570222433
Mean train loss after  1300 batches of 1  epochs =0.186865476037
Mean train loss after  1400 batches of 1  epochs =0.188886462216
Mean train loss after  1500 batches of 1  epochs =0.187722615126
Mean train loss after  1600 batches of 1  epochs =0.190561213969
Mean train loss after  1700 batches of 1  epochs =0.192485002703
Mean train loss after  1800 batches of 1  epochs =0.191168317809
Mean train loss after  1900 batches of 1  epochs =0.190664941453
Mean train loss after  2000 batches of 1  epochs =0.189784320998
Mean train loss after  2100 batches of 1  epochs =0.189536674398
Mean train loss after  2200 batches of 1  epochs =0.189659581084
Mean train loss after  2300 batches of 1  epochs =0.189999989535
Mean train loss after  2400 batches of 1  epochs =0.189215020722
Mean train loss after  2500 batches of 1  epochs =0.189823518264
Mean train loss after  2600 batches of 1  epochs =0.190031523086
Mean train loss after  2700 batches of 1  epochs =0.189540113687
Mean train loss after  2800 batches of 1  epochs =0.187614126953
Mean train loss after  2900 batches of 1  epochs =0.188009562444
Mean train loss after  3000 batches of 1  epochs =0.189469039171
Mean train loss after  3100 batches of 1  epochs =0.188783239221
Mean train loss after  3200 batches of 1  epochs =0.189067428903
Mean train loss after  3300 batches of 1  epochs =0.189511040139
Mean train loss after  3400 batches of 1  epochs =0.189610396297
Mean train loss after  3500 batches of 1  epochs =0.190856330148
Mean train loss after  3600 batches of 1  epochs =0.192754080735
Mean train loss after  3700 batches of 1  epochs =0.193451468421
Mean train loss after  3800 batches of 1  epochs =0.192895745444
Mean train loss after  3900 batches of 1  epochs =0.192627949276
Mean train loss after  4000 batches of 1  epochs =0.191962814069
Mean train loss after  4100 batches of 1  epochs =0.192491036141
Mean train loss after  4200 batches of 1  epochs =0.192018091641
Mean train loss after  4300 batches of 1  epochs =0.192859490976
Mean train loss after  4400 batches of 1  epochs =0.192260795278
Mean train loss after  4500 batches of 1  epochs =0.192724442166
Mean train loss after  4600 batches of 1  epochs =0.192869759003
Mean train loss after  4700 batches of 1  epochs =0.192799163499
Mean train loss after  4800 batches of 1  epochs =0.192626148395
Mean train loss after  4900 batches of 1  epochs =0.192597343046
Mean train loss after  5000 batches of 1  epochs =0.192348552316
Mean train loss after  5100 batches of 1  epochs =0.192984869859
Mean train loss after  5200 batches of 1  epochs =0.193527494509
Mean train loss after  5300 batches of 1  epochs =0.194070033267
Mean train loss after  5400 batches of 1  epochs =0.193398016317
Mean train loss after  5500 batches of 1  epochs =0.193479666562
Mean train loss after  5600 batches of 1  epochs =0.193238858945
Mean train loss after  5700 batches of 1  epochs =0.193854018714
Mean train loss after  5800 batches of 1  epochs =0.194134268126
Mean train loss after  5900 batches of 1  epochs =0.194488452851
Mean train loss after  6000 batches of 1  epochs =0.194591512607
Mean train loss after  6100 batches of 1  epochs =0.194326622048
Mean train loss after  6200 batches of 1  epochs =0.194303485975
Mean train loss after  6300 batches of 1  epochs =0.194416599922
Mean train loss after  6400 batches of 1  epochs =0.194133476338
Mean train loss after  6500 batches of 1  epochs =0.193764220936
Mean train loss after  6600 batches of 1  epochs =0.194105876598
Mean train loss after  6700 batches of 1  epochs =0.19442077938
Mean train loss after  6800 batches of 1  epochs =0.194572844449
Mean train loss after  6900 batches of 1  epochs =0.194190116984
Mean train loss after  7000 batches of 1  epochs =0.19380001082
Mean train loss after  7100 batches of 1  epochs =0.194043774024
Mean train loss after  7200 batches of 1  epochs =0.19402657446
Mean train loss after  7300 batches of 1  epochs =0.193815513804
Mean train loss after  7400 batches of 1  epochs =0.1934648529
Mean train loss after  7500 batches of 1  epochs =0.193451251299
Mean train loss after  7600 batches of 1  epochs =0.192985305124
Mean train loss after  7700 batches of 1  epochs =0.193310262908
Mean train loss after  7800 batches of 1  epochs =0.193061695085
Mean train loss after  7900 batches of 1  epochs =0.19312804028
Mean train loss after  8000 batches of 1  epochs =0.192759907434
Mean train loss after  8100 batches of 1  epochs =0.192708395405
Mean train loss after  8200 batches of 1  epochs =0.192424017437
Mean train loss after  8300 batches of 1  epochs =0.192236176287
Mean train loss after  8400 batches of 1  epochs =0.192538714494
Mean train loss after  8500 batches of 1  epochs =0.192661258151
Mean train loss after  8600 batches of 1  epochs =0.192890295781
Mean train loss after  8700 batches of 1  epochs =0.193010884758
Mean train loss after  8800 batches of 1  epochs =0.193112679166
Mean train loss after  8900 batches of 1  epochs =0.193045355124
Mean train loss after  9000 batches of 1  epochs =0.193093373797
Mean train loss after  9100 batches of 1  epochs =0.19282938594
Mean train loss after  9200 batches of 1  epochs =0.193278252125
Mean train loss after  9300 batches of 1  epochs =0.193247127098
Mean train loss after  9400 batches of 1  epochs =0.193813289342
Mean train loss after  9500 batches of 1  epochs =0.194023518375
Mean train loss after  9600 batches of 1  epochs =0.194311752404
Mean train loss after  9700 batches of 1  epochs =0.194402718949
Mean train loss after  9800 batches of 1  epochs =0.193919649196
Mean train loss after  9900 batches of 1  epochs =0.194017351255
Mean train loss after  10000 batches of 1  epochs =0.193680793866
Mean train loss after  10100 batches of 1  epochs =0.193772621271
Mean train loss after  10200 batches of 1  epochs =0.193672254926
Mean train loss after  10300 batches of 1  epochs =0.193647842674
Mean train loss after  10400 batches of 1  epochs =0.193511170387
Mean train loss after  10500 batches of 1  epochs =0.193444045229
Mean train loss after  10600 batches of 1  epochs =0.193603569361
Mean train loss after  10700 batches of 1  epochs =0.193983371779
Mean train loss after  10800 batches of 1  epochs =0.194294221873
Mean train loss after  10900 batches of 1  epochs =0.194403221305
Mean train loss after  11000 batches of 1  epochs =0.194233481713
Mean train loss after  11100 batches of 1  epochs =0.194163594423
Mean train loss after  11200 batches of 1  epochs =0.194356026812
Mean train loss after  11300 batches of 1  epochs =0.194560703908
Mean train loss after  11400 batches of 1  epochs =0.194700146634
Mean train loss after  11500 batches of 1  epochs =0.194490453842
Mean train loss after  11600 batches of 1  epochs =0.194222756481
Mean train loss after  11700 batches of 1  epochs =0.194352350293
Mean train loss after  11800 batches of 1  epochs =0.194588575997
Mean train loss after  11900 batches of 1  epochs =0.194888268681
Mean train loss after  12000 batches of 1  epochs =0.195210797243
Mean train loss after  12100 batches of 1  epochs =0.195182066496
Mean train loss after  12200 batches of 1  epochs =0.195430869461
Mean train loss after  12300 batches of 1  epochs =0.195567214963
Mean train loss after  12400 batches of 1  epochs =0.195262303888
Mean train loss after  12500 batches of 1  epochs =0.195525785676
Mean train loss after  12600 batches of 1  epochs =0.195642933602
Mean train loss after  12700 batches of 1  epochs =0.195198125055
Mean train loss after  12800 batches of 1  epochs =0.19521433466
Mean train loss after  12900 batches of 1  epochs =0.194936414995
Mean train loss after  13000 batches of 1  epochs =0.194843271461
Mean train loss after  13100 batches of 1  epochs =0.194936334759
Mean train loss after  13200 batches of 1  epochs =0.1948344299
Mean train loss after  13300 batches of 1  epochs =0.194898302153
Mean train loss after  13400 batches of 1  epochs =0.194552990443
Mean train loss after  13500 batches of 1  epochs =0.194497053273
Mean train loss after  13600 batches of 1  epochs =0.19466898745
Mean train loss after  13700 batches of 1  epochs =0.194748765292
Mean train loss after  13800 batches of 1  epochs =0.194545132982
Mean train loss after  13900 batches of 1  epochs =0.194439743623
Mean train loss after  14000 batches of 1  epochs =0.194393481653
Mean train loss after  14100 batches of 1  epochs =0.194536277622
Mean train loss after  14200 batches of 1  epochs =0.194447040717
Mean train loss after  14300 batches of 1  epochs =0.194274109196
Mean train loss after  14400 batches of 1  epochs =0.194157887922
Mean train loss after  14500 batches of 1  epochs =0.194075236446
Mean train loss after  14600 batches of 1  epochs =0.194200473033
Mean train loss after  14700 batches of 1  epochs =0.19397334359
Mean train loss after  14800 batches of 1  epochs =0.193915064794
Mean train loss after  14900 batches of 1  epochs =0.194028997265
Epoch 1 : Mean train epoch loss =0.194201792045
Epoch 1 Epoch val loss = 12480.6641238
Epoch 1 Epoch val perplexity = 1.2898563013634186
SCORES =  (92.4, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 2---------------------

=================================
fscore(z) =  [218.03564] || goldscore = [217.97208]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-3.36	-0.65	0.26	-0.73	0.01	-1.59	1.30	-1.29	-0.21	-1.11	-2.01	0.13	0.03	-0.21	-0.25	-0.98	-1.84	-2.31	-1.50	-0.67	-2.58	-2.34	0.76	-1.33	-2.03	-2.17	-2.28	-1.26	-0.15	0.49	-0.33	0.73	-1.27	-0.89	-0.15	-2.05	-2.34	-0.05	-2.54	-0.99	-2.07	-0.87	-2.39	-0.63	-0.06	-2.59	-100000000.00	-2.23	
VBG 	-1.56	-2.03	0.24	0.32	0.13	-0.05	-0.89	-0.38	-0.57	-1.34	-2.13	0.67	0.39	-0.67	-0.96	-3.20	-0.04	-1.41	-1.95	-3.14	-0.16	-0.89	0.18	0.79	-1.86	-0.45	-0.90	0.35	-1.92	0.08	-1.31	0.30	-2.31	0.02	0.92	-0.49	-1.74	0.52	-0.76	-0.66	0.10	-0.45	-0.02	-1.54	-1.18	-4.71	-100000000.00	-0.86	
VBD 	-1.99	-3.25	-2.31	-1.27	-0.73	0.82	-0.42	-0.63	1.85	-1.69	-0.31	-0.94	-1.13	-0.13	-0.50	-1.28	-0.23	0.80	-0.60	-1.05	0.05	-1.00	-2.84	-1.02	-2.93	-0.18	-0.84	0.03	0.91	-1.64	-0.42	-0.68	-1.58	-0.97	1.63	-1.24	-0.80	-2.12	0.41	-2.73	-2.09	-0.20	-0.19	-0.40	-3.02	-1.54	-100000000.00	0.20	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-1.09	-1.55	-0.43	-0.42	-0.60	-0.68	-2.92	0.70	-0.54	-1.22	-1.47	1.05	-0.37	0.14	-1.38	-2.66	-0.87	-0.90	-0.62	-0.48	-1.35	-1.66	-1.52	-0.02	-1.80	0.77	-1.03	-0.22	-0.70	0.03	-1.50	-0.58	-1.89	-1.09	-2.78	-1.99	-3.33	-1.30	-0.82	0.26	-1.93	-1.50	-1.14	-1.18	0.21	-2.94	-100000000.00	-1.93	
, 	-1.01	-1.78	0.03	-2.90	-0.57	-1.17	0.64	-1.31	1.52	0.70	-1.54	-1.46	-0.69	-1.06	-0.92	-2.85	0.63	0.87	-1.72	-0.72	-2.03	-2.09	-1.50	0.35	-2.77	0.74	-1.73	0.01	-0.16	-0.60	-2.61	-0.68	-2.69	-2.86	0.52	1.13	-1.59	-0.22	-2.17	-3.30	-0.54	-0.32	-0.97	-0.03	-3.42	-0.55	-100000000.00	0.56	
'' 	-3.83	0.21	-0.58	0.81	-2.04	-1.95	0.15	-1.77	0.67	-0.79	-1.40	0.49	-1.87	-3.48	0.98	0.41	-1.49	-1.69	0.21	-0.84	0.27	0.42	-2.15	1.05	-1.07	0.54	1.46	-2.74	-0.61	-0.10	-1.96	-0.20	0.32	-1.79	2.67	-0.23	-0.06	-0.81	0.34	-1.33	-0.27	-1.24	-1.46	-1.85	-2.39	-0.87	-100000000.00	0.73	
VBP 	-3.45	-1.68	-2.16	-2.60	-0.39	-0.79	0.59	-0.61	-0.05	-1.95	0.29	-0.34	-1.07	-2.64	-2.17	-2.29	-0.73	0.09	-1.11	-3.41	-2.16	-0.72	-2.07	-1.00	-2.57	-0.65	-1.65	1.27	0.99	-1.87	-1.07	-0.13	0.27	-1.05	1.24	-0.03	0.73	-1.67	-0.55	-0.20	-3.31	0.86	-1.35	-2.54	-1.45	-2.81	-100000000.00	-0.06	
WDT 	-2.06	-2.68	-2.59	-1.16	-1.68	-1.17	-2.88	-0.68	-0.63	-1.79	-2.61	-1.02	0.87	-2.62	-1.04	-2.66	0.18	-0.43	-3.01	-2.16	-1.72	-0.54	-0.13	-0.70	-1.27	-1.14	1.24	0.70	-1.06	-1.13	-1.56	-1.56	0.11	-2.21	-1.28	-1.24	0.38	0.63	0.95	-0.73	-0.13	-1.52	-1.54	-1.18	-1.18	-1.18	-100000000.00	-0.37	
JJ 	0.83	-0.43	0.00	-0.19	0.19	-0.72	-0.61	0.18	-1.17	0.22	-1.69	0.32	1.77	0.24	-1.46	0.71	-1.54	-1.34	-0.20	-1.46	-0.10	-2.12	0.16	-0.28	-4.43	-0.09	1.11	-1.34	-0.44	0.06	0.11	-0.19	-4.35	0.09	0.50	0.11	-2.69	0.77	-0.23	-1.88	-2.24	-1.50	-0.37	-0.48	-1.17	-2.57	-100000000.00	-0.83	
WP 	-1.25	-2.32	-2.09	-2.71	-0.33	-0.10	0.85	0.40	-0.14	-1.17	-0.40	0.15	-0.25	-0.77	-1.06	-1.61	0.44	-0.27	0.77	-0.34	-1.45	-2.04	1.24	-1.99	-0.53	0.49	-0.63	-0.21	-0.77	0.36	-0.94	-0.02	-1.44	-0.98	-1.66	-1.74	-0.53	0.39	-1.64	0.65	-1.57	-0.34	-1.68	-0.18	-0.50	-0.52	-100000000.00	-1.45	
VBZ 	-0.65	-1.58	-2.63	-2.41	-1.32	0.47	-0.81	0.01	2.31	-0.90	-0.97	-1.03	0.15	0.64	-1.36	-1.20	0.62	-0.31	-0.37	-2.51	-1.53	-0.64	-1.87	-1.19	-1.64	0.33	0.19	-1.61	1.63	-0.76	1.03	-0.20	-2.02	-2.03	-1.80	-0.44	0.26	-1.62	-1.01	-0.70	-1.95	-2.04	-0.33	-1.52	-1.68	-2.83	-100000000.00	0.22	
DT 	-1.56	-1.49	-0.79	0.53	-0.26	0.29	-1.05	-0.44	-1.14	-0.32	-1.47	0.11	-1.02	-0.21	0.19	-3.28	0.44	-0.20	0.66	-1.16	-1.06	-0.55	0.77	-1.72	-2.21	-0.66	-0.01	-0.88	-1.32	1.31	0.29	1.48	-0.32	-0.34	0.85	-2.31	-0.48	1.50	0.85	-1.17	-0.96	-1.01	-1.63	-0.89	-0.83	-3.37	-100000000.00	0.07	
" 	0.20	0.19	-1.78	-0.61	-0.90	-0.10	0.40	-0.46	-0.64	-0.37	-0.63	-0.20	0.19	-0.44	0.54	-2.09	0.58	-0.50	-1.96	-1.53	1.06	0.58	-1.37	0.17	0.15	-0.69	0.41	-1.44	-1.80	-1.09	-1.57	-0.70	-1.26	-2.22	-0.35	-0.48	-1.69	-0.96	-0.64	-3.30	-1.58	-1.42	-0.79	0.93	-0.95	-2.19	-100000000.00	0.02	
RP 	-2.64	0.61	0.63	-2.08	0.90	-0.66	-2.18	1.19	-1.18	-0.37	-2.34	-0.12	0.70	-1.58	-0.92	-1.09	-1.26	-0.47	-1.94	-1.74	-0.30	0.16	-1.83	-0.88	-1.26	-1.23	-1.19	-1.19	0.62	0.21	-1.28	-2.81	-1.37	-1.47	-0.00	0.04	-5.27	-1.58	-0.44	-0.71	-3.28	-3.15	-1.75	-1.22	-1.79	-3.41	-100000000.00	-2.08	
$ 	-2.15	-0.85	-0.21	-3.79	-0.15	-1.71	-0.67	0.26	-0.47	0.28	-1.13	0.06	-1.00	-1.05	-0.15	1.80	0.76	-1.06	-0.35	-4.08	-0.44	-0.57	0.96	-0.62	1.70	-0.79	-0.06	-0.64	-1.30	0.71	-0.75	-0.18	-1.50	0.22	-1.66	-0.78	-0.65	0.19	-1.74	-2.45	0.23	-1.67	-0.45	-1.41	-2.68	-1.02	-100000000.00	0.41	
NN 	1.00	-0.32	-0.57	0.53	0.35	0.75	-0.40	-0.72	-1.26	0.75	0.20	-0.09	0.54	-0.56	-1.07	-2.15	-0.49	-0.49	-0.79	-0.08	1.14	0.20	-1.38	-1.40	-5.28	-2.22	0.74	-1.86	-2.47	-0.22	-1.84	-1.39	-1.21	-3.04	0.30	-0.26	-2.13	0.10	1.81	-3.40	-3.80	-1.04	0.71	0.84	-1.27	-4.59	-100000000.00	-0.39	
) 	-2.07	-0.77	-1.57	-2.74	-0.67	-2.74	-2.36	-3.05	-3.34	-0.66	-2.43	-0.78	-1.86	-1.18	0.59	-1.75	-0.84	-0.88	-0.39	-0.98	-0.34	-2.95	-2.43	0.65	0.02	-1.65	-1.11	-1.98	-3.01	-0.60	-2.88	-1.70	-2.90	-0.87	-1.35	1.23	-0.22	-0.26	-1.90	-3.65	-1.08	-0.57	-4.30	-3.13	-2.67	-1.64	-100000000.00	-0.07	
( 	1.19	-3.45	-0.54	-0.67	-2.96	-1.98	-1.36	-2.23	-0.85	-0.81	-0.18	-0.63	-0.68	-0.23	-1.10	-3.20	0.44	-1.09	-2.20	-0.56	-0.43	-0.88	-0.28	0.12	-1.02	-1.56	-0.79	-0.49	-0.99	-0.83	-1.54	-1.49	-3.75	-2.41	-2.22	0.73	-1.56	-2.47	-1.69	-1.26	-1.53	-0.80	-0.13	-2.03	-3.05	0.04	-100000000.00	1.38	
FW 	-2.50	-2.43	-2.76	-0.74	-2.91	-0.77	-1.15	-0.58	-0.37	-1.65	-1.14	-4.00	-2.22	-2.69	-2.97	-0.62	-1.18	-1.12	-2.65	0.05	-1.57	-0.49	-2.64	-0.42	0.08	-2.73	-1.54	-2.75	-2.54	-1.93	1.00	-0.75	-0.83	-1.22	-1.25	-1.23	-1.26	-6.66	0.49	-1.27	-0.39	-0.59	-2.45	-1.80	-0.67	0.56	-100000000.00	-0.40	
POS 	-0.86	-2.54	-0.72	-1.11	0.54	-1.00	0.23	-1.30	1.64	0.64	-4.20	-1.90	-0.40	0.23	-2.28	-1.81	1.84	-1.64	-0.78	-3.39	-1.74	-1.12	-1.32	-1.91	-4.04	-0.52	1.38	0.20	-0.13	-1.85	-0.39	-1.83	-0.38	1.09	-0.89	-0.80	-0.00	-1.52	-1.97	-1.73	-1.47	-1.90	-2.10	-0.20	-1.94	-2.26	-100000000.00	1.82	
. 	-2.19	-0.34	-1.16	-2.79	-0.41	-3.81	-1.66	0.05	-0.96	0.06	-1.12	0.63	0.49	-0.12	-0.01	-4.03	-0.16	-0.65	-1.94	-1.44	-0.40	-0.10	-0.38	-0.33	0.01	-0.31	-0.52	0.96	-0.26	-0.90	0.49	-1.49	-1.21	-2.33	-0.72	0.72	0.46	-1.07	-1.07	-2.02	-2.17	-0.28	-2.78	-0.15	-3.32	-2.19	-100000000.00	1.25	
TO 	-1.06	-1.51	-0.24	-0.20	-0.63	-1.40	-0.83	-0.04	-1.41	-0.53	-1.01	0.87	-2.08	-1.11	-0.10	-3.20	-0.68	-0.91	-0.90	-1.73	-2.09	-1.70	-0.77	-0.77	-1.83	-0.37	-1.39	-0.71	-0.93	-1.07	0.24	-1.64	-2.69	-1.08	-0.30	0.94	-1.78	-0.07	-0.51	-0.46	-2.38	-2.33	0.08	-0.19	-3.04	-4.37	-100000000.00	-1.58	
-X- 	-0.22	0.67	-1.78	-1.82	-1.17	-1.23	-1.65	-1.13	-0.78	-1.34	-2.44	-2.25	-1.11	-2.15	0.57	-2.18	0.21	-1.08	-2.15	-0.39	-1.45	-0.22	-1.85	2.00	-1.41	-1.79	-1.65	-0.49	-1.47	-1.07	0.27	0.44	1.82	-0.29	-0.18	-1.50	0.50	-1.67	0.85	1.16	1.14	-1.88	-1.84	2.17	-0.68	0.49	-100000000.00	-3.73	
LS 	-0.61	-0.58	-2.73	-0.46	-1.73	-1.13	-0.18	-2.76	-0.27	-2.70	0.74	-0.63	-3.22	-2.32	-2.82	-3.41	-2.58	-1.34	-1.78	-1.49	-0.04	0.38	-1.82	-1.55	-2.45	-3.19	0.82	-3.77	-1.61	-1.25	1.58	-2.72	0.00	0.11	-1.19	-2.44	-1.88	-1.53	-0.81	-0.61	-2.17	-2.99	-0.82	-2.92	-0.55	-0.99	-100000000.00	-2.21	
RB 	-0.61	-0.08	0.70	-0.28	-0.06	-0.48	-0.01	0.56	-1.12	-1.34	-0.96	0.73	-0.02	0.66	0.43	-1.22	-0.61	0.50	0.46	-2.03	-1.08	-2.00	0.52	-0.71	-2.21	-0.47	-0.26	-0.16	0.02	-0.11	0.46	-0.69	-3.13	-1.50	-0.86	-0.51	-1.36	-0.26	-0.67	0.31	1.02	-1.98	-0.76	-1.52	-1.27	-3.07	-100000000.00	-0.61	
: 	-3.25	-0.93	-0.62	-1.60	-0.64	-1.49	-2.19	-0.56	-0.81	0.30	0.08	-0.10	-1.63	-1.55	-2.59	-1.23	0.22	-2.03	-1.53	-4.09	0.78	-1.47	-3.85	-1.71	-1.92	-1.12	-0.80	-1.97	-0.90	0.38	-2.35	-3.30	-0.84	-1.16	-1.33	0.33	-0.82	0.51	-1.87	-2.02	-2.87	0.26	-3.03	0.27	-3.05	-1.95	-100000000.00	-0.04	
NNS 	1.78	-0.44	-0.46	0.19	-0.05	-1.62	-1.98	-0.77	-0.87	0.77	-0.54	-1.04	-0.62	-1.20	-1.36	-2.35	-0.12	-1.35	-0.56	-1.85	0.48	-1.23	-1.64	-1.60	-3.75	-2.50	0.17	-2.58	-0.78	-0.08	0.24	0.60	-1.94	-1.62	-0.13	-0.31	-1.00	-0.81	0.91	-2.71	-0.56	-2.26	-0.34	0.50	-1.75	-4.64	-100000000.00	-1.08	
PRP 	-1.59	-0.85	-0.60	-0.04	0.68	-1.03	0.66	-0.96	-0.10	-1.13	0.91	-0.16	-1.84	-0.03	-1.86	-2.01	-0.05	-0.78	-2.27	-3.00	-0.19	0.14	0.16	0.55	-1.63	-0.84	0.85	-0.74	-3.00	1.15	0.33	-0.90	-0.41	-1.30	-0.57	-1.78	0.02	0.84	-1.79	-0.89	-0.94	-2.77	-0.67	-2.02	-1.44	-1.69	-100000000.00	-0.72	
VB 	-1.28	-0.84	-2.84	-0.06	-3.65	0.37	-1.54	-0.76	0.35	-1.59	-0.26	-1.13	-0.25	-0.28	-1.71	1.78	-0.72	0.41	-1.10	-0.81	-3.72	0.10	0.57	-0.62	-1.90	0.59	0.55	-0.91	0.36	-0.73	-1.21	0.91	1.04	-0.78	0.77	-0.80	-1.84	-1.49	-1.77	0.01	1.40	-1.85	-0.43	0.43	-2.30	-0.36	-100000000.00	-0.97	
WRB 	-1.83	-0.39	-1.40	-0.67	-0.80	-0.10	-0.80	-0.36	-1.31	0.11	-0.69	0.60	-3.65	-0.34	-0.09	-0.80	-0.37	-1.35	-0.57	-1.59	-1.86	0.03	-0.66	0.12	-0.95	-1.23	-2.13	-1.14	-0.87	-0.79	-2.04	-0.89	-2.41	-0.72	-3.18	-0.97	-1.72	-1.12	0.96	-0.72	-1.66	-3.49	-1.17	-0.59	-1.88	0.50	-100000000.00	-0.33	
CC 	-2.89	-1.20	-1.50	-0.94	-0.27	0.30	-1.95	-0.21	-0.80	0.66	-1.73	-0.96	-2.93	-0.87	-0.57	-1.55	-0.16	-1.38	-2.43	-2.27	-0.78	0.30	-0.37	-2.12	-1.76	-0.35	0.85	-0.96	-0.30	0.47	-1.29	-2.34	-0.78	-3.34	0.13	0.46	-0.34	-1.11	-0.95	-1.28	-1.58	0.33	-0.91	0.20	-1.39	-3.52	-100000000.00	0.29	
PDT 	-1.98	1.09	-2.77	-1.82	0.10	-2.20	-1.83	-0.35	-2.68	-1.09	-2.73	0.03	-2.07	-1.95	-0.68	-1.53	-2.55	-1.13	0.21	-0.65	0.70	-0.24	-3.35	0.10	-0.65	-0.60	-0.75	-0.36	-1.63	-1.60	0.20	-0.95	0.28	1.39	-1.26	-1.90	0.26	1.06	-0.45	-0.90	0.20	-0.95	-1.47	-0.54	-3.16	-0.71	-100000000.00	0.19	
RBS 	-0.51	-1.45	-0.56	-2.76	-0.62	-0.80	0.28	-1.12	-3.30	-0.87	1.42	-0.64	-0.76	-0.87	-1.03	-0.58	-0.84	-1.68	-1.78	-1.38	-0.43	0.13	-0.21	1.87	-2.42	0.63	-1.38	-6.00	-2.73	-0.97	-2.46	0.81	-1.42	0.01	-0.80	-1.20	-0.45	0.79	-0.73	0.64	-1.57	-1.35	-2.63	-3.27	-1.60	-1.00	-100000000.00	-4.43	
RBR 	-1.62	-1.29	0.18	-0.37	0.24	-1.92	0.00	-1.40	0.73	-0.85	0.91	0.26	-0.34	-1.92	-0.38	-1.24	-0.15	-0.67	-1.18	-3.01	-1.50	-1.05	-0.74	0.66	1.22	0.31	-0.21	0.19	-1.24	0.21	-1.81	-0.87	-0.21	0.02	-2.58	-1.28	-3.07	-0.46	-0.35	0.58	0.80	-1.56	-0.34	-1.12	-0.71	0.18	-100000000.00	-0.46	
CD 	-0.62	-0.73	-0.46	-0.77	-1.01	-0.41	-0.86	-1.10	-0.99	-0.46	-0.28	-0.50	-0.87	-0.89	-2.48	2.19	-0.67	-0.49	-0.64	-0.93	0.55	-2.35	0.28	-1.67	-5.52	-0.63	-0.09	-1.48	-0.70	-0.06	-0.08	-0.48	-0.87	-3.25	-4.25	-0.30	-3.73	-0.31	-0.17	-0.12	-2.43	-0.90	-1.04	-0.76	-1.49	-1.08	-100000000.00	-0.11	
EX 	-0.54	-0.87	0.14	0.36	-1.08	-2.72	-1.32	-0.86	-0.37	-0.16	0.32	0.11	0.66	-0.32	-1.57	-1.58	-0.47	-1.95	-1.93	-2.66	-1.53	-1.93	-2.51	-1.14	-0.67	-1.48	-0.33	-2.08	-0.52	-0.43	-0.39	0.72	-0.62	-1.36	1.02	-1.73	-1.25	-1.74	-0.60	-0.12	-0.39	-1.27	-0.14	-1.80	-2.37	-0.45	-100000000.00	-0.93	
IN 	-1.98	-0.64	-0.94	0.02	0.17	-0.02	-1.38	0.50	0.04	-0.83	-2.33	-0.19	-0.83	0.92	-1.01	-1.11	0.15	-0.23	-1.01	-2.01	-0.38	-2.13	-0.51	-1.45	-4.54	-1.29	-1.23	0.08	-1.25	-0.18	-1.42	-0.09	-2.31	-1.34	1.12	-0.71	-0.90	-0.06	-1.87	1.83	-2.95	-1.69	0.60	0.24	-1.33	-4.47	-100000000.00	-0.44	
WP$ 	-0.11	-1.16	-0.61	-3.35	-1.46	0.49	-0.64	-2.24	-0.03	-0.83	1.39	-1.47	0.00	-0.49	-0.99	1.17	-0.69	-0.23	-1.51	-0.50	0.45	-2.36	-1.62	0.36	-0.87	-1.22	-1.37	-0.66	-0.50	-2.26	-2.35	-2.06	-0.20	0.49	0.43	-1.85	-0.59	-1.15	-1.87	0.10	0.12	-0.32	-1.74	-0.92	-1.23	0.43	-100000000.00	-1.68	
NN|SYM 	0.53	-1.99	-0.23	-1.81	-1.61	0.77	-1.09	-2.22	1.69	0.05	-0.59	-1.22	-1.29	-2.30	-1.11	-1.58	-3.35	-0.45	0.27	-0.56	-0.01	1.60	-2.24	0.50	-0.33	-0.18	-1.35	-1.90	-1.18	-1.31	-0.81	-1.72	0.46	1.42	-1.46	-1.79	0.47	-1.25	0.03	-0.60	-0.93	-0.06	-1.69	-1.20	-2.05	-0.84	-100000000.00	-0.88	
MD 	0.02	-1.69	-1.30	-2.17	-2.30	-1.08	-0.70	-1.83	0.66	-0.53	-0.26	-1.37	-1.09	-0.86	0.14	-2.20	-0.42	-0.87	-2.04	-3.22	-1.38	0.72	-1.58	-0.71	-0.94	-1.17	-0.95	-0.18	0.28	-1.42	-0.36	-0.72	-0.84	-0.89	-2.44	-1.09	-0.35	-1.53	-1.88	0.82	-1.80	-0.63	-2.65	-3.00	-2.83	-0.57	-100000000.00	-0.12	
NNPS 	-2.89	-2.09	-1.47	-1.44	-1.09	-1.17	-1.64	-0.20	-1.44	-0.80	-1.78	-1.27	-0.71	-1.07	-2.59	-1.88	-2.63	0.78	-0.90	-2.89	-1.91	-0.72	-1.84	-0.66	-1.82	-3.56	-1.09	-4.19	-2.50	-0.82	-1.23	-1.80	-1.61	-0.43	-2.82	-0.68	-1.79	-1.34	-0.42	-2.40	-2.24	-0.56	-2.28	-1.85	-1.37	-4.04	-100000000.00	0.49	
JJS 	-0.26	-2.98	-0.56	-0.72	-0.17	-1.67	-0.35	-0.48	-2.40	-0.36	-0.54	-2.56	-1.00	-0.01	-2.17	-1.35	-2.61	-1.77	-1.39	-1.47	-1.07	-0.49	-1.03	-2.42	-1.79	-2.47	-1.84	-3.22	-1.70	-1.20	-1.53	-1.77	0.16	0.09	-1.58	-1.29	0.24	0.02	-0.00	0.11	-1.84	-2.82	-1.43	-3.42	-1.98	0.31	-100000000.00	-2.85	
JJR 	-0.89	-1.15	-0.02	-0.07	-0.07	-1.84	-0.66	-0.60	-1.82	-0.89	-2.39	0.04	-1.13	-0.81	-1.42	-0.75	-1.47	-3.11	0.60	-1.34	-3.56	-0.38	-0.83	0.04	-1.61	0.30	-1.36	-0.40	-0.75	0.86	-0.54	-1.44	-2.35	-2.41	-1.60	-1.09	-1.04	-0.74	-1.03	0.77	-1.00	-1.82	-2.12	-2.91	-1.57	-2.63	-100000000.00	-1.56	
SYM 	0.14	-0.23	-3.26	-1.06	-3.95	-4.09	-0.50	0.22	-2.36	0.30	-2.50	-2.54	-2.37	0.41	-2.63	0.01	-1.27	-0.38	-1.64	-1.33	-1.65	-0.04	-4.25	-1.06	-1.87	-1.93	-1.98	-1.03	-0.49	-2.35	-2.40	-0.77	-0.74	-1.44	-2.36	-0.20	-2.39	-2.83	0.00	-0.86	-2.22	-3.26	-0.97	-0.73	-2.02	-0.07	-100000000.00	-0.58	
UH 	-0.96	-1.93	-2.23	-0.70	-3.03	-0.55	1.61	-0.09	-2.79	-3.06	0.71	-2.85	-5.14	0.26	-2.22	-2.56	-5.19	-3.76	-2.48	-1.09	-3.57	-2.06	-2.47	-0.50	-0.29	-0.66	-2.41	-4.47	-1.65	-2.63	-0.41	-1.48	-0.02	-1.31	-2.40	-6.58	-3.01	-0.78	-1.33	1.64	-2.02	-3.87	-1.68	-0.75	-1.23	-2.05	-100000000.00	-4.01	
stop_tag 	-1.00	-3.53	-1.29	-0.88	-0.99	-2.29	-1.80	-2.52	-3.67	0.66	-2.08	-0.22	-0.97	-0.76	0.12	-1.94	0.32	-0.07	-3.05	-0.67	0.57	-0.40	-2.84	-0.86	-3.87	-0.65	-0.48	-0.18	-2.47	-0.64	-3.31	-0.86	-3.99	-3.08	-3.08	1.52	-1.14	-0.98	-0.99	-1.89	-1.76	-1.06	-4.10	-2.92	0.24	-2.90	-100000000.00	0.36	
NNP 	-0.50	-1.08	-0.45	0.09	-0.61	-0.95	-0.36	-0.88	-0.73	-0.66	-0.57	-0.23	-0.69	-0.65	-0.89	-1.55	-0.93	-0.51	-0.41	0.06	1.06	-0.85	-1.03	0.44	-4.30	-2.26	0.24	-1.89	-1.73	-0.20	-0.44	0.47	-3.47	-2.76	-0.00	-0.55	-1.85	-0.41	-1.26	-2.75	-1.67	-0.75	-1.99	0.07	-0.93	0.01	-100000000.00	1.07	
Mean train loss after  0 batches of 2  epochs =0.00373930089614
Mean train loss after  100 batches of 2  epochs =0.125440709589
Mean train loss after  200 batches of 2  epochs =0.118610777608
Mean train loss after  300 batches of 2  epochs =0.116780412797
Mean train loss after  400 batches of 2  epochs =0.116268811629
Mean train loss after  500 batches of 2  epochs =0.112848604577
Mean train loss after  600 batches of 2  epochs =0.110670325854
Mean train loss after  700 batches of 2  epochs =0.111195688574
Mean train loss after  800 batches of 2  epochs =0.110353164441
Mean train loss after  900 batches of 2  epochs =0.109715823572
Mean train loss after  1000 batches of 2  epochs =0.10981336393
Mean train loss after  1100 batches of 2  epochs =0.109793849896
Mean train loss after  1200 batches of 2  epochs =0.11157606785
Mean train loss after  1300 batches of 2  epochs =0.112812271861
Mean train loss after  1400 batches of 2  epochs =0.112212602488
Mean train loss after  1500 batches of 2  epochs =0.113607764144
Mean train loss after  1600 batches of 2  epochs =0.114448501872
Mean train loss after  1700 batches of 2  epochs =0.114365262705
Mean train loss after  1800 batches of 2  epochs =0.113098479792
Mean train loss after  1900 batches of 2  epochs =0.114710651957
Mean train loss after  2000 batches of 2  epochs =0.115171912173
Mean train loss after  2100 batches of 2  epochs =0.114668285731
Mean train loss after  2200 batches of 2  epochs =0.115163894926
Mean train loss after  2300 batches of 2  epochs =0.115583184627
Mean train loss after  2400 batches of 2  epochs =0.11499427591
Mean train loss after  2500 batches of 2  epochs =0.114465956472
Mean train loss after  2600 batches of 2  epochs =0.114347076743
Mean train loss after  2700 batches of 2  epochs =0.114235666326
Mean train loss after  2800 batches of 2  epochs =0.115191733338
Mean train loss after  2900 batches of 2  epochs =0.115930334389
Mean train loss after  3000 batches of 2  epochs =0.116510110908
Mean train loss after  3100 batches of 2  epochs =0.116182518965
Mean train loss after  3200 batches of 2  epochs =0.1165728258
Mean train loss after  3300 batches of 2  epochs =0.116365134153
Mean train loss after  3400 batches of 2  epochs =0.116475861694
Mean train loss after  3500 batches of 2  epochs =0.116799889099
Mean train loss after  3600 batches of 2  epochs =0.117039797477
Mean train loss after  3700 batches of 2  epochs =0.117309447453
Mean train loss after  3800 batches of 2  epochs =0.117947417108
Mean train loss after  3900 batches of 2  epochs =0.118049294831
Mean train loss after  4000 batches of 2  epochs =0.117822587683
Mean train loss after  4100 batches of 2  epochs =0.118206883929
Mean train loss after  4200 batches of 2  epochs =0.117888624323
Mean train loss after  4300 batches of 2  epochs =0.118062889162
Mean train loss after  4400 batches of 2  epochs =0.11835962755
Mean train loss after  4500 batches of 2  epochs =0.118065356033
Mean train loss after  4600 batches of 2  epochs =0.117913945807
Mean train loss after  4700 batches of 2  epochs =0.118296905305
Mean train loss after  4800 batches of 2  epochs =0.11809313049
Mean train loss after  4900 batches of 2  epochs =0.118857231958
Mean train loss after  5000 batches of 2  epochs =0.118612368989
Mean train loss after  5100 batches of 2  epochs =0.11870428251
Mean train loss after  5200 batches of 2  epochs =0.118687342844
Mean train loss after  5300 batches of 2  epochs =0.118910282588
Mean train loss after  5400 batches of 2  epochs =0.11874185086
Mean train loss after  5500 batches of 2  epochs =0.118862752666
Mean train loss after  5600 batches of 2  epochs =0.119344344932
Mean train loss after  5700 batches of 2  epochs =0.11952262047
Mean train loss after  5800 batches of 2  epochs =0.119988565654
Mean train loss after  5900 batches of 2  epochs =0.120173127296
Mean train loss after  6000 batches of 2  epochs =0.120361553326
Mean train loss after  6100 batches of 2  epochs =0.119881106514
Mean train loss after  6200 batches of 2  epochs =0.119803695211
Mean train loss after  6300 batches of 2  epochs =0.119971536233
Mean train loss after  6400 batches of 2  epochs =0.120166611196
Mean train loss after  6500 batches of 2  epochs =0.120025209989
Mean train loss after  6600 batches of 2  epochs =0.120392678301
Mean train loss after  6700 batches of 2  epochs =0.120291497031
Mean train loss after  6800 batches of 2  epochs =0.120650909231
Mean train loss after  6900 batches of 2  epochs =0.120504188063
Mean train loss after  7000 batches of 2  epochs =0.120622756587
Mean train loss after  7100 batches of 2  epochs =0.120448289535
Mean train loss after  7200 batches of 2  epochs =0.120683748
Mean train loss after  7300 batches of 2  epochs =0.120857545292
Mean train loss after  7400 batches of 2  epochs =0.121069543348
Mean train loss after  7500 batches of 2  epochs =0.12138690151
Mean train loss after  7600 batches of 2  epochs =0.121494569997
Mean train loss after  7700 batches of 2  epochs =0.121757013704
Mean train loss after  7800 batches of 2  epochs =0.121933953458
Mean train loss after  7900 batches of 2  epochs =0.121720793372
Mean train loss after  8000 batches of 2  epochs =0.121923314271
Mean train loss after  8100 batches of 2  epochs =0.121991358719
Mean train loss after  8200 batches of 2  epochs =0.122094075478
Mean train loss after  8300 batches of 2  epochs =0.122456851117
Mean train loss after  8400 batches of 2  epochs =0.122428368317
Mean train loss after  8500 batches of 2  epochs =0.122745905112
Mean train loss after  8600 batches of 2  epochs =0.122690405054
Mean train loss after  8700 batches of 2  epochs =0.122793520002
Mean train loss after  8800 batches of 2  epochs =0.122950131838
Mean train loss after  8900 batches of 2  epochs =0.123242732113
Mean train loss after  9000 batches of 2  epochs =0.122932543262
Mean train loss after  9100 batches of 2  epochs =0.12298420413
Mean train loss after  9200 batches of 2  epochs =0.123198654494
Mean train loss after  9300 batches of 2  epochs =0.123332961302
Mean train loss after  9400 batches of 2  epochs =0.123458851777
Mean train loss after  9500 batches of 2  epochs =0.123313079387
Mean train loss after  9600 batches of 2  epochs =0.123705105414
Mean train loss after  9700 batches of 2  epochs =0.124035542454
Mean train loss after  9800 batches of 2  epochs =0.124140682802
Mean train loss after  9900 batches of 2  epochs =0.124337514331
Mean train loss after  10000 batches of 2  epochs =0.124348751069
Mean train loss after  10100 batches of 2  epochs =0.124479254547
Mean train loss after  10200 batches of 2  epochs =0.124889134159
Mean train loss after  10300 batches of 2  epochs =0.125033117329
Mean train loss after  10400 batches of 2  epochs =0.125265328132
Mean train loss after  10500 batches of 2  epochs =0.12526707578
Mean train loss after  10600 batches of 2  epochs =0.125365396951
Mean train loss after  10700 batches of 2  epochs =0.125550542101
Mean train loss after  10800 batches of 2  epochs =0.12554046677
Mean train loss after  10900 batches of 2  epochs =0.125686043589
Mean train loss after  11000 batches of 2  epochs =0.126157349431
Mean train loss after  11100 batches of 2  epochs =0.126233799616
Mean train loss after  11200 batches of 2  epochs =0.126053079836
Mean train loss after  11300 batches of 2  epochs =0.126377644964
Mean train loss after  11400 batches of 2  epochs =0.126456388842
Mean train loss after  11500 batches of 2  epochs =0.126612990201
Mean train loss after  11600 batches of 2  epochs =0.126687330282
Mean train loss after  11700 batches of 2  epochs =0.126842879647
Mean train loss after  11800 batches of 2  epochs =0.126616876118
Mean train loss after  11900 batches of 2  epochs =0.126553822917
Mean train loss after  12000 batches of 2  epochs =0.126550427153
Mean train loss after  12100 batches of 2  epochs =0.126380514302
Mean train loss after  12200 batches of 2  epochs =0.126519125908
Mean train loss after  12300 batches of 2  epochs =0.126574307078
Mean train loss after  12400 batches of 2  epochs =0.126516685892
Mean train loss after  12500 batches of 2  epochs =0.126733274942
Mean train loss after  12600 batches of 2  epochs =0.126789386566
Mean train loss after  12700 batches of 2  epochs =0.126564650813
Mean train loss after  12800 batches of 2  epochs =0.126989070373
Mean train loss after  12900 batches of 2  epochs =0.12720260786
Mean train loss after  13000 batches of 2  epochs =0.127000010877
Mean train loss after  13100 batches of 2  epochs =0.127084239294
Mean train loss after  13200 batches of 2  epochs =0.127142156177
Mean train loss after  13300 batches of 2  epochs =0.127318432956
Mean train loss after  13400 batches of 2  epochs =0.127192136491
Mean train loss after  13500 batches of 2  epochs =0.127180211254
Mean train loss after  13600 batches of 2  epochs =0.127231949168
Mean train loss after  13700 batches of 2  epochs =0.127405354101
Mean train loss after  13800 batches of 2  epochs =0.127475753369
Mean train loss after  13900 batches of 2  epochs =0.127619633276
Mean train loss after  14000 batches of 2  epochs =0.127553830083
Mean train loss after  14100 batches of 2  epochs =0.127591627129
Mean train loss after  14200 batches of 2  epochs =0.127677719118
Mean train loss after  14300 batches of 2  epochs =0.127813012221
Mean train loss after  14400 batches of 2  epochs =0.127714980196
Mean train loss after  14500 batches of 2  epochs =0.127773325505
Mean train loss after  14600 batches of 2  epochs =0.127760033744
Mean train loss after  14700 batches of 2  epochs =0.12795255487
Mean train loss after  14800 batches of 2  epochs =0.128019274749
Mean train loss after  14900 batches of 2  epochs =0.128171925745
Epoch 2 : Mean train epoch loss =0.128255399528
Epoch 2 Epoch val loss = 12433.2435894
Epoch 2 Epoch val perplexity = 1.2886094908217907
SCORES =  (92.66, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 3---------------------

=================================
fscore(z) =  [103.98915] || goldscore = [103.84865]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-3.89	-0.75	0.14	-1.23	-0.03	-1.61	0.86	-1.25	-0.45	-1.27	-2.15	0.09	-0.10	-0.37	-0.30	-1.45	-1.87	-2.65	-2.00	-1.34	-2.59	-2.72	0.79	-1.42	-2.50	-2.31	-2.74	-1.61	-0.61	0.53	-0.62	0.67	-1.24	-1.23	-0.52	-2.58	-2.70	0.02	-2.67	-1.38	-2.72	-1.39	-2.66	-1.08	-0.43	-3.03	-100000000.00	-2.44	
VBG 	-1.46	-2.27	0.15	0.29	0.03	-0.02	-1.15	-0.37	-0.99	-1.61	-2.50	0.45	0.32	-0.71	-1.03	-3.58	-0.01	-1.67	-2.10	-3.99	-0.38	-1.18	-0.01	0.60	-2.14	-0.54	-0.94	0.28	-2.05	-0.00	-1.48	0.17	-2.51	-0.22	0.52	-0.69	-2.26	0.47	-0.88	-0.98	-0.39	-0.64	-0.02	-1.79	-1.49	-5.62	-100000000.00	-0.95	
VBD 	-2.17	-3.40	-2.73	-1.40	-0.91	0.83	-0.49	-0.80	1.82	-1.72	-0.24	-1.17	-1.27	-0.28	-0.79	-1.68	-0.18	0.81	-0.97	-1.09	-0.38	-1.37	-3.28	-1.22	-3.65	-0.09	-1.27	0.10	0.99	-1.74	-0.52	-0.73	-2.10	-0.99	1.18	-1.33	-0.68	-2.41	0.28	-3.44	-2.53	-0.37	-0.34	-0.33	-3.58	-1.77	-100000000.00	0.22	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-1.40	-1.67	-0.46	-0.51	-0.91	-0.65	-3.17	0.68	-0.65	-1.32	-1.62	0.94	-0.41	-0.01	-1.40	-3.27	-0.74	-1.11	-0.61	-0.78	-1.37	-2.16	-1.61	-0.22	-2.32	0.76	-1.07	-0.26	-0.84	-0.01	-1.54	-0.62	-2.16	-1.20	-2.57	-2.08	-3.80	-1.29	-0.98	-0.15	-2.39	-1.54	-1.45	-1.36	-0.12	-3.75	-100000000.00	-2.10	
, 	-1.28	-1.99	-0.11	-3.61	-0.64	-1.80	0.65	-1.47	1.29	0.66	-1.99	-1.71	-0.77	-1.52	-0.80	-3.74	0.58	0.77	-2.22	-0.81	-2.03	-2.52	-2.44	0.15	-3.28	0.78	-2.12	0.01	-0.30	-0.73	-3.13	-1.21	-2.90	-2.87	0.52	1.16	-1.72	-0.34	-2.61	-3.88	-1.25	-0.37	-1.39	-0.12	-4.41	-0.55	-100000000.00	0.52	
'' 	-4.05	-0.08	-0.75	0.82	-2.29	-1.69	0.04	-2.04	0.53	-1.07	-1.64	0.23	-2.12	-4.04	0.82	0.19	-1.37	-1.81	-0.26	-1.04	0.09	0.51	-2.62	0.95	-1.30	0.33	1.21	-3.04	-0.97	-0.56	-2.24	-0.16	0.09	-1.95	2.35	-0.46	-0.21	-0.83	0.16	-1.52	-0.50	-1.51	-1.67	-2.12	-2.96	-0.98	-100000000.00	0.48	
VBP 	-4.09	-2.18	-2.65	-2.82	-1.08	-0.89	0.50	-1.19	0.15	-2.42	0.28	-0.74	-1.20	-2.85	-2.16	-2.79	-0.92	-0.29	-1.53	-4.33	-2.79	-1.10	-2.24	-1.14	-3.03	-0.52	-1.87	1.21	1.02	-2.26	-1.28	-0.27	-0.23	-1.45	0.93	-0.02	0.73	-2.06	-0.73	-0.70	-3.98	0.82	-1.76	-2.92	-1.86	-3.39	-100000000.00	-0.14	
WDT 	-2.44	-3.04	-3.03	-1.21	-1.93	-1.04	-3.08	-1.11	-0.87	-2.05	-2.98	-1.29	0.73	-2.81	-1.40	-2.97	0.37	-0.71	-3.55	-2.64	-2.20	-0.81	-0.25	-0.72	-1.72	-1.51	1.05	0.63	-1.30	-1.36	-1.91	-1.65	-0.08	-2.57	-1.61	-1.19	-0.06	0.47	0.79	-0.96	-0.46	-1.72	-2.13	-1.52	-1.87	-1.43	-100000000.00	-0.47	
JJ 	0.88	-0.50	-0.05	-0.29	0.13	-0.79	-0.77	0.11	-1.49	0.11	-2.11	0.27	1.75	0.14	-1.42	0.57	-1.55	-1.33	-0.47	-1.85	-0.04	-2.39	0.07	-0.48	-4.96	-0.16	1.01	-1.51	-0.55	-0.01	0.15	-0.21	-4.63	0.18	0.54	0.26	-3.05	0.86	-0.33	-2.18	-2.45	-1.75	-0.37	-0.47	-1.32	-2.70	-100000000.00	-0.87	
WP 	-1.73	-2.38	-2.31	-2.67	-0.61	-0.29	0.75	0.14	-0.50	-1.33	-0.88	-0.00	-0.51	-0.92	-1.37	-1.95	0.42	-0.74	0.06	-0.86	-1.79	-2.18	1.07	-2.00	-0.91	0.18	-1.15	-0.08	-1.07	0.15	-1.33	-0.34	-1.72	-1.39	-1.96	-2.19	-0.73	0.41	-1.75	0.32	-1.93	-0.43	-2.00	-0.53	-1.01	-0.79	-100000000.00	-1.52	
VBZ 	-0.87	-1.98	-3.17	-2.90	-1.55	0.41	-1.08	-0.23	2.24	-1.01	-0.79	-1.32	-0.07	0.09	-1.71	-1.81	0.73	-0.47	-0.46	-2.57	-1.78	-0.90	-2.17	-1.36	-2.00	0.18	-0.46	-1.82	1.74	-1.18	0.81	-0.22	-2.35	-2.26	-2.49	-0.57	0.46	-2.01	-1.17	-1.13	-2.56	-2.44	-0.58	-1.78	-1.91	-3.92	-100000000.00	0.21	
DT 	-1.88	-1.47	-0.84	0.47	-0.24	0.10	-1.09	-0.37	-1.28	-0.47	-1.66	0.05	-1.25	-0.15	0.15	-4.09	0.23	-0.34	0.72	-1.37	-1.18	-0.97	0.59	-1.92	-2.86	-0.70	0.04	-0.96	-1.31	1.23	0.02	1.41	-0.07	-0.62	0.84	-2.42	-1.20	1.48	0.57	-1.39	-1.33	-1.61	-2.30	-1.44	-0.72	-4.13	-100000000.00	0.05	
" 	0.14	0.02	-1.78	-1.13	-0.98	-0.15	0.54	-0.64	-0.62	-0.35	-1.04	-0.40	0.02	-0.78	0.41	-2.57	0.42	-0.66	-2.13	-2.11	1.00	0.70	-1.45	0.09	0.05	-1.03	0.47	-1.51	-2.23	-1.15	-1.72	-1.00	-1.66	-2.73	-0.80	-0.65	-2.13	-1.01	-0.83	-3.46	-1.98	-1.68	-1.28	0.34	-1.34	-2.65	-100000000.00	0.07	
RP 	-3.18	0.75	0.74	-2.39	0.97	-0.96	-2.43	1.15	-1.53	-0.71	-2.94	-0.19	0.57	-2.20	-1.06	-1.65	-1.44	-0.75	-2.37	-2.38	-0.74	-0.03	-2.73	-0.94	-1.67	-1.33	-1.89	-1.41	0.51	0.20	-1.84	-3.00	-1.48	-2.12	-0.28	-0.45	-5.62	-1.87	-0.61	-0.89	-3.83	-3.31	-1.97	-1.56	-2.35	-3.91	-100000000.00	-2.23	
$ 	-2.28	-0.97	-0.35	-4.40	-0.25	-1.82	-0.85	-0.15	-1.00	0.29	-1.57	-0.02	-0.81	-1.38	-0.25	1.65	0.62	-1.55	-0.45	-4.49	-0.36	-0.68	0.69	-0.65	1.32	-0.79	-0.31	-0.85	-1.52	0.53	-0.99	-0.19	-1.80	-0.11	-2.01	-0.88	-1.10	0.19	-1.84	-2.62	-0.08	-1.97	-0.87	-1.78	-2.92	-1.36	-100000000.00	0.48	
NN 	0.87	-0.30	-0.69	0.57	0.23	0.67	-0.71	-0.88	-1.42	0.85	-0.11	-0.00	0.48	-0.58	-1.20	-2.70	-0.57	-0.62	-0.79	-0.25	1.06	-0.28	-1.37	-1.66	-5.77	-2.28	0.70	-1.80	-2.48	-0.29	-1.86	-1.39	-1.60	-3.15	0.07	-0.22	-2.90	0.09	1.73	-3.91	-3.90	-1.19	0.58	0.77	-1.23	-5.97	-100000000.00	-0.42	
) 	-2.66	-0.88	-1.89	-3.41	-0.71	-3.12	-2.76	-3.19	-3.92	-0.71	-3.14	-0.97	-2.12	-1.47	0.75	-2.32	-0.95	-1.14	-0.73	-1.52	-0.64	-3.10	-2.74	0.47	0.10	-1.99	-1.48	-2.10	-3.88	-0.72	-3.34	-2.25	-3.54	-1.45	-2.28	1.21	-0.52	-0.67	-2.09	-4.05	-2.01	-0.70	-5.06	-4.11	-2.77	-2.40	-100000000.00	-0.10	
( 	0.97	-3.53	-0.71	-1.00	-2.89	-2.27	-1.52	-2.75	-1.07	-0.85	-0.41	-0.93	-1.00	-0.39	-1.61	-3.88	0.41	-1.36	-2.47	-0.99	-0.59	-1.23	-0.78	-0.02	-1.42	-1.61	-1.13	-0.58	-0.93	-1.05	-1.69	-2.06	-4.15	-2.78	-2.82	0.78	-2.12	-2.76	-1.80	-1.72	-2.78	-0.87	-0.48	-2.20	-3.90	-0.64	-100000000.00	1.26	
FW 	-3.26	-2.82	-3.11	-1.06	-3.32	-0.88	-1.42	-0.73	-0.85	-1.84	-1.65	-4.60	-2.56	-2.76	-3.44	-1.13	-1.43	-1.22	-2.64	-0.04	-2.57	-0.72	-3.75	-0.50	-0.32	-3.09	-1.85	-2.78	-3.43	-2.09	0.64	-0.97	-1.34	-1.54	-1.79	-1.50	-1.53	-7.97	0.36	-1.52	-0.91	-1.03	-2.84	-2.55	-1.29	0.11	-100000000.00	-0.40	
POS 	-1.26	-3.29	-1.08	-1.36	0.28	-1.26	0.34	-1.56	1.38	0.50	-4.27	-2.37	-0.77	-0.53	-2.66	-2.28	1.81	-1.87	-1.22	-3.87	-2.09	-1.22	-1.75	-1.99	-4.43	-0.82	0.71	0.08	-0.34	-2.12	-0.92	-1.94	-0.67	0.64	-1.40	-1.15	-0.14	-1.69	-2.11	-2.00	-2.01	-1.70	-2.39	-0.82	-2.46	-2.79	-100000000.00	1.86	
. 	-2.28	-0.44	-1.19	-3.44	-0.53	-4.29	-1.86	-0.11	-1.40	0.03	-1.37	0.43	0.42	-0.28	-0.07	-5.01	-0.16	-0.71	-2.37	-2.20	-0.48	-0.41	-1.19	-0.49	-0.06	-0.35	-0.76	0.92	-0.32	-0.87	0.04	-1.65	-1.55	-3.67	-0.69	0.66	-0.04	-1.19	-1.31	-2.82	-2.68	-0.31	-2.87	-0.37	-4.23	-2.08	-100000000.00	1.25	
TO 	-1.17	-1.65	-0.26	-0.94	-0.63	-1.72	-1.33	-0.06	-2.14	-0.67	-1.71	0.76	-2.26	-1.40	-0.18	-3.64	-0.74	-1.23	-1.29	-2.24	-2.71	-2.06	-1.18	-1.04	-2.47	-0.38	-1.40	-0.82	-1.19	-1.02	-0.22	-2.00	-3.51	-1.49	-0.34	0.85	-2.19	-0.04	-0.81	-1.01	-2.92	-2.41	-0.21	-0.36	-3.68	-5.18	-100000000.00	-1.42	
-X- 	-0.30	0.39	-2.01	-2.17	-1.33	-1.42	-1.66	-1.26	-0.81	-1.58	-2.46	-2.32	-1.27	-2.18	0.46	-2.18	-0.22	-1.14	-2.27	-0.51	-1.50	-0.32	-1.98	2.00	-1.45	-1.96	-1.80	-0.89	-1.64	-1.31	0.23	0.18	1.73	-0.30	-0.26	-1.87	0.45	-1.87	0.85	1.12	0.95	-2.05	-1.86	1.85	-0.82	0.42	-100000000.00	-3.91	
LS 	-0.88	-1.19	-3.20	-0.48	-2.04	-1.52	-0.34	-3.32	-0.60	-3.15	0.50	-1.01	-3.96	-2.41	-3.12	-3.67	-2.62	-1.78	-2.12	-2.03	-0.39	0.21	-2.27	-1.55	-2.71	-3.65	0.86	-4.23	-2.07	-1.63	1.30	-3.32	-0.28	-0.19	-1.53	-3.35	-2.26	-2.21	-0.99	-0.84	-2.64	-3.23	-1.35	-3.37	-0.79	-1.29	-100000000.00	-2.57	
RB 	-0.79	-0.14	0.66	-0.31	0.07	-0.52	-0.30	0.42	-1.05	-1.37	-1.16	0.62	-0.11	0.46	0.11	-1.75	-0.54	0.43	-0.04	-3.13	-1.26	-2.18	0.25	-0.94	-2.61	-0.64	-0.63	-0.23	-0.08	0.05	0.23	-0.63	-3.46	-1.56	-0.84	-0.49	-1.82	-0.44	-0.83	-0.06	0.92	-2.35	-0.97	-1.56	-1.45	-3.85	-100000000.00	-0.74	
: 	-3.75	-1.10	-0.80	-2.14	-0.77	-1.85	-2.75	-0.67	-1.52	0.28	-0.54	-0.27	-1.87	-1.84	-2.64	-1.73	0.15	-2.03	-1.70	-5.04	0.74	-1.80	-4.46	-1.79	-2.18	-1.12	-1.10	-1.96	-1.49	0.25	-2.77	-3.73	-1.57	-1.77	-1.34	0.26	-1.34	0.27	-2.06	-2.57	-3.73	0.08	-3.89	0.05	-3.64	-2.80	-100000000.00	-0.05	
NNS 	1.67	-0.49	-0.50	0.07	-0.15	-1.65	-2.07	-0.75	-0.83	0.86	-0.72	-1.05	-0.52	-1.33	-1.46	-2.90	-0.19	-1.54	-0.70	-1.83	0.52	-1.61	-1.69	-1.87	-4.47	-2.70	0.06	-2.97	-1.01	-0.14	0.12	0.50	-2.39	-1.83	-0.60	-0.34	-1.78	-0.75	0.89	-3.14	-0.91	-2.62	-0.39	0.61	-1.86	-6.12	-100000000.00	-1.08	
PRP 	-2.29	-0.94	-0.52	-0.29	0.59	-1.14	0.60	-0.89	-0.37	-1.40	0.70	-0.05	-2.00	-0.35	-2.19	-2.45	-0.25	-1.17	-2.87	-3.48	-0.22	-0.06	-0.16	0.27	-1.97	-0.89	0.67	-0.99	-3.51	1.07	0.38	-0.93	-0.90	-1.82	-1.24	-1.92	-0.47	0.91	-1.99	-1.25	-1.26	-3.36	-1.06	-2.71	-1.65	-2.10	-100000000.00	-0.92	
VB 	-1.94	-1.13	-2.77	0.03	-3.65	0.23	-1.66	-1.08	-0.11	-2.00	-0.54	-1.27	-0.42	-0.47	-1.79	1.31	-0.80	0.33	-1.50	-1.13	-4.09	-0.20	0.55	-0.80	-2.22	0.59	0.41	-1.15	0.28	-1.22	-1.39	0.95	0.73	-1.04	0.62	-1.24	-2.07	-1.71	-1.96	-0.38	1.48	-1.92	-0.82	0.08	-2.87	-0.57	-100000000.00	-1.03	
WRB 	-1.96	-0.59	-1.44	-0.73	-0.83	-0.33	-1.12	-0.59	-1.42	0.03	-1.02	0.52	-3.94	-0.84	-0.19	-1.09	-0.43	-1.93	-1.01	-2.34	-2.01	-0.13	-1.14	0.10	-1.29	-1.24	-2.65	-1.30	-1.08	-0.75	-2.24	-0.98	-2.71	-1.06	-3.60	-0.98	-1.76	-1.00	0.86	-1.01	-2.16	-3.84	-1.57	-0.81	-2.38	0.12	-100000000.00	-0.51	
CC 	-2.98	-1.41	-1.64	-1.00	-0.40	0.13	-2.30	-0.29	-1.37	0.73	-2.23	-1.15	-2.99	-1.09	-0.67	-2.22	-0.15	-1.48	-3.02	-2.61	-0.84	-0.02	-1.08	-2.17	-2.46	-0.36	0.72	-0.97	-0.57	0.28	-1.70	-2.59	-1.18	-3.67	0.12	0.57	-0.48	-1.24	-1.14	-1.52	-2.06	0.19	-1.67	0.13	-1.54	-4.44	-100000000.00	0.20	
PDT 	-2.27	0.80	-2.77	-1.78	-0.07	-2.96	-2.00	-0.41	-2.95	-1.33	-3.09	-0.16	-2.32	-2.08	-1.11	-1.82	-2.68	-1.57	0.12	-0.83	0.22	-0.35	-3.77	0.09	-0.91	-0.59	-0.88	-0.58	-1.90	-1.63	0.06	-1.35	-0.13	1.18	-1.56	-2.10	-0.18	1.11	-0.61	-1.00	-0.06	-1.18	-1.72	-0.86	-3.43	-0.94	-100000000.00	-0.02	
RBS 	-0.53	-2.10	-0.65	-4.02	-0.72	-0.89	0.07	-1.56	-3.33	-1.33	1.15	-0.61	-0.69	-1.56	-1.17	-1.00	-0.99	-2.07	-2.55	-1.76	-0.48	-0.04	-0.67	1.84	-2.64	0.40	-2.15	-6.78	-3.61	-1.09	-2.56	0.72	-1.68	-0.27	-1.16	-1.71	-0.81	0.70	-0.84	0.41	-2.26	-1.63	-3.06	-3.66	-2.00	-1.41	-100000000.00	-5.40	
RBR 	-2.39	-1.40	0.20	-0.54	0.26	-2.01	-0.21	-1.54	0.57	-1.28	0.67	0.14	-0.43	-2.07	-0.46	-1.76	-0.25	-1.15	-1.90	-3.51	-1.98	-1.24	-0.85	0.58	0.74	0.25	-0.37	0.16	-1.24	-0.01	-1.94	-1.00	-0.40	-0.38	-2.96	-1.54	-3.38	-0.48	-0.47	0.29	0.49	-2.10	-0.90	-1.57	-0.96	-0.32	-100000000.00	-0.48	
CD 	-0.67	-0.77	-0.45	-0.83	-1.19	-0.36	-0.99	-1.22	-1.12	-0.49	-1.19	-0.51	-0.77	-0.81	-2.65	2.39	-0.75	-0.55	-0.58	-1.18	0.47	-2.67	0.23	-2.03	-6.19	-0.70	-0.10	-1.47	-1.01	-0.09	-0.26	-0.62	-1.12	-3.72	-5.07	-0.44	-4.36	-0.32	-0.12	-0.07	-3.35	-0.87	-1.13	-0.85	-1.54	-1.69	-100000000.00	-0.23	
EX 	-0.71	-0.92	0.07	0.23	-1.36	-2.58	-1.56	-0.90	-0.41	-0.33	0.15	-0.14	0.44	-0.28	-1.75	-1.88	-0.48	-2.17	-2.35	-3.05	-1.97	-2.09	-2.91	-1.20	-0.85	-1.60	-0.70	-2.21	-0.65	-0.63	-0.66	0.76	-0.77	-1.54	0.81	-1.90	-1.45	-1.61	-0.79	-0.31	-0.59	-1.57	-0.39	-2.08	-2.69	-0.66	-100000000.00	-1.11	
IN 	-2.21	-0.78	-0.98	-0.08	0.19	-0.10	-1.46	0.37	-0.30	-0.91	-2.56	-0.18	-0.83	0.74	-0.84	-1.58	0.20	-0.29	-1.11	-2.71	-0.68	-2.59	-0.83	-1.76	-5.47	-1.37	-1.27	0.15	-1.16	-0.15	-1.76	-0.25	-2.52	-1.55	1.04	-0.61	-0.98	-0.16	-2.01	1.23	-3.56	-1.71	0.48	0.16	-1.78	-5.90	-100000000.00	-0.48	
WP$ 	-0.24	-1.46	-0.82	-4.08	-1.70	0.43	-0.73	-2.38	-0.13	-1.01	1.20	-1.57	-0.30	-0.87	-1.18	1.04	-0.80	-0.35	-1.77	-0.65	0.06	-2.41	-1.84	0.36	-1.02	-1.37	-1.56	-0.57	-0.86	-2.38	-2.44	-2.34	-0.33	0.41	0.34	-2.01	-0.74	-1.51	-1.91	0.06	-0.08	-0.46	-1.83	-1.07	-1.33	0.27	-100000000.00	-1.74	
NN|SYM 	0.09	-2.58	-1.12	-2.84	-2.34	0.26	-1.22	-2.71	1.25	-0.83	-0.96	-1.72	-2.20	-2.87	-1.54	-1.84	-4.20	-0.42	-0.34	-0.78	-0.54	1.51	-2.78	0.50	-0.68	-0.85	-1.86	-2.67	-1.63	-1.94	-1.02	-2.16	0.21	1.11	-1.81	-2.63	0.11	-1.86	-0.07	-0.67	-1.51	-0.63	-1.94	-1.77	-2.43	-1.25	-100000000.00	-2.04	
MD 	-0.09	-1.82	-1.44	-2.68	-2.56	-1.01	-1.07	-1.79	0.74	-0.81	-0.61	-1.50	-1.07	-0.98	-0.03	-2.77	-0.42	-1.04	-2.79	-3.73	-1.53	0.44	-2.08	-0.78	-1.14	-1.19	-1.50	-0.16	0.20	-1.67	-0.37	-1.03	-1.31	-1.17	-3.08	-1.26	-0.37	-1.91	-2.00	0.51	-2.06	-0.83	-2.89	-3.44	-3.22	-1.06	-100000000.00	-0.19	
NNPS 	-3.40	-2.12	-1.76	-1.72	-1.29	-1.28	-2.02	-0.56	-1.64	-1.05	-2.29	-1.57	-0.77	-1.49	-2.66	-2.42	-2.66	0.52	-1.06	-3.63	-2.62	-0.98	-2.54	-0.86	-2.16	-4.67	-1.27	-4.50	-3.02	-0.95	-1.53	-1.82	-1.75	-0.74	-3.53	-0.74	-2.23	-1.32	-0.41	-2.87	-2.78	-1.01	-2.88	-2.71	-1.75	-4.99	-100000000.00	0.40	
JJS 	-0.27	-3.71	-0.95	-0.72	-0.40	-1.84	-0.55	-1.18	-2.41	-0.78	-0.95	-2.79	-1.03	-0.64	-2.60	-1.74	-3.30	-2.32	-1.90	-2.11	-1.14	-0.62	-1.28	-2.46	-2.22	-2.95	-2.75	-3.71	-2.20	-1.53	-1.60	-1.92	-0.28	-0.17	-2.15	-1.63	-0.07	-0.35	-0.08	-0.19	-2.18	-3.51	-1.85	-4.06	-2.32	-0.27	-100000000.00	-3.29	
JJR 	-1.55	-1.18	-0.02	-0.07	-0.37	-2.21	-1.00	-0.57	-2.20	-1.08	-2.79	0.10	-1.07	-1.07	-1.71	-1.25	-1.65	-3.81	0.54	-2.21	-4.37	-0.58	-0.93	-0.04	-1.97	0.15	-1.44	-0.61	-0.93	0.63	-0.49	-1.40	-2.77	-2.74	-2.16	-1.22	-1.34	-0.74	-1.19	0.39	-1.25	-2.33	-2.58	-3.71	-1.72	-3.23	-100000000.00	-1.72	
SYM 	-0.12	-0.69	-3.72	-0.88	-4.47	-4.81	-0.83	-0.21	-2.84	0.04	-3.00	-3.09	-3.14	-0.07	-3.23	-0.70	-1.22	-0.57	-2.12	-1.94	-2.21	-0.25	-4.94	-1.11	-2.08	-2.27	-2.82	-1.41	-0.62	-2.61	-2.88	-0.92	-1.31	-2.11	-2.94	-0.23	-2.75	-2.99	-0.11	-1.11	-2.36	-3.45	-1.50	-1.23	-2.42	-0.29	-100000000.00	-0.57	
UH 	-1.65	-2.73	-2.92	-0.84	-4.04	-0.68	1.37	-0.54	-3.17	-4.10	0.43	-3.52	-6.97	0.13	-2.58	-2.98	-6.80	-4.26	-3.32	-1.33	-4.25	-2.24	-3.28	-0.52	-0.90	-1.43	-3.52	-5.26	-1.78	-3.41	-0.67	-2.57	-0.45	-1.51	-2.69	-7.84	-3.37	-1.06	-1.44	1.41	-2.44	-4.62	-1.91	-1.13	-1.81	-2.26	-100000000.00	-4.04	
stop_tag 	-1.73	-4.87	-1.25	-0.88	-1.11	-2.74	-1.65	-2.82	-4.22	0.62	-2.73	-0.49	-1.05	-1.03	-0.14	-2.66	0.38	-0.41	-3.34	-1.05	0.29	-0.59	-3.52	-1.07	-4.56	-0.91	-0.70	-0.19	-2.69	-0.83	-4.08	-1.70	-4.64	-3.48	-4.35	1.32	-1.83	-1.04	-1.29	-1.99	-2.82	-1.06	-5.09	-3.84	0.43	-3.67	-100000000.00	0.34	
NNP 	-0.41	-1.04	-0.42	-0.02	-0.57	-1.00	-0.38	-1.00	-0.99	-0.67	-0.92	-0.31	-0.65	-0.75	-1.14	-1.68	-0.96	-0.45	-0.48	-0.10	1.00	-1.41	-1.00	-0.14	-4.99	-2.25	0.17	-1.97	-2.09	-0.22	-0.42	0.52	-3.97	-3.01	-0.44	-0.58	-2.66	-0.41	-1.35	-3.27	-1.73	-0.84	-2.00	-0.19	-1.00	-0.47	-100000000.00	1.07	
Mean train loss after  0 batches of 3  epochs =0.0175628662109
Mean train loss after  100 batches of 3  epochs =0.0821070432301
Mean train loss after  200 batches of 3  epochs =0.086247227952
Mean train loss after  300 batches of 3  epochs =0.0807185352157
Mean train loss after  400 batches of 3  epochs =0.0759907995429
Mean train loss after  500 batches of 3  epochs =0.079089149071
Mean train loss after  600 batches of 3  epochs =0.0788619462426
Mean train loss after  700 batches of 3  epochs =0.0799191652214
Mean train loss after  800 batches of 3  epochs =0.0816817334276
Mean train loss after  900 batches of 3  epochs =0.0807295098594
Mean train loss after  1000 batches of 3  epochs =0.0809255937094
Mean train loss after  1100 batches of 3  epochs =0.0803133953019
Mean train loss after  1200 batches of 3  epochs =0.0797592620229
Mean train loss after  1300 batches of 3  epochs =0.0802949866876
Mean train loss after  1400 batches of 3  epochs =0.0797645614703
Mean train loss after  1500 batches of 3  epochs =0.0804991575915
Mean train loss after  1600 batches of 3  epochs =0.0801548209407
Mean train loss after  1700 batches of 3  epochs =0.0802375662089
Mean train loss after  1800 batches of 3  epochs =0.0793785461635
Mean train loss after  1900 batches of 3  epochs =0.0779846511618
Mean train loss after  2000 batches of 3  epochs =0.0773905678098
Mean train loss after  2100 batches of 3  epochs =0.0769901441363
Mean train loss after  2200 batches of 3  epochs =0.0775567574252
Mean train loss after  2300 batches of 3  epochs =0.0778370524426
Mean train loss after  2400 batches of 3  epochs =0.077521444272
Mean train loss after  2500 batches of 3  epochs =0.0772056786238
Mean train loss after  2600 batches of 3  epochs =0.077327481146
Mean train loss after  2700 batches of 3  epochs =0.0775691612481
Mean train loss after  2800 batches of 3  epochs =0.0784577501663
Mean train loss after  2900 batches of 3  epochs =0.078923424159
Mean train loss after  3000 batches of 3  epochs =0.0789337717481
Mean train loss after  3100 batches of 3  epochs =0.0791639951977
Mean train loss after  3200 batches of 3  epochs =0.0793260402337
Mean train loss after  3300 batches of 3  epochs =0.0793490321465
Mean train loss after  3400 batches of 3  epochs =0.0801710792734
Mean train loss after  3500 batches of 3  epochs =0.0808249343524
Mean train loss after  3600 batches of 3  epochs =0.0803307152917
Mean train loss after  3700 batches of 3  epochs =0.0806786848108
Mean train loss after  3800 batches of 3  epochs =0.0803359995644
Mean train loss after  3900 batches of 3  epochs =0.0805425319032
Mean train loss after  4000 batches of 3  epochs =0.0809571797956
Mean train loss after  4100 batches of 3  epochs =0.0806455618091
Mean train loss after  4200 batches of 3  epochs =0.0808644603955
Mean train loss after  4300 batches of 3  epochs =0.0808341205105
Mean train loss after  4400 batches of 3  epochs =0.0808401224401
Mean train loss after  4500 batches of 3  epochs =0.0806996159515
Mean train loss after  4600 batches of 3  epochs =0.0808374388285
Mean train loss after  4700 batches of 3  epochs =0.0810546231472
Mean train loss after  4800 batches of 3  epochs =0.0816430506648
Mean train loss after  4900 batches of 3  epochs =0.0815508537551
Mean train loss after  5000 batches of 3  epochs =0.0815261080094
Mean train loss after  5100 batches of 3  epochs =0.0813410873326
Mean train loss after  5200 batches of 3  epochs =0.0813450652804
Mean train loss after  5300 batches of 3  epochs =0.0814007380556
Mean train loss after  5400 batches of 3  epochs =0.0817677850102
Mean train loss after  5500 batches of 3  epochs =0.0817472569179
Mean train loss after  5600 batches of 3  epochs =0.0819156453518
Mean train loss after  5700 batches of 3  epochs =0.081969459311
Mean train loss after  5800 batches of 3  epochs =0.0814947705593
Mean train loss after  5900 batches of 3  epochs =0.081526701184
Mean train loss after  6000 batches of 3  epochs =0.0818191592628
Mean train loss after  6100 batches of 3  epochs =0.0817433630704
Mean train loss after  6200 batches of 3  epochs =0.0818289790426
Mean train loss after  6300 batches of 3  epochs =0.0825960234453
Mean train loss after  6400 batches of 3  epochs =0.0823475945553
Mean train loss after  6500 batches of 3  epochs =0.0825381903143
Mean train loss after  6600 batches of 3  epochs =0.0825081499328
Mean train loss after  6700 batches of 3  epochs =0.0828292615442
Mean train loss after  6800 batches of 3  epochs =0.0830446649833
Mean train loss after  6900 batches of 3  epochs =0.0833397764172
Mean train loss after  7000 batches of 3  epochs =0.0834746479868
Mean train loss after  7100 batches of 3  epochs =0.0837050455219
Mean train loss after  7200 batches of 3  epochs =0.0837402447156
Mean train loss after  7300 batches of 3  epochs =0.0841013953477
Mean train loss after  7400 batches of 3  epochs =0.0843919154087
Mean train loss after  7500 batches of 3  epochs =0.0844353918879
Mean train loss after  7600 batches of 3  epochs =0.0844188246455
Mean train loss after  7700 batches of 3  epochs =0.0843061577295
Mean train loss after  7800 batches of 3  epochs =0.084325562191
Mean train loss after  7900 batches of 3  epochs =0.0846685886396
Mean train loss after  8000 batches of 3  epochs =0.0848610968911
Mean train loss after  8100 batches of 3  epochs =0.0845535576154
Mean train loss after  8200 batches of 3  epochs =0.0844551486841
Mean train loss after  8300 batches of 3  epochs =0.0845636159233
Mean train loss after  8400 batches of 3  epochs =0.0850117879757
Mean train loss after  8500 batches of 3  epochs =0.0851706084148
Mean train loss after  8600 batches of 3  epochs =0.0854485041822
Mean train loss after  8700 batches of 3  epochs =0.0856351118397
Mean train loss after  8800 batches of 3  epochs =0.0854593968867
Mean train loss after  8900 batches of 3  epochs =0.0855383239014
Mean train loss after  9000 batches of 3  epochs =0.085542466455
Mean train loss after  9100 batches of 3  epochs =0.0855769611487
Mean train loss after  9200 batches of 3  epochs =0.0857930678368
Mean train loss after  9300 batches of 3  epochs =0.085960509184
Mean train loss after  9400 batches of 3  epochs =0.0862091004603
Mean train loss after  9500 batches of 3  epochs =0.0862219107385
Mean train loss after  9600 batches of 3  epochs =0.0864335918953
Mean train loss after  9700 batches of 3  epochs =0.08685780689
Mean train loss after  9800 batches of 3  epochs =0.0870636283561
Mean train loss after  9900 batches of 3  epochs =0.0870183692452
Mean train loss after  10000 batches of 3  epochs =0.0870553537094
Mean train loss after  10100 batches of 3  epochs =0.0869863314255
Mean train loss after  10200 batches of 3  epochs =0.0872077133486
Mean train loss after  10300 batches of 3  epochs =0.0871874843899
Mean train loss after  10400 batches of 3  epochs =0.0872460810213
Mean train loss after  10500 batches of 3  epochs =0.0876586840889
Mean train loss after  10600 batches of 3  epochs =0.0879610973908
Mean train loss after  10700 batches of 3  epochs =0.0881643122622
Mean train loss after  10800 batches of 3  epochs =0.0882419432296
Mean train loss after  10900 batches of 3  epochs =0.0884914768299
Mean train loss after  11000 batches of 3  epochs =0.0886126244509
Mean train loss after  11100 batches of 3  epochs =0.0886296312988
Mean train loss after  11200 batches of 3  epochs =0.0889294145924
Mean train loss after  11300 batches of 3  epochs =0.0888678053403
Mean train loss after  11400 batches of 3  epochs =0.0890022926454
Mean train loss after  11500 batches of 3  epochs =0.0893587145677
Mean train loss after  11600 batches of 3  epochs =0.0893887245366
Mean train loss after  11700 batches of 3  epochs =0.089552706672
Mean train loss after  11800 batches of 3  epochs =0.0897237897642
Mean train loss after  11900 batches of 3  epochs =0.0897959291896
Mean train loss after  12000 batches of 3  epochs =0.0898601786686
Mean train loss after  12100 batches of 3  epochs =0.0898340517725
Mean train loss after  12200 batches of 3  epochs =0.0898381415046
Mean train loss after  12300 batches of 3  epochs =0.0899071823791
Mean train loss after  12400 batches of 3  epochs =0.0898129995781
Mean train loss after  12500 batches of 3  epochs =0.0898377366698
Mean train loss after  12600 batches of 3  epochs =0.0897767458887
Mean train loss after  12700 batches of 3  epochs =0.0898838694493
Mean train loss after  12800 batches of 3  epochs =0.0898377523749
Mean train loss after  12900 batches of 3  epochs =0.090071822927
Mean train loss after  13000 batches of 3  epochs =0.0901808792744
Mean train loss after  13100 batches of 3  epochs =0.090121655279
Mean train loss after  13200 batches of 3  epochs =0.0901734075924
Mean train loss after  13300 batches of 3  epochs =0.0901290729617
Mean train loss after  13400 batches of 3  epochs =0.0902286845499
Mean train loss after  13500 batches of 3  epochs =0.0905100742601
Mean train loss after  13600 batches of 3  epochs =0.0906727360441
Mean train loss after  13700 batches of 3  epochs =0.0905067013417
Mean train loss after  13800 batches of 3  epochs =0.0906410542469
Mean train loss after  13900 batches of 3  epochs =0.0906588791061
Mean train loss after  14000 batches of 3  epochs =0.090806378932
Mean train loss after  14100 batches of 3  epochs =0.0906957471074
Mean train loss after  14200 batches of 3  epochs =0.0906640647337
Mean train loss after  14300 batches of 3  epochs =0.0909930374255
Mean train loss after  14400 batches of 3  epochs =0.0910422935143
Mean train loss after  14500 batches of 3  epochs =0.0912854210659
Mean train loss after  14600 batches of 3  epochs =0.0914809281505
Mean train loss after  14700 batches of 3  epochs =0.0915404751336
Mean train loss after  14800 batches of 3  epochs =0.0915494473718
Mean train loss after  14900 batches of 3  epochs =0.0915421783203
Epoch 3 : Mean train epoch loss =0.0917352491386
Epoch 3 Epoch val loss = 13365.1756995
Epoch 3 Epoch val perplexity = 1.31333480847715
SCORES =  (92.47, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 4---------------------

=================================
fscore(z) =  [266.08087] || goldscore = [265.01465]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-4.05	-0.94	0.14	-1.54	-0.11	-1.63	0.52	-1.28	-0.70	-1.36	-2.23	0.08	-0.22	-0.38	-0.44	-1.66	-1.94	-2.95	-2.33	-1.89	-2.61	-2.90	0.79	-1.45	-2.77	-2.69	-3.40	-1.73	-1.06	0.49	-0.69	0.45	-1.27	-1.59	-0.76	-2.92	-2.85	0.06	-2.77	-1.71	-3.22	-1.78	-3.01	-1.54	-0.87	-3.31	-100000000.00	-2.64	
VBG 	-1.45	-2.58	0.05	0.23	-0.01	0.01	-1.40	-0.31	-1.40	-1.80	-2.77	0.27	0.18	-0.90	-1.27	-3.84	-0.20	-1.82	-2.62	-4.64	-0.70	-1.54	-0.25	0.50	-2.32	-0.57	-1.24	0.31	-2.41	-0.15	-1.66	-0.07	-2.91	-0.48	0.29	-0.76	-2.79	0.47	-0.96	-1.44	-0.90	-0.86	-0.05	-1.78	-1.83	-6.29	-100000000.00	-0.98	
VBD 	-2.34	-3.52	-3.01	-1.43	-1.12	0.85	-0.63	-0.82	1.75	-1.77	-0.13	-1.43	-1.39	-0.36	-0.98	-2.03	-0.11	0.68	-1.31	-1.20	-0.66	-1.73	-3.73	-1.28	-4.04	-0.07	-1.39	0.09	0.98	-1.80	-0.53	-0.78	-2.41	-1.12	0.85	-1.32	-0.60	-2.57	0.21	-4.01	-2.78	-0.42	-0.74	-0.57	-4.10	-2.13	-100000000.00	0.17	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-1.84	-1.61	-0.52	-0.59	-1.26	-0.75	-3.24	0.69	-0.87	-1.42	-1.84	0.90	-0.36	-0.13	-1.42	-3.76	-0.75	-1.35	-0.66	-1.02	-1.37	-2.56	-2.01	-0.35	-2.79	0.68	-1.20	-0.23	-1.01	-0.13	-1.56	-0.60	-2.36	-1.42	-2.37	-2.17	-3.92	-1.34	-1.13	-0.44	-2.90	-1.56	-1.59	-1.61	-0.46	-4.14	-100000000.00	-2.19	
, 	-1.75	-2.08	-0.17	-3.97	-0.74	-2.15	0.61	-1.69	1.13	0.75	-2.47	-1.81	-0.96	-1.66	-0.79	-4.82	0.58	0.62	-2.54	-0.95	-2.05	-2.84	-2.74	0.01	-3.84	0.68	-2.41	-0.09	-0.60	-0.89	-3.52	-1.57	-3.44	-2.88	0.45	1.28	-1.83	-0.35	-2.83	-4.34	-1.53	-0.45	-1.89	-0.26	-5.46	-0.61	-100000000.00	0.42	
'' 	-4.26	-0.32	-0.80	0.71	-2.40	-1.49	-0.13	-2.21	0.31	-1.38	-1.87	-0.01	-2.47	-4.54	0.76	0.09	-1.27	-2.02	-0.84	-1.26	-0.08	0.59	-3.04	0.90	-1.47	0.22	1.07	-3.35	-1.28	-0.89	-2.40	-0.21	-0.19	-2.02	2.13	-0.76	-0.23	-0.79	0.01	-1.69	-0.78	-1.79	-1.77	-2.30	-3.31	-1.09	-100000000.00	0.30	
VBP 	-4.60	-2.25	-3.17	-3.21	-1.33	-1.04	0.35	-1.55	0.43	-2.74	0.31	-1.10	-1.44	-3.18	-2.14	-3.10	-1.02	-0.49	-1.83	-5.09	-3.00	-1.37	-2.42	-1.19	-3.35	-0.58	-1.92	1.15	1.09	-2.45	-1.57	-0.32	-0.38	-1.73	0.65	-0.11	0.77	-2.39	-0.87	-1.03	-4.61	0.75	-2.36	-2.97	-2.33	-3.90	-100000000.00	-0.23	
WDT 	-2.79	-3.43	-3.39	-1.31	-2.21	-1.04	-3.24	-1.32	-1.19	-2.35	-3.32	-1.65	0.67	-2.98	-1.65	-3.34	0.36	-0.73	-4.02	-3.11	-2.50	-0.99	-0.42	-0.73	-2.11	-1.93	0.56	0.60	-1.49	-1.63	-2.20	-1.73	-0.22	-2.89	-1.79	-1.20	-0.39	0.26	0.60	-1.15	-0.81	-1.91	-2.36	-1.80	-2.45	-1.75	-100000000.00	-0.38	
JJ 	0.91	-0.54	-0.12	-0.24	-0.02	-0.84	-0.91	0.03	-1.64	-0.09	-2.45	0.26	1.77	0.01	-1.41	0.42	-1.56	-1.34	-0.60	-2.22	0.05	-2.69	0.03	-0.74	-5.46	-0.12	0.83	-1.59	-0.70	-0.11	0.15	-0.26	-5.06	0.25	0.66	0.46	-3.36	0.90	-0.38	-2.33	-2.60	-2.19	-0.47	-0.52	-1.38	-3.36	-100000000.00	-0.92	
WP 	-2.14	-2.50	-2.51	-2.63	-0.78	-0.69	0.63	-0.05	-0.88	-1.41	-1.17	-0.05	-0.54	-0.93	-1.62	-2.26	0.40	-1.02	-0.38	-1.25	-1.97	-2.32	0.89	-2.01	-1.29	-0.19	-1.73	-0.01	-1.42	0.07	-1.56	-0.58	-1.99	-1.62	-2.22	-2.52	-0.95	0.41	-1.82	0.06	-2.19	-0.64	-2.17	-0.82	-1.45	-1.06	-100000000.00	-1.54	
VBZ 	-1.23	-2.24	-3.61	-3.18	-1.77	0.32	-1.31	-0.43	2.21	-1.11	-0.76	-1.69	-0.13	-0.28	-2.02	-2.21	0.79	-0.64	-0.52	-2.86	-2.21	-1.10	-2.59	-1.42	-2.29	0.11	-0.79	-2.06	1.76	-1.53	0.61	-0.32	-2.74	-2.41	-2.98	-0.73	0.59	-2.48	-1.30	-1.45	-2.77	-2.74	-0.87	-2.05	-2.06	-4.68	-100000000.00	0.18	
DT 	-2.44	-1.61	-0.83	0.37	-0.27	0.02	-1.13	-0.37	-1.39	-0.57	-1.87	-0.01	-1.31	-0.33	0.07	-4.87	0.13	-0.45	0.69	-1.41	-1.22	-1.37	0.63	-1.99	-3.24	-0.71	-0.16	-1.03	-1.22	1.21	-0.14	1.48	-0.04	-0.83	0.91	-2.52	-1.83	1.48	0.38	-1.44	-1.46	-2.08	-2.70	-1.63	-0.72	-4.55	-100000000.00	0.06	
" 	0.08	-0.21	-1.86	-1.44	-1.05	-0.13	0.68	-0.91	-0.63	-0.38	-1.29	-0.40	-0.19	-1.13	0.22	-2.85	0.30	-0.87	-2.29	-2.60	0.91	0.80	-1.43	0.03	-0.02	-1.21	0.45	-1.76	-2.44	-1.22	-1.80	-1.22	-2.17	-3.12	-1.27	-0.74	-2.54	-1.12	-0.99	-3.57	-2.26	-1.86	-1.75	-0.25	-1.57	-3.01	-100000000.00	0.15	
RP 	-3.71	0.85	0.92	-2.83	0.93	-1.25	-2.53	1.14	-1.86	-1.02	-3.38	-0.29	0.53	-2.78	-1.27	-1.96	-1.61	-0.87	-2.70	-2.73	-1.23	-0.23	-3.46	-0.95	-2.06	-1.39	-2.72	-1.60	0.35	0.16	-2.32	-3.35	-1.63	-2.61	-0.55	-0.78	-5.84	-2.30	-0.77	-1.06	-4.33	-3.43	-2.32	-1.96	-2.85	-4.34	-100000000.00	-2.35	
$ 	-2.28	-1.09	-0.44	-4.69	-0.36	-2.11	-1.18	-0.42	-1.34	0.14	-1.75	-0.10	-0.73	-1.72	-0.39	1.40	0.50	-1.88	-0.52	-4.85	-0.29	-0.78	0.57	-0.66	1.10	-0.83	-0.34	-1.10	-1.62	0.32	-1.40	-0.16	-2.15	-0.30	-2.29	-0.98	-1.37	0.22	-1.93	-2.73	-0.41	-2.30	-1.11	-2.09	-3.26	-1.63	-100000000.00	0.50	
NN 	0.90	-0.33	-0.81	0.62	0.27	0.77	-0.95	-0.93	-1.60	0.82	-0.34	-0.02	0.40	-0.55	-1.23	-3.28	-0.69	-0.60	-0.87	-0.37	1.06	-0.84	-1.41	-1.82	-6.15	-2.38	0.66	-1.90	-2.50	-0.23	-1.87	-1.41	-2.05	-3.29	-0.03	-0.30	-3.46	0.10	1.67	-4.30	-4.26	-1.35	0.47	0.54	-1.28	-7.15	-100000000.00	-0.42	
) 	-3.30	-0.96	-2.26	-3.66	-0.78	-3.45	-3.02	-3.34	-4.39	-0.68	-3.75	-1.07	-2.24	-1.70	0.74	-2.81	-1.09	-1.52	-1.07	-2.03	-0.83	-3.29	-3.08	0.33	0.13	-2.08	-1.94	-2.27	-4.40	-0.78	-3.88	-2.51	-4.11	-1.98	-3.00	1.16	-0.80	-0.93	-2.26	-4.67	-2.61	-0.86	-5.51	-4.97	-3.03	-3.06	-100000000.00	-0.13	
( 	0.84	-3.70	-0.88	-1.46	-2.96	-2.45	-1.64	-3.21	-1.40	-0.95	-0.61	-0.96	-1.26	-0.56	-2.11	-4.35	0.33	-1.65	-2.98	-0.99	-0.68	-1.47	-1.19	-0.14	-1.67	-1.87	-1.32	-0.55	-1.18	-1.15	-1.86	-2.60	-4.52	-2.98	-3.51	0.70	-2.50	-3.06	-1.88	-2.06	-3.53	-1.05	-0.66	-2.28	-4.52	-1.16	-100000000.00	1.25	
FW 	-3.89	-3.12	-3.16	-1.17	-4.18	-0.91	-1.67	-1.16	-1.32	-2.18	-2.08	-5.22	-2.86	-3.35	-3.80	-1.27	-1.65	-1.34	-2.67	-0.21	-3.43	-0.87	-4.39	-0.58	-0.82	-3.55	-2.01	-2.92	-3.92	-2.16	0.34	-1.54	-1.87	-1.82	-2.49	-1.72	-2.03	-8.95	0.28	-1.70	-1.42	-1.28	-3.19	-3.31	-1.52	-0.34	-100000000.00	-0.49	
POS 	-1.56	-3.97	-1.37	-1.83	-0.10	-1.46	0.50	-1.62	1.21	0.35	-4.44	-2.87	-0.98	-1.16	-2.86	-2.70	1.74	-2.14	-1.65	-4.36	-2.44	-1.28	-2.22	-2.03	-4.61	-1.38	0.00	0.08	-0.52	-2.12	-1.30	-2.19	-1.03	0.32	-1.81	-1.29	-0.25	-1.81	-2.25	-2.20	-2.51	-1.59	-2.62	-1.20	-2.79	-3.24	-100000000.00	1.87	
. 	-2.36	-0.48	-1.20	-4.08	-0.62	-4.70	-2.11	-0.21	-2.22	-0.08	-2.23	0.28	0.18	-0.36	-0.14	-5.81	-0.24	-0.61	-2.70	-2.49	-0.65	-0.79	-2.05	-0.65	-0.12	-0.30	-1.11	0.81	-0.63	-1.02	-0.15	-2.08	-2.11	-4.94	-0.67	0.67	-0.85	-1.26	-1.64	-3.60	-3.13	-0.33	-3.45	-0.69	-5.02	-2.03	-100000000.00	1.34	
TO 	-1.25	-1.67	-0.30	-1.06	-0.61	-1.94	-1.90	-0.04	-2.89	-0.80	-2.06	0.64	-2.68	-1.66	-0.21	-4.13	-0.79	-1.42	-1.55	-2.63	-3.28	-2.51	-1.69	-1.11	-2.79	-0.42	-1.45	-0.88	-1.28	-1.10	-0.51	-2.37	-4.14	-2.02	-0.42	0.86	-2.28	0.03	-1.02	-1.62	-3.21	-2.48	-0.58	-0.47	-4.11	-5.81	-100000000.00	-1.53	
-X- 	-0.33	0.16	-2.13	-2.44	-1.43	-1.51	-1.66	-1.36	-0.82	-1.73	-2.47	-2.36	-1.38	-2.20	0.39	-2.18	-0.48	-1.25	-2.39	-0.59	-1.52	-0.41	-2.09	2.00	-1.46	-2.06	-1.93	-1.07	-1.71	-1.42	0.22	0.05	1.70	-0.30	-0.27	-2.10	0.43	-1.96	0.84	1.11	0.86	-2.10	-1.87	1.73	-0.94	0.38	-100000000.00	-4.01	
LS 	-1.11	-1.61	-3.67	-0.54	-2.28	-1.72	-0.51	-3.58	-0.80	-3.50	0.17	-1.31	-4.35	-2.50	-3.30	-3.89	-2.78	-1.99	-2.21	-2.39	-0.78	0.05	-2.70	-1.55	-2.89	-4.05	0.96	-4.56	-2.34	-1.83	1.01	-3.75	-0.51	-0.45	-1.76	-3.76	-2.55	-2.67	-1.08	-0.96	-3.09	-3.43	-1.59	-3.72	-0.98	-1.62	-100000000.00	-2.94	
RB 	-1.01	-0.22	0.64	-0.35	0.14	-0.68	-0.44	0.40	-1.05	-1.40	-1.25	0.57	-0.32	0.31	-0.07	-2.24	-0.55	0.41	-0.35	-3.90	-1.37	-2.40	-0.06	-1.02	-2.91	-0.83	-0.94	-0.27	-0.16	0.19	-0.00	-0.76	-3.82	-1.66	-0.94	-0.48	-1.90	-0.52	-0.98	-0.37	0.95	-2.51	-1.10	-1.64	-1.55	-4.45	-100000000.00	-0.80	
: 	-4.18	-1.34	-0.88	-2.45	-0.95	-2.18	-3.04	-0.90	-2.02	0.28	-1.06	-0.30	-1.85	-2.00	-2.67	-2.07	0.15	-2.04	-1.91	-5.96	0.58	-2.02	-4.90	-1.81	-2.49	-1.16	-1.43	-2.00	-2.00	0.13	-3.06	-4.10	-1.84	-2.12	-1.68	0.24	-2.05	0.03	-2.15	-2.95	-4.33	-0.01	-4.49	-0.39	-3.64	-3.48	-100000000.00	-0.15	
NNS 	1.58	-0.62	-0.47	-0.03	-0.29	-1.79	-2.12	-0.67	-0.87	1.00	-1.01	-1.11	-0.56	-1.48	-1.55	-3.29	-0.14	-1.73	-0.79	-1.91	0.39	-2.00	-1.77	-2.00	-4.94	-2.98	-0.04	-3.30	-1.34	-0.16	-0.01	0.40	-2.76	-1.94	-0.97	-0.35	-2.57	-0.81	0.83	-3.39	-1.21	-2.91	-0.48	0.59	-1.97	-7.02	-100000000.00	-1.10	
PRP 	-2.77	-0.88	-0.49	-0.41	0.57	-1.36	0.53	-0.87	-0.50	-1.60	0.61	-0.05	-2.12	-0.46	-2.73	-2.89	-0.46	-1.51	-3.35	-3.92	-0.31	-0.39	-0.40	0.08	-2.25	-1.02	0.61	-1.21	-3.86	1.05	0.44	-0.99	-1.21	-2.44	-1.40	-2.10	-0.71	0.90	-2.13	-1.58	-1.60	-3.72	-1.45	-3.20	-1.97	-2.54	-100000000.00	-1.14	
VB 	-2.41	-1.24	-2.77	0.08	-3.57	0.04	-1.82	-1.23	-0.49	-2.17	-0.61	-1.38	-0.61	-0.60	-1.83	0.86	-0.93	0.28	-1.83	-1.38	-4.31	-0.48	0.56	-0.88	-2.72	0.49	0.36	-1.29	0.18	-1.62	-1.60	0.97	0.58	-1.39	0.53	-1.54	-2.32	-1.97	-2.06	-0.81	1.52	-2.13	-0.86	-0.14	-3.35	-0.66	-100000000.00	-1.21	
WRB 	-2.25	-0.77	-1.52	-1.05	-0.85	-0.35	-1.40	-0.74	-1.52	-0.02	-1.25	0.58	-4.19	-1.08	-0.32	-1.19	-0.48	-2.25	-1.48	-2.72	-2.17	-0.36	-1.50	0.06	-1.53	-1.34	-3.07	-1.34	-1.23	-0.75	-2.46	-1.04	-2.83	-1.18	-3.91	-1.00	-1.92	-0.90	0.81	-1.07	-2.46	-4.09	-1.67	-1.01	-2.86	-0.12	-100000000.00	-0.66	
CC 	-3.29	-1.62	-1.79	-1.43	-0.42	-0.02	-2.55	-0.48	-1.69	0.77	-2.41	-1.35	-2.97	-1.23	-0.72	-2.84	-0.22	-1.65	-3.50	-3.56	-1.02	-0.25	-1.20	-2.20	-2.87	-0.51	0.39	-1.00	-0.75	0.20	-1.89	-2.75	-1.63	-4.16	0.02	0.60	-0.57	-1.26	-1.30	-1.94	-2.46	0.07	-1.88	-0.17	-1.57	-5.08	-100000000.00	0.26	
PDT 	-2.52	0.58	-2.81	-1.87	-0.20	-3.54	-2.19	-0.52	-3.20	-1.46	-3.42	-0.47	-2.57	-2.19	-1.27	-2.05	-2.67	-1.79	-0.24	-1.05	-0.02	-0.50	-3.76	0.08	-1.06	-0.61	-1.42	-0.83	-2.44	-1.59	-0.12	-1.39	-0.33	0.87	-1.83	-2.27	-0.47	1.07	-0.75	-1.08	-0.18	-1.39	-1.95	-1.20	-3.76	-1.11	-100000000.00	-0.11	
RBS 	-0.49	-2.62	-0.70	-4.85	-0.80	-1.03	-0.17	-2.26	-3.46	-1.85	0.82	-0.59	-0.69	-1.97	-1.25	-1.46	-1.16	-2.41	-3.08	-2.07	-0.52	-0.15	-0.92	1.81	-2.84	0.04	-2.95	-7.30	-4.10	-1.17	-2.65	0.46	-1.94	-0.57	-1.36	-2.15	-1.13	0.59	-0.93	0.23	-2.86	-2.04	-3.53	-3.93	-2.41	-1.86	-100000000.00	-6.33	
RBR 	-2.72	-1.53	0.17	-0.69	0.14	-2.16	-0.38	-1.59	0.29	-1.43	0.40	-0.01	-0.49	-2.14	-0.49	-2.22	-0.29	-1.59	-2.37	-3.97	-2.79	-1.43	-1.00	0.57	0.46	0.20	-0.43	0.18	-1.38	-0.12	-2.19	-1.13	-0.75	-0.66	-3.26	-1.77	-3.69	-0.55	-0.58	0.11	0.08	-2.38	-1.14	-1.93	-1.20	-0.68	-100000000.00	-0.56	
CD 	-0.74	-0.77	-0.50	-0.81	-1.33	-0.39	-1.03	-1.38	-1.43	-0.49	-1.80	-0.51	-0.71	-0.78	-2.74	2.53	-0.74	-0.61	-0.57	-1.33	0.41	-3.06	0.15	-2.34	-6.69	-0.71	-0.20	-1.56	-1.22	-0.05	-0.59	-0.66	-1.31	-4.34	-5.37	-0.55	-5.17	-0.33	-0.06	-0.04	-4.26	-0.91	-1.17	-0.84	-1.59	-1.92	-100000000.00	-0.39	
EX 	-0.88	-0.97	0.13	0.19	-1.48	-2.53	-1.74	-0.86	-0.51	-0.55	-0.02	-0.26	0.31	-0.27	-1.96	-2.11	-0.57	-2.40	-3.00	-3.32	-2.40	-2.25	-3.36	-1.21	-0.99	-1.83	-1.13	-2.33	-0.64	-0.74	-0.70	0.81	-0.96	-1.69	0.60	-2.06	-1.59	-1.48	-0.92	-0.45	-0.75	-1.79	-0.61	-2.29	-2.83	-0.81	-100000000.00	-1.25	
IN 	-2.47	-0.96	-1.01	-0.37	0.17	-0.19	-1.74	0.38	-0.53	-0.92	-2.99	-0.19	-0.89	0.62	-0.76	-1.64	0.21	-0.40	-1.33	-3.11	-1.18	-2.97	-1.05	-1.99	-6.07	-1.26	-1.42	0.21	-1.11	-0.18	-1.98	-0.43	-2.84	-1.60	0.96	-0.64	-1.00	-0.26	-2.11	0.83	-3.82	-1.65	0.31	0.10	-2.16	-6.94	-100000000.00	-0.52	
WP$ 	-0.36	-1.57	-0.97	-4.67	-1.87	0.46	-0.84	-2.58	-0.27	-1.14	0.92	-1.63	-0.47	-1.12	-1.32	0.85	-0.94	-0.54	-1.95	-0.77	-0.14	-2.50	-2.02	0.36	-1.08	-1.46	-1.72	-0.46	-1.13	-2.46	-2.49	-2.46	-0.43	0.33	0.25	-2.19	-0.86	-1.63	-1.92	0.04	-0.28	-0.59	-1.93	-1.17	-1.41	0.12	-100000000.00	-1.78	
NN|SYM 	-0.28	-3.10	-1.64	-3.94	-2.98	-0.27	-1.40	-3.17	0.90	-1.75	-1.24	-2.15	-2.87	-3.23	-1.87	-2.04	-4.89	-0.42	-0.72	-1.08	-1.20	1.40	-3.26	0.50	-1.06	-1.66	-2.54	-3.39	-2.08	-2.31	-1.18	-2.62	0.00	0.83	-2.07	-3.33	-0.17	-2.15	-0.12	-0.73	-2.04	-1.11	-2.30	-2.21	-2.84	-1.64	-100000000.00	-3.18	
MD 	-0.27	-1.94	-1.69	-3.30	-2.86	-1.04	-1.34	-1.81	0.89	-0.90	-0.97	-1.58	-1.08	-1.03	-0.22	-3.10	-0.45	-1.30	-3.49	-4.32	-1.79	0.25	-2.47	-0.81	-1.38	-1.26	-1.53	-0.25	0.18	-1.77	-0.38	-1.33	-1.62	-1.42	-3.43	-1.41	-0.32	-2.29	-2.17	0.27	-2.26	-1.10	-3.32	-4.00	-3.54	-1.39	-100000000.00	-0.24	
NNPS 	-3.80	-2.21	-1.96	-2.00	-1.50	-1.40	-2.28	-0.77	-1.76	-1.31	-2.70	-1.63	-0.72	-1.76	-2.85	-3.09	-2.75	0.42	-1.21	-4.26	-2.67	-1.14	-3.38	-0.99	-2.50	-5.47	-1.38	-5.33	-3.66	-1.05	-1.75	-1.89	-2.02	-0.95	-4.14	-0.83	-2.74	-1.32	-0.46	-3.14	-3.16	-1.12	-3.31	-3.40	-2.13	-5.66	-100000000.00	0.36	
JJS 	-0.25	-4.33	-1.13	-0.75	-0.70	-1.80	-0.62	-1.77	-2.64	-1.09	-1.31	-3.09	-1.11	-1.09	-2.83	-2.12	-3.94	-2.74	-2.02	-2.64	-1.25	-0.81	-1.43	-2.47	-2.62	-3.25	-3.53	-3.97	-2.48	-1.70	-1.69	-2.13	-0.71	-0.38	-2.64	-2.16	-0.31	-0.56	-0.14	-0.49	-2.80	-4.15	-2.30	-4.76	-2.74	-0.95	-100000000.00	-3.98	
JJR 	-1.69	-1.20	0.01	-0.14	-0.51	-2.32	-1.13	-0.60	-2.69	-1.21	-3.33	0.11	-1.01	-1.35	-1.97	-1.75	-1.85	-4.55	0.45	-2.69	-5.29	-0.80	-1.15	-0.09	-2.34	-0.03	-1.40	-0.87	-1.13	0.46	-0.54	-1.37	-3.33	-3.00	-2.65	-1.30	-1.68	-0.79	-1.30	0.00	-1.63	-2.54	-2.95	-4.18	-1.84	-3.79	-100000000.00	-1.81	
SYM 	-0.50	-1.00	-4.02	-0.86	-4.89	-5.28	-1.14	-0.73	-3.19	-0.12	-3.51	-3.61	-3.46	-0.46	-3.70	-1.22	-1.17	-0.68	-2.33	-2.49	-2.80	-0.37	-5.29	-1.13	-2.36	-2.67	-3.40	-1.73	-0.69	-2.90	-3.22	-1.08	-1.80	-2.54	-3.51	-0.35	-3.20	-3.04	-0.22	-1.15	-2.64	-3.93	-1.93	-1.86	-2.88	-0.45	-100000000.00	-0.71	
UH 	-2.06	-3.23	-3.35	-0.89	-4.66	-0.84	1.16	-1.09	-3.62	-5.03	0.09	-4.12	-8.18	0.06	-2.82	-3.35	-7.40	-4.73	-4.23	-1.49	-4.89	-2.39	-4.04	-0.55	-1.13	-2.22	-4.41	-6.06	-1.96	-3.87	-0.91	-3.52	-0.96	-1.80	-3.04	-8.48	-3.70	-1.42	-1.56	1.10	-2.88	-5.37	-2.14	-1.45	-2.28	-2.23	-100000000.00	-4.75	
stop_tag 	-2.40	-5.83	-1.19	-0.88	-1.22	-3.10	-1.52	-3.26	-5.11	0.65	-3.35	-0.99	-1.16	-1.33	-0.32	-3.22	0.43	-0.62	-3.96	-1.30	-0.09	-0.85	-4.01	-1.33	-5.09	-1.00	-1.13	-0.21	-2.87	-0.96	-4.62	-2.22	-5.64	-3.96	-5.80	1.13	-2.43	-1.18	-1.55	-2.14	-3.98	-1.18	-5.89	-4.47	0.40	-4.27	-100000000.00	0.23	
NNP 	-0.35	-0.98	-0.44	-0.24	-0.59	-1.08	-0.40	-1.13	-1.15	-0.63	-1.38	-0.29	-0.64	-0.78	-1.35	-1.85	-0.93	-0.44	-0.50	-0.27	0.87	-1.74	-0.96	-0.32	-5.50	-2.43	0.14	-1.94	-2.33	-0.36	-0.45	0.54	-4.41	-3.38	-1.29	-0.65	-3.94	-0.42	-1.52	-3.47	-1.89	-0.93	-2.17	-0.28	-1.12	-1.11	-100000000.00	1.10	
Mean train loss after  0 batches of 4  epochs =0.0484646883878
Mean train loss after  100 batches of 4  epochs =0.0436516892623
Mean train loss after  200 batches of 4  epochs =0.0611054132161
Mean train loss after  300 batches of 4  epochs =0.055932971904
Mean train loss after  400 batches of 4  epochs =0.0556979023975
Mean train loss after  500 batches of 4  epochs =0.0545998855358
Mean train loss after  600 batches of 4  epochs =0.0549367559256
Mean train loss after  700 batches of 4  epochs =0.0580438321588
Mean train loss after  800 batches of 4  epochs =0.0586900476596
Mean train loss after  900 batches of 4  epochs =0.058101088365
Mean train loss after  1000 batches of 4  epochs =0.0586801572097
Mean train loss after  1100 batches of 4  epochs =0.0587858407604
Mean train loss after  1200 batches of 4  epochs =0.0588494086771
Mean train loss after  1300 batches of 4  epochs =0.0584613259603
Mean train loss after  1400 batches of 4  epochs =0.0589285870481
Mean train loss after  1500 batches of 4  epochs =0.0585791801456
Mean train loss after  1600 batches of 4  epochs =0.057685102911
Mean train loss after  1700 batches of 4  epochs =0.0566188857111
Mean train loss after  1800 batches of 4  epochs =0.0564319040421
Mean train loss after  1900 batches of 4  epochs =0.0560976579736
Mean train loss after  2000 batches of 4  epochs =0.056932180754
Mean train loss after  2100 batches of 4  epochs =0.0562166443301
Mean train loss after  2200 batches of 4  epochs =0.0565434650924
Mean train loss after  2300 batches of 4  epochs =0.0557933426742
Mean train loss after  2400 batches of 4  epochs =0.0557204707721
Mean train loss after  2500 batches of 4  epochs =0.0553265316064
Mean train loss after  2600 batches of 4  epochs =0.0553950978864
Mean train loss after  2700 batches of 4  epochs =0.0557038878458
Mean train loss after  2800 batches of 4  epochs =0.0562372696272
Mean train loss after  2900 batches of 4  epochs =0.0562533901733
Mean train loss after  3000 batches of 4  epochs =0.0564893357385
Mean train loss after  3100 batches of 4  epochs =0.0565202996364
Mean train loss after  3200 batches of 4  epochs =0.0567729729809
Mean train loss after  3300 batches of 4  epochs =0.0567527826586
Mean train loss after  3400 batches of 4  epochs =0.0564273893814
Mean train loss after  3500 batches of 4  epochs =0.0561358480113
Mean train loss after  3600 batches of 4  epochs =0.0560742065503
Mean train loss after  3700 batches of 4  epochs =0.0560491053132
Mean train loss after  3800 batches of 4  epochs =0.0563299663892
Mean train loss after  3900 batches of 4  epochs =0.057400555352
Mean train loss after  4000 batches of 4  epochs =0.0573037477388
Mean train loss after  4100 batches of 4  epochs =0.0569814200759
Mean train loss after  4200 batches of 4  epochs =0.0573207729057
Mean train loss after  4300 batches of 4  epochs =0.056990190182
Mean train loss after  4400 batches of 4  epochs =0.0572951701612
Mean train loss after  4500 batches of 4  epochs =0.0572785051064
Mean train loss after  4600 batches of 4  epochs =0.0572375560141
Mean train loss after  4700 batches of 4  epochs =0.0573981397065
Mean train loss after  4800 batches of 4  epochs =0.0574183530123
Mean train loss after  4900 batches of 4  epochs =0.0582587677217
Mean train loss after  5000 batches of 4  epochs =0.0581975061042
Mean train loss after  5100 batches of 4  epochs =0.0582798594814
Mean train loss after  5200 batches of 4  epochs =0.0585684871665
Mean train loss after  5300 batches of 4  epochs =0.0586676317502
Mean train loss after  5400 batches of 4  epochs =0.0587032471647
Mean train loss after  5500 batches of 4  epochs =0.0586054134864
Mean train loss after  5600 batches of 4  epochs =0.0585181296187
Mean train loss after  5700 batches of 4  epochs =0.0583121375541
Mean train loss after  5800 batches of 4  epochs =0.0582145282782
Mean train loss after  5900 batches of 4  epochs =0.0581673597009
Mean train loss after  6000 batches of 4  epochs =0.0582209480267
Mean train loss after  6100 batches of 4  epochs =0.0584749398394
Mean train loss after  6200 batches of 4  epochs =0.0585091202166
Mean train loss after  6300 batches of 4  epochs =0.058655455626
Mean train loss after  6400 batches of 4  epochs =0.0586859049027
Mean train loss after  6500 batches of 4  epochs =0.0588213094557
Mean train loss after  6600 batches of 4  epochs =0.0592412520036
Mean train loss after  6700 batches of 4  epochs =0.0593799104454
Mean train loss after  6800 batches of 4  epochs =0.0597465515772
Mean train loss after  6900 batches of 4  epochs =0.0598290333534
Mean train loss after  7000 batches of 4  epochs =0.0601354130828
Mean train loss after  7100 batches of 4  epochs =0.060410986121
Mean train loss after  7200 batches of 4  epochs =0.0605189354626
Mean train loss after  7300 batches of 4  epochs =0.0607977438477
Mean train loss after  7400 batches of 4  epochs =0.0609542918833
Mean train loss after  7500 batches of 4  epochs =0.0609713487219
Mean train loss after  7600 batches of 4  epochs =0.0613052605418
Mean train loss after  7700 batches of 4  epochs =0.0614292359727
Mean train loss after  7800 batches of 4  epochs =0.0617010459818
Mean train loss after  7900 batches of 4  epochs =0.0617620305202
Mean train loss after  8000 batches of 4  epochs =0.061778153158
Mean train loss after  8100 batches of 4  epochs =0.0621957250738
Mean train loss after  8200 batches of 4  epochs =0.0621847407866
Mean train loss after  8300 batches of 4  epochs =0.0623191395307
Mean train loss after  8400 batches of 4  epochs =0.062465385743
Mean train loss after  8500 batches of 4  epochs =0.0624929234152
Mean train loss after  8600 batches of 4  epochs =0.0625947262468
Mean train loss after  8700 batches of 4  epochs =0.0626883358053
Mean train loss after  8800 batches of 4  epochs =0.0628354007029
Mean train loss after  8900 batches of 4  epochs =0.0628110076062
Mean train loss after  9000 batches of 4  epochs =0.0633401180237
Mean train loss after  9100 batches of 4  epochs =0.0631771550243
Mean train loss after  9200 batches of 4  epochs =0.0633306047522
Mean train loss after  9300 batches of 4  epochs =0.0634378075736
Mean train loss after  9400 batches of 4  epochs =0.0633383560619
Mean train loss after  9500 batches of 4  epochs =0.0633060021278
Mean train loss after  9600 batches of 4  epochs =0.0632613982031
Mean train loss after  9700 batches of 4  epochs =0.0633090055774
Mean train loss after  9800 batches of 4  epochs =0.0634265693522
Mean train loss after  9900 batches of 4  epochs =0.0637524166169
Mean train loss after  10000 batches of 4  epochs =0.0636614741336
Mean train loss after  10100 batches of 4  epochs =0.0638048616381
Mean train loss after  10200 batches of 4  epochs =0.0640133395259
Mean train loss after  10300 batches of 4  epochs =0.0642387713173
Mean train loss after  10400 batches of 4  epochs =0.064421218058
Mean train loss after  10500 batches of 4  epochs =0.0642336138998
Mean train loss after  10600 batches of 4  epochs =0.0641892005636
Mean train loss after  10700 batches of 4  epochs =0.0642543915017
Mean train loss after  10800 batches of 4  epochs =0.0643674868813
Mean train loss after  10900 batches of 4  epochs =0.0644321440493
Mean train loss after  11000 batches of 4  epochs =0.0646377854479
Mean train loss after  11100 batches of 4  epochs =0.0647111458515
Mean train loss after  11200 batches of 4  epochs =0.0648612118759
Mean train loss after  11300 batches of 4  epochs =0.0649737070748
Mean train loss after  11400 batches of 4  epochs =0.0648613212705
Mean train loss after  11500 batches of 4  epochs =0.0651037789991
Mean train loss after  11600 batches of 4  epochs =0.0653011174659
Mean train loss after  11700 batches of 4  epochs =0.0652122933186
Mean train loss after  11800 batches of 4  epochs =0.0652597183632
Mean train loss after  11900 batches of 4  epochs =0.0653106757121
Mean train loss after  12000 batches of 4  epochs =0.0652958275314
Mean train loss after  12100 batches of 4  epochs =0.0654411197642
Mean train loss after  12200 batches of 4  epochs =0.0655225005206
Mean train loss after  12300 batches of 4  epochs =0.0656871801612
Mean train loss after  12400 batches of 4  epochs =0.0657578917085
Mean train loss after  12500 batches of 4  epochs =0.0659615524655
Mean train loss after  12600 batches of 4  epochs =0.0660493013408
Mean train loss after  12700 batches of 4  epochs =0.066149603857
Mean train loss after  12800 batches of 4  epochs =0.0662153727548
Mean train loss after  12900 batches of 4  epochs =0.0663684833302
Mean train loss after  13000 batches of 4  epochs =0.0664793609348
Mean train loss after  13100 batches of 4  epochs =0.0666260209868
Mean train loss after  13200 batches of 4  epochs =0.0667892998581
Mean train loss after  13300 batches of 4  epochs =0.0669891114403
Mean train loss after  13400 batches of 4  epochs =0.0669969513449
Mean train loss after  13500 batches of 4  epochs =0.0672253777786
Mean train loss after  13600 batches of 4  epochs =0.067307899657
Mean train loss after  13700 batches of 4  epochs =0.0674782670219
Mean train loss after  13800 batches of 4  epochs =0.0674232235783
Mean train loss after  13900 batches of 4  epochs =0.0674468380671
Mean train loss after  14000 batches of 4  epochs =0.0675747044363
Mean train loss after  14100 batches of 4  epochs =0.067547186533
Mean train loss after  14200 batches of 4  epochs =0.0674893550725
Mean train loss after  14300 batches of 4  epochs =0.0676300754562
Mean train loss after  14400 batches of 4  epochs =0.0676367499679
Mean train loss after  14500 batches of 4  epochs =0.0675855727233
Mean train loss after  14600 batches of 4  epochs =0.0676692061182
Mean train loss after  14700 batches of 4  epochs =0.0676997430921
Mean train loss after  14800 batches of 4  epochs =0.0678337770228
Mean train loss after  14900 batches of 4  epochs =0.0680294526154
Epoch 4 : Mean train epoch loss =0.0680565114733
Epoch 4 Epoch val loss = 13951.8808177
Epoch 4 Epoch val perplexity = 1.3291436055743415
SCORES =  (92.61, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 5---------------------

=================================
fscore(z) =  [56.97327] || goldscore = [56.888878]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-4.56	-0.91	0.17	-2.04	-0.31	-1.77	0.27	-1.32	-0.96	-1.55	-2.38	0.01	-0.28	-0.52	-0.45	-2.07	-2.05	-3.24	-2.66	-2.41	-2.62	-3.04	0.86	-1.46	-2.96	-2.79	-3.69	-1.85	-1.26	0.51	-0.79	0.43	-1.27	-1.83	-0.88	-3.34	-3.01	0.02	-2.82	-1.87	-3.70	-2.14	-3.24	-1.76	-1.10	-3.62	-100000000.00	-2.80	
VBG 	-1.59	-2.79	0.00	0.26	-0.16	-0.05	-1.65	-0.41	-1.83	-2.05	-3.06	0.20	0.06	-1.00	-1.38	-4.08	-0.13	-2.03	-2.70	-5.21	-0.88	-1.70	-0.32	0.43	-2.66	-0.67	-1.30	0.27	-2.49	-0.23	-1.81	-0.25	-3.14	-0.69	0.03	-0.88	-3.33	0.40	-1.03	-1.75	-1.31	-1.04	-0.13	-1.95	-2.08	-6.88	-100000000.00	-0.99	
VBD 	-2.60	-3.66	-3.36	-1.51	-1.27	0.95	-0.87	-0.99	1.72	-1.78	-0.12	-1.67	-1.48	-0.63	-1.21	-2.36	-0.15	0.61	-1.49	-1.64	-0.84	-1.88	-4.43	-1.32	-4.44	-0.11	-1.62	0.12	0.96	-1.87	-0.55	-0.81	-2.77	-1.11	0.56	-1.32	-0.45	-2.79	0.14	-4.29	-3.32	-0.53	-0.82	-0.55	-4.44	-2.41	-100000000.00	0.11	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.02	-1.70	-0.55	-0.62	-1.37	-0.85	-3.44	0.60	-1.07	-1.52	-2.02	0.80	-0.47	-0.36	-1.49	-4.00	-0.70	-1.53	-0.83	-1.20	-1.45	-2.80	-2.36	-0.43	-3.15	0.75	-1.49	-0.33	-1.20	-0.20	-1.58	-0.54	-2.68	-1.57	-2.25	-2.22	-3.97	-1.39	-1.32	-0.77	-3.31	-1.63	-1.92	-1.79	-0.64	-4.67	-100000000.00	-2.32	
, 	-1.96	-2.27	-0.37	-4.22	-0.88	-2.69	0.60	-1.94	0.98	0.84	-2.65	-1.95	-1.03	-1.78	-0.71	-5.27	0.61	0.46	-2.81	-1.04	-2.02	-3.12	-3.07	-0.17	-4.17	0.58	-2.71	-0.14	-0.77	-0.99	-3.99	-1.84	-3.73	-3.01	0.39	1.22	-2.05	-0.37	-2.96	-4.55	-2.07	-0.55	-2.35	-0.36	-6.11	-0.76	-100000000.00	0.33	
'' 	-4.47	-0.67	-1.05	0.64	-2.71	-1.34	-0.22	-2.54	-0.00	-1.71	-2.07	-0.33	-2.85	-4.89	0.56	0.00	-1.15	-2.32	-1.19	-1.36	-0.41	0.69	-3.34	0.89	-1.71	0.09	0.90	-3.62	-1.61	-1.27	-2.62	-0.18	-0.37	-2.18	1.82	-1.31	-0.27	-0.73	-0.09	-1.78	-1.06	-1.91	-1.97	-2.50	-3.59	-1.35	-100000000.00	0.05	
VBP 	-4.87	-2.39	-3.67	-3.62	-1.58	-1.10	0.30	-1.99	0.42	-3.13	0.37	-1.28	-1.70	-3.41	-2.18	-3.35	-1.17	-0.59	-2.20	-5.82	-3.65	-1.56	-2.62	-1.20	-3.84	-0.53	-2.11	1.05	1.03	-2.54	-1.83	-0.49	-0.61	-1.92	0.40	-0.15	0.73	-2.77	-1.02	-1.31	-5.12	0.73	-3.03	-3.00	-2.55	-4.27	-100000000.00	-0.24	
WDT 	-3.28	-3.64	-3.68	-1.39	-2.45	-0.96	-3.39	-1.69	-1.35	-2.57	-3.57	-1.93	0.50	-3.09	-2.09	-3.59	0.30	-0.73	-4.40	-3.59	-2.81	-1.06	-0.51	-0.73	-2.49	-2.13	0.48	0.50	-1.88	-1.95	-2.51	-1.81	-0.40	-3.11	-1.99	-1.16	-0.76	0.20	0.49	-1.22	-1.13	-2.02	-2.77	-2.19	-2.92	-2.02	-100000000.00	-0.36	
JJ 	0.84	-0.57	-0.21	-0.38	-0.17	-0.90	-1.06	0.01	-1.77	-0.19	-2.68	0.32	1.81	-0.11	-1.40	0.36	-1.61	-1.35	-0.77	-2.58	-0.01	-2.82	-0.10	-0.86	-5.73	-0.20	0.72	-1.68	-0.84	-0.11	0.23	-0.23	-5.18	0.33	0.73	0.51	-3.56	0.92	-0.39	-2.49	-2.82	-2.51	-0.63	-0.65	-1.55	-3.38	-100000000.00	-0.95	
WP 	-2.66	-2.51	-2.73	-2.58	-0.87	-0.87	0.66	-0.13	-1.01	-1.60	-1.39	-0.22	-0.74	-1.22	-1.90	-2.53	0.30	-1.40	-0.79	-1.75	-2.05	-2.40	0.70	-2.01	-1.57	-0.46	-2.05	0.08	-1.64	-0.04	-1.76	-0.90	-2.20	-1.85	-2.43	-2.66	-1.11	0.36	-1.92	-0.14	-2.45	-0.76	-2.32	-1.03	-1.80	-1.37	-100000000.00	-1.56	
VBZ 	-1.51	-2.59	-4.09	-3.49	-1.97	0.22	-1.58	-0.74	2.10	-1.22	-0.65	-1.93	-0.32	-0.52	-2.25	-2.51	0.70	-0.76	-0.58	-2.86	-2.44	-1.21	-2.87	-1.50	-2.50	-0.08	-1.10	-2.20	1.82	-2.04	0.23	-0.49	-3.25	-2.57	-3.44	-0.77	0.68	-2.64	-1.42	-1.63	-3.24	-3.12	-1.09	-2.64	-2.25	-5.40	-100000000.00	0.15	
DT 	-2.88	-1.76	-0.92	0.20	-0.31	-0.00	-1.17	-0.47	-1.49	-0.63	-2.10	-0.12	-1.48	-0.50	0.05	-5.34	0.10	-0.69	0.60	-1.67	-1.37	-1.65	0.62	-2.03	-3.54	-0.70	-0.21	-1.13	-1.24	1.20	-0.13	1.42	0.02	-1.01	0.80	-2.75	-2.17	1.54	0.17	-1.48	-1.65	-2.29	-3.19	-2.12	-0.67	-5.07	-100000000.00	-0.01	
" 	0.11	-0.35	-1.93	-1.59	-1.08	-0.15	0.77	-1.22	-0.58	-0.45	-1.62	-0.50	-0.46	-1.37	-0.01	-3.07	0.22	-0.95	-2.38	-3.12	0.95	0.87	-1.47	0.03	-0.12	-1.55	0.43	-1.90	-2.69	-1.34	-1.99	-1.27	-2.56	-3.39	-1.64	-0.80	-2.85	-1.12	-1.01	-3.60	-2.52	-2.07	-2.21	-0.72	-1.89	-3.35	-100000000.00	0.09	
RP 	-4.28	0.74	1.03	-3.29	0.94	-1.57	-2.91	1.17	-2.25	-1.25	-3.87	-0.43	0.43	-3.23	-1.41	-2.37	-1.67	-1.15	-3.02	-3.24	-1.77	-0.36	-4.05	-0.96	-2.40	-1.50	-3.32	-1.83	0.32	0.16	-2.72	-3.55	-1.69	-2.79	-0.83	-1.17	-6.02	-2.79	-0.85	-1.22	-4.75	-3.60	-2.46	-2.57	-3.38	-4.46	-100000000.00	-2.49	
$ 	-2.44	-1.21	-0.53	-4.97	-0.36	-2.13	-1.42	-0.64	-1.71	0.09	-1.85	-0.11	-0.63	-1.99	-0.43	1.18	0.38	-2.06	-0.61	-5.12	-0.22	-0.84	0.44	-0.66	0.85	-0.89	-0.40	-1.26	-1.89	0.15	-1.69	-0.16	-2.34	-0.61	-2.58	-1.06	-1.59	0.26	-1.97	-2.78	-0.54	-2.56	-1.36	-2.35	-3.55	-1.84	-100000000.00	0.52	
NN 	0.91	-0.33	-0.81	0.61	0.22	0.68	-1.21	-0.98	-1.77	0.77	-0.60	-0.13	0.40	-0.60	-1.26	-3.49	-0.77	-0.66	-0.95	-0.45	0.95	-1.00	-1.42	-1.90	-6.51	-2.49	0.63	-1.90	-2.67	-0.23	-1.87	-1.51	-2.42	-3.37	-0.29	-0.32	-4.08	0.14	1.65	-4.52	-4.48	-1.42	0.43	0.52	-1.30	-7.92	-100000000.00	-0.38	
) 	-3.51	-1.09	-2.72	-3.96	-1.01	-3.72	-3.34	-3.62	-4.72	-0.69	-4.31	-1.13	-2.38	-1.82	0.68	-3.17	-1.24	-2.03	-1.44	-2.27	-0.80	-3.38	-3.51	0.22	0.16	-2.23	-2.16	-2.38	-4.87	-0.97	-4.17	-2.81	-4.42	-2.23	-3.60	1.23	-1.05	-1.28	-2.32	-4.85	-3.09	-1.01	-5.92	-5.80	-3.31	-3.67	-100000000.00	-0.27	
( 	0.76	-3.72	-0.96	-1.99	-2.99	-2.70	-1.84	-3.62	-1.63	-1.07	-0.85	-1.02	-1.35	-0.60	-2.69	-4.51	0.35	-1.97	-3.32	-1.21	-0.89	-1.68	-1.47	-0.21	-1.88	-2.22	-1.61	-0.62	-1.37	-1.41	-1.98	-2.94	-4.81	-3.20	-4.04	0.62	-2.76	-3.31	-1.93	-2.28	-3.94	-1.20	-0.95	-2.38	-5.18	-1.76	-100000000.00	1.21	
FW 	-4.37	-3.57	-3.25	-1.43	-4.68	-1.24	-1.88	-1.24	-1.79	-2.21	-2.45	-5.91	-3.14	-3.42	-4.17	-1.58	-1.89	-1.37	-2.91	-0.43	-4.08	-0.98	-4.97	-0.61	-1.11	-3.90	-2.22	-2.94	-4.43	-2.36	0.11	-2.07	-2.26	-1.97	-2.78	-1.94	-2.34	-9.79	0.22	-1.81	-1.85	-1.55	-3.55	-3.66	-1.81	-0.81	-100000000.00	-0.52	
POS 	-1.81	-4.37	-1.61	-2.11	-0.16	-1.61	0.58	-1.64	0.98	0.13	-4.50	-3.26	-1.24	-1.76	-3.13	-2.93	1.69	-2.44	-2.00	-4.66	-2.74	-1.38	-2.66	-2.04	-4.80	-1.62	-0.65	0.03	-0.74	-2.20	-1.59	-2.29	-1.34	-0.06	-2.21	-1.42	-0.41	-1.90	-2.32	-2.43	-2.88	-1.58	-3.02	-1.68	-3.19	-3.73	-100000000.00	1.90	
. 	-2.44	-0.63	-1.37	-4.25	-0.63	-4.95	-2.50	-0.33	-3.03	-0.07	-2.59	0.13	-0.11	-0.53	-0.16	-6.15	-0.33	-0.68	-3.04	-2.82	-0.79	-0.98	-2.62	-0.73	-0.09	-0.41	-1.50	0.84	-0.82	-1.10	-0.60	-2.10	-2.41	-5.92	-0.67	0.58	-1.18	-1.43	-1.75	-3.94	-3.47	-0.43	-3.64	-0.78	-5.27	-2.07	-100000000.00	1.39	
TO 	-1.47	-1.72	-0.20	-1.40	-0.69	-2.02	-2.46	-0.02	-3.40	-0.86	-2.60	0.57	-2.70	-1.79	-0.26	-4.46	-0.82	-1.54	-1.89	-3.10	-3.75	-2.82	-2.07	-1.24	-3.24	-0.48	-1.49	-1.04	-1.76	-1.15	-0.94	-2.63	-4.72	-2.77	-0.51	0.67	-2.41	0.06	-1.27	-2.11	-3.43	-2.58	-1.19	-0.75	-4.52	-6.39	-100000000.00	-1.52	
-X- 	-0.34	0.07	-2.18	-2.55	-1.50	-1.56	-1.66	-1.40	-0.82	-1.85	-2.48	-2.38	-1.44	-2.21	0.35	-2.18	-0.64	-1.30	-2.44	-0.63	-1.52	-0.45	-2.14	2.00	-1.46	-2.13	-2.02	-1.25	-1.78	-1.48	0.22	0.00	1.67	-0.30	-0.29	-2.24	0.41	-2.03	0.84	1.11	0.82	-2.13	-1.87	1.64	-0.97	0.36	-100000000.00	-4.07	
LS 	-1.39	-1.92	-4.30	-0.60	-2.58	-1.90	-0.71	-3.76	-1.08	-3.72	-0.34	-1.69	-4.86	-2.57	-3.53	-4.08	-2.96	-2.19	-2.57	-2.80	-1.12	-0.03	-3.08	-1.55	-3.02	-4.51	1.00	-4.85	-2.55	-2.06	0.71	-3.96	-0.73	-0.63	-1.96	-4.12	-2.73	-3.01	-1.13	-1.04	-3.34	-3.59	-1.78	-4.06	-1.27	-1.85	-100000000.00	-3.29	
RB 	-1.35	-0.20	0.63	-0.48	0.16	-0.75	-0.63	0.29	-1.17	-1.55	-1.38	0.51	-0.38	0.12	-0.27	-2.59	-0.43	0.42	-0.64	-4.73	-1.48	-2.56	-0.16	-1.07	-3.18	-1.07	-1.39	-0.34	-0.16	0.15	-0.15	-0.80	-3.88	-1.75	-0.94	-0.45	-2.03	-0.66	-1.12	-0.52	0.85	-2.85	-1.29	-1.72	-1.81	-4.96	-100000000.00	-0.96	
: 	-4.50	-1.67	-1.03	-2.78	-1.08	-2.45	-3.35	-1.02	-2.35	0.30	-1.62	-0.36	-2.03	-2.33	-2.68	-2.38	0.15	-2.03	-2.10	-6.61	0.55	-2.11	-5.29	-1.86	-2.73	-1.22	-1.77	-2.18	-2.51	0.11	-3.58	-4.45	-2.34	-2.43	-1.68	0.21	-2.53	-0.22	-2.21	-3.15	-4.74	-0.19	-5.05	-0.62	-3.74	-4.08	-100000000.00	-0.19	
NNS 	1.68	-0.67	-0.58	-0.14	-0.30	-1.79	-2.18	-0.78	-0.97	0.93	-1.26	-1.15	-0.62	-1.65	-1.66	-3.55	-0.11	-1.95	-0.93	-2.07	0.37	-2.24	-1.96	-2.09	-5.32	-3.13	-0.14	-3.64	-1.50	-0.13	-0.13	0.29	-3.03	-2.03	-1.14	-0.39	-3.12	-0.85	0.77	-3.65	-1.65	-3.14	-0.62	0.61	-2.10	-7.82	-100000000.00	-1.09	
PRP 	-3.38	-0.96	-0.43	-0.64	0.54	-1.41	0.50	-0.95	-0.65	-1.68	0.47	-0.05	-2.35	-0.63	-2.90	-3.31	-0.51	-1.89	-3.67	-4.50	-0.40	-0.58	-0.64	0.01	-2.52	-1.20	0.49	-1.40	-4.37	0.95	0.53	-1.04	-1.61	-2.80	-1.71	-2.29	-0.80	0.92	-2.26	-1.88	-1.94	-4.10	-1.80	-3.55	-2.06	-2.90	-100000000.00	-1.28	
VB 	-2.83	-1.46	-2.78	0.09	-3.62	-0.11	-1.91	-1.32	-0.85	-2.46	-0.70	-1.46	-0.78	-0.71	-1.85	0.47	-1.03	0.18	-2.08	-1.67	-4.44	-0.64	0.51	-0.90	-3.10	0.54	0.14	-1.39	0.17	-2.01	-1.79	0.95	0.34	-1.70	0.47	-1.61	-2.47	-2.14	-2.20	-1.14	1.62	-2.17	-0.99	-0.26	-3.69	-0.92	-100000000.00	-1.33	
WRB 	-2.32	-1.01	-1.57	-1.13	-0.79	-0.50	-1.63	-0.91	-1.61	-0.08	-1.44	0.53	-4.27	-1.50	-0.43	-1.33	-0.49	-2.67	-2.01	-2.96	-2.27	-0.45	-1.80	0.05	-1.68	-1.38	-3.36	-1.54	-1.28	-0.77	-2.72	-1.17	-2.96	-1.38	-4.25	-1.07	-1.95	-0.82	0.72	-1.17	-2.73	-4.33	-1.82	-1.19	-3.29	-0.38	-100000000.00	-0.72	
CC 	-3.44	-1.81	-2.01	-1.56	-0.53	-0.23	-3.04	-0.72	-2.00	0.88	-2.61	-1.52	-3.01	-1.44	-0.75	-3.09	-0.30	-1.63	-3.98	-3.69	-1.05	-0.36	-1.42	-2.21	-2.99	-0.62	0.37	-1.09	-0.77	0.19	-2.04	-2.92	-1.79	-4.62	-0.06	0.61	-0.66	-1.38	-1.44	-2.21	-2.81	-0.24	-2.34	-0.52	-1.57	-5.69	-100000000.00	0.29	
PDT 	-2.82	0.29	-2.95	-1.95	-0.38	-4.11	-2.34	-0.64	-3.43	-1.65	-3.80	-0.67	-2.78	-2.40	-1.53	-2.31	-2.89	-2.18	-0.33	-1.23	-0.21	-0.58	-3.80	0.08	-1.28	-0.67	-1.61	-0.98	-2.79	-1.57	-0.44	-1.51	-0.53	0.50	-2.15	-2.60	-0.76	0.97	-0.83	-1.15	-0.34	-1.68	-2.17	-1.62	-4.19	-1.37	-100000000.00	-0.43	
RBS 	-0.50	-3.02	-0.81	-5.50	-1.31	-1.07	-0.49	-2.72	-3.55	-2.26	0.63	-0.60	-0.60	-2.45	-1.41	-1.72	-1.21	-2.76	-3.49	-2.47	-0.48	-0.27	-1.21	1.78	-3.07	-0.17	-3.55	-7.69	-4.47	-1.18	-2.83	0.20	-2.21	-0.84	-1.69	-2.53	-1.41	0.54	-1.00	0.17	-3.45	-2.48	-3.86	-4.19	-2.67	-2.13	-100000000.00	-6.97	
RBR 	-3.17	-1.60	0.08	-0.94	0.11	-2.22	-0.65	-1.61	-0.05	-1.64	0.13	-0.20	-0.51	-2.21	-0.56	-2.43	-0.28	-1.92	-2.77	-4.22	-3.38	-1.51	-0.99	0.54	0.06	0.11	-0.51	0.12	-1.43	-0.31	-2.38	-1.29	-1.17	-0.95	-3.52	-2.14	-3.98	-0.61	-0.70	0.00	-0.25	-2.55	-1.46	-2.19	-1.40	-0.91	-100000000.00	-0.59	
CD 	-0.93	-0.84	-0.57	-0.87	-1.49	-0.44	-1.15	-1.61	-1.61	-0.50	-2.42	-0.66	-0.71	-0.72	-2.84	2.63	-0.83	-0.57	-0.43	-1.51	0.39	-3.31	0.10	-2.49	-7.09	-0.72	-0.15	-1.63	-1.39	-0.14	-0.91	-0.75	-1.68	-4.68	-5.84	-0.73	-5.82	-0.32	-0.03	-0.01	-5.17	-0.97	-1.45	-0.93	-1.60	-2.28	-100000000.00	-0.41	
EX 	-1.00	-1.01	0.11	0.06	-1.57	-2.46	-1.91	-0.77	-0.57	-0.66	-0.11	-0.26	0.13	-0.44	-2.10	-2.25	-0.64	-2.58	-3.46	-3.44	-2.84	-2.33	-3.75	-1.22	-1.21	-1.88	-1.52	-2.43	-0.71	-0.73	-0.81	0.89	-1.02	-1.79	0.46	-2.28	-1.82	-1.37	-1.00	-0.58	-0.94	-1.97	-0.77	-2.45	-3.06	-0.90	-100000000.00	-1.33	
IN 	-2.73	-0.98	-1.05	-0.45	0.18	-0.24	-1.99	0.37	-0.74	-0.95	-3.55	-0.28	-0.83	0.50	-0.75	-2.15	0.22	-0.57	-1.47	-4.00	-1.47	-3.17	-1.05	-2.08	-6.56	-1.27	-1.46	0.17	-1.12	-0.20	-2.10	-0.59	-3.00	-1.63	0.93	-0.54	-1.07	-0.35	-2.24	0.44	-4.42	-1.74	0.10	0.01	-2.53	-7.59	-100000000.00	-0.53	
WP$ 	-0.49	-1.71	-1.08	-4.98	-2.01	0.50	-0.86	-2.66	-0.32	-1.31	0.73	-1.66	-0.73	-1.33	-1.41	0.77	-1.11	-0.82	-2.12	-0.89	-0.30	-2.53	-2.15	0.36	-1.11	-1.58	-1.83	-0.42	-1.30	-2.52	-2.50	-2.54	-0.48	0.28	0.18	-2.39	-0.91	-1.82	-1.94	0.04	-0.39	-0.73	-1.99	-1.29	-1.52	-0.00	-100000000.00	-1.81	
NN|SYM 	-0.63	-3.45	-2.23	-4.99	-3.27	-0.82	-1.53	-3.41	0.45	-2.18	-1.41	-2.61	-3.47	-3.37	-2.09	-2.14	-5.27	-0.40	-1.13	-1.47	-1.74	1.33	-3.65	0.50	-1.25	-2.35	-3.16	-3.91	-2.57	-2.62	-1.26	-3.00	-0.09	0.69	-2.19	-3.99	-0.44	-2.50	-0.14	-0.78	-2.40	-1.58	-2.52	-2.46	-3.14	-1.87	-100000000.00	-3.90	
MD 	-0.47	-2.14	-1.68	-3.43	-3.12	-1.09	-1.61	-1.93	1.02	-1.00	-1.13	-1.82	-1.15	-1.26	-0.43	-3.35	-0.51	-1.40	-4.01	-4.62	-2.04	0.11	-2.89	-0.83	-1.54	-1.50	-1.79	-0.27	0.23	-1.92	-0.48	-1.43	-2.00	-1.60	-3.77	-1.63	-0.36	-2.58	-2.25	0.03	-2.48	-1.23	-3.57	-4.50	-3.88	-1.83	-100000000.00	-0.30	
NNPS 	-3.92	-2.33	-2.13	-2.33	-1.76	-1.68	-2.53	-1.08	-2.20	-1.52	-3.08	-1.76	-0.86	-1.89	-3.06	-3.52	-2.90	0.29	-1.38	-5.03	-3.21	-1.25	-3.77	-1.03	-2.86	-6.13	-1.64	-5.66	-4.08	-1.30	-2.04	-1.96	-2.16	-1.22	-4.64	-0.91	-3.20	-1.40	-0.44	-3.35	-3.54	-1.40	-3.66	-4.14	-2.53	-6.43	-100000000.00	0.31	
JJS 	-0.29	-4.80	-1.34	-0.84	-0.70	-1.96	-0.82	-2.27	-2.73	-1.33	-1.58	-3.36	-1.25	-1.41	-2.99	-2.30	-4.45	-3.08	-2.18	-3.21	-1.30	-0.98	-1.56	-2.47	-3.03	-3.67	-4.03	-4.16	-3.05	-1.72	-1.80	-2.55	-1.00	-0.69	-3.04	-2.68	-0.54	-0.78	-0.18	-0.71	-3.11	-4.56	-2.58	-5.25	-3.13	-1.59	-100000000.00	-4.21	
JJR 	-1.80	-1.28	-0.01	-0.18	-0.82	-2.70	-1.40	-0.77	-3.18	-1.33	-3.67	0.11	-1.09	-1.53	-2.31	-1.98	-2.10	-5.14	0.39	-3.12	-6.18	-0.91	-1.21	-0.16	-2.47	-0.16	-1.43	-1.08	-1.23	0.46	-0.51	-1.40	-3.69	-3.36	-3.10	-1.53	-1.89	-0.80	-1.40	-0.19	-1.81	-2.68	-3.30	-4.69	-2.01	-4.10	-100000000.00	-1.94	
SYM 	-0.73	-1.37	-4.36	-0.79	-5.31	-5.67	-1.48	-0.93	-3.60	-0.28	-3.91	-4.06	-4.08	-0.85	-3.94	-1.83	-1.17	-0.72	-2.65	-2.95	-3.20	-0.45	-5.59	-1.14	-2.69	-3.00	-3.73	-2.01	-0.97	-3.30	-3.50	-1.06	-2.13	-2.71	-4.01	-0.46	-3.52	-3.09	-0.32	-1.28	-2.74	-4.18	-2.30	-2.30	-3.30	-0.55	-100000000.00	-0.72	
UH 	-2.56	-3.61	-3.90	-1.03	-5.26	-0.97	0.89	-1.32	-4.02	-5.97	-0.15	-4.69	-9.47	-0.02	-3.08	-3.57	-8.14	-5.13	-4.94	-1.73	-5.41	-2.45	-4.70	-0.55	-1.33	-2.70	-5.21	-6.86	-2.22	-4.27	-1.12	-4.22	-1.22	-1.95	-3.20	-9.27	-3.94	-1.59	-1.63	0.85	-3.20	-5.74	-2.31	-1.86	-2.58	-2.24	-100000000.00	-4.78	
stop_tag 	-3.07	-6.49	-1.26	-0.88	-1.49	-3.52	-1.45	-3.78	-6.28	0.57	-3.79	-1.39	-1.26	-1.60	-0.45	-3.75	0.39	-0.73	-4.42	-1.64	-0.32	-0.98	-4.62	-1.44	-5.44	-1.14	-1.41	-0.33	-3.09	-1.05	-5.49	-2.68	-5.92	-4.35	-6.72	1.07	-3.11	-1.36	-1.75	-2.25	-4.89	-1.24	-6.88	-5.35	0.46	-5.08	-100000000.00	0.12	
NNP 	-0.38	-1.04	-0.47	-0.31	-0.65	-1.06	-0.47	-1.25	-1.30	-0.66	-1.67	-0.37	-0.62	-0.78	-1.47	-2.05	-0.87	-0.43	-0.66	-0.41	0.92	-2.03	-0.96	-0.41	-5.99	-2.44	0.07	-1.99	-2.60	-0.34	-0.54	0.59	-5.02	-3.86	-1.62	-0.67	-4.45	-0.48	-1.62	-3.71	-1.84	-0.95	-2.24	-0.31	-1.24	-1.58	-100000000.00	1.06	
Mean train loss after  0 batches of 5  epochs =0.0168785095215
Mean train loss after  100 batches of 5  epochs =0.0470870179993
Mean train loss after  200 batches of 5  epochs =0.0464556664621
Mean train loss after  300 batches of 5  epochs =0.0441882940139
Mean train loss after  400 batches of 5  epochs =0.0467252632885
Mean train loss after  500 batches of 5  epochs =0.0438157675103
Mean train loss after  600 batches of 5  epochs =0.0430859991843
Mean train loss after  700 batches of 5  epochs =0.0438332066966
Mean train loss after  800 batches of 5  epochs =0.0415417141033
Mean train loss after  900 batches of 5  epochs =0.0402649614901
Mean train loss after  1000 batches of 5  epochs =0.039504530822
Mean train loss after  1100 batches of 5  epochs =0.0403725932677
Mean train loss after  1200 batches of 5  epochs =0.0403876209314
Mean train loss after  1300 batches of 5  epochs =0.0400916235508
Mean train loss after  1400 batches of 5  epochs =0.0415857159831
Mean train loss after  1500 batches of 5  epochs =0.0420855898234
Mean train loss after  1600 batches of 5  epochs =0.0417278943893
Mean train loss after  1700 batches of 5  epochs =0.0421377384517
Mean train loss after  1800 batches of 5  epochs =0.0419337944249
Mean train loss after  1900 batches of 5  epochs =0.0414839193388
Mean train loss after  2000 batches of 5  epochs =0.0413653888875
Mean train loss after  2100 batches of 5  epochs =0.0418665101078
Mean train loss after  2200 batches of 5  epochs =0.0414850823921
Mean train loss after  2300 batches of 5  epochs =0.0414122125008
Mean train loss after  2400 batches of 5  epochs =0.0406621820574
Mean train loss after  2500 batches of 5  epochs =0.0408007173343
Mean train loss after  2600 batches of 5  epochs =0.0409567888599
Mean train loss after  2700 batches of 5  epochs =0.0412517669112
Mean train loss after  2800 batches of 5  epochs =0.0407278376077
Mean train loss after  2900 batches of 5  epochs =0.0408007997118
Mean train loss after  3000 batches of 5  epochs =0.0406260727764
Mean train loss after  3100 batches of 5  epochs =0.0406900092044
Mean train loss after  3200 batches of 5  epochs =0.0409433764899
Mean train loss after  3300 batches of 5  epochs =0.0407809312627
Mean train loss after  3400 batches of 5  epochs =0.0403853688615
Mean train loss after  3500 batches of 5  epochs =0.0408350658167
Mean train loss after  3600 batches of 5  epochs =0.0408496060348
Mean train loss after  3700 batches of 5  epochs =0.0406388294521
Mean train loss after  3800 batches of 5  epochs =0.0408060947695
Mean train loss after  3900 batches of 5  epochs =0.0408456630557
Mean train loss after  4000 batches of 5  epochs =0.0411749827682
Mean train loss after  4100 batches of 5  epochs =0.0414351964588
Mean train loss after  4200 batches of 5  epochs =0.0416713423245
Mean train loss after  4300 batches of 5  epochs =0.0419672075936
Mean train loss after  4400 batches of 5  epochs =0.0424982607568
Mean train loss after  4500 batches of 5  epochs =0.042662813287
Mean train loss after  4600 batches of 5  epochs =0.042349432644
Mean train loss after  4700 batches of 5  epochs =0.0424202910934
Mean train loss after  4800 batches of 5  epochs =0.0426566622538
Mean train loss after  4900 batches of 5  epochs =0.0429628983558
Mean train loss after  5000 batches of 5  epochs =0.0432251195536
Mean train loss after  5100 batches of 5  epochs =0.0436730072869
Mean train loss after  5200 batches of 5  epochs =0.0436596824368
Mean train loss after  5300 batches of 5  epochs =0.043949512491
Mean train loss after  5400 batches of 5  epochs =0.0439194682579
Mean train loss after  5500 batches of 5  epochs =0.0438644596739
Mean train loss after  5600 batches of 5  epochs =0.0438203952982
Mean train loss after  5700 batches of 5  epochs =0.0438534185843
Mean train loss after  5800 batches of 5  epochs =0.0441084081436
Mean train loss after  5900 batches of 5  epochs =0.0442404472703
Mean train loss after  6000 batches of 5  epochs =0.0442342083383
Mean train loss after  6100 batches of 5  epochs =0.0447058337942
Mean train loss after  6200 batches of 5  epochs =0.0448408962487
Mean train loss after  6300 batches of 5  epochs =0.0449350531682
Mean train loss after  6400 batches of 5  epochs =0.0448063582069
Mean train loss after  6500 batches of 5  epochs =0.0448216306524
Mean train loss after  6600 batches of 5  epochs =0.0451978099029
Mean train loss after  6700 batches of 5  epochs =0.0450847382598
Mean train loss after  6800 batches of 5  epochs =0.0451232933247
Mean train loss after  6900 batches of 5  epochs =0.0450238823645
Mean train loss after  7000 batches of 5  epochs =0.0450330909788
Mean train loss after  7100 batches of 5  epochs =0.0452947564712
Mean train loss after  7200 batches of 5  epochs =0.0452457670852
Mean train loss after  7300 batches of 5  epochs =0.0452273071317
Mean train loss after  7400 batches of 5  epochs =0.0455835640259
Mean train loss after  7500 batches of 5  epochs =0.0458208444769
Mean train loss after  7600 batches of 5  epochs =0.046188989991
Mean train loss after  7700 batches of 5  epochs =0.0462793744438
Mean train loss after  7800 batches of 5  epochs =0.0462385512224
Mean train loss after  7900 batches of 5  epochs =0.0462475579674
Mean train loss after  8000 batches of 5  epochs =0.0464822550537
Mean train loss after  8100 batches of 5  epochs =0.0464334346403
Mean train loss after  8200 batches of 5  epochs =0.0466188283784
Mean train loss after  8300 batches of 5  epochs =0.0466257363288
Mean train loss after  8400 batches of 5  epochs =0.0465942776769
Mean train loss after  8500 batches of 5  epochs =0.0466614543057
Mean train loss after  8600 batches of 5  epochs =0.0467043340474
Mean train loss after  8700 batches of 5  epochs =0.0469028559879
Mean train loss after  8800 batches of 5  epochs =0.0470153087482
Mean train loss after  8900 batches of 5  epochs =0.0472321206076
Mean train loss after  9000 batches of 5  epochs =0.0471785473823
Mean train loss after  9100 batches of 5  epochs =0.0472241085525
Mean train loss after  9200 batches of 5  epochs =0.0471729928483
Mean train loss after  9300 batches of 5  epochs =0.0471369490751
Mean train loss after  9400 batches of 5  epochs =0.0470659988693
Mean train loss after  9500 batches of 5  epochs =0.047278200421
Mean train loss after  9600 batches of 5  epochs =0.047341781279
Mean train loss after  9700 batches of 5  epochs =0.0476211553265
Mean train loss after  9800 batches of 5  epochs =0.0477904979163
Mean train loss after  9900 batches of 5  epochs =0.0478191662488
Mean train loss after  10000 batches of 5  epochs =0.0479236028814
Mean train loss after  10100 batches of 5  epochs =0.0480965648402
Mean train loss after  10200 batches of 5  epochs =0.04824905131
Mean train loss after  10300 batches of 5  epochs =0.0483975711868
Mean train loss after  10400 batches of 5  epochs =0.048456028174
Mean train loss after  10500 batches of 5  epochs =0.0485811388185
Mean train loss after  10600 batches of 5  epochs =0.048691789254
Mean train loss after  10700 batches of 5  epochs =0.04875020848
Mean train loss after  10800 batches of 5  epochs =0.0487692747666
Mean train loss after  10900 batches of 5  epochs =0.0488337242219
Mean train loss after  11000 batches of 5  epochs =0.0489555270777
Mean train loss after  11100 batches of 5  epochs =0.0488344973651
Mean train loss after  11200 batches of 5  epochs =0.0489094299124
Mean train loss after  11300 batches of 5  epochs =0.0492233997991
Mean train loss after  11400 batches of 5  epochs =0.0494812701259
Mean train loss after  11500 batches of 5  epochs =0.049432054104
Mean train loss after  11600 batches of 5  epochs =0.0493939761541
Mean train loss after  11700 batches of 5  epochs =0.0495725665142
Mean train loss after  11800 batches of 5  epochs =0.0494844257349
Mean train loss after  11900 batches of 5  epochs =0.0496206577521
Mean train loss after  12000 batches of 5  epochs =0.0496507311556
Mean train loss after  12100 batches of 5  epochs =0.049663255691
Mean train loss after  12200 batches of 5  epochs =0.0496169896935
Mean train loss after  12300 batches of 5  epochs =0.0497041892807
Mean train loss after  12400 batches of 5  epochs =0.0497328973278
Mean train loss after  12500 batches of 5  epochs =0.0496976877827
Mean train loss after  12600 batches of 5  epochs =0.0497163145642
Mean train loss after  12700 batches of 5  epochs =0.0497035856318
Mean train loss after  12800 batches of 5  epochs =0.0497190712415
Mean train loss after  12900 batches of 5  epochs =0.0497717033802
Mean train loss after  13000 batches of 5  epochs =0.0499231465923
Mean train loss after  13100 batches of 5  epochs =0.0500882970492
Mean train loss after  13200 batches of 5  epochs =0.0500470129284
Mean train loss after  13300 batches of 5  epochs =0.050154149458
Mean train loss after  13400 batches of 5  epochs =0.0501605511199
Mean train loss after  13500 batches of 5  epochs =0.0501319125524
Mean train loss after  13600 batches of 5  epochs =0.0502881474243
Mean train loss after  13700 batches of 5  epochs =0.0504206991592
Mean train loss after  13800 batches of 5  epochs =0.0503664413951
Mean train loss after  13900 batches of 5  epochs =0.0504186249681
Mean train loss after  14000 batches of 5  epochs =0.0505086537227
Mean train loss after  14100 batches of 5  epochs =0.0504770275566
Mean train loss after  14200 batches of 5  epochs =0.0505837390841
Mean train loss after  14300 batches of 5  epochs =0.0506877014529
Mean train loss after  14400 batches of 5  epochs =0.0507936925921
Mean train loss after  14500 batches of 5  epochs =0.0508145242616
Mean train loss after  14600 batches of 5  epochs =0.0507698097588
Mean train loss after  14700 batches of 5  epochs =0.0509035761017
Mean train loss after  14800 batches of 5  epochs =0.0509154288886
Mean train loss after  14900 batches of 5  epochs =0.0509459275777
Epoch 5 : Mean train epoch loss =0.0510019500688
Epoch 5 Epoch val loss = 15436.4317324
Epoch 5 Epoch val perplexity = 1.3700000535075045
SCORES =  (92.56, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 6---------------------

=================================
fscore(z) =  [18.478075] || goldscore = [18.478075]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-4.96	-0.91	-0.02	-2.34	-0.32	-1.86	-0.06	-1.44	-1.14	-1.68	-2.62	-0.00	-0.33	-0.67	-0.72	-2.43	-2.20	-3.45	-3.08	-2.77	-2.60	-3.10	0.85	-1.46	-3.22	-3.09	-4.03	-1.99	-1.71	0.48	-0.77	0.42	-1.30	-2.23	-1.15	-3.65	-3.27	0.09	-2.87	-2.04	-4.21	-2.39	-3.56	-2.21	-1.43	-3.76	-100000000.00	-2.92	
VBG 	-1.64	-3.08	-0.02	0.17	-0.28	-0.02	-1.79	-0.47	-2.13	-2.26	-3.30	0.22	-0.00	-1.10	-1.46	-4.33	-0.21	-2.14	-2.85	-5.64	-0.94	-1.85	-0.46	0.40	-2.94	-0.73	-1.50	0.15	-2.82	-0.42	-1.92	-0.38	-3.55	-0.98	-0.17	-0.88	-3.77	0.27	-1.20	-1.97	-1.54	-1.20	-0.24	-2.01	-2.29	-7.22	-100000000.00	-1.20	
VBD 	-2.86	-3.75	-3.63	-1.55	-1.47	0.86	-1.14	-1.19	1.75	-1.87	-0.12	-1.81	-1.55	-0.89	-1.42	-2.66	-0.11	0.53	-1.75	-1.99	-1.09	-2.07	-4.67	-1.36	-4.80	-0.14	-1.87	0.08	0.96	-1.97	-0.62	-0.88	-3.13	-1.14	0.30	-1.46	-0.35	-2.88	0.02	-4.46	-3.67	-0.56	-0.92	-0.61	-4.74	-2.80	-100000000.00	0.04	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.37	-1.79	-0.70	-0.60	-1.63	-0.95	-3.56	0.65	-1.26	-1.63	-2.22	0.80	-0.60	-0.63	-1.56	-4.21	-0.62	-1.76	-1.07	-1.45	-1.48	-2.97	-2.52	-0.49	-3.52	0.74	-1.52	-0.44	-1.30	-0.31	-1.59	-0.53	-2.79	-1.77	-2.14	-2.30	-4.15	-1.43	-1.43	-1.12	-3.81	-1.73	-2.17	-1.92	-0.91	-5.23	-100000000.00	-2.44	
, 	-2.06	-2.43	-0.46	-4.53	-0.95	-3.18	0.58	-2.07	0.72	0.86	-3.02	-2.17	-1.18	-2.01	-0.68	-5.54	0.57	0.32	-3.10	-1.19	-2.01	-3.32	-3.35	-0.22	-4.38	0.66	-2.87	-0.09	-0.95	-1.22	-4.26	-2.06	-4.08	-3.12	0.47	1.22	-2.19	-0.38	-3.02	-4.73	-2.20	-0.61	-2.76	-0.69	-6.71	-0.89	-100000000.00	0.25	
'' 	-4.60	-0.79	-1.06	0.62	-2.84	-1.15	-0.38	-2.67	-0.09	-1.91	-2.14	-0.54	-3.07	-5.17	0.50	-0.16	-1.05	-2.44	-1.46	-1.46	-0.80	0.80	-3.63	0.89	-1.80	-0.05	0.54	-3.80	-1.83	-1.40	-2.74	-0.15	-0.55	-2.35	1.76	-1.36	-0.34	-0.75	-0.19	-1.85	-1.12	-2.18	-2.09	-2.57	-3.76	-1.46	-100000000.00	-0.09	
VBP 	-5.34	-2.68	-4.07	-4.02	-1.79	-1.34	0.12	-2.22	0.58	-3.45	0.36	-1.53	-1.94	-3.72	-2.34	-3.64	-1.35	-0.72	-2.40	-6.46	-3.81	-1.76	-2.76	-1.21	-4.23	-0.57	-2.58	1.09	0.98	-2.66	-2.16	-0.61	-0.73	-2.22	0.03	-0.25	0.80	-3.24	-1.18	-1.58	-5.68	0.69	-3.50	-3.22	-2.80	-4.57	-100000000.00	-0.34	
WDT 	-3.52	-3.86	-3.98	-1.38	-2.63	-0.98	-3.53	-1.87	-1.50	-2.69	-4.05	-2.26	0.39	-3.22	-2.25	-3.74	0.38	-0.85	-4.75	-3.86	-3.02	-1.10	-0.62	-0.73	-2.73	-2.48	0.35	0.51	-2.09	-2.32	-2.73	-1.88	-0.60	-3.37	-2.35	-1.21	-1.00	0.09	0.36	-1.29	-1.40	-2.34	-3.08	-2.41	-3.18	-2.20	-100000000.00	-0.39	
JJ 	0.68	-0.76	-0.26	-0.44	-0.22	-1.03	-1.20	0.04	-1.91	-0.37	-3.01	0.24	1.81	-0.09	-1.44	0.27	-1.76	-1.40	-0.87	-2.74	-0.08	-3.00	-0.13	-0.93	-6.00	-0.18	0.63	-1.74	-0.88	-0.11	0.13	-0.29	-5.35	0.30	0.80	0.56	-3.90	1.05	-0.44	-2.87	-2.93	-2.67	-0.67	-0.76	-1.66	-3.56	-100000000.00	-0.97	
WP 	-2.84	-2.56	-2.89	-2.59	-1.01	-1.02	0.67	-0.28	-1.06	-1.63	-1.70	-0.24	-0.86	-1.27	-2.14	-2.75	0.26	-1.64	-1.07	-2.03	-2.23	-2.43	0.51	-2.02	-1.80	-0.82	-2.41	0.11	-1.81	-0.23	-2.02	-1.00	-2.44	-2.07	-2.81	-2.88	-1.35	0.23	-2.09	-0.29	-2.67	-0.84	-2.56	-1.34	-2.08	-1.45	-100000000.00	-1.56	
VBZ 	-1.69	-2.84	-4.39	-3.79	-2.34	0.13	-1.68	-0.96	2.07	-1.38	-0.53	-2.18	-0.44	-0.76	-2.47	-2.70	0.79	-0.78	-0.65	-2.87	-2.80	-1.40	-2.91	-1.55	-2.82	-0.19	-1.49	-2.28	1.80	-2.47	0.01	-0.65	-3.58	-2.75	-3.59	-0.96	0.82	-2.81	-1.54	-1.87	-3.52	-3.41	-1.34	-2.76	-2.45	-5.73	-100000000.00	-0.02	
DT 	-3.10	-1.84	-0.93	0.10	-0.38	-0.09	-1.28	-0.40	-1.64	-0.76	-2.22	-0.18	-1.79	-0.60	0.10	-5.60	-0.11	-0.82	0.44	-1.89	-1.57	-1.92	0.64	-2.06	-3.84	-0.82	-0.34	-1.18	-1.37	1.21	-0.16	1.50	0.13	-1.39	0.80	-2.87	-2.53	1.59	-0.02	-1.86	-1.86	-2.64	-3.46	-2.24	-0.73	-5.25	-100000000.00	0.04	
" 	0.06	-0.43	-2.02	-1.72	-1.15	-0.12	0.82	-1.45	-0.56	-0.38	-1.92	-0.56	-0.58	-1.79	-0.11	-3.32	0.11	-1.05	-2.49	-3.37	0.96	0.99	-1.60	0.03	-0.24	-1.68	0.48	-2.14	-2.94	-1.48	-2.17	-1.45	-2.79	-3.64	-1.97	-0.99	-3.08	-1.13	-1.06	-3.62	-2.86	-2.26	-2.56	-1.11	-2.03	-3.63	-100000000.00	0.06	
RP 	-4.71	0.84	1.13	-3.47	0.94	-1.68	-3.13	1.15	-2.63	-1.49	-4.29	-0.50	0.24	-3.64	-1.61	-2.66	-1.68	-1.29	-3.38	-3.53	-2.05	-0.51	-4.54	-0.96	-2.63	-1.65	-3.98	-1.86	0.22	0.22	-2.96	-3.73	-1.86	-2.99	-1.09	-1.43	-6.12	-3.13	-0.98	-1.43	-4.97	-3.73	-2.57	-2.86	-3.53	-4.67	-100000000.00	-2.70	
$ 	-2.49	-1.27	-0.63	-5.35	-0.42	-2.12	-1.57	-0.99	-1.92	0.09	-2.23	-0.22	-0.56	-2.28	-0.46	0.98	0.28	-2.22	-0.67	-5.45	-0.17	-0.91	0.41	-0.68	0.63	-1.02	-0.50	-1.35	-1.87	0.10	-1.96	-0.21	-2.50	-0.82	-2.91	-1.11	-1.87	0.33	-1.99	-2.84	-0.82	-2.81	-1.55	-2.51	-3.75	-2.18	-100000000.00	0.56	
NN 	0.94	-0.36	-0.85	0.60	0.24	0.65	-1.48	-1.07	-1.89	0.75	-0.89	-0.15	0.35	-0.69	-1.26	-3.77	-0.86	-0.72	-1.06	-0.75	0.95	-1.24	-1.46	-1.98	-6.68	-2.65	0.63	-1.93	-2.76	-0.29	-1.92	-1.60	-2.88	-3.47	-0.44	-0.42	-4.49	0.08	1.60	-4.81	-4.73	-1.56	0.39	0.42	-1.39	-8.55	-100000000.00	-0.37	
) 	-3.90	-1.35	-2.94	-4.17	-1.15	-4.01	-3.70	-3.75	-5.18	-0.81	-4.89	-1.08	-2.54	-2.01	0.46	-3.52	-1.41	-2.43	-1.67	-2.70	-0.90	-3.45	-3.80	0.18	0.14	-2.41	-2.56	-2.44	-5.36	-1.17	-4.50	-3.24	-4.81	-2.66	-4.11	1.20	-1.44	-1.61	-2.36	-5.06	-3.56	-1.09	-6.20	-6.43	-3.41	-3.96	-100000000.00	-0.23	
( 	0.52	-3.68	-1.12	-2.26	-3.13	-2.83	-2.09	-3.92	-1.70	-1.17	-1.14	-1.13	-1.64	-0.70	-2.98	-4.88	0.25	-2.14	-3.74	-1.36	-0.91	-1.98	-1.82	-0.28	-2.18	-2.57	-1.79	-0.67	-1.66	-1.62	-2.12	-3.27	-5.13	-3.37	-4.59	0.60	-2.92	-3.69	-2.01	-2.56	-4.46	-1.26	-1.02	-2.46	-5.48	-2.26	-100000000.00	1.19	
FW 	-4.83	-4.14	-3.35	-1.78	-5.12	-1.72	-2.00	-1.36	-2.05	-2.25	-2.78	-6.23	-3.27	-3.57	-4.59	-1.72	-2.19	-1.45	-3.18	-0.61	-4.79	-1.11	-5.26	-0.62	-1.51	-4.44	-2.35	-2.96	-4.92	-2.45	-0.13	-2.27	-2.52	-2.18	-3.02	-2.22	-2.66	-10.40	0.07	-1.99	-2.15	-1.83	-3.89	-4.07	-2.13	-1.33	-100000000.00	-0.61	
POS 	-2.09	-4.75	-1.79	-2.33	-0.36	-1.79	0.75	-1.69	0.81	0.03	-4.62	-3.53	-1.46	-2.21	-3.28	-3.21	1.61	-2.70	-2.42	-4.97	-3.08	-1.48	-3.01	-2.07	-5.09	-1.93	-1.27	-0.01	-0.96	-2.23	-1.80	-2.37	-1.63	-0.36	-2.44	-1.58	-0.57	-2.06	-2.38	-2.64	-3.12	-1.53	-3.27	-2.06	-3.53	-4.09	-100000000.00	1.93	
. 	-2.58	-0.81	-1.49	-4.64	-0.76	-5.34	-2.67	-0.49	-3.64	0.03	-3.02	-0.17	-0.25	-0.65	-0.18	-6.40	-0.39	-0.75	-3.30	-3.52	-0.89	-1.29	-2.99	-0.76	-0.12	-0.58	-1.82	0.79	-0.99	-1.22	-1.08	-2.17	-2.80	-6.57	-0.68	0.57	-1.42	-1.56	-1.86	-4.18	-3.91	-0.45	-3.98	-1.12	-5.64	-2.17	-100000000.00	1.43	
TO 	-1.64	-1.86	-0.36	-1.80	-0.80	-2.23	-2.96	-0.08	-3.78	-0.89	-2.98	0.53	-2.82	-1.98	-0.37	-4.78	-0.80	-1.72	-2.26	-3.41	-4.14	-3.13	-2.68	-1.33	-3.64	-0.49	-1.63	-1.04	-1.95	-1.15	-1.17	-2.73	-5.12	-3.20	-0.54	0.67	-2.57	0.05	-1.44	-2.47	-3.69	-2.84	-1.58	-0.86	-4.89	-6.85	-100000000.00	-1.50	
-X- 	-0.35	-0.00	-2.21	-2.67	-1.52	-1.61	-1.66	-1.41	-0.82	-1.91	-2.48	-2.39	-1.47	-2.22	0.34	-2.18	-0.75	-1.34	-2.47	-0.64	-1.53	-0.47	-2.19	2.00	-1.46	-2.16	-2.09	-1.35	-1.84	-1.52	0.21	-0.03	1.66	-0.30	-0.29	-2.34	0.41	-2.08	0.84	1.11	0.80	-2.15	-1.88	1.62	-1.00	0.35	-100000000.00	-4.10	
LS 	-1.59	-2.14	-4.47	-0.68	-2.85	-2.14	-0.85	-3.95	-1.23	-3.98	-0.65	-1.92	-5.32	-2.68	-3.71	-4.19	-3.01	-2.35	-2.84	-3.04	-1.28	-0.10	-3.42	-1.55	-3.20	-4.79	1.00	-5.16	-2.84	-2.27	0.49	-4.23	-0.82	-0.79	-2.17	-4.44	-2.85	-3.41	-1.17	-1.10	-3.54	-3.80	-1.92	-4.32	-1.46	-1.99	-100000000.00	-3.64	
RB 	-1.89	-0.24	0.70	-0.54	0.01	-0.82	-0.72	0.26	-1.27	-1.81	-1.50	0.40	-0.53	-0.03	-0.54	-2.83	-0.54	0.32	-0.86	-5.33	-1.60	-2.73	-0.29	-1.09	-3.29	-1.11	-1.62	-0.40	-0.17	0.22	-0.27	-0.86	-4.41	-1.82	-0.98	-0.46	-2.07	-0.73	-1.35	-0.92	0.70	-3.13	-1.50	-1.85	-1.94	-5.25	-100000000.00	-0.98	
: 	-4.94	-1.86	-1.06	-2.81	-1.18	-2.81	-3.63	-1.23	-2.67	0.27	-1.87	-0.51	-2.03	-2.67	-2.69	-2.71	0.15	-2.12	-2.25	-7.15	0.41	-2.26	-5.55	-1.86	-2.87	-1.44	-2.01	-2.27	-2.74	-0.06	-3.85	-4.71	-2.69	-2.66	-1.77	0.25	-2.96	-0.49	-2.23	-3.25	-5.32	-0.31	-5.52	-0.90	-4.03	-4.37	-100000000.00	-0.25	
NNS 	1.66	-0.65	-0.69	-0.27	-0.49	-1.83	-2.22	-0.85	-1.08	0.94	-1.59	-1.42	-0.61	-1.86	-1.76	-3.72	-0.01	-2.10	-1.00	-2.33	0.39	-2.56	-2.07	-2.13	-5.62	-3.37	-0.29	-3.86	-1.68	-0.16	-0.22	0.37	-3.41	-2.18	-1.47	-0.43	-3.86	-0.87	0.73	-3.93	-1.87	-3.34	-0.61	0.50	-2.10	-8.43	-100000000.00	-1.11	
PRP 	-3.81	-0.98	-0.36	-0.87	0.52	-1.50	0.43	-0.99	-0.75	-1.85	0.36	-0.04	-2.48	-0.87	-3.16	-3.63	-0.68	-2.18	-4.03	-5.04	-0.47	-0.72	-0.70	-0.07	-2.88	-1.30	0.34	-1.62	-4.62	0.89	0.69	-1.24	-1.72	-3.23	-1.91	-2.58	-1.00	0.96	-2.36	-2.15	-2.28	-4.53	-2.08	-3.89	-2.41	-3.16	-100000000.00	-1.48	
VB 	-3.26	-1.68	-2.75	-0.00	-3.59	-0.10	-2.12	-1.41	-1.02	-2.70	-0.84	-1.63	-0.86	-0.92	-1.86	0.13	-1.16	0.17	-2.42	-1.68	-4.57	-0.86	0.52	-0.94	-3.38	0.42	0.12	-1.64	0.16	-2.17	-1.99	0.82	0.12	-2.08	0.37	-1.83	-2.77	-2.50	-2.33	-1.46	1.69	-2.34	-1.15	-0.41	-4.07	-1.06	-100000000.00	-1.40	
WRB 	-2.73	-1.07	-1.57	-1.34	-0.80	-0.38	-1.77	-1.22	-1.76	-0.08	-1.72	0.42	-4.46	-1.79	-0.52	-1.55	-0.54	-2.75	-2.39	-3.21	-2.38	-0.50	-2.21	0.04	-1.92	-1.49	-3.76	-1.57	-1.42	-0.76	-2.95	-1.28	-3.07	-1.52	-4.46	-1.11	-2.02	-0.79	0.61	-1.21	-3.02	-4.58	-1.95	-1.34	-3.60	-0.60	-100000000.00	-0.81	
CC 	-3.55	-1.92	-2.19	-1.94	-0.58	-0.24	-3.35	-0.93	-2.28	0.94	-3.04	-1.67	-3.09	-1.59	-0.82	-3.54	-0.32	-1.83	-4.52	-3.73	-1.13	-0.49	-1.67	-2.22	-3.38	-0.81	0.27	-1.22	-0.97	0.29	-2.42	-3.22	-1.88	-4.95	-0.19	0.56	-0.73	-1.35	-1.51	-2.33	-3.08	-0.21	-2.59	-0.79	-1.80	-6.08	-100000000.00	0.17	
PDT 	-3.02	0.13	-3.01	-1.98	-0.48	-4.66	-2.54	-0.76	-3.56	-1.79	-4.01	-0.76	-3.00	-2.63	-1.71	-2.41	-2.98	-2.53	-0.45	-1.30	-0.36	-0.62	-3.84	0.08	-1.38	-0.65	-1.89	-1.05	-2.95	-1.55	-0.62	-1.52	-0.69	0.34	-2.38	-2.80	-0.99	0.90	-0.89	-1.17	-0.50	-1.79	-2.27	-1.71	-4.40	-1.39	-100000000.00	-0.44	
RBS 	-0.51	-3.46	-0.79	-5.96	-1.35	-1.24	-0.70	-2.87	-3.62	-2.72	0.36	-0.58	-0.61	-2.82	-1.50	-1.89	-1.37	-3.19	-3.82	-2.78	-0.52	-0.39	-1.42	1.77	-3.13	-0.31	-3.82	-7.92	-4.85	-1.21	-3.07	0.13	-2.44	-0.97	-1.98	-2.80	-1.63	0.39	-1.03	0.11	-3.70	-2.87	-4.00	-4.41	-2.84	-2.32	-100000000.00	-7.30	
RBR 	-3.52	-1.64	0.01	-1.35	0.06	-2.30	-0.87	-1.69	-0.34	-1.77	-0.19	-0.30	-0.65	-2.39	-0.58	-2.63	-0.22	-2.23	-3.09	-4.51	-4.01	-1.60	-1.03	0.54	-0.30	0.02	-0.67	-0.01	-1.53	-0.60	-2.51	-1.30	-1.48	-1.20	-3.86	-2.26	-4.10	-0.62	-0.82	-0.15	-0.64	-2.83	-1.72	-2.62	-1.64	-1.08	-100000000.00	-0.70	
CD 	-1.01	-0.97	-0.65	-0.94	-1.59	-0.38	-1.16	-1.91	-1.64	-0.50	-3.04	-0.67	-0.67	-0.70	-3.02	2.76	-0.91	-0.62	-0.47	-1.64	0.35	-3.73	0.02	-2.56	-7.43	-0.64	-0.21	-1.74	-1.56	-0.11	-1.31	-0.82	-1.92	-5.01	-6.26	-0.75	-6.40	-0.43	-0.03	0.01	-5.96	-1.05	-1.57	-1.12	-1.75	-2.72	-100000000.00	-0.50	
EX 	-1.15	-1.04	0.08	-0.17	-1.84	-2.32	-2.09	-0.75	-0.69	-0.78	-0.21	-0.33	-0.05	-0.57	-2.26	-2.37	-0.59	-2.79	-3.74	-3.62	-3.02	-2.38	-4.08	-1.22	-1.36	-1.99	-1.75	-2.44	-0.87	-0.84	-0.97	0.87	-1.17	-1.90	0.21	-2.58	-1.95	-1.35	-1.07	-0.66	-1.14	-2.09	-0.87	-2.65	-3.18	-1.03	-100000000.00	-1.42	
IN 	-2.98	-1.08	-1.14	-0.58	0.19	-0.25	-2.07	0.27	-0.84	-0.92	-3.85	-0.31	-0.89	0.47	-0.62	-2.46	0.24	-0.70	-1.55	-4.21	-1.69	-3.33	-1.36	-2.10	-6.94	-1.31	-1.53	0.29	-1.12	-0.22	-2.32	-0.68	-3.26	-1.87	0.87	-0.68	-1.14	-0.54	-2.43	-0.08	-4.54	-1.81	-0.13	-0.01	-2.93	-8.13	-100000000.00	-0.54	
WP$ 	-0.57	-1.81	-1.17	-5.12	-2.06	0.54	-0.90	-2.79	-0.39	-1.38	0.53	-1.70	-0.87	-1.43	-1.49	0.74	-1.26	-0.95	-2.19	-0.94	-0.42	-2.55	-2.25	0.36	-1.12	-1.73	-1.97	-0.39	-1.42	-2.62	-2.51	-2.62	-0.50	0.23	0.09	-2.65	-0.93	-1.96	-1.94	0.03	-0.49	-0.81	-2.03	-1.38	-1.55	-0.04	-100000000.00	-1.91	
NN|SYM 	-0.87	-3.72	-2.72	-5.64	-3.54	-1.39	-1.61	-3.66	0.06	-2.63	-1.64	-2.87	-3.91	-3.54	-2.25	-2.23	-5.58	-0.41	-1.49	-1.80	-1.98	1.22	-3.96	0.50	-1.36	-2.85	-3.55	-4.28	-2.84	-2.92	-1.33	-3.28	-0.15	0.58	-2.35	-4.42	-0.59	-2.77	-0.16	-0.82	-2.62	-2.08	-2.68	-2.62	-3.40	-2.04	-100000000.00	-4.73	
MD 	-0.59	-2.37	-1.70	-4.21	-3.39	-1.12	-1.83	-2.03	1.11	-1.15	-1.27	-1.84	-1.22	-1.38	-0.61	-3.58	-0.57	-1.58	-4.38	-5.13	-2.31	-0.04	-3.25	-0.84	-1.68	-1.50	-2.00	-0.40	0.19	-1.93	-0.55	-1.49	-2.40	-1.74	-4.09	-1.58	-0.38	-2.80	-2.34	-0.21	-2.73	-1.37	-3.91	-4.85	-4.10	-2.16	-100000000.00	-0.26	
NNPS 	-4.11	-2.52	-2.40	-2.48	-2.11	-1.75	-2.62	-1.33	-2.26	-1.88	-3.46	-2.06	-0.98	-2.09	-3.21	-3.76	-3.04	0.05	-1.45	-5.74	-3.24	-1.40	-4.17	-1.04	-3.18	-6.78	-1.83	-6.16	-4.49	-1.31	-2.26	-2.21	-2.34	-1.39	-5.40	-0.93	-3.56	-1.40	-0.47	-3.54	-4.01	-1.71	-3.95	-4.71	-2.96	-6.91	-100000000.00	0.30	
JJS 	-0.26	-5.01	-1.42	-1.00	-0.86	-2.13	-0.97	-2.49	-2.92	-1.44	-1.81	-3.52	-1.30	-1.82	-3.06	-2.40	-4.66	-3.48	-2.31	-3.36	-1.31	-1.14	-1.86	-2.48	-3.38	-3.84	-4.48	-4.15	-3.35	-1.89	-1.88	-2.56	-1.34	-0.90	-3.29	-2.99	-0.92	-0.85	-0.30	-0.96	-3.21	-4.85	-2.81	-5.55	-3.34	-1.80	-100000000.00	-4.67	
JJR 	-2.04	-1.32	-0.01	-0.36	-0.86	-2.87	-1.56	-0.84	-3.38	-1.42	-4.07	0.02	-1.15	-1.83	-2.39	-2.29	-2.25	-5.48	0.32	-3.52	-6.58	-1.10	-1.28	-0.17	-2.61	-0.29	-1.66	-1.28	-1.42	0.21	-0.51	-1.51	-3.98	-3.65	-3.55	-1.92	-2.10	-0.89	-1.55	-0.46	-2.25	-2.86	-3.59	-5.07	-2.22	-4.48	-100000000.00	-2.08	
SYM 	-1.02	-1.70	-4.53	-0.79	-5.64	-5.99	-1.63	-1.04	-3.82	-0.30	-4.29	-4.41	-4.57	-1.24	-4.09	-2.04	-1.17	-0.85	-2.90	-3.38	-3.49	-0.58	-5.90	-1.15	-2.87	-3.16	-3.98	-2.32	-1.02	-3.48	-3.81	-1.27	-2.41	-2.92	-4.46	-0.55	-3.84	-3.32	-0.40	-1.47	-2.97	-4.36	-2.56	-2.62	-3.53	-0.64	-100000000.00	-0.82	
UH 	-2.98	-4.19	-4.20	-1.38	-5.66	-1.04	0.74	-1.69	-4.14	-6.43	-0.42	-5.21	-10.34	-0.19	-3.23	-3.77	-9.08	-5.31	-5.43	-2.07	-5.91	-2.47	-5.15	-0.55	-1.63	-3.37	-5.71	-7.44	-2.32	-4.58	-1.34	-4.92	-1.59	-2.14	-3.50	-9.93	-4.08	-1.66	-1.72	0.59	-3.62	-6.27	-2.63	-2.19	-2.88	-2.30	-100000000.00	-5.47	
stop_tag 	-3.54	-7.24	-1.22	-0.88	-1.68	-4.03	-1.41	-4.13	-7.02	0.55	-4.49	-1.62	-1.44	-1.88	-0.64	-4.03	0.28	-0.98	-4.89	-1.91	-0.44	-1.13	-4.92	-1.57	-5.72	-1.42	-1.58	-0.47	-3.30	-1.21	-6.54	-3.03	-6.54	-4.61	-7.48	1.02	-3.63	-1.72	-1.97	-2.34	-5.70	-1.32	-7.67	-6.23	0.49	-5.71	-100000000.00	0.04	
NNP 	-0.28	-1.08	-0.46	-0.38	-0.69	-1.07	-0.53	-1.31	-1.38	-0.75	-2.36	-0.46	-0.59	-0.89	-1.55	-2.16	-0.92	-0.48	-0.70	-0.62	0.88	-2.27	-0.95	-0.57	-6.55	-2.49	-0.01	-1.98	-2.94	-0.54	-0.51	0.59	-5.33	-4.25	-2.10	-0.72	-5.15	-0.49	-1.79	-4.17	-1.91	-1.03	-2.31	-0.53	-1.28	-1.71	-100000000.00	1.06	
Mean train loss after  0 batches of 6  epochs =0.0
Mean train loss after  100 batches of 6  epochs =0.0242914811345
Mean train loss after  200 batches of 6  epochs =0.021445562707
Mean train loss after  300 batches of 6  epochs =0.0222147300718
Mean train loss after  400 batches of 6  epochs =0.0268625645758
Mean train loss after  500 batches of 6  epochs =0.0280618975163
Mean train loss after  600 batches of 6  epochs =0.0299361552526
Mean train loss after  700 batches of 6  epochs =0.0305220357114
Mean train loss after  800 batches of 6  epochs =0.0292391292024
Mean train loss after  900 batches of 6  epochs =0.0318401126286
Mean train loss after  1000 batches of 6  epochs =0.0325899022221
Mean train loss after  1100 batches of 6  epochs =0.0317550918119
Mean train loss after  1200 batches of 6  epochs =0.0313053246507
Mean train loss after  1300 batches of 6  epochs =0.0303400864044
Mean train loss after  1400 batches of 6  epochs =0.0297129883184
Mean train loss after  1500 batches of 6  epochs =0.0300483524942
Mean train loss after  1600 batches of 6  epochs =0.0294633867453
Mean train loss after  1700 batches of 6  epochs =0.0296511405094
Mean train loss after  1800 batches of 6  epochs =0.0298222126952
Mean train loss after  1900 batches of 6  epochs =0.0295280022032
Mean train loss after  2000 batches of 6  epochs =0.0296388592475
Mean train loss after  2100 batches of 6  epochs =0.029743516747
Mean train loss after  2200 batches of 6  epochs =0.0301036143884
Mean train loss after  2300 batches of 6  epochs =0.0303307983316
Mean train loss after  2400 batches of 6  epochs =0.0301253081044
Mean train loss after  2500 batches of 6  epochs =0.030362754163
Mean train loss after  2600 batches of 6  epochs =0.0302528793512
Mean train loss after  2700 batches of 6  epochs =0.0302246093236
Mean train loss after  2800 batches of 6  epochs =0.0305166431091
Mean train loss after  2900 batches of 6  epochs =0.0307539672672
Mean train loss after  3000 batches of 6  epochs =0.0305656055447
Mean train loss after  3100 batches of 6  epochs =0.0305532734293
Mean train loss after  3200 batches of 6  epochs =0.0307586572393
Mean train loss after  3300 batches of 6  epochs =0.0305718319945
Mean train loss after  3400 batches of 6  epochs =0.0308976517069
Mean train loss after  3500 batches of 6  epochs =0.0308832430804
Mean train loss after  3600 batches of 6  epochs =0.0314628003239
Mean train loss after  3700 batches of 6  epochs =0.0311568025835
Mean train loss after  3800 batches of 6  epochs =0.0314218571608
Mean train loss after  3900 batches of 6  epochs =0.0313309694415
Mean train loss after  4000 batches of 6  epochs =0.0315072283492
Mean train loss after  4100 batches of 6  epochs =0.0314909930412
Mean train loss after  4200 batches of 6  epochs =0.0315011396297
Mean train loss after  4300 batches of 6  epochs =0.0317327015215
Mean train loss after  4400 batches of 6  epochs =0.0317981410627
Mean train loss after  4500 batches of 6  epochs =0.0318462175397
Mean train loss after  4600 batches of 6  epochs =0.0319259363278
Mean train loss after  4700 batches of 6  epochs =0.0320461997481
Mean train loss after  4800 batches of 6  epochs =0.0322023068
Mean train loss after  4900 batches of 6  epochs =0.032210707368
Mean train loss after  5000 batches of 6  epochs =0.0324213176367
Mean train loss after  5100 batches of 6  epochs =0.0323787099985
Mean train loss after  5200 batches of 6  epochs =0.0325114925975
Mean train loss after  5300 batches of 6  epochs =0.0326392640381
Mean train loss after  5400 batches of 6  epochs =0.0326222007283
Mean train loss after  5500 batches of 6  epochs =0.0327213163989
Mean train loss after  5600 batches of 6  epochs =0.0328335997371
Mean train loss after  5700 batches of 6  epochs =0.0329832445729
Mean train loss after  5800 batches of 6  epochs =0.0333198208643
Mean train loss after  5900 batches of 6  epochs =0.0332427356843
Mean train loss after  6000 batches of 6  epochs =0.033497822318
Mean train loss after  6100 batches of 6  epochs =0.0336268145977
Mean train loss after  6200 batches of 6  epochs =0.0337980275653
Mean train loss after  6300 batches of 6  epochs =0.0336899124683
Mean train loss after  6400 batches of 6  epochs =0.0339910285136
Mean train loss after  6500 batches of 6  epochs =0.0339739627332
Mean train loss after  6600 batches of 6  epochs =0.0340798021001
Mean train loss after  6700 batches of 6  epochs =0.0341575804848
Mean train loss after  6800 batches of 6  epochs =0.0340348800013
Mean train loss after  6900 batches of 6  epochs =0.0342214875277
Mean train loss after  7000 batches of 6  epochs =0.0342072129611
Mean train loss after  7100 batches of 6  epochs =0.0342933161841
Mean train loss after  7200 batches of 6  epochs =0.034478465646
Mean train loss after  7300 batches of 6  epochs =0.0344780119593
Mean train loss after  7400 batches of 6  epochs =0.0342325222345
Mean train loss after  7500 batches of 6  epochs =0.0341783032416
Mean train loss after  7600 batches of 6  epochs =0.0343165194286
Mean train loss after  7700 batches of 6  epochs =0.0343537512195
Mean train loss after  7800 batches of 6  epochs =0.0345898451586
Mean train loss after  7900 batches of 6  epochs =0.0346807094024
Mean train loss after  8000 batches of 6  epochs =0.0349205051749
Mean train loss after  8100 batches of 6  epochs =0.0349448775988
Mean train loss after  8200 batches of 6  epochs =0.0350768475957
Mean train loss after  8300 batches of 6  epochs =0.0350828595009
Mean train loss after  8400 batches of 6  epochs =0.0351480415764
Mean train loss after  8500 batches of 6  epochs =0.0351928396534
Mean train loss after  8600 batches of 6  epochs =0.0353664564148
Mean train loss after  8700 batches of 6  epochs =0.0354713146034
Mean train loss after  8800 batches of 6  epochs =0.0353644082129
Mean train loss after  8900 batches of 6  epochs =0.0353136580676
Mean train loss after  9000 batches of 6  epochs =0.0352859398018
Mean train loss after  9100 batches of 6  epochs =0.0352957965198
Mean train loss after  9200 batches of 6  epochs =0.0353449512706
Mean train loss after  9300 batches of 6  epochs =0.0353851721157
Mean train loss after  9400 batches of 6  epochs =0.0354491511701
Mean train loss after  9500 batches of 6  epochs =0.0355791420733
Mean train loss after  9600 batches of 6  epochs =0.0358834332672
Mean train loss after  9700 batches of 6  epochs =0.0360077324587
Mean train loss after  9800 batches of 6  epochs =0.0362128183519
Mean train loss after  9900 batches of 6  epochs =0.0361501839024
Mean train loss after  10000 batches of 6  epochs =0.0362340967511
Mean train loss after  10100 batches of 6  epochs =0.0362871961959
Mean train loss after  10200 batches of 6  epochs =0.0364738401494
Mean train loss after  10300 batches of 6  epochs =0.0364401038021
Mean train loss after  10400 batches of 6  epochs =0.0365369080266
Mean train loss after  10500 batches of 6  epochs =0.0366930473788
Mean train loss after  10600 batches of 6  epochs =0.036705705893
Mean train loss after  10700 batches of 6  epochs =0.0367916056466
Mean train loss after  10800 batches of 6  epochs =0.0368099495953
Mean train loss after  10900 batches of 6  epochs =0.0368453554192
Mean train loss after  11000 batches of 6  epochs =0.0368662004441
Mean train loss after  11100 batches of 6  epochs =0.036860788563
Mean train loss after  11200 batches of 6  epochs =0.0369499796036
Mean train loss after  11300 batches of 6  epochs =0.0369424818757
Mean train loss after  11400 batches of 6  epochs =0.036901971168
Mean train loss after  11500 batches of 6  epochs =0.0369296786146
Mean train loss after  11600 batches of 6  epochs =0.0371070951978
Mean train loss after  11700 batches of 6  epochs =0.0370751629651
Mean train loss after  11800 batches of 6  epochs =0.0373459228654
Mean train loss after  11900 batches of 6  epochs =0.0375243160758
Mean train loss after  12000 batches of 6  epochs =0.0375796403868
Mean train loss after  12100 batches of 6  epochs =0.0375367130848
Mean train loss after  12200 batches of 6  epochs =0.0375568701029
Mean train loss after  12300 batches of 6  epochs =0.0376315887886
Mean train loss after  12400 batches of 6  epochs =0.0379778301196
Mean train loss after  12500 batches of 6  epochs =0.0379437900094
Mean train loss after  12600 batches of 6  epochs =0.0382166921094
Mean train loss after  12700 batches of 6  epochs =0.0382590040103
Mean train loss after  12800 batches of 6  epochs =0.0383010876474
Mean train loss after  12900 batches of 6  epochs =0.0383458590119
Mean train loss after  13000 batches of 6  epochs =0.0383274090045
Mean train loss after  13100 batches of 6  epochs =0.0383975503418
Mean train loss after  13200 batches of 6  epochs =0.0384784887256
Mean train loss after  13300 batches of 6  epochs =0.0385013694145
Mean train loss after  13400 batches of 6  epochs =0.0385711550819
Mean train loss after  13500 batches of 6  epochs =0.0386877923306
Mean train loss after  13600 batches of 6  epochs =0.0387464678486
Mean train loss after  13700 batches of 6  epochs =0.0388141201126
Mean train loss after  13800 batches of 6  epochs =0.0388512603629
Mean train loss after  13900 batches of 6  epochs =0.0388634161215
Mean train loss after  14000 batches of 6  epochs =0.0389252600465
Mean train loss after  14100 batches of 6  epochs =0.0389654681134
Mean train loss after  14200 batches of 6  epochs =0.0389252234245
Mean train loss after  14300 batches of 6  epochs =0.0389751463335
Mean train loss after  14400 batches of 6  epochs =0.039002706431
Mean train loss after  14500 batches of 6  epochs =0.0389928339002
Mean train loss after  14600 batches of 6  epochs =0.0391084352457
Mean train loss after  14700 batches of 6  epochs =0.0391809669773
Mean train loss after  14800 batches of 6  epochs =0.0391971833518
Mean train loss after  14900 batches of 6  epochs =0.0392205057419
Epoch 6 : Mean train epoch loss =0.0392935370976
Epoch 6 Epoch val loss = 16752.9826367
Epoch 6 Epoch val perplexity = 1.4072824922206535
SCORES =  (92.6, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 7---------------------

=================================
fscore(z) =  [237.3899] || goldscore = [237.08698]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-5.30	-0.95	-0.01	-2.71	-0.35	-1.95	-0.35	-1.44	-1.35	-1.82	-2.89	0.01	-0.45	-0.92	-0.70	-2.66	-2.30	-3.65	-3.41	-3.30	-2.59	-3.15	0.87	-1.46	-3.46	-3.14	-4.41	-2.12	-2.04	0.42	-0.70	0.39	-1.31	-2.51	-1.41	-3.80	-3.50	0.06	-2.94	-2.10	-4.53	-2.61	-3.87	-2.58	-1.82	-3.93	-100000000.00	-2.93	
VBG 	-1.72	-3.51	-0.04	0.12	-0.48	-0.03	-1.94	-0.57	-2.48	-2.38	-3.66	0.07	-0.07	-1.16	-1.60	-4.53	-0.21	-2.28	-3.07	-6.20	-1.09	-1.94	-0.63	0.39	-3.11	-0.86	-1.52	0.02	-2.91	-0.54	-2.03	-0.49	-3.95	-1.21	-0.35	-1.15	-4.11	0.35	-1.29	-2.11	-1.76	-1.44	-0.32	-2.14	-2.50	-7.59	-100000000.00	-1.34	
VBD 	-3.10	-3.89	-3.81	-1.50	-1.66	0.89	-1.40	-1.33	1.73	-2.00	-0.18	-1.94	-1.60	-1.10	-1.72	-3.02	-0.04	0.31	-1.99	-2.35	-1.34	-2.20	-5.14	-1.36	-5.11	-0.24	-2.03	0.12	0.95	-1.98	-0.64	-0.85	-3.29	-1.14	-0.12	-1.52	-0.18	-3.01	-0.10	-4.53	-3.89	-0.65	-1.13	-0.70	-4.98	-2.99	-100000000.00	-0.01	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.46	-1.91	-0.78	-0.58	-1.81	-1.00	-3.70	0.65	-1.35	-1.70	-2.48	0.80	-0.67	-0.75	-1.64	-4.57	-0.62	-1.83	-1.13	-1.74	-1.59	-3.05	-2.74	-0.49	-3.90	0.70	-1.67	-0.58	-1.43	-0.34	-1.64	-0.60	-3.05	-1.85	-2.11	-2.43	-4.24	-1.61	-1.57	-1.45	-3.99	-1.81	-2.50	-2.10	-1.17	-5.59	-100000000.00	-2.58	
, 	-2.20	-2.58	-0.47	-4.82	-1.03	-3.77	0.49	-2.21	0.44	0.85	-3.29	-2.31	-1.57	-2.33	-0.61	-5.88	0.57	0.12	-3.31	-1.48	-2.02	-3.45	-3.67	-0.24	-4.75	0.65	-3.11	-0.11	-1.20	-1.23	-4.63	-2.45	-4.48	-3.19	0.42	1.13	-2.51	-0.37	-3.07	-4.80	-2.50	-0.67	-2.93	-0.78	-7.33	-1.19	-100000000.00	0.20	
'' 	-4.68	-1.00	-1.11	0.54	-2.97	-0.95	-0.53	-2.90	-0.30	-2.16	-2.37	-0.70	-3.49	-5.40	0.43	-0.32	-0.93	-2.70	-1.87	-1.64	-1.02	0.90	-3.85	0.89	-1.93	-0.13	0.37	-4.05	-2.00	-1.83	-2.85	-0.19	-0.62	-2.45	1.52	-1.57	-0.38	-0.75	-0.25	-1.87	-1.26	-2.37	-2.28	-2.81	-4.01	-1.66	-100000000.00	-0.29	
VBP 	-5.55	-2.97	-4.49	-4.35	-2.04	-1.46	0.06	-2.57	0.63	-3.63	0.36	-1.86	-2.12	-3.86	-2.38	-3.97	-1.56	-0.75	-2.65	-6.85	-4.02	-1.87	-2.88	-1.23	-4.33	-0.68	-2.72	1.02	0.94	-2.82	-2.44	-0.84	-0.87	-2.38	-0.24	-0.33	0.84	-3.51	-1.33	-1.73	-6.11	0.60	-3.89	-3.37	-2.96	-4.84	-100000000.00	-0.39	
WDT 	-3.64	-3.98	-4.13	-1.46	-2.88	-0.91	-3.62	-2.20	-1.72	-2.87	-4.30	-2.56	0.22	-3.34	-2.45	-3.88	0.34	-0.92	-5.03	-4.20	-3.23	-1.11	-0.72	-0.73	-2.91	-2.74	0.21	0.47	-2.31	-2.63	-3.02	-2.04	-0.69	-3.49	-2.72	-1.19	-1.23	0.02	0.26	-1.30	-1.66	-2.47	-3.26	-2.63	-3.49	-2.32	-100000000.00	-0.31	
JJ 	0.63	-0.75	-0.30	-0.52	-0.34	-1.15	-1.26	-0.06	-2.05	-0.49	-3.26	0.20	1.84	-0.12	-1.58	0.22	-1.73	-1.47	-0.98	-3.14	-0.19	-3.13	-0.20	-0.96	-6.29	-0.12	0.38	-1.79	-0.87	-0.20	0.18	-0.25	-5.51	0.39	0.79	0.58	-4.23	1.12	-0.45	-3.08	-3.00	-2.76	-0.67	-0.82	-1.81	-3.65	-100000000.00	-1.07	
WP 	-3.04	-2.57	-2.97	-2.66	-1.05	-1.23	0.65	-0.44	-1.31	-1.70	-1.85	-0.42	-1.02	-1.33	-2.38	-2.93	0.31	-1.94	-1.32	-2.43	-2.38	-2.45	0.45	-2.02	-2.10	-0.99	-2.82	0.13	-2.11	-0.31	-2.25	-1.24	-2.64	-2.15	-3.15	-3.12	-1.46	0.21	-2.15	-0.39	-2.97	-1.00	-2.67	-1.60	-2.44	-1.58	-100000000.00	-1.62	
VBZ 	-2.03	-3.11	-4.79	-3.92	-2.56	0.15	-1.90	-1.09	2.03	-1.53	-0.51	-2.60	-0.64	-0.95	-2.74	-2.92	0.82	-0.93	-0.87	-2.94	-2.97	-1.55	-3.30	-1.60	-3.00	-0.33	-1.76	-2.59	1.82	-2.85	-0.25	-0.73	-3.90	-2.82	-3.77	-1.16	0.97	-3.09	-1.64	-2.14	-3.81	-3.69	-1.71	-2.88	-2.67	-6.13	-100000000.00	-0.06	
DT 	-3.57	-1.90	-1.05	-0.09	-0.37	-0.14	-1.35	-0.49	-1.74	-0.83	-2.28	-0.16	-1.80	-0.72	-0.02	-6.04	-0.18	-1.07	0.31	-2.24	-1.67	-2.13	0.67	-2.07	-4.19	-0.77	-0.38	-1.28	-1.51	1.03	-0.22	1.50	0.12	-1.55	0.73	-2.87	-2.73	1.55	-0.25	-1.89	-1.89	-2.89	-3.71	-2.49	-0.63	-5.69	-100000000.00	-0.08	
" 	0.05	-0.54	-2.19	-1.84	-1.19	-0.10	0.89	-1.80	-0.57	-0.48	-2.18	-0.69	-0.70	-1.90	-0.26	-3.50	0.13	-1.17	-2.57	-3.68	0.95	1.06	-1.81	0.02	-0.41	-1.91	0.42	-2.27	-3.29	-1.60	-2.28	-1.57	-2.95	-3.89	-2.32	-1.09	-3.28	-1.04	-1.12	-3.63	-3.15	-2.38	-2.86	-1.36	-2.25	-3.87	-100000000.00	0.02	
RP 	-5.03	0.79	1.16	-3.60	0.94	-1.85	-3.23	1.19	-2.94	-1.73	-4.48	-0.57	0.13	-4.02	-1.69	-2.97	-1.74	-1.33	-3.66	-3.90	-2.26	-0.67	-4.80	-0.96	-2.89	-1.71	-4.47	-1.94	0.18	0.10	-3.23	-4.00	-1.99	-3.22	-1.36	-1.71	-6.17	-3.56	-1.08	-1.56	-5.23	-3.77	-2.73	-3.09	-3.95	-4.88	-100000000.00	-2.86	
$ 	-2.57	-1.32	-0.74	-5.45	-0.49	-2.24	-1.77	-1.23	-2.09	0.06	-2.46	-0.33	-0.52	-2.40	-0.48	0.70	0.22	-2.27	-0.65	-5.69	-0.19	-0.94	0.41	-0.69	0.34	-0.99	-0.60	-1.63	-2.05	-0.02	-2.13	-0.28	-2.69	-1.01	-3.20	-1.15	-2.08	0.29	-1.99	-2.85	-1.17	-3.09	-1.72	-2.68	-4.00	-2.32	-100000000.00	0.48	
NN 	0.95	-0.45	-0.91	0.57	0.22	0.74	-1.79	-1.17	-2.04	0.71	-1.03	-0.23	0.34	-0.83	-1.38	-3.97	-0.89	-0.80	-1.23	-0.85	0.85	-1.38	-1.50	-2.02	-7.07	-2.68	0.64	-2.03	-2.86	-0.30	-2.00	-1.61	-3.22	-3.54	-0.51	-0.38	-4.75	0.02	1.53	-4.98	-4.99	-1.73	0.30	0.33	-1.37	-9.23	-100000000.00	-0.44	
) 	-4.14	-1.54	-3.27	-4.51	-1.31	-4.26	-4.14	-3.94	-5.42	-0.83	-5.15	-1.22	-3.02	-2.13	0.40	-3.87	-1.50	-2.66	-1.86	-2.99	-1.01	-3.52	-4.21	0.16	0.13	-2.56	-2.78	-2.44	-5.66	-1.35	-4.80	-3.53	-5.17	-3.05	-4.51	1.22	-1.67	-1.84	-2.38	-5.17	-3.99	-1.21	-6.44	-7.13	-3.62	-4.22	-100000000.00	-0.36	
( 	0.43	-3.71	-1.16	-2.37	-3.37	-2.97	-2.25	-4.35	-1.97	-1.32	-1.50	-1.15	-1.82	-0.77	-3.36	-5.14	0.20	-2.20	-3.94	-1.50	-0.94	-2.14	-1.94	-0.34	-2.37	-2.85	-1.83	-0.71	-1.77	-1.79	-2.34	-3.46	-5.50	-3.65	-4.98	0.44	-3.21	-4.11	-2.06	-2.70	-4.94	-1.47	-1.46	-2.48	-6.03	-2.78	-100000000.00	1.19	
FW 	-5.14	-4.58	-3.47	-2.07	-5.50	-1.93	-2.24	-1.47	-2.25	-2.31	-3.09	-6.64	-3.76	-3.99	-4.92	-1.90	-2.56	-1.52	-3.33	-0.80	-5.29	-1.22	-5.69	-0.63	-1.71	-4.64	-2.46	-3.11	-5.23	-2.65	-0.38	-2.53	-2.85	-2.28	-3.44	-2.47	-2.83	-11.02	0.01	-2.07	-2.49	-2.14	-4.18	-4.44	-2.46	-1.65	-100000000.00	-0.72	
POS 	-2.32	-5.10	-2.17	-2.67	-0.60	-1.96	0.91	-1.77	0.55	-0.11	-4.74	-3.87	-1.68	-2.54	-3.38	-3.49	1.61	-3.15	-2.75	-5.24	-3.31	-1.57	-3.32	-2.07	-5.32	-2.34	-1.75	0.00	-1.13	-2.26	-2.12	-2.55	-1.99	-0.66	-2.80	-1.79	-0.72	-2.21	-2.43	-2.76	-3.42	-1.64	-3.59	-2.49	-3.92	-4.53	-100000000.00	1.92	
. 	-2.66	-0.95	-1.53	-4.75	-0.90	-5.58	-2.96	-0.62	-4.36	-0.05	-3.46	-0.42	-0.32	-0.79	-0.25	-6.60	-0.56	-0.70	-3.49	-3.68	-1.06	-1.58	-3.52	-0.77	-0.07	-0.70	-2.06	0.72	-1.04	-1.30	-1.23	-2.28	-2.86	-7.14	-0.74	0.61	-1.93	-1.69	-1.93	-4.34	-4.26	-0.44	-4.15	-1.59	-5.94	-2.30	-100000000.00	1.52	
TO 	-1.74	-1.96	-0.33	-2.19	-0.81	-2.36	-3.38	-0.13	-4.11	-0.95	-3.29	0.41	-3.20	-2.21	-0.37	-5.12	-0.85	-1.97	-2.50	-3.81	-4.41	-3.29	-3.06	-1.36	-3.83	-0.49	-1.61	-1.08	-2.05	-1.16	-1.41	-2.85	-5.55	-3.38	-0.63	0.66	-2.69	0.07	-1.58	-2.67	-4.08	-2.93	-1.63	-0.86	-5.26	-7.23	-100000000.00	-1.63	
-X- 	-0.35	-0.05	-2.23	-2.66	-1.52	-1.63	-1.66	-1.43	-0.82	-1.97	-2.48	-2.39	-1.47	-2.22	0.31	-2.18	-0.82	-1.38	-2.49	-0.65	-1.53	-0.49	-2.19	2.00	-1.47	-2.17	-2.15	-1.38	-1.88	-1.55	0.21	-0.06	1.66	-0.30	-0.29	-2.40	0.36	-2.09	0.84	1.11	0.80	-2.17	-1.88	1.59	-1.01	0.35	-100000000.00	-4.11	
LS 	-1.79	-2.35	-4.71	-0.84	-3.04	-2.38	-0.96	-4.10	-1.47	-4.20	-0.86	-2.18	-5.60	-2.82	-3.88	-4.36	-3.15	-2.57	-3.04	-3.36	-1.52	-0.14	-3.75	-1.55	-3.37	-4.89	1.08	-5.40	-3.19	-2.45	0.24	-4.56	-0.92	-0.87	-2.27	-4.75	-2.93	-3.71	-1.19	-1.14	-3.76	-4.04	-2.03	-4.51	-1.72	-2.15	-100000000.00	-3.87	
RB 	-1.92	-0.21	0.70	-0.68	-0.11	-0.90	-0.91	0.18	-1.29	-1.95	-1.58	0.31	-0.60	-0.23	-0.67	-3.19	-0.54	0.15	-1.12	-5.93	-1.66	-2.88	-0.43	-1.11	-3.44	-1.29	-1.96	-0.40	-0.29	0.15	-0.39	-0.96	-4.73	-1.79	-0.94	-0.45	-2.26	-0.81	-1.42	-1.16	0.77	-3.34	-1.68	-1.89	-2.18	-5.50	-100000000.00	-0.96	
: 	-5.22	-2.00	-1.23	-3.02	-1.23	-3.21	-3.78	-1.34	-3.02	0.24	-2.38	-0.59	-2.29	-2.94	-2.77	-3.01	0.17	-1.98	-2.50	-7.41	0.28	-2.36	-5.74	-1.87	-3.11	-1.73	-2.37	-2.39	-3.05	-0.13	-4.19	-5.11	-3.03	-2.88	-1.98	0.15	-3.30	-0.71	-2.24	-3.29	-5.62	-0.42	-6.04	-1.19	-4.02	-4.78	-100000000.00	-0.25	
NNS 	1.56	-0.71	-0.77	-0.40	-0.46	-1.94	-2.34	-0.94	-1.10	0.93	-1.75	-1.47	-0.55	-2.00	-1.83	-3.86	-0.10	-2.46	-1.03	-2.47	0.39	-2.74	-2.28	-2.15	-5.73	-3.54	-0.37	-4.09	-1.79	-0.11	-0.32	0.30	-3.58	-2.23	-1.69	-0.42	-4.22	-0.95	0.71	-4.10	-2.16	-3.62	-0.62	0.44	-2.17	-9.04	-100000000.00	-1.06	
PRP 	-4.08	-0.98	-0.35	-1.33	0.56	-1.58	0.36	-1.06	-0.93	-1.97	0.39	-0.00	-2.56	-1.08	-3.56	-4.04	-0.86	-2.54	-4.33	-5.39	-0.53	-0.89	-0.94	-0.09	-3.18	-1.48	0.05	-1.74	-4.95	0.78	0.65	-1.29	-2.07	-3.47	-2.20	-2.68	-1.23	1.06	-2.46	-2.33	-2.54	-4.77	-2.27	-4.23	-2.42	-3.36	-100000000.00	-1.60	
VB 	-3.72	-1.82	-2.86	-0.01	-3.51	-0.16	-2.20	-1.56	-1.25	-2.76	-0.96	-1.80	-1.26	-1.20	-1.97	-0.28	-1.20	0.14	-2.78	-2.06	-4.82	-1.00	0.50	-0.96	-3.72	0.42	0.05	-1.73	0.03	-2.50	-2.18	0.75	-0.06	-2.31	0.38	-2.00	-3.03	-2.79	-2.47	-1.68	1.63	-2.50	-1.27	-0.62	-4.35	-1.17	-100000000.00	-1.48	
WRB 	-2.92	-1.16	-1.60	-1.33	-0.74	-0.36	-1.95	-1.55	-1.93	-0.14	-1.86	0.39	-4.61	-2.03	-0.60	-1.84	-0.60	-2.82	-2.73	-3.48	-2.48	-0.51	-2.44	0.04	-2.12	-1.56	-4.23	-1.63	-1.62	-0.74	-3.03	-1.34	-3.18	-1.69	-4.69	-1.19	-2.14	-0.78	0.54	-1.29	-3.29	-4.80	-2.08	-1.55	-3.95	-0.76	-100000000.00	-0.86	
CC 	-3.61	-1.98	-2.35	-2.02	-0.65	-0.16	-3.63	-1.14	-2.45	0.96	-3.20	-1.90	-3.25	-1.69	-0.90	-3.89	-0.34	-1.88	-4.78	-3.85	-1.14	-0.62	-2.06	-2.22	-3.54	-0.91	0.00	-1.34	-1.24	0.32	-2.70	-3.50	-2.14	-5.21	-0.26	0.51	-0.85	-1.56	-1.58	-2.40	-3.35	-0.32	-2.72	-1.03	-1.99	-6.62	-100000000.00	0.27	
PDT 	-3.17	-0.11	-3.17	-2.23	-0.56	-5.01	-2.65	-0.83	-3.76	-1.97	-4.27	-1.03	-3.24	-2.72	-1.90	-2.62	-3.02	-2.81	-0.71	-1.43	-0.61	-0.66	-3.87	0.08	-1.51	-0.69	-2.25	-1.41	-3.27	-1.56	-0.72	-1.62	-0.81	0.16	-2.61	-2.94	-1.24	0.84	-0.92	-1.20	-0.72	-1.98	-2.37	-1.89	-4.65	-1.52	-100000000.00	-0.53	
RBS 	-0.47	-3.84	-0.93	-6.52	-1.71	-1.59	-0.88	-3.16	-3.81	-3.14	0.12	-0.58	-0.61	-3.14	-1.67	-2.09	-1.61	-3.39	-4.06	-3.14	-0.54	-0.48	-1.93	1.77	-3.21	-0.65	-4.22	-8.03	-5.15	-1.24	-3.17	-0.18	-2.61	-1.14	-2.18	-3.43	-1.85	0.32	-1.06	0.08	-3.91	-3.14	-4.16	-4.59	-3.14	-2.53	-100000000.00	-7.66	
RBR 	-3.85	-1.79	-0.06	-1.55	0.03	-2.59	-1.05	-1.72	-0.48	-2.27	-0.47	-0.42	-0.61	-2.63	-0.66	-3.04	-0.34	-2.61	-3.41	-4.87	-4.42	-1.63	-1.09	0.54	-0.70	-0.09	-0.70	-0.04	-1.53	-0.84	-2.76	-1.35	-1.74	-1.37	-4.03	-2.36	-4.31	-0.63	-0.93	-0.22	-1.17	-3.14	-2.06	-2.95	-1.81	-1.38	-100000000.00	-0.82	
CD 	-1.12	-1.12	-0.74	-0.97	-1.74	-0.54	-1.20	-1.94	-1.68	-0.49	-3.62	-0.84	-0.72	-0.70	-3.07	2.87	-0.96	-0.56	-0.41	-2.04	0.39	-3.94	0.02	-2.65	-7.78	-0.77	-0.22	-1.87	-1.65	-0.25	-1.47	-0.83	-2.06	-5.13	-6.59	-0.80	-6.98	-0.47	0.03	0.06	-6.78	-1.19	-1.86	-1.21	-1.81	-3.10	-100000000.00	-0.53	
EX 	-1.38	-1.04	0.08	-0.34	-2.16	-2.24	-2.18	-0.74	-0.74	-1.01	-0.32	-0.45	-0.20	-0.57	-2.35	-2.46	-0.60	-3.02	-4.00	-3.87	-3.32	-2.44	-4.23	-1.22	-1.48	-2.10	-2.17	-2.55	-0.97	-1.04	-1.04	0.87	-1.41	-2.04	-0.06	-3.03	-2.18	-1.22	-1.13	-0.72	-1.19	-2.32	-0.98	-2.94	-3.26	-1.12	-100000000.00	-1.47	
IN 	-3.31	-1.16	-1.11	-0.74	0.11	-0.24	-2.21	0.26	-0.94	-0.98	-4.31	-0.45	-0.94	0.41	-0.64	-2.75	0.21	-0.84	-1.62	-4.86	-1.79	-3.52	-1.54	-2.13	-7.23	-1.27	-1.53	0.40	-1.19	-0.22	-2.50	-0.76	-3.39	-2.06	0.94	-0.62	-1.18	-0.56	-2.57	-0.64	-4.73	-1.92	-0.27	-0.11	-3.31	-8.58	-100000000.00	-0.57	
WP$ 	-0.63	-1.90	-1.39	-5.29	-2.12	0.64	-0.92	-2.82	-0.45	-1.52	0.37	-1.80	-0.96	-1.50	-1.56	0.72	-1.43	-1.10	-2.34	-1.07	-0.52	-2.57	-2.32	0.36	-1.15	-1.79	-2.05	-0.36	-1.54	-2.74	-2.51	-2.70	-0.52	0.20	0.05	-2.82	-0.95	-2.12	-1.94	0.03	-0.51	-0.94	-2.07	-1.48	-1.61	-0.07	-100000000.00	-1.95	
NN|SYM 	-1.12	-3.90	-3.04	-6.31	-3.66	-1.79	-1.70	-3.83	-0.14	-3.01	-1.78	-3.08	-4.26	-3.76	-2.40	-2.27	-5.81	-0.39	-1.87	-2.12	-2.27	1.13	-4.19	0.50	-1.42	-3.26	-4.06	-4.70	-3.08	-3.17	-1.38	-3.47	-0.18	0.53	-2.42	-4.98	-0.81	-3.08	-0.17	-0.83	-2.74	-2.39	-2.76	-2.76	-3.61	-2.11	-100000000.00	-5.28	
MD 	-0.73	-2.61	-1.83	-4.19	-3.74	-1.14	-2.15	-2.09	1.21	-1.25	-1.43	-2.08	-1.24	-1.54	-0.80	-3.88	-0.71	-1.67	-4.62	-5.61	-2.43	-0.12	-3.52	-0.86	-1.85	-1.53	-2.14	-0.43	0.26	-2.19	-0.75	-1.54	-2.71	-1.83	-4.22	-1.61	-0.49	-2.97	-2.38	-0.39	-3.16	-1.49	-4.14	-5.15	-4.34	-2.46	-100000000.00	-0.34	
NNPS 	-4.21	-2.98	-2.54	-2.57	-2.13	-1.87	-2.75	-1.48	-2.32	-2.03	-3.85	-2.17	-1.11	-2.19	-3.34	-4.04	-3.06	-0.17	-1.76	-6.42	-3.29	-1.52	-4.47	-1.06	-3.41	-7.44	-2.08	-6.28	-4.93	-1.46	-2.44	-2.30	-2.69	-1.54	-5.86	-1.08	-4.06	-1.51	-0.45	-3.64	-4.39	-2.01	-4.28	-5.31	-3.17	-7.40	-100000000.00	0.21	
JJS 	-0.27	-5.33	-1.76	-1.15	-0.86	-2.40	-1.20	-2.74	-3.17	-1.78	-2.08	-3.72	-1.45	-2.10	-3.17	-2.68	-4.92	-3.83	-2.55	-3.75	-1.30	-1.24	-2.14	-2.48	-3.57	-4.09	-4.92	-4.27	-3.72	-2.02	-1.94	-2.82	-1.55	-1.14	-3.55	-3.25	-1.06	-1.03	-0.37	-1.12	-3.35	-5.34	-3.12	-5.88	-3.59	-2.23	-100000000.00	-5.22	
JJR 	-2.25	-1.44	-0.12	-0.45	-0.98	-3.22	-1.75	-0.84	-3.52	-1.59	-4.45	-0.02	-1.24	-2.13	-2.57	-2.64	-2.36	-6.01	0.22	-3.83	-7.05	-1.22	-1.24	-0.21	-2.84	-0.49	-1.73	-1.42	-1.69	0.21	-0.54	-1.49	-4.30	-3.83	-3.84	-2.08	-2.28	-1.02	-1.62	-0.69	-2.54	-3.00	-3.96	-5.50	-2.30	-4.63	-100000000.00	-2.19	
SYM 	-1.18	-1.90	-4.73	-0.79	-6.03	-6.16	-1.96	-1.29	-4.04	-0.45	-4.55	-4.73	-5.01	-1.58	-4.19	-2.34	-1.23	-0.84	-3.26	-3.74	-3.92	-0.68	-6.14	-1.15	-3.09	-3.40	-4.42	-2.48	-1.06	-3.81	-4.08	-1.50	-2.62	-3.09	-4.86	-0.69	-3.98	-3.32	-0.50	-1.64	-3.08	-4.60	-2.77	-2.89	-3.77	-0.76	-100000000.00	-0.85	
UH 	-3.23	-4.50	-4.61	-1.53	-6.11	-1.11	0.61	-1.96	-4.31	-6.61	-0.65	-5.67	-10.85	-0.37	-3.40	-4.05	-9.42	-5.59	-5.96	-2.27	-6.32	-2.49	-5.59	-0.56	-1.82	-3.62	-6.17	-7.95	-2.54	-4.84	-1.56	-5.33	-1.74	-2.25	-3.62	-10.34	-4.20	-1.82	-1.77	0.50	-4.00	-6.64	-2.97	-2.35	-3.14	-2.38	-100000000.00	-5.49	
stop_tag 	-4.35	-7.74	-1.26	-0.88	-2.02	-4.27	-1.41	-4.61	-7.28	0.56	-5.11	-1.85	-1.55	-2.01	-0.88	-4.56	0.26	-1.23	-5.13	-2.10	-0.73	-1.21	-5.34	-1.62	-6.11	-1.57	-1.71	-0.62	-3.63	-1.42	-7.33	-3.51	-6.87	-4.87	-8.18	0.86	-4.34	-2.03	-2.27	-2.47	-6.20	-1.55	-8.51	-6.52	0.48	-6.47	-100000000.00	-0.02	
NNP 	-0.37	-1.11	-0.43	-0.52	-0.76	-1.13	-0.64	-1.37	-1.47	-0.74	-2.67	-0.39	-0.66	-0.88	-1.63	-2.37	-1.02	-0.48	-0.77	-0.78	0.92	-2.47	-0.89	-0.66	-6.75	-2.58	-0.14	-2.01	-3.24	-0.57	-0.53	0.51	-5.64	-4.41	-2.38	-0.76	-5.42	-0.46	-1.84	-4.29	-1.94	-1.15	-2.42	-0.73	-1.42	-1.87	-100000000.00	1.02	
Mean train loss after  0 batches of 7  epochs =0.0159430252878
Mean train loss after  100 batches of 7  epochs =0.0180872966884
Mean train loss after  200 batches of 7  epochs =0.0253807719165
Mean train loss after  300 batches of 7  epochs =0.029787354254
Mean train loss after  400 batches of 7  epochs =0.028025700742
Mean train loss after  500 batches of 7  epochs =0.0259795373544
Mean train loss after  600 batches of 7  epochs =0.0237733917155
Mean train loss after  700 batches of 7  epochs =0.0234656124604
Mean train loss after  800 batches of 7  epochs =0.0228019272266
Mean train loss after  900 batches of 7  epochs =0.0221136563564
Mean train loss after  1000 batches of 7  epochs =0.0222361177573
Mean train loss after  1100 batches of 7  epochs =0.0231424288844
Mean train loss after  1200 batches of 7  epochs =0.0237212912138
Mean train loss after  1300 batches of 7  epochs =0.0240552362329
Mean train loss after  1400 batches of 7  epochs =0.023985325255
Mean train loss after  1500 batches of 7  epochs =0.0240455596159
Mean train loss after  1600 batches of 7  epochs =0.0236220396346
Mean train loss after  1700 batches of 7  epochs =0.0235263968543
Mean train loss after  1800 batches of 7  epochs =0.0238319974431
Mean train loss after  1900 batches of 7  epochs =0.023782304431
Mean train loss after  2000 batches of 7  epochs =0.0235076307306
Mean train loss after  2100 batches of 7  epochs =0.0234246370392
Mean train loss after  2200 batches of 7  epochs =0.0231961481675
Mean train loss after  2300 batches of 7  epochs =0.0229105269881
Mean train loss after  2400 batches of 7  epochs =0.0226203705314
Mean train loss after  2500 batches of 7  epochs =0.0229951253398
Mean train loss after  2600 batches of 7  epochs =0.0228879369197
Mean train loss after  2700 batches of 7  epochs =0.0233749832467
Mean train loss after  2800 batches of 7  epochs =0.0238850142211
Mean train loss after  2900 batches of 7  epochs =0.0239192587224
Mean train loss after  3000 batches of 7  epochs =0.0238153149431
Mean train loss after  3100 batches of 7  epochs =0.0240177921419
Mean train loss after  3200 batches of 7  epochs =0.0242275633758
Mean train loss after  3300 batches of 7  epochs =0.0241305875603
Mean train loss after  3400 batches of 7  epochs =0.0243643586715
Mean train loss after  3500 batches of 7  epochs =0.0243372073538
Mean train loss after  3600 batches of 7  epochs =0.0244339216532
Mean train loss after  3700 batches of 7  epochs =0.0244874998647
Mean train loss after  3800 batches of 7  epochs =0.024444650491
Mean train loss after  3900 batches of 7  epochs =0.0245565913102
Mean train loss after  4000 batches of 7  epochs =0.0245146225487
Mean train loss after  4100 batches of 7  epochs =0.0245494931933
Mean train loss after  4200 batches of 7  epochs =0.0251138380691
Mean train loss after  4300 batches of 7  epochs =0.0252514412819
Mean train loss after  4400 batches of 7  epochs =0.024986460975
Mean train loss after  4500 batches of 7  epochs =0.0247888229909
Mean train loss after  4600 batches of 7  epochs =0.0248082567692
Mean train loss after  4700 batches of 7  epochs =0.0249241530081
Mean train loss after  4800 batches of 7  epochs =0.0249830505459
Mean train loss after  4900 batches of 7  epochs =0.0253489529203
Mean train loss after  5000 batches of 7  epochs =0.0253067397687
Mean train loss after  5100 batches of 7  epochs =0.0251052658542
Mean train loss after  5200 batches of 7  epochs =0.0253475928636
Mean train loss after  5300 batches of 7  epochs =0.0254774195399
Mean train loss after  5400 batches of 7  epochs =0.0258391988859
Mean train loss after  5500 batches of 7  epochs =0.0261663046104
Mean train loss after  5600 batches of 7  epochs =0.0267610459062
Mean train loss after  5700 batches of 7  epochs =0.0268301502933
Mean train loss after  5800 batches of 7  epochs =0.026750044202
Mean train loss after  5900 batches of 7  epochs =0.0266528705864
Mean train loss after  6000 batches of 7  epochs =0.0265425502597
Mean train loss after  6100 batches of 7  epochs =0.026579380881
Mean train loss after  6200 batches of 7  epochs =0.0265768301394
Mean train loss after  6300 batches of 7  epochs =0.0265126641585
Mean train loss after  6400 batches of 7  epochs =0.0265346294672
Mean train loss after  6500 batches of 7  epochs =0.0264784962393
Mean train loss after  6600 batches of 7  epochs =0.0264697894214
Mean train loss after  6700 batches of 7  epochs =0.0265245519505
Mean train loss after  6800 batches of 7  epochs =0.0266546302931
Mean train loss after  6900 batches of 7  epochs =0.0267245298986
Mean train loss after  7000 batches of 7  epochs =0.0266576210051
Mean train loss after  7100 batches of 7  epochs =0.0268166575135
Mean train loss after  7200 batches of 7  epochs =0.0268264338479
Mean train loss after  7300 batches of 7  epochs =0.0268829263128
Mean train loss after  7400 batches of 7  epochs =0.0268528404234
Mean train loss after  7500 batches of 7  epochs =0.0269732648469
Mean train loss after  7600 batches of 7  epochs =0.0270437647981
Mean train loss after  7700 batches of 7  epochs =0.0269555078175
Mean train loss after  7800 batches of 7  epochs =0.0269905571103
Mean train loss after  7900 batches of 7  epochs =0.0270343312202
Mean train loss after  8000 batches of 7  epochs =0.0271681398124
Mean train loss after  8100 batches of 7  epochs =0.0272840527882
Mean train loss after  8200 batches of 7  epochs =0.027357493918
Mean train loss after  8300 batches of 7  epochs =0.0273971086841
Mean train loss after  8400 batches of 7  epochs =0.0274969383418
Mean train loss after  8500 batches of 7  epochs =0.0275316280806
Mean train loss after  8600 batches of 7  epochs =0.0275472159555
Mean train loss after  8700 batches of 7  epochs =0.0275016597972
Mean train loss after  8800 batches of 7  epochs =0.0274244400747
Mean train loss after  8900 batches of 7  epochs =0.0273998662807
Mean train loss after  9000 batches of 7  epochs =0.0274908664409
Mean train loss after  9100 batches of 7  epochs =0.0275115355023
Mean train loss after  9200 batches of 7  epochs =0.0275489002848
Mean train loss after  9300 batches of 7  epochs =0.0278773481271
Mean train loss after  9400 batches of 7  epochs =0.0278266487849
Mean train loss after  9500 batches of 7  epochs =0.0278118877286
Mean train loss after  9600 batches of 7  epochs =0.0279297974004
Mean train loss after  9700 batches of 7  epochs =0.0278821887361
Mean train loss after  9800 batches of 7  epochs =0.0280313919628
Mean train loss after  9900 batches of 7  epochs =0.0280341287495
Mean train loss after  10000 batches of 7  epochs =0.0279392666297
Mean train loss after  10100 batches of 7  epochs =0.0278665544379
Mean train loss after  10200 batches of 7  epochs =0.0278690397606
Mean train loss after  10300 batches of 7  epochs =0.0278705751956
Mean train loss after  10400 batches of 7  epochs =0.0278453662084
Mean train loss after  10500 batches of 7  epochs =0.0280552861495
Mean train loss after  10600 batches of 7  epochs =0.0281425072528
Mean train loss after  10700 batches of 7  epochs =0.0282373123751
Mean train loss after  10800 batches of 7  epochs =0.0282207530722
Mean train loss after  10900 batches of 7  epochs =0.028225866371
Mean train loss after  11000 batches of 7  epochs =0.0283650878002
Mean train loss after  11100 batches of 7  epochs =0.0283965783106
Mean train loss after  11200 batches of 7  epochs =0.0285809210801
Mean train loss after  11300 batches of 7  epochs =0.0285641907657
Mean train loss after  11400 batches of 7  epochs =0.02861143058
Mean train loss after  11500 batches of 7  epochs =0.0286852674528
Mean train loss after  11600 batches of 7  epochs =0.0287559004619
Mean train loss after  11700 batches of 7  epochs =0.0287936585923
Mean train loss after  11800 batches of 7  epochs =0.029003871388
Mean train loss after  11900 batches of 7  epochs =0.0289869418511
Mean train loss after  12000 batches of 7  epochs =0.0290097666604
Mean train loss after  12100 batches of 7  epochs =0.0291259726398
Mean train loss after  12200 batches of 7  epochs =0.0293280263659
Mean train loss after  12300 batches of 7  epochs =0.0292723145544
Mean train loss after  12400 batches of 7  epochs =0.02939473324
Mean train loss after  12500 batches of 7  epochs =0.0293085113365
Mean train loss after  12600 batches of 7  epochs =0.029263380284
Mean train loss after  12700 batches of 7  epochs =0.0292749312874
Mean train loss after  12800 batches of 7  epochs =0.0293413170067
Mean train loss after  12900 batches of 7  epochs =0.0293470463966
Mean train loss after  13000 batches of 7  epochs =0.0292597340841
Mean train loss after  13100 batches of 7  epochs =0.0293878866579
Mean train loss after  13200 batches of 7  epochs =0.0294822442136
Mean train loss after  13300 batches of 7  epochs =0.0294663492146
Mean train loss after  13400 batches of 7  epochs =0.0296262696261
Mean train loss after  13500 batches of 7  epochs =0.0296199646166
Mean train loss after  13600 batches of 7  epochs =0.0296027361574
Mean train loss after  13700 batches of 7  epochs =0.0297278026645
Mean train loss after  13800 batches of 7  epochs =0.0297283038437
Mean train loss after  13900 batches of 7  epochs =0.0297199414453
Mean train loss after  14000 batches of 7  epochs =0.0297211412668
Mean train loss after  14100 batches of 7  epochs =0.0298315038896
Mean train loss after  14200 batches of 7  epochs =0.0300296589531
Mean train loss after  14300 batches of 7  epochs =0.0300099092527
Mean train loss after  14400 batches of 7  epochs =0.0302292686203
Mean train loss after  14500 batches of 7  epochs =0.0303502250292
Mean train loss after  14600 batches of 7  epochs =0.0304970257907
Mean train loss after  14700 batches of 7  epochs =0.030544679725
Mean train loss after  14800 batches of 7  epochs =0.0306558056062
Mean train loss after  14900 batches of 7  epochs =0.0306680644085
Epoch 7 : Mean train epoch loss =0.0306306404317
Epoch 7 Epoch val loss = 17537.9113488
Epoch 7 Epoch val perplexity = 1.4299913282313266
SCORES =  (92.61, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 8---------------------

=================================
fscore(z) =  [130.01631] || goldscore = [130.00723]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-5.45	-0.90	0.02	-3.03	-0.45	-2.09	-0.59	-1.51	-1.46	-1.97	-3.04	-0.03	-0.61	-0.99	-0.78	-2.86	-2.36	-3.84	-3.58	-3.46	-2.59	-3.18	0.81	-1.46	-3.61	-3.36	-4.65	-2.30	-2.32	0.49	-0.63	0.39	-1.33	-2.81	-1.71	-3.94	-3.73	0.01	-2.96	-2.17	-4.78	-2.94	-4.10	-2.83	-2.12	-4.14	-100000000.00	-3.08	
VBG 	-1.74	-3.84	-0.12	0.08	-0.46	-0.01	-2.00	-0.59	-2.90	-2.60	-3.91	0.04	-0.06	-1.25	-1.75	-4.71	-0.35	-2.36	-3.20	-6.62	-1.17	-1.98	-0.75	0.35	-3.27	-0.90	-1.56	-0.03	-3.10	-0.58	-2.13	-0.53	-4.22	-1.42	-0.62	-1.22	-4.35	0.31	-1.35	-2.19	-1.97	-1.49	-0.45	-2.32	-2.74	-7.81	-100000000.00	-1.53	
VBD 	-3.31	-4.02	-4.05	-1.61	-1.73	0.92	-1.68	-1.39	1.73	-2.01	-0.02	-2.03	-1.67	-1.28	-1.82	-3.14	-0.14	0.36	-2.12	-2.55	-1.49	-2.35	-5.55	-1.37	-5.24	-0.18	-2.23	-0.03	1.00	-2.08	-0.68	-0.86	-3.41	-1.23	-0.48	-1.57	-0.05	-3.17	-0.21	-4.61	-4.08	-0.60	-1.26	-0.82	-5.25	-3.34	-100000000.00	-0.03	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.67	-1.93	-0.84	-0.59	-2.01	-1.03	-3.78	0.74	-1.60	-1.85	-2.69	0.83	-0.79	-0.88	-1.75	-4.85	-0.75	-2.06	-1.24	-1.93	-1.67	-3.12	-2.99	-0.52	-4.28	0.77	-1.94	-0.57	-1.64	-0.35	-1.60	-0.60	-3.29	-2.05	-2.04	-2.49	-4.30	-1.64	-1.71	-1.70	-4.18	-2.01	-2.68	-2.30	-1.42	-5.89	-100000000.00	-2.66	
, 	-2.38	-2.79	-0.49	-5.13	-1.17	-4.00	0.41	-2.41	0.25	0.92	-3.54	-2.52	-1.70	-2.32	-0.66	-6.07	0.61	0.06	-3.43	-1.61	-2.03	-3.54	-3.95	-0.27	-5.12	0.60	-3.36	-0.19	-1.31	-1.49	-4.89	-2.67	-4.81	-3.21	0.31	1.11	-2.66	-0.47	-3.11	-4.83	-2.73	-0.78	-3.07	-0.90	-7.80	-1.29	-100000000.00	0.13	
'' 	-4.75	-1.11	-1.17	0.46	-3.20	-0.84	-0.68	-3.10	-0.45	-2.36	-2.48	-0.85	-3.69	-5.57	0.30	-0.44	-0.84	-2.81	-2.03	-1.71	-1.15	1.01	-4.03	0.89	-2.02	-0.25	0.21	-4.20	-2.15	-2.17	-2.93	-0.18	-0.77	-2.58	1.35	-1.73	-0.42	-0.80	-0.28	-1.89	-1.43	-2.52	-2.39	-3.02	-4.09	-1.73	-100000000.00	-0.43	
VBP 	-5.80	-3.06	-4.87	-4.76	-2.20	-1.59	0.05	-2.86	0.61	-3.83	0.41	-1.90	-2.22	-4.02	-2.41	-4.19	-1.62	-0.83	-2.87	-7.26	-4.22	-1.92	-2.96	-1.23	-4.58	-0.76	-2.97	0.98	0.95	-2.80	-2.51	-1.01	-1.23	-2.55	-0.60	-0.37	0.92	-3.83	-1.42	-1.84	-6.44	0.64	-4.21	-3.51	-3.09	-5.06	-100000000.00	-0.46	
WDT 	-3.88	-4.26	-4.40	-1.48	-3.09	-0.89	-3.70	-2.44	-1.97	-3.10	-4.49	-2.83	0.15	-3.58	-2.60	-3.96	0.31	-0.93	-5.14	-4.51	-3.31	-1.11	-0.78	-0.73	-3.00	-2.95	0.06	0.33	-2.46	-2.89	-3.16	-2.06	-0.79	-3.55	-3.09	-1.32	-1.48	-0.08	0.20	-1.31	-1.84	-2.63	-3.44	-2.90	-3.74	-2.43	-100000000.00	-0.44	
JJ 	0.63	-0.83	-0.37	-0.60	-0.36	-1.32	-1.37	-0.22	-2.24	-0.55	-3.55	0.12	1.84	-0.14	-1.55	0.13	-1.75	-1.58	-1.09	-3.32	-0.29	-3.26	-0.24	-0.97	-6.51	-0.15	0.29	-1.85	-0.91	-0.30	0.17	-0.37	-5.81	0.35	0.80	0.69	-4.65	1.11	-0.47	-3.30	-3.14	-2.93	-0.66	-0.88	-1.95	-3.64	-100000000.00	-1.04	
WP 	-3.27	-2.60	-3.07	-2.70	-1.14	-1.30	0.65	-0.52	-1.54	-1.86	-2.08	-0.58	-1.08	-1.32	-2.54	-3.11	0.32	-2.17	-1.49	-2.56	-2.52	-2.45	0.35	-2.02	-2.18	-1.17	-3.19	0.17	-2.26	-0.36	-2.54	-1.36	-2.69	-2.28	-3.41	-3.26	-1.64	0.12	-2.20	-0.49	-3.33	-1.03	-2.82	-1.77	-2.68	-1.64	-100000000.00	-1.63	
VBZ 	-2.30	-3.40	-5.12	-3.99	-2.71	0.07	-2.11	-1.31	1.98	-1.68	-0.61	-2.84	-0.62	-1.24	-2.99	-3.13	0.82	-1.05	-0.92	-3.05	-3.24	-1.65	-3.50	-1.62	-3.28	-0.41	-1.92	-2.74	1.86	-3.13	-0.49	-0.80	-4.32	-2.93	-4.25	-1.17	1.12	-3.29	-1.77	-2.32	-4.18	-3.79	-1.84	-3.10	-2.71	-6.65	-100000000.00	-0.10	
DT 	-3.87	-1.92	-0.99	-0.20	-0.40	-0.23	-1.36	-0.56	-1.97	-0.95	-2.31	-0.27	-1.92	-0.82	0.05	-6.25	-0.30	-1.29	0.19	-2.45	-1.81	-2.27	0.70	-2.08	-4.36	-0.95	-0.47	-1.33	-1.71	0.94	-0.19	1.58	0.21	-1.63	0.73	-2.97	-3.00	1.61	-0.44	-1.96	-2.22	-3.15	-3.94	-2.58	-0.60	-5.91	-100000000.00	-0.04	
" 	0.01	-0.55	-2.32	-1.90	-1.28	0.04	0.90	-1.97	-0.52	-0.53	-2.31	-0.77	-0.89	-2.17	-0.40	-3.61	0.11	-1.26	-2.65	-3.87	0.97	1.18	-1.97	0.02	-0.51	-2.07	0.44	-2.50	-3.58	-1.74	-2.39	-1.79	-3.17	-3.98	-2.57	-1.26	-3.45	-1.09	-1.16	-3.64	-3.47	-2.51	-3.14	-1.65	-2.41	-4.05	-100000000.00	0.01	
RP 	-5.23	0.69	1.22	-3.93	0.99	-2.05	-3.34	1.18	-3.22	-2.03	-4.65	-0.75	-0.03	-4.37	-1.89	-3.14	-1.93	-1.42	-4.06	-4.05	-2.55	-0.85	-5.33	-0.97	-3.12	-1.75	-4.80	-2.07	0.15	0.14	-3.43	-4.36	-2.15	-3.41	-1.49	-1.91	-6.23	-3.91	-1.15	-1.66	-5.53	-3.92	-2.87	-3.45	-4.30	-4.94	-100000000.00	-3.05	
$ 	-2.70	-1.40	-0.81	-5.81	-0.64	-2.35	-1.93	-1.49	-2.29	-0.00	-2.65	-0.37	-0.48	-2.46	-0.56	0.61	0.17	-2.32	-0.67	-5.95	-0.14	-0.94	0.44	-0.69	0.10	-1.04	-0.62	-1.77	-2.06	-0.18	-2.29	-0.31	-2.94	-1.15	-3.39	-1.25	-2.12	0.30	-2.00	-2.86	-1.29	-3.36	-1.96	-2.83	-4.27	-2.52	-100000000.00	0.50	
NN 	0.92	-0.39	-0.96	0.50	0.12	0.70	-2.00	-1.19	-2.12	0.59	-1.22	-0.32	0.38	-0.85	-1.51	-4.16	-0.99	-0.77	-1.36	-0.92	0.93	-1.57	-1.63	-2.05	-7.16	-2.74	0.53	-2.04	-2.99	-0.18	-2.02	-1.72	-3.30	-3.65	-0.62	-0.39	-5.36	0.11	1.52	-5.10	-5.05	-1.81	0.26	0.22	-1.55	-9.82	-100000000.00	-0.45	
) 	-4.28	-1.72	-3.52	-4.74	-1.44	-4.46	-4.39	-4.05	-5.61	-0.88	-5.37	-1.27	-3.13	-2.23	0.32	-4.12	-1.58	-2.80	-2.23	-3.19	-0.97	-3.55	-4.39	0.12	0.01	-2.62	-3.04	-2.58	-5.93	-1.42	-4.95	-3.85	-5.38	-3.31	-4.86	1.17	-1.93	-1.96	-2.44	-5.26	-4.21	-1.33	-6.72	-7.80	-3.78	-4.54	-100000000.00	-0.38	
( 	0.33	-3.81	-1.27	-2.53	-3.42	-3.14	-2.29	-4.56	-2.23	-1.43	-1.83	-1.35	-2.00	-0.80	-3.63	-5.31	0.09	-2.30	-4.07	-1.62	-0.91	-2.31	-2.12	-0.39	-2.63	-3.21	-1.98	-0.76	-1.82	-1.87	-2.51	-3.77	-5.70	-3.82	-5.14	0.39	-3.54	-4.51	-2.10	-2.83	-5.20	-1.67	-1.63	-2.66	-6.35	-3.22	-100000000.00	1.25	
FW 	-5.44	-4.80	-3.79	-2.26	-5.85	-2.01	-2.31	-1.52	-2.43	-2.35	-3.33	-6.95	-4.09	-4.01	-5.16	-2.05	-2.90	-1.60	-3.45	-1.06	-5.71	-1.33	-5.88	-0.65	-1.86	-4.98	-2.61	-3.41	-5.51	-2.82	-0.63	-2.71	-3.02	-2.48	-3.77	-2.65	-2.96	-11.44	-0.03	-2.17	-2.62	-2.33	-4.35	-4.73	-2.62	-1.88	-100000000.00	-0.80	
POS 	-2.67	-5.46	-2.39	-2.93	-0.68	-2.05	1.02	-1.80	0.47	-0.30	-4.84	-4.20	-1.85	-2.99	-3.68	-3.72	1.58	-3.61	-3.13	-5.52	-3.59	-1.66	-3.65	-2.07	-5.44	-2.62	-2.10	-0.14	-1.26	-2.36	-2.27	-2.59	-2.25	-0.93	-3.06	-1.93	-0.89	-2.31	-2.44	-2.82	-3.54	-1.56	-3.85	-2.77	-4.09	-4.82	-100000000.00	1.97	
. 	-2.87	-0.89	-1.52	-4.88	-0.97	-5.64	-3.12	-0.61	-4.82	-0.09	-3.62	-0.58	-0.22	-1.01	-0.31	-6.73	-0.68	-0.78	-3.67	-3.83	-1.06	-1.81	-3.84	-0.78	-0.08	-0.73	-2.26	0.72	-1.11	-1.36	-1.61	-2.38	-3.00	-7.42	-0.85	0.66	-1.97	-1.80	-2.01	-4.42	-4.64	-0.59	-4.62	-1.79	-6.36	-2.35	-100000000.00	1.41	
TO 	-1.97	-1.99	-0.30	-2.54	-1.02	-2.43	-3.63	-0.15	-4.56	-0.92	-3.50	0.42	-3.18	-2.35	-0.29	-5.39	-0.95	-2.06	-2.62	-4.22	-4.66	-3.40	-3.30	-1.39	-4.17	-0.62	-1.61	-1.15	-2.43	-1.23	-1.46	-3.00	-5.95	-3.60	-0.59	0.75	-2.84	-0.02	-1.70	-2.83	-4.22	-3.03	-1.93	-0.96	-5.53	-7.58	-100000000.00	-1.57	
-X- 	-0.35	-0.07	-2.23	-2.72	-1.53	-1.63	-1.66	-1.44	-0.83	-2.00	-2.48	-2.39	-1.48	-2.23	0.30	-2.18	-0.87	-1.38	-2.51	-0.67	-1.53	-0.49	-2.19	2.00	-1.47	-2.17	-2.19	-1.42	-1.88	-1.60	0.21	-0.07	1.66	-0.31	-0.30	-2.46	0.35	-2.12	0.84	1.11	0.79	-2.17	-1.88	1.58	-1.02	0.35	-100000000.00	-4.12	
LS 	-2.05	-2.51	-4.92	-0.99	-3.39	-2.45	-1.03	-4.26	-1.66	-4.35	-1.02	-2.32	-5.80	-2.91	-4.07	-4.51	-3.28	-2.69	-3.17	-3.49	-1.65	-0.15	-4.05	-1.55	-3.45	-5.03	1.13	-5.56	-3.40	-2.69	0.08	-4.70	-1.02	-0.96	-2.45	-5.09	-3.01	-3.86	-1.19	-1.15	-3.89	-4.19	-2.14	-4.72	-1.99	-2.33	-100000000.00	-4.12	
RB 	-2.17	-0.31	0.66	-0.95	-0.10	-0.94	-0.97	0.26	-1.41	-2.14	-1.59	0.43	-0.81	-0.26	-0.86	-3.48	-0.42	0.02	-1.27	-6.62	-1.78	-2.96	-0.63	-1.11	-3.67	-1.40	-2.19	-0.43	-0.37	0.12	-0.59	-1.17	-5.09	-1.93	-0.98	-0.55	-2.49	-0.90	-1.53	-1.34	0.74	-3.62	-1.77	-1.95	-2.38	-5.74	-100000000.00	-1.01	
: 	-5.38	-2.12	-1.19	-2.92	-1.43	-3.49	-3.89	-1.45	-3.32	0.31	-2.62	-0.82	-2.28	-3.11	-2.78	-3.19	0.17	-1.91	-2.62	-7.66	0.22	-2.42	-5.85	-1.87	-3.24	-1.90	-2.60	-2.45	-3.30	-0.40	-4.30	-5.41	-3.27	-2.97	-2.06	0.20	-3.52	-1.00	-2.25	-3.33	-5.99	-0.42	-6.46	-1.34	-4.17	-5.20	-100000000.00	-0.28	
NNS 	1.51	-0.76	-0.85	-0.51	-0.54	-1.95	-2.34	-1.03	-1.25	0.96	-1.98	-1.60	-0.60	-2.23	-2.01	-4.02	-0.03	-2.55	-1.04	-2.56	0.38	-2.91	-2.43	-2.19	-5.93	-3.65	-0.39	-4.45	-1.94	-0.16	-0.45	0.38	-3.84	-2.29	-1.96	-0.53	-4.55	-1.06	0.65	-4.22	-2.51	-3.81	-0.68	0.27	-2.34	-9.49	-100000000.00	-1.17	
PRP 	-4.50	-1.04	-0.25	-1.53	0.40	-1.39	0.38	-1.10	-1.06	-2.14	0.33	-0.06	-2.80	-1.20	-3.92	-4.35	-0.86	-2.79	-4.72	-5.69	-0.67	-1.03	-1.12	-0.10	-3.38	-1.66	-0.10	-1.82	-5.31	0.72	0.63	-1.33	-2.29	-3.72	-2.37	-2.82	-1.34	1.06	-2.50	-2.45	-2.62	-5.07	-2.39	-4.57	-2.67	-3.57	-100000000.00	-1.61	
VB 	-4.05	-1.90	-2.95	-0.05	-3.55	-0.32	-2.24	-1.72	-1.51	-2.88	-1.07	-1.95	-1.50	-1.22	-2.04	-0.57	-1.31	0.01	-3.17	-2.15	-5.02	-1.13	0.53	-0.97	-4.04	0.32	-0.10	-1.91	-0.08	-2.87	-2.38	0.74	-0.23	-2.58	0.29	-2.16	-3.18	-2.94	-2.54	-1.82	1.71	-2.68	-1.40	-0.86	-4.69	-1.28	-100000000.00	-1.58	
WRB 	-3.12	-1.27	-1.71	-1.48	-0.79	-0.47	-2.02	-1.80	-1.98	-0.13	-2.00	0.23	-4.75	-2.28	-0.72	-1.97	-0.71	-2.85	-3.00	-3.74	-2.57	-0.53	-2.53	0.02	-2.25	-1.67	-4.65	-1.77	-1.75	-0.75	-3.13	-1.42	-3.25	-1.77	-4.84	-1.17	-2.27	-0.78	0.47	-1.33	-3.59	-5.09	-2.20	-1.71	-4.22	-0.94	-100000000.00	-0.90	
CC 	-3.72	-2.07	-2.53	-2.17	-0.74	-0.09	-3.70	-1.33	-2.63	0.99	-3.56	-1.97	-3.35	-1.98	-1.00	-4.15	-0.36	-1.82	-5.08	-4.09	-1.17	-0.69	-2.27	-2.22	-3.71	-1.01	-0.17	-1.39	-1.42	0.30	-2.95	-3.56	-2.40	-5.30	-0.27	0.56	-0.93	-1.59	-1.61	-2.43	-3.68	-0.44	-2.84	-1.35	-2.14	-6.99	-100000000.00	0.26	
PDT 	-3.37	-0.25	-3.39	-2.28	-0.65	-5.29	-2.69	-0.91	-3.96	-2.07	-4.49	-1.35	-3.47	-2.88	-2.09	-2.75	-3.14	-3.09	-0.90	-1.57	-0.76	-0.67	-3.93	0.08	-1.57	-0.68	-2.55	-1.46	-3.51	-1.48	-0.81	-1.77	-1.04	0.01	-2.77	-3.11	-1.35	0.76	-0.94	-1.20	-0.86	-2.27	-2.54	-2.05	-4.93	-1.60	-100000000.00	-0.98	
RBS 	-0.46	-4.17	-1.10	-6.80	-1.74	-1.84	-0.97	-3.39	-3.96	-3.43	-0.11	-0.59	-0.58	-3.46	-1.76	-2.22	-1.72	-3.59	-4.27	-3.31	-0.64	-0.54	-2.00	1.77	-3.23	-1.06	-4.50	-8.19	-5.27	-1.49	-3.27	-0.34	-2.78	-1.32	-2.36	-3.83	-2.01	0.26	-1.08	0.06	-4.04	-3.29	-4.30	-4.68	-3.33	-2.72	-100000000.00	-7.93	
RBR 	-4.01	-1.92	-0.11	-2.13	0.04	-2.68	-1.16	-1.69	-0.72	-2.50	-0.78	-0.62	-0.72	-2.88	-0.71	-3.28	-0.31	-2.81	-3.70	-5.10	-4.82	-1.65	-1.32	0.53	-0.98	-0.22	-0.84	-0.18	-1.62	-0.99	-2.85	-1.41	-1.96	-1.51	-4.15	-2.60	-4.47	-0.78	-1.03	-0.30	-1.57	-3.34	-2.30	-3.13	-1.98	-1.57	-100000000.00	-0.95	
CD 	-1.15	-1.13	-0.79	-0.91	-1.95	-0.70	-1.21	-2.02	-1.77	-0.45	-3.75	-1.03	-0.79	-0.74	-3.23	3.04	-0.93	-0.57	-0.41	-2.16	0.30	-4.10	0.01	-2.67	-8.01	-0.85	-0.13	-1.82	-1.77	-0.34	-1.49	-1.00	-2.32	-5.44	-7.02	-0.90	-7.47	-0.47	0.04	0.10	-7.55	-1.31	-1.92	-1.29	-1.76	-3.41	-100000000.00	-0.59	
EX 	-1.46	-1.08	0.15	-0.36	-2.24	-2.10	-2.23	-0.78	-0.80	-1.09	-0.45	-0.57	-0.43	-0.74	-2.49	-2.51	-0.64	-3.16	-4.17	-4.04	-3.47	-2.44	-4.36	-1.22	-1.55	-2.12	-2.52	-2.60	-1.01	-1.11	-1.10	0.87	-1.53	-2.12	-0.19	-3.19	-2.44	-1.16	-1.15	-0.74	-1.44	-2.47	-1.11	-3.08	-3.38	-1.24	-100000000.00	-1.50	
IN 	-3.53	-1.31	-1.21	-1.01	0.17	-0.34	-2.32	0.27	-1.27	-0.98	-4.52	-0.51	-1.07	0.27	-0.60	-2.99	0.30	-0.82	-1.69	-4.89	-1.96	-3.71	-1.67	-2.15	-7.56	-1.21	-1.52	0.42	-1.33	-0.36	-2.69	-0.90	-3.50	-2.12	0.86	-0.70	-1.30	-0.71	-2.68	-1.05	-5.00	-1.95	-0.37	-0.17	-3.59	-9.12	-100000000.00	-0.56	
WP$ 	-0.68	-1.94	-1.47	-5.41	-2.14	0.79	-0.94	-2.85	-0.49	-1.65	0.33	-1.80	-1.08	-1.55	-1.62	0.72	-1.55	-1.15	-2.46	-1.13	-0.60	-2.57	-2.39	0.36	-1.15	-1.87	-2.14	-0.32	-1.61	-2.81	-2.52	-2.76	-0.54	0.16	-0.00	-2.95	-0.96	-2.20	-1.94	0.03	-0.54	-1.01	-2.08	-1.53	-1.64	-0.10	-100000000.00	-2.05	
NN|SYM 	-1.29	-4.02	-3.29	-6.81	-3.76	-2.18	-1.73	-3.93	-0.37	-3.34	-1.92	-3.26	-4.41	-3.88	-2.48	-2.30	-5.97	-0.38	-2.08	-2.34	-2.40	1.05	-4.31	0.50	-1.44	-3.53	-4.40	-4.98	-3.20	-3.37	-1.41	-3.54	-0.25	0.50	-2.49	-5.35	-0.92	-3.31	-0.18	-0.84	-2.85	-2.66	-2.85	-2.84	-3.79	-2.18	-100000000.00	-5.61	
MD 	-0.92	-2.81	-1.84	-4.29	-3.94	-1.23	-2.26	-2.16	1.13	-1.29	-1.53	-2.18	-1.27	-1.82	-0.87	-4.03	-0.61	-1.67	-4.90	-5.70	-2.65	-0.21	-3.79	-0.86	-2.02	-1.64	-2.28	-0.51	0.24	-2.27	-0.79	-1.67	-2.98	-1.97	-4.36	-1.66	-0.44	-3.32	-2.41	-0.47	-3.64	-1.57	-4.30	-5.50	-4.64	-2.74	-100000000.00	-0.46	
NNPS 	-4.46	-3.17	-2.74	-2.88	-2.37	-2.09	-2.88	-1.57	-2.59	-2.25	-4.13	-2.27	-1.22	-2.33	-3.50	-4.37	-3.14	-0.28	-1.87	-6.88	-3.32	-1.64	-4.71	-1.06	-3.64	-7.88	-2.22	-6.32	-5.18	-1.66	-2.71	-2.27	-2.93	-1.77	-6.07	-1.11	-4.41	-1.57	-0.43	-3.73	-4.68	-2.35	-4.58	-5.65	-3.51	-7.74	-100000000.00	0.14	
JJS 	-0.25	-5.59	-1.84	-1.24	-0.96	-2.70	-1.38	-2.92	-3.40	-1.93	-2.27	-3.90	-1.43	-2.24	-3.33	-2.92	-5.12	-4.15	-2.74	-4.02	-1.34	-1.32	-2.18	-2.48	-3.76	-4.39	-5.23	-4.33	-3.93	-2.36	-2.05	-3.12	-1.84	-1.42	-3.79	-3.58	-1.29	-0.98	-0.41	-1.24	-3.55	-5.62	-3.46	-6.25	-3.85	-2.52	-100000000.00	-5.46	
JJR 	-2.36	-1.47	-0.14	-0.56	-1.10	-3.37	-1.92	-0.93	-3.75	-1.69	-4.66	0.05	-1.29	-2.47	-2.59	-2.90	-2.63	-6.38	0.21	-4.12	-7.49	-1.31	-1.35	-0.22	-3.00	-0.60	-2.06	-1.59	-1.87	0.23	-0.55	-1.57	-4.57	-4.09	-4.09	-2.14	-2.39	-1.17	-1.68	-0.81	-2.86	-3.12	-4.14	-5.86	-2.37	-4.88	-100000000.00	-2.21	
SYM 	-1.53	-2.24	-5.02	-0.88	-6.29	-6.48	-2.10	-1.50	-4.30	-0.52	-4.81	-5.07	-5.41	-1.79	-4.48	-2.59	-1.37	-0.91	-3.47	-4.08	-3.99	-0.78	-6.39	-1.15	-3.21	-3.80	-4.84	-2.72	-1.14	-3.99	-4.29	-1.59	-2.88	-3.31	-5.21	-0.72	-4.19	-3.38	-0.55	-1.78	-3.27	-4.82	-3.00	-3.20	-4.00	-0.83	-100000000.00	-0.87	
UH 	-3.55	-4.98	-4.79	-1.65	-6.62	-1.14	0.45	-2.16	-4.59	-6.66	-0.92	-5.94	-11.32	-0.48	-3.56	-4.28	-9.98	-5.94	-6.48	-2.67	-6.71	-2.49	-5.94	-0.56	-2.05	-4.07	-6.55	-8.33	-2.60	-5.08	-1.84	-5.81	-1.92	-2.40	-3.81	-10.58	-4.25	-1.93	-1.81	0.42	-4.30	-6.98	-3.28	-2.56	-3.42	-2.48	-100000000.00	-5.69	
stop_tag 	-4.72	-8.31	-1.18	-0.88	-2.42	-4.44	-1.39	-4.98	-7.86	0.39	-5.66	-2.25	-1.75	-2.24	-1.14	-4.89	0.19	-1.30	-5.36	-2.31	-0.91	-1.39	-5.72	-1.63	-6.36	-1.65	-1.96	-0.79	-4.01	-1.50	-7.96	-3.95	-7.17	-5.13	-8.76	0.89	-4.93	-2.32	-2.44	-2.58	-6.89	-1.95	-9.27	-7.06	0.33	-7.17	-100000000.00	-0.17	
NNP 	-0.40	-1.25	-0.59	-0.58	-0.80	-1.07	-0.70	-1.44	-1.59	-0.78	-2.92	-0.45	-0.65	-0.95	-1.87	-2.53	-1.03	-0.46	-0.79	-0.92	0.95	-2.71	-0.88	-0.71	-7.08	-2.72	-0.24	-1.96	-3.39	-0.57	-0.59	0.54	-6.04	-4.74	-2.73	-0.83	-5.93	-0.48	-1.93	-4.51	-2.02	-1.27	-2.57	-0.86	-1.38	-2.07	-100000000.00	0.98	
Mean train loss after  0 batches of 8  epochs =0.00100877549913
Mean train loss after  100 batches of 8  epochs =0.0131407875988
Mean train loss after  200 batches of 8  epochs =0.01364210501
Mean train loss after  300 batches of 8  epochs =0.0144976849755
Mean train loss after  400 batches of 8  epochs =0.0138747117641
Mean train loss after  500 batches of 8  epochs =0.0142568373839
Mean train loss after  600 batches of 8  epochs =0.0142882297957
Mean train loss after  700 batches of 8  epochs =0.0154489610648
Mean train loss after  800 batches of 8  epochs =0.0158580943996
Mean train loss after  900 batches of 8  epochs =0.0158380991738
Mean train loss after  1000 batches of 8  epochs =0.0154447735089
Mean train loss after  1100 batches of 8  epochs =0.0150678761429
Mean train loss after  1200 batches of 8  epochs =0.0148623600834
Mean train loss after  1300 batches of 8  epochs =0.0147751483202
Mean train loss after  1400 batches of 8  epochs =0.0150186634892
Mean train loss after  1500 batches of 8  epochs =0.0151243674609
Mean train loss after  1600 batches of 8  epochs =0.0149447453068
Mean train loss after  1700 batches of 8  epochs =0.0156060795487
Mean train loss after  1800 batches of 8  epochs =0.0160049684224
Mean train loss after  1900 batches of 8  epochs =0.015744222739
Mean train loss after  2000 batches of 8  epochs =0.0165256492333
Mean train loss after  2100 batches of 8  epochs =0.0168730417672
Mean train loss after  2200 batches of 8  epochs =0.0169123113573
Mean train loss after  2300 batches of 8  epochs =0.0168713696212
Mean train loss after  2400 batches of 8  epochs =0.0172901221597
Mean train loss after  2500 batches of 8  epochs =0.0171277142779
Mean train loss after  2600 batches of 8  epochs =0.0169326105935
Mean train loss after  2700 batches of 8  epochs =0.0173010476342
Mean train loss after  2800 batches of 8  epochs =0.0172419048353
Mean train loss after  2900 batches of 8  epochs =0.0173897693946
Mean train loss after  3000 batches of 8  epochs =0.0173018041408
Mean train loss after  3100 batches of 8  epochs =0.0172276438559
Mean train loss after  3200 batches of 8  epochs =0.0178036937475
Mean train loss after  3300 batches of 8  epochs =0.017833208046
Mean train loss after  3400 batches of 8  epochs =0.0183038661691
Mean train loss after  3500 batches of 8  epochs =0.0183681332453
Mean train loss after  3600 batches of 8  epochs =0.0183366320382
Mean train loss after  3700 batches of 8  epochs =0.0184109476184
Mean train loss after  3800 batches of 8  epochs =0.018427873639
Mean train loss after  3900 batches of 8  epochs =0.0182533077702
Mean train loss after  4000 batches of 8  epochs =0.0186663808084
Mean train loss after  4100 batches of 8  epochs =0.018863882926
Mean train loss after  4200 batches of 8  epochs =0.0186414342592
Mean train loss after  4300 batches of 8  epochs =0.0188414776675
Mean train loss after  4400 batches of 8  epochs =0.0189713125644
Mean train loss after  4500 batches of 8  epochs =0.0190265453255
Mean train loss after  4600 batches of 8  epochs =0.0190187541031
Mean train loss after  4700 batches of 8  epochs =0.0190472879246
Mean train loss after  4800 batches of 8  epochs =0.0191153670688
Mean train loss after  4900 batches of 8  epochs =0.0190064849346
Mean train loss after  5000 batches of 8  epochs =0.0191417991027
Mean train loss after  5100 batches of 8  epochs =0.0194486446082
Mean train loss after  5200 batches of 8  epochs =0.0193571373184
Mean train loss after  5300 batches of 8  epochs =0.0193260366949
Mean train loss after  5400 batches of 8  epochs =0.0193917885289
Mean train loss after  5500 batches of 8  epochs =0.0196853677968
Mean train loss after  5600 batches of 8  epochs =0.0198218432703
Mean train loss after  5700 batches of 8  epochs =0.0199722169234
Mean train loss after  5800 batches of 8  epochs =0.0202301433513
Mean train loss after  5900 batches of 8  epochs =0.0203469621749
Mean train loss after  6000 batches of 8  epochs =0.0204823294702
Mean train loss after  6100 batches of 8  epochs =0.0206663864814
Mean train loss after  6200 batches of 8  epochs =0.0207312202187
Mean train loss after  6300 batches of 8  epochs =0.0209139862104
Mean train loss after  6400 batches of 8  epochs =0.020841603498
Mean train loss after  6500 batches of 8  epochs =0.021037272326
Mean train loss after  6600 batches of 8  epochs =0.0209948130546
Mean train loss after  6700 batches of 8  epochs =0.021020840216
Mean train loss after  6800 batches of 8  epochs =0.0210099927725
Mean train loss after  6900 batches of 8  epochs =0.0210494065856
Mean train loss after  7000 batches of 8  epochs =0.0212497713028
Mean train loss after  7100 batches of 8  epochs =0.0212535781757
Mean train loss after  7200 batches of 8  epochs =0.0212099152271
Mean train loss after  7300 batches of 8  epochs =0.0212433154134
Mean train loss after  7400 batches of 8  epochs =0.021208358189
Mean train loss after  7500 batches of 8  epochs =0.0214140977944
Mean train loss after  7600 batches of 8  epochs =0.0217715734517
Mean train loss after  7700 batches of 8  epochs =0.0218854094686
Mean train loss after  7800 batches of 8  epochs =0.0218493356239
Mean train loss after  7900 batches of 8  epochs =0.0219768777049
Mean train loss after  8000 batches of 8  epochs =0.0220894713061
Mean train loss after  8100 batches of 8  epochs =0.0221123319047
Mean train loss after  8200 batches of 8  epochs =0.0221760425524
Mean train loss after  8300 batches of 8  epochs =0.0222646829355
Mean train loss after  8400 batches of 8  epochs =0.0223277150582
Mean train loss after  8500 batches of 8  epochs =0.0223034329405
Mean train loss after  8600 batches of 8  epochs =0.0223887318919
Mean train loss after  8700 batches of 8  epochs =0.0224899343205
Mean train loss after  8800 batches of 8  epochs =0.0225289966472
Mean train loss after  8900 batches of 8  epochs =0.0226409578114
Mean train loss after  9000 batches of 8  epochs =0.0226790758128
Mean train loss after  9100 batches of 8  epochs =0.0228771815318
Mean train loss after  9200 batches of 8  epochs =0.0229873330437
Mean train loss after  9300 batches of 8  epochs =0.0229335974846
Mean train loss after  9400 batches of 8  epochs =0.0230281787798
Mean train loss after  9500 batches of 8  epochs =0.0231934401941
Mean train loss after  9600 batches of 8  epochs =0.023237844501
Mean train loss after  9700 batches of 8  epochs =0.0232038371507
Mean train loss after  9800 batches of 8  epochs =0.0232966236144
Mean train loss after  9900 batches of 8  epochs =0.0233334286263
Mean train loss after  10000 batches of 8  epochs =0.0233515882895
Mean train loss after  10100 batches of 8  epochs =0.0234204755831
Mean train loss after  10200 batches of 8  epochs =0.0233625626385
Mean train loss after  10300 batches of 8  epochs =0.0233195870118
Mean train loss after  10400 batches of 8  epochs =0.0232973993313
Mean train loss after  10500 batches of 8  epochs =0.0232686445267
Mean train loss after  10600 batches of 8  epochs =0.0232776917326
Mean train loss after  10700 batches of 8  epochs =0.0233565523112
Mean train loss after  10800 batches of 8  epochs =0.0232834579834
Mean train loss after  10900 batches of 8  epochs =0.0233979053753
Mean train loss after  11000 batches of 8  epochs =0.0233693475237
Mean train loss after  11100 batches of 8  epochs =0.0234187646979
Mean train loss after  11200 batches of 8  epochs =0.0234301236012
Mean train loss after  11300 batches of 8  epochs =0.0235356918647
Mean train loss after  11400 batches of 8  epochs =0.0235042523384
Mean train loss after  11500 batches of 8  epochs =0.0234879785575
Mean train loss after  11600 batches of 8  epochs =0.0234664199907
Mean train loss after  11700 batches of 8  epochs =0.0234902430202
Mean train loss after  11800 batches of 8  epochs =0.0234531358813
Mean train loss after  11900 batches of 8  epochs =0.023520048977
Mean train loss after  12000 batches of 8  epochs =0.0235018069834
Mean train loss after  12100 batches of 8  epochs =0.02370550203
Mean train loss after  12200 batches of 8  epochs =0.023783090305
Mean train loss after  12300 batches of 8  epochs =0.0238358758426
Mean train loss after  12400 batches of 8  epochs =0.0238763739169
Mean train loss after  12500 batches of 8  epochs =0.0238637949914
Mean train loss after  12600 batches of 8  epochs =0.0239100737469
Mean train loss after  12700 batches of 8  epochs =0.0239455491891
Mean train loss after  12800 batches of 8  epochs =0.0240261507046
Mean train loss after  12900 batches of 8  epochs =0.0240744024496
Mean train loss after  13000 batches of 8  epochs =0.0242171452616
Mean train loss after  13100 batches of 8  epochs =0.0244611456541
Mean train loss after  13200 batches of 8  epochs =0.0244744932739
Mean train loss after  13300 batches of 8  epochs =0.0244613373153
Mean train loss after  13400 batches of 8  epochs =0.0245362661298
Mean train loss after  13500 batches of 8  epochs =0.0246456405412
Mean train loss after  13600 batches of 8  epochs =0.0247012493018
Mean train loss after  13700 batches of 8  epochs =0.0248503616532
Mean train loss after  13800 batches of 8  epochs =0.0248093805266
Mean train loss after  13900 batches of 8  epochs =0.0247920613244
Mean train loss after  14000 batches of 8  epochs =0.02495302865
Mean train loss after  14100 batches of 8  epochs =0.0250478841843
Mean train loss after  14200 batches of 8  epochs =0.0250410027403
Mean train loss after  14300 batches of 8  epochs =0.0251110183624
Mean train loss after  14400 batches of 8  epochs =0.0250813790426
Mean train loss after  14500 batches of 8  epochs =0.0251498980531
Mean train loss after  14600 batches of 8  epochs =0.0252135942695
Mean train loss after  14700 batches of 8  epochs =0.0253216788235
Mean train loss after  14800 batches of 8  epochs =0.0253731700219
Mean train loss after  14900 batches of 8  epochs =0.025430696002
Epoch 8 : Mean train epoch loss =0.025441388092
Epoch 8 Epoch val loss = 18637.4481933
Epoch 8 Epoch val perplexity = 1.4624196347693286
SCORES =  (92.55, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 9---------------------

=================================
fscore(z) =  [140.4382] || goldscore = [140.43817]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-5.81	-0.98	0.06	-3.31	-0.48	-2.08	-0.77	-1.57	-1.72	-2.07	-3.15	-0.13	-0.73	-1.21	-0.87	-3.12	-2.31	-3.91	-3.71	-3.82	-2.67	-3.27	0.62	-1.46	-3.76	-3.45	-4.95	-2.42	-2.59	0.40	-0.63	0.43	-1.33	-3.16	-1.82	-4.11	-3.94	0.03	-2.97	-2.26	-4.94	-3.23	-4.52	-3.20	-2.37	-4.30	-100000000.00	-3.18	
VBG 	-1.79	-4.09	-0.09	-0.06	-0.55	-0.10	-2.17	-0.67	-3.14	-2.78	-4.14	0.10	-0.14	-1.40	-1.81	-4.83	-0.36	-2.56	-3.39	-7.02	-1.39	-2.00	-0.90	0.34	-3.57	-1.09	-1.73	-0.08	-3.18	-0.71	-2.29	-0.52	-4.47	-1.59	-0.89	-1.44	-4.53	0.38	-1.44	-2.27	-2.25	-1.62	-0.64	-2.59	-2.89	-8.08	-100000000.00	-1.57	
VBD 	-3.52	-4.15	-4.22	-1.67	-1.77	0.89	-1.95	-1.49	1.72	-2.21	0.05	-2.29	-1.78	-1.33	-2.19	-3.29	-0.13	0.29	-2.34	-2.79	-1.63	-2.44	-5.97	-1.38	-5.53	-0.25	-2.48	-0.00	1.09	-2.26	-0.75	-0.85	-3.66	-1.23	-0.79	-1.57	-0.04	-3.36	-0.35	-4.67	-4.40	-0.91	-1.43	-0.91	-5.64	-3.59	-100000000.00	0.01	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.85	-1.96	-0.86	-0.67	-2.17	-1.12	-3.88	0.70	-1.65	-1.93	-2.75	0.80	-0.75	-1.04	-1.84	-5.08	-0.64	-2.17	-1.36	-2.30	-1.58	-3.18	-3.17	-0.53	-4.62	0.71	-2.15	-0.63	-1.77	-0.35	-1.58	-0.76	-3.54	-2.22	-1.94	-2.62	-4.38	-1.62	-1.83	-1.86	-4.34	-2.07	-2.76	-2.48	-1.63	-6.14	-100000000.00	-2.74	
, 	-2.61	-2.90	-0.43	-5.34	-1.28	-4.11	0.44	-2.60	0.02	0.84	-3.72	-2.64	-1.88	-2.34	-0.71	-6.13	0.57	-0.12	-3.56	-1.99	-2.06	-3.60	-4.11	-0.28	-5.31	0.60	-3.55	-0.22	-1.53	-1.63	-5.13	-2.92	-5.11	-3.23	0.32	1.01	-2.87	-0.52	-3.12	-4.86	-3.00	-0.75	-3.21	-1.06	-8.21	-1.44	-100000000.00	0.12	
'' 	-4.80	-1.30	-1.23	0.38	-3.32	-0.68	-0.81	-3.23	-0.54	-2.56	-2.56	-1.00	-3.92	-5.67	0.16	-0.56	-0.81	-2.97	-2.23	-1.79	-1.32	1.07	-4.16	0.89	-2.07	-0.32	0.24	-4.36	-2.34	-2.42	-2.99	-0.19	-0.92	-2.61	1.24	-1.81	-0.46	-0.75	-0.32	-1.90	-1.50	-2.73	-2.52	-3.16	-4.19	-1.78	-100000000.00	-0.52	
VBP 	-6.02	-3.26	-5.21	-4.98	-2.33	-1.83	0.11	-3.09	0.58	-4.06	0.36	-2.08	-2.46	-4.12	-2.37	-4.33	-1.80	-0.92	-3.14	-7.57	-4.37	-1.97	-3.07	-1.23	-4.70	-0.91	-3.27	0.98	1.07	-3.00	-2.70	-1.16	-1.47	-2.69	-0.84	-0.35	0.87	-4.15	-1.54	-1.96	-6.95	0.63	-4.63	-3.65	-3.23	-5.25	-100000000.00	-0.45	
WDT 	-4.13	-4.46	-4.58	-1.62	-3.34	-0.85	-3.73	-2.67	-2.10	-3.13	-4.68	-3.04	0.04	-3.72	-2.80	-4.05	0.19	-0.96	-5.25	-4.78	-3.65	-1.12	-0.88	-0.73	-3.13	-3.28	-0.10	0.39	-2.63	-3.05	-3.29	-2.16	-0.95	-3.61	-3.28	-1.33	-1.68	-0.30	0.08	-1.32	-2.09	-2.76	-3.53	-3.00	-4.02	-2.56	-100000000.00	-0.41	
JJ 	0.55	-0.86	-0.48	-0.69	-0.40	-1.21	-1.46	-0.20	-2.29	-0.77	-3.80	0.08	1.86	-0.19	-1.59	0.04	-1.82	-1.61	-1.13	-3.57	-0.32	-3.35	-0.24	-0.98	-6.70	-0.23	0.21	-1.79	-1.08	-0.40	0.17	-0.39	-6.24	0.44	0.77	0.76	-5.05	1.08	-0.59	-3.46	-3.23	-3.14	-0.85	-0.95	-2.00	-3.81	-100000000.00	-1.14	
WP 	-3.53	-2.64	-3.21	-2.79	-1.33	-1.32	0.65	-0.66	-1.76	-1.91	-2.20	-0.64	-1.12	-1.40	-2.70	-3.26	0.30	-2.43	-1.64	-2.69	-2.62	-2.45	0.34	-2.02	-2.32	-1.29	-3.54	0.23	-2.39	-0.54	-2.71	-1.56	-2.75	-2.43	-3.63	-3.46	-1.89	0.00	-2.29	-0.54	-3.45	-1.11	-3.00	-1.99	-2.92	-1.71	-100000000.00	-1.67	
VBZ 	-2.49	-3.66	-5.40	-4.30	-2.89	-0.07	-2.22	-1.35	1.90	-1.74	-0.57	-3.27	-0.76	-1.32	-3.29	-3.31	0.79	-1.19	-1.05	-3.13	-3.36	-1.78	-3.57	-1.63	-3.36	-0.56	-2.19	-2.85	1.90	-3.32	-0.85	-0.81	-4.72	-3.07	-4.62	-1.19	1.10	-3.55	-1.90	-2.53	-4.56	-3.92	-2.00	-3.12	-2.86	-6.93	-100000000.00	-0.17	
DT 	-4.01	-1.95	-0.93	-0.43	-0.45	-0.22	-1.43	-0.65	-2.03	-1.06	-2.32	-0.28	-2.06	-1.07	-0.10	-6.42	-0.40	-1.63	-0.01	-2.45	-1.88	-2.55	0.74	-2.08	-4.60	-0.97	-0.62	-1.40	-1.76	0.85	-0.27	1.51	0.27	-1.74	0.67	-3.09	-3.29	1.69	-0.57	-1.98	-2.58	-3.38	-4.08	-2.69	-0.69	-6.18	-100000000.00	-0.13	
" 	0.04	-0.74	-2.39	-2.12	-1.38	-0.13	0.94	-2.10	-0.57	-0.47	-2.55	-0.92	-1.04	-2.34	-0.48	-3.76	0.07	-1.37	-2.74	-4.01	0.91	1.21	-2.09	0.02	-0.60	-2.22	0.35	-2.59	-3.64	-1.91	-2.46	-1.90	-3.37	-4.08	-2.87	-1.30	-3.66	-1.16	-1.21	-3.64	-3.64	-2.64	-3.30	-1.82	-2.52	-4.23	-100000000.00	-0.03	
RP 	-5.54	0.84	1.17	-4.49	0.94	-2.22	-3.48	1.21	-3.42	-2.05	-4.92	-0.79	-0.19	-4.81	-1.92	-3.37	-2.13	-1.46	-4.52	-4.34	-2.91	-0.94	-5.90	-0.97	-3.38	-1.74	-5.18	-2.19	0.10	0.03	-3.54	-4.62	-2.44	-3.58	-1.75	-2.13	-6.25	-4.20	-1.22	-1.73	-5.79	-4.16	-3.02	-3.66	-4.56	-5.19	-100000000.00	-3.18	
$ 	-2.74	-1.52	-0.87	-6.11	-0.72	-2.39	-2.05	-1.82	-2.49	-0.08	-2.84	-0.37	-0.31	-2.59	-0.56	0.29	0.06	-2.43	-0.66	-6.16	-0.09	-0.95	0.43	-0.69	-0.13	-1.08	-0.61	-1.97	-2.08	-0.32	-2.54	-0.29	-3.16	-1.31	-3.66	-1.43	-2.22	0.27	-2.00	-2.87	-1.57	-3.60	-2.15	-3.04	-4.59	-2.74	-100000000.00	0.52	
NN 	0.96	-0.37	-1.05	0.46	0.19	0.70	-2.19	-1.25	-2.32	0.71	-1.30	-0.31	0.39	-0.87	-1.61	-4.38	-1.11	-0.82	-1.64	-1.03	0.86	-1.84	-1.71	-2.07	-7.51	-2.88	0.46	-2.13	-3.05	-0.21	-2.02	-1.85	-3.82	-3.76	-0.77	-0.51	-5.58	0.07	1.56	-5.24	-5.18	-1.97	0.20	0.18	-1.61	-10.35	-100000000.00	-0.54	
) 	-4.37	-1.95	-3.71	-5.04	-1.43	-4.61	-4.62	-4.34	-5.88	-0.91	-5.68	-1.29	-3.61	-2.28	0.48	-4.29	-1.81	-2.95	-2.48	-3.38	-1.14	-3.59	-4.62	0.10	-0.01	-2.82	-3.15	-2.74	-6.21	-1.62	-5.09	-4.18	-5.61	-3.55	-5.12	1.15	-2.16	-2.10	-2.45	-5.36	-4.60	-1.34	-7.00	-8.28	-4.06	-4.81	-100000000.00	-0.37	
( 	0.26	-4.11	-1.40	-2.71	-3.44	-3.31	-2.35	-4.77	-2.40	-1.65	-1.86	-1.51	-2.02	-0.77	-3.89	-5.41	0.01	-2.40	-4.29	-1.85	-0.93	-2.41	-2.36	-0.43	-2.69	-3.43	-2.02	-0.84	-2.14	-2.15	-2.66	-4.19	-5.90	-4.03	-5.53	0.41	-3.74	-4.64	-2.15	-2.94	-5.57	-1.78	-1.91	-2.70	-6.62	-3.59	-100000000.00	1.31	
FW 	-5.64	-5.04	-4.04	-2.73	-6.24	-2.15	-2.38	-1.66	-2.68	-2.47	-3.58	-7.24	-4.48	-4.20	-5.41	-2.29	-2.98	-1.74	-3.61	-1.19	-6.23	-1.42	-6.19	-0.66	-2.14	-5.44	-2.86	-3.46	-5.80	-2.90	-0.81	-2.83	-3.17	-2.60	-4.03	-2.83	-3.15	-11.79	-0.12	-2.29	-2.80	-2.61	-4.63	-5.05	-2.94	-2.19	-100000000.00	-0.88	
POS 	-2.94	-5.78	-2.58	-3.12	-1.00	-2.22	1.11	-1.85	0.26	-0.54	-4.97	-4.44	-2.08	-3.33	-3.79	-3.82	1.57	-3.80	-3.45	-5.77	-3.77	-1.72	-3.92	-2.07	-5.54	-2.86	-2.31	-0.14	-1.38	-2.49	-2.59	-2.74	-2.52	-1.20	-3.28	-2.11	-0.98	-2.38	-2.45	-2.88	-3.70	-1.62	-4.11	-3.04	-4.23	-5.05	-100000000.00	2.05	
. 	-2.98	-0.99	-1.58	-5.11	-1.13	-5.75	-3.27	-0.65	-5.04	-0.14	-4.00	-0.68	-0.35	-1.32	-0.25	-6.83	-0.69	-0.86	-3.82	-4.16	-1.09	-2.15	-4.28	-0.78	-0.10	-0.64	-2.50	0.62	-1.37	-1.53	-1.96	-2.51	-3.18	-7.64	-1.01	0.65	-2.17	-2.00	-2.06	-4.52	-5.00	-0.66	-4.68	-1.91	-6.77	-2.47	-100000000.00	1.41	
TO 	-2.14	-2.05	-0.42	-2.93	-1.09	-2.52	-4.02	-0.16	-4.70	-0.92	-3.81	0.31	-3.23	-2.65	-0.33	-5.71	-1.03	-2.16	-2.76	-4.47	-5.02	-3.52	-3.41	-1.39	-4.45	-0.68	-1.67	-1.16	-2.71	-1.35	-1.58	-3.14	-6.22	-3.75	-0.78	0.73	-2.92	0.03	-1.76	-2.96	-4.55	-3.31	-2.06	-1.32	-5.78	-7.99	-100000000.00	-1.57	
-X- 	-0.35	-0.07	-2.24	-2.78	-1.54	-1.63	-1.66	-1.44	-0.83	-2.01	-2.48	-2.39	-1.48	-2.23	0.30	-2.18	-0.89	-1.38	-2.54	-0.68	-1.54	-0.50	-2.20	2.00	-1.47	-2.18	-2.22	-1.45	-1.88	-1.60	0.21	-0.08	1.66	-0.31	-0.30	-2.47	0.35	-2.14	0.84	1.11	0.79	-2.18	-1.88	1.57	-1.03	0.35	-100000000.00	-4.13	
LS 	-2.23	-2.62	-5.19	-1.02	-3.53	-2.61	-1.08	-4.44	-1.79	-4.54	-1.24	-2.57	-6.07	-2.99	-4.20	-4.66	-3.37	-2.82	-3.31	-3.67	-1.82	-0.15	-4.32	-1.55	-3.50	-5.23	1.25	-5.78	-3.72	-2.91	-0.02	-4.95	-1.10	-1.01	-2.59	-5.23	-3.02	-4.15	-1.23	-1.15	-3.99	-4.37	-2.22	-4.86	-2.27	-2.45	-100000000.00	-4.45	
RB 	-2.40	-0.40	0.68	-1.07	-0.08	-0.92	-1.09	0.23	-1.42	-2.25	-1.67	0.30	-0.91	-0.36	-0.91	-3.74	-0.38	0.02	-1.42	-6.91	-1.88	-3.02	-0.82	-1.12	-3.71	-1.56	-2.49	-0.48	-0.51	-0.07	-0.66	-1.27	-5.47	-1.99	-0.96	-0.50	-2.67	-1.00	-1.64	-1.48	0.70	-3.88	-1.84	-2.11	-2.54	-6.07	-100000000.00	-1.00	
: 	-5.59	-2.34	-1.30	-3.29	-1.53	-3.79	-4.03	-1.75	-3.60	0.29	-2.99	-0.92	-2.46	-3.40	-2.81	-3.30	0.13	-1.87	-2.68	-7.77	0.06	-2.54	-6.02	-1.90	-3.47	-2.10	-3.01	-2.51	-3.62	-0.52	-4.65	-5.54	-3.45	-3.13	-2.22	0.09	-3.73	-1.30	-2.33	-3.35	-6.21	-0.55	-6.74	-1.53	-4.24	-5.68	-100000000.00	-0.25	
NNS 	1.52	-0.86	-0.93	-0.63	-0.61	-2.02	-2.41	-1.23	-1.34	1.07	-2.15	-1.78	-0.59	-2.35	-2.18	-4.28	-0.12	-2.64	-1.29	-2.73	0.43	-3.00	-2.52	-2.20	-6.08	-3.97	-0.49	-4.69	-2.09	-0.16	-0.56	0.26	-4.18	-2.33	-2.38	-0.61	-4.74	-1.04	0.70	-4.36	-2.90	-4.06	-0.64	0.16	-2.51	-10.02	-100000000.00	-1.20	
PRP 	-5.02	-1.12	-0.29	-1.76	0.48	-1.55	0.31	-1.21	-1.32	-2.32	0.27	-0.13	-2.92	-1.36	-4.05	-4.46	-0.93	-3.08	-5.00	-5.96	-0.68	-1.17	-1.46	-0.11	-3.59	-1.70	-0.42	-1.94	-5.66	0.73	0.57	-1.27	-2.34	-3.95	-2.39	-3.04	-1.45	1.13	-2.56	-2.53	-2.87	-5.37	-2.47	-4.90	-2.86	-3.74	-100000000.00	-1.71	
VB 	-4.31	-1.94	-3.05	-0.13	-3.64	-0.44	-2.36	-1.82	-1.82	-3.09	-1.18	-1.97	-1.81	-1.36	-2.11	-0.83	-1.48	0.12	-3.46	-2.25	-5.13	-1.19	0.57	-0.99	-4.37	0.36	-0.33	-1.97	-0.22	-3.11	-2.57	0.73	-0.47	-2.76	0.25	-2.34	-3.39	-3.29	-2.65	-1.96	1.82	-3.07	-1.45	-1.03	-5.05	-1.60	-100000000.00	-1.68	
WRB 	-3.21	-1.42	-1.82	-1.56	-0.75	-0.78	-2.13	-2.05	-2.07	-0.14	-2.14	0.12	-4.91	-2.52	-0.79	-2.16	-0.82	-3.15	-3.17	-4.00	-2.64	-0.54	-2.88	0.02	-2.37	-1.75	-4.95	-1.84	-1.91	-0.79	-3.26	-1.54	-3.35	-1.83	-4.97	-1.26	-2.38	-0.74	0.43	-1.37	-3.83	-5.30	-2.32	-1.87	-4.48	-1.20	-100000000.00	-0.89	
CC 	-4.01	-2.15	-2.67	-2.26	-0.81	-0.11	-3.86	-1.43	-2.91	1.07	-3.89	-2.00	-3.34	-2.17	-1.23	-4.42	-0.28	-1.70	-5.18	-4.40	-1.15	-0.76	-2.40	-2.22	-3.92	-1.16	-0.45	-1.58	-1.52	0.19	-3.43	-3.88	-2.58	-5.43	-0.33	0.53	-1.05	-1.71	-1.65	-2.48	-4.00	-0.53	-3.00	-1.47	-2.22	-7.44	-100000000.00	0.19	
PDT 	-3.52	-0.37	-3.43	-2.31	-0.72	-5.54	-2.74	-0.92	-4.15	-2.37	-4.70	-1.44	-3.87	-3.10	-2.28	-2.92	-3.28	-3.52	-1.06	-1.68	-0.94	-0.67	-3.98	0.08	-1.60	-0.66	-2.72	-1.58	-3.65	-1.56	-0.92	-2.03	-1.14	-0.06	-2.91	-3.16	-1.51	0.73	-0.97	-1.21	-1.07	-2.40	-2.66	-2.26	-5.09	-1.69	-100000000.00	-1.12	
RBS 	-0.57	-4.36	-1.09	-7.34	-1.99	-2.08	-1.13	-3.59	-4.02	-3.57	-0.33	-0.62	-0.54	-3.67	-1.79	-2.30	-1.92	-3.76	-4.48	-3.40	-0.63	-0.57	-2.17	1.77	-3.27	-1.16	-4.86	-8.29	-5.42	-1.47	-3.37	-0.48	-2.85	-1.42	-2.52	-4.13	-2.10	0.11	-1.09	0.05	-4.16	-3.43	-4.41	-4.79	-3.53	-2.83	-100000000.00	-8.20	
RBR 	-4.29	-2.09	-0.17	-2.45	0.02	-3.09	-1.34	-1.92	-0.99	-2.74	-1.05	-0.72	-0.88	-3.11	-0.79	-3.50	-0.27	-3.00	-3.94	-5.36	-5.22	-1.67	-1.44	0.53	-1.29	-0.36	-1.04	-0.26	-1.78	-1.29	-3.03	-1.50	-2.18	-1.74	-4.40	-2.75	-4.57	-0.89	-1.11	-0.35	-1.92	-3.60	-2.53	-3.36	-2.20	-1.76	-100000000.00	-1.11	
CD 	-1.23	-1.28	-0.93	-0.86	-2.25	-0.64	-1.29	-2.16	-1.77	-0.43	-4.16	-1.05	-0.96	-0.79	-3.32	3.15	-1.06	-0.55	-0.33	-2.31	0.29	-4.23	-0.07	-2.69	-8.18	-0.87	-0.14	-1.93	-1.85	-0.40	-1.68	-1.11	-2.63	-5.59	-7.53	-0.95	-7.76	-0.48	0.10	0.13	-8.16	-1.46	-2.23	-1.48	-1.87	-3.88	-100000000.00	-0.61	
EX 	-1.65	-1.07	0.21	-0.49	-2.31	-2.03	-2.27	-0.72	-0.89	-1.21	-0.60	-0.66	-0.60	-0.90	-2.67	-2.59	-0.62	-3.22	-4.40	-4.27	-3.57	-2.44	-4.48	-1.22	-1.63	-2.18	-2.85	-2.71	-1.04	-1.22	-1.15	0.86	-1.65	-2.18	-0.29	-3.28	-2.58	-1.16	-1.17	-0.76	-1.60	-2.73	-1.20	-3.15	-3.52	-1.36	-100000000.00	-1.62	
IN 	-3.84	-1.42	-1.29	-1.25	0.12	-0.42	-2.35	0.31	-1.36	-1.06	-4.58	-0.55	-1.17	0.14	-0.63	-3.17	0.35	-0.85	-1.83	-4.95	-2.17	-3.84	-1.73	-2.17	-7.80	-1.23	-1.67	0.43	-1.35	-0.26	-3.00	-0.98	-3.76	-2.31	0.79	-0.65	-1.44	-0.81	-2.82	-1.44	-5.43	-2.05	-0.44	-0.24	-3.97	-9.62	-100000000.00	-0.65	
WP$ 	-0.69	-2.01	-1.57	-5.52	-2.16	0.82	-0.95	-2.87	-0.53	-1.76	0.26	-1.86	-1.22	-1.62	-1.65	0.71	-1.66	-1.23	-2.55	-1.20	-0.65	-2.57	-2.44	0.36	-1.15	-1.96	-2.15	-0.28	-1.64	-2.82	-2.52	-2.80	-0.55	0.16	-0.01	-3.03	-0.96	-2.33	-1.94	0.03	-0.54	-1.15	-2.09	-1.59	-1.64	-0.10	-100000000.00	-2.10	
NN|SYM 	-1.41	-4.09	-3.46	-7.21	-3.81	-2.56	-1.74	-4.00	-0.50	-3.60	-2.00	-3.37	-4.58	-4.07	-2.56	-2.33	-6.09	-0.38	-2.27	-2.47	-2.55	0.99	-4.43	0.50	-1.48	-3.68	-4.64	-5.15	-3.34	-3.54	-1.45	-3.64	-0.27	0.48	-2.54	-5.55	-1.01	-3.57	-0.18	-0.87	-2.89	-2.88	-2.90	-2.92	-3.94	-2.26	-100000000.00	-5.89	
MD 	-1.15	-3.00	-1.98	-4.47	-4.11	-1.17	-2.37	-2.29	1.14	-1.48	-1.68	-2.34	-1.42	-1.95	-1.07	-4.11	-0.59	-1.73	-5.21	-5.98	-2.79	-0.30	-4.15	-0.86	-2.21	-1.69	-2.46	-0.66	0.20	-2.43	-0.79	-1.62	-3.21	-2.18	-4.46	-1.73	-0.40	-3.65	-2.44	-0.57	-3.77	-1.71	-4.60	-5.75	-4.91	-2.97	-100000000.00	-0.48	
NNPS 	-4.73	-3.47	-3.14	-3.03	-2.55	-2.22	-3.08	-1.73	-2.80	-2.66	-4.51	-2.57	-1.28	-2.47	-3.60	-4.63	-3.14	-0.46	-1.95	-7.23	-3.65	-1.72	-4.89	-1.06	-3.89	-8.23	-2.33	-6.59	-5.43	-1.93	-2.88	-2.31	-3.04	-1.93	-6.30	-1.26	-4.61	-1.76	-0.42	-3.83	-4.98	-2.64	-4.81	-6.07	-3.72	-8.22	-100000000.00	0.12	
JJS 	-0.23	-5.77	-1.90	-1.44	-1.28	-2.78	-1.45	-3.36	-3.47	-1.96	-2.52	-3.94	-1.51	-2.50	-3.37	-3.05	-5.25	-4.43	-3.04	-4.26	-1.31	-1.34	-2.35	-2.48	-3.91	-4.60	-5.66	-4.41	-4.28	-2.31	-2.18	-3.35	-2.05	-1.58	-3.97	-3.96	-1.39	-1.10	-0.49	-1.28	-3.74	-5.85	-3.79	-6.51	-4.16	-2.82	-100000000.00	-5.80	
JJR 	-2.56	-1.49	-0.08	-0.66	-1.32	-3.74	-2.12	-1.16	-4.03	-1.73	-4.93	-0.08	-1.33	-2.78	-2.67	-3.20	-2.84	-6.69	0.04	-4.23	-7.78	-1.37	-1.44	-0.23	-3.19	-0.71	-2.14	-1.62	-2.07	0.12	-0.49	-1.65	-4.81	-4.26	-4.33	-2.20	-2.64	-1.23	-1.75	-0.92	-3.16	-3.29	-4.19	-6.14	-2.55	-5.14	-100000000.00	-2.38	
SYM 	-1.93	-2.43	-5.17	-0.88	-6.55	-6.64	-2.37	-1.71	-4.49	-0.65	-5.02	-5.24	-5.61	-2.16	-4.66	-2.88	-1.37	-0.94	-3.65	-4.46	-4.15	-0.85	-6.62	-1.16	-3.45	-4.00	-5.13	-2.81	-1.20	-4.21	-4.47	-1.81	-3.12	-3.51	-5.42	-0.68	-4.37	-3.41	-0.61	-1.94	-3.36	-5.04	-3.28	-3.49	-4.20	-0.91	-100000000.00	-0.93	
UH 	-3.78	-5.54	-5.06	-1.90	-6.84	-1.28	0.31	-2.50	-4.90	-6.90	-1.24	-6.31	-11.77	-0.52	-3.71	-4.53	-10.39	-6.17	-6.98	-2.89	-6.96	-2.50	-6.36	-0.56	-2.40	-4.43	-7.11	-8.64	-2.78	-5.46	-2.06	-6.30	-2.20	-2.51	-4.10	-10.91	-4.32	-1.94	-1.84	0.31	-4.56	-7.34	-3.54	-2.70	-3.64	-2.68	-100000000.00	-5.83	
stop_tag 	-5.00	-8.89	-1.16	-0.88	-2.49	-4.61	-1.43	-5.17	-8.31	0.39	-6.52	-2.45	-2.21	-2.57	-1.46	-5.14	0.15	-1.46	-5.47	-2.51	-1.13	-1.45	-6.15	-1.62	-6.56	-1.89	-2.18	-0.88	-4.39	-1.84	-8.58	-4.19	-7.58	-5.47	-9.22	0.85	-5.69	-2.69	-2.56	-2.70	-7.51	-2.07	-10.03	-7.94	0.26	-8.04	-100000000.00	-0.34	
NNP 	-0.47	-1.24	-0.52	-0.70	-0.89	-1.18	-0.77	-1.60	-1.73	-0.88	-3.14	-0.48	-0.68	-0.93	-1.91	-2.69	-1.02	-0.55	-0.84	-1.04	0.88	-2.93	-0.93	-0.79	-7.44	-2.69	-0.32	-1.97	-3.63	-0.50	-0.51	0.54	-6.50	-5.14	-2.94	-0.84	-6.46	-0.52	-1.98	-4.74	-2.13	-1.28	-2.72	-1.11	-1.46	-2.13	-100000000.00	0.95	
Mean train loss after  0 batches of 9  epochs =3.81469726562e-06
Mean train loss after  100 batches of 9  epochs =0.0169511940686
Mean train loss after  200 batches of 9  epochs =0.0115373471509
Mean train loss after  300 batches of 9  epochs =0.0137346479784
Mean train loss after  400 batches of 9  epochs =0.0152622567302
Mean train loss after  500 batches of 9  epochs =0.0135003526401
Mean train loss after  600 batches of 9  epochs =0.0123272929941
Mean train loss after  700 batches of 9  epochs =0.0134209312094
Mean train loss after  800 batches of 9  epochs =0.013221957095
Mean train loss after  900 batches of 9  epochs =0.0141830717839
Mean train loss after  1000 batches of 9  epochs =0.0138844465081
Mean train loss after  1100 batches of 9  epochs =0.0145588619729
Mean train loss after  1200 batches of 9  epochs =0.014277178237
Mean train loss after  1300 batches of 9  epochs =0.0140828070676
Mean train loss after  1400 batches of 9  epochs =0.0143498123674
Mean train loss after  1500 batches of 9  epochs =0.0154524046033
Mean train loss after  1600 batches of 9  epochs =0.0155830109421
Mean train loss after  1700 batches of 9  epochs =0.0157302464347
Mean train loss after  1800 batches of 9  epochs =0.0152527453597
Mean train loss after  1900 batches of 9  epochs =0.015155692282
Mean train loss after  2000 batches of 9  epochs =0.0152753376187
Mean train loss after  2100 batches of 9  epochs =0.0150033667388
Mean train loss after  2200 batches of 9  epochs =0.0155097583149
Mean train loss after  2300 batches of 9  epochs =0.0155413221781
Mean train loss after  2400 batches of 9  epochs =0.0157070242012
Mean train loss after  2500 batches of 9  epochs =0.0157299114074
Mean train loss after  2600 batches of 9  epochs =0.0156504774028
Mean train loss after  2700 batches of 9  epochs =0.0157271296495
Mean train loss after  2800 batches of 9  epochs =0.0155263601392
Mean train loss after  2900 batches of 9  epochs =0.0158889920878
Mean train loss after  3000 batches of 9  epochs =0.0159794229783
Mean train loss after  3100 batches of 9  epochs =0.0159646206458
Mean train loss after  3200 batches of 9  epochs =0.0162570754323
Mean train loss after  3300 batches of 9  epochs =0.016581106268
Mean train loss after  3400 batches of 9  epochs =0.0164579344864
Mean train loss after  3500 batches of 9  epochs =0.0164402601295
Mean train loss after  3600 batches of 9  epochs =0.0163355531129
Mean train loss after  3700 batches of 9  epochs =0.0161882715368
Mean train loss after  3800 batches of 9  epochs =0.0160894977705
Mean train loss after  3900 batches of 9  epochs =0.0165995616544
Mean train loss after  4000 batches of 9  epochs =0.0167497599488
Mean train loss after  4100 batches of 9  epochs =0.0166424800113
Mean train loss after  4200 batches of 9  epochs =0.0165936871265
Mean train loss after  4300 batches of 9  epochs =0.0167435051668
Mean train loss after  4400 batches of 9  epochs =0.0168512864719
Mean train loss after  4500 batches of 9  epochs =0.01694013819
Mean train loss after  4600 batches of 9  epochs =0.0168784149465
Mean train loss after  4700 batches of 9  epochs =0.016812083182
Mean train loss after  4800 batches of 9  epochs =0.0168092091183
Mean train loss after  4900 batches of 9  epochs =0.0168653005979
Mean train loss after  5000 batches of 9  epochs =0.0168496954771
Mean train loss after  5100 batches of 9  epochs =0.0168905120336
Mean train loss after  5200 batches of 9  epochs =0.0169660780609
Mean train loss after  5300 batches of 9  epochs =0.0168715830199
Mean train loss after  5400 batches of 9  epochs =0.0169975480138
Mean train loss after  5500 batches of 9  epochs =0.0171834429383
Mean train loss after  5600 batches of 9  epochs =0.0171426483957
Mean train loss after  5700 batches of 9  epochs =0.0172570809816
Mean train loss after  5800 batches of 9  epochs =0.0173175864789
Mean train loss after  5900 batches of 9  epochs =0.0174718502741
Mean train loss after  6000 batches of 9  epochs =0.0176420540887
Mean train loss after  6100 batches of 9  epochs =0.0177627545993
Mean train loss after  6200 batches of 9  epochs =0.0177910889506
Mean train loss after  6300 batches of 9  epochs =0.0179180832149
Mean train loss after  6400 batches of 9  epochs =0.0181152475212
Mean train loss after  6500 batches of 9  epochs =0.0180909151501
Mean train loss after  6600 batches of 9  epochs =0.0182149435642
Mean train loss after  6700 batches of 9  epochs =0.0182168287824
Mean train loss after  6800 batches of 9  epochs =0.0183166646251
Mean train loss after  6900 batches of 9  epochs =0.0184570497312
Mean train loss after  7000 batches of 9  epochs =0.0184366113106
Mean train loss after  7100 batches of 9  epochs =0.0183868103922
Mean train loss after  7200 batches of 9  epochs =0.0183674218252
Mean train loss after  7300 batches of 9  epochs =0.0183603094804
Mean train loss after  7400 batches of 9  epochs =0.0183811112069
Mean train loss after  7500 batches of 9  epochs =0.018398276425
Mean train loss after  7600 batches of 9  epochs =0.0184616307757
Mean train loss after  7700 batches of 9  epochs =0.0185116331297
Mean train loss after  7800 batches of 9  epochs =0.0185388262486
Mean train loss after  7900 batches of 9  epochs =0.01859676056
Mean train loss after  8000 batches of 9  epochs =0.0186586133959
Mean train loss after  8100 batches of 9  epochs =0.0187199894726
Mean train loss after  8200 batches of 9  epochs =0.0187976302417
Mean train loss after  8300 batches of 9  epochs =0.0187817269381
Mean train loss after  8400 batches of 9  epochs =0.0188360341435
Mean train loss after  8500 batches of 9  epochs =0.0187914094675
Mean train loss after  8600 batches of 9  epochs =0.018814299877
Mean train loss after  8700 batches of 9  epochs =0.0188027054727
Mean train loss after  8800 batches of 9  epochs =0.0188375605374
Mean train loss after  8900 batches of 9  epochs =0.0188392910569
Mean train loss after  9000 batches of 9  epochs =0.0189557047318
Mean train loss after  9100 batches of 9  epochs =0.0189582405853
Mean train loss after  9200 batches of 9  epochs =0.0189619452015
Mean train loss after  9300 batches of 9  epochs =0.018975544785
Mean train loss after  9400 batches of 9  epochs =0.0190497474239
Mean train loss after  9500 batches of 9  epochs =0.0191462195154
Mean train loss after  9600 batches of 9  epochs =0.01926567082
Mean train loss after  9700 batches of 9  epochs =0.0192692941792
Mean train loss after  9800 batches of 9  epochs =0.0192799186115
Mean train loss after  9900 batches of 9  epochs =0.0193533206764
Mean train loss after  10000 batches of 9  epochs =0.0194105943519
Mean train loss after  10100 batches of 9  epochs =0.0194695470026
Mean train loss after  10200 batches of 9  epochs =0.0196155562368
Mean train loss after  10300 batches of 9  epochs =0.0198424927247
Mean train loss after  10400 batches of 9  epochs =0.0198851613668
Mean train loss after  10500 batches of 9  epochs =0.0198847034914
Mean train loss after  10600 batches of 9  epochs =0.0198744319456
Mean train loss after  10700 batches of 9  epochs =0.0198797436094
Mean train loss after  10800 batches of 9  epochs =0.0199011624163
Mean train loss after  10900 batches of 9  epochs =0.019989953806
Mean train loss after  11000 batches of 9  epochs =0.02012141729
Mean train loss after  11100 batches of 9  epochs =0.0201686995195
Mean train loss after  11200 batches of 9  epochs =0.0202721084082
Mean train loss after  11300 batches of 9  epochs =0.0203063496733
Mean train loss after  11400 batches of 9  epochs =0.0203134779105
Mean train loss after  11500 batches of 9  epochs =0.0203153797911
Mean train loss after  11600 batches of 9  epochs =0.0202669292943
Mean train loss after  11700 batches of 9  epochs =0.020312005811
Mean train loss after  11800 batches of 9  epochs =0.020399081942
Mean train loss after  11900 batches of 9  epochs =0.0204152798429
Mean train loss after  12000 batches of 9  epochs =0.0204277743793
Mean train loss after  12100 batches of 9  epochs =0.0204275189366
Mean train loss after  12200 batches of 9  epochs =0.0204940314245
Mean train loss after  12300 batches of 9  epochs =0.0205005667342
Mean train loss after  12400 batches of 9  epochs =0.0205106891858
Mean train loss after  12500 batches of 9  epochs =0.020580577545
Mean train loss after  12600 batches of 9  epochs =0.020637646008
Mean train loss after  12700 batches of 9  epochs =0.0207011156613
Mean train loss after  12800 batches of 9  epochs =0.0207952677112
Mean train loss after  12900 batches of 9  epochs =0.0208627669303
Mean train loss after  13000 batches of 9  epochs =0.0208518816089
Mean train loss after  13100 batches of 9  epochs =0.0209485141324
Mean train loss after  13200 batches of 9  epochs =0.0209163702789
Mean train loss after  13300 batches of 9  epochs =0.0209936286834
Mean train loss after  13400 batches of 9  epochs =0.0210868542897
Mean train loss after  13500 batches of 9  epochs =0.0213078054523
Mean train loss after  13600 batches of 9  epochs =0.0213180466928
Mean train loss after  13700 batches of 9  epochs =0.0214982307894
Mean train loss after  13800 batches of 9  epochs =0.0214705288365
Mean train loss after  13900 batches of 9  epochs =0.0215439701578
Mean train loss after  14000 batches of 9  epochs =0.0215777453996
Mean train loss after  14100 batches of 9  epochs =0.0216209512755
Mean train loss after  14200 batches of 9  epochs =0.0215837266268
Mean train loss after  14300 batches of 9  epochs =0.0216018454131
Mean train loss after  14400 batches of 9  epochs =0.0215988990986
Mean train loss after  14500 batches of 9  epochs =0.021667122423
Mean train loss after  14600 batches of 9  epochs =0.0216323666373
Mean train loss after  14700 batches of 9  epochs =0.0217844052524
Mean train loss after  14800 batches of 9  epochs =0.0217935056274
Mean train loss after  14900 batches of 9  epochs =0.0217670780295
Epoch 9 : Mean train epoch loss =0.0219704030766
Epoch 9 Epoch val loss = 19759.1108878
Epoch 9 Epoch val perplexity = 1.4962583385458605
SCORES =  (92.44, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 10---------------------

=================================
fscore(z) =  [495.0666] || goldscore = [494.0848]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-6.09	-0.99	-0.00	-3.55	-0.48	-2.08	-0.94	-1.67	-1.86	-2.13	-3.25	-0.11	-0.78	-1.35	-1.03	-3.32	-2.42	-4.03	-3.82	-4.07	-2.65	-3.30	0.52	-1.46	-3.91	-3.52	-5.35	-2.49	-2.97	0.36	-0.81	0.38	-1.48	-3.33	-1.86	-4.31	-4.08	0.07	-3.00	-2.32	-5.16	-3.38	-4.79	-3.47	-2.62	-4.42	-100000000.00	-3.25	
VBG 	-1.90	-4.44	-0.23	-0.04	-0.63	-0.12	-2.31	-0.65	-3.38	-2.99	-4.49	0.07	-0.32	-1.47	-1.88	-5.02	-0.43	-2.72	-3.68	-7.48	-1.64	-2.02	-0.88	0.34	-3.74	-1.07	-2.01	-0.08	-3.35	-0.72	-2.46	-0.65	-4.57	-1.80	-1.03	-1.40	-4.70	0.29	-1.53	-2.31	-2.63	-1.80	-0.62	-2.63	-3.04	-8.25	-100000000.00	-1.71	
VBD 	-3.56	-4.34	-4.41	-1.75	-1.92	0.91	-2.06	-1.65	1.72	-2.15	0.01	-2.36	-1.84	-1.36	-2.30	-3.48	-0.18	0.13	-2.53	-2.93	-1.68	-2.53	-6.22	-1.38	-5.79	-0.31	-2.69	-0.01	1.04	-2.33	-0.76	-0.84	-3.78	-1.25	-1.04	-1.69	0.09	-3.45	-0.47	-4.71	-4.62	-0.90	-1.42	-1.10	-5.92	-3.99	-100000000.00	0.01	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-3.03	-2.10	-0.93	-0.71	-2.29	-1.17	-3.97	0.74	-1.80	-2.04	-2.88	0.74	-0.73	-1.23	-1.97	-5.27	-0.57	-2.24	-1.50	-2.39	-1.63	-3.24	-3.24	-0.55	-4.85	0.72	-2.20	-0.73	-1.82	-0.39	-1.56	-0.80	-3.83	-2.29	-1.98	-2.73	-4.39	-1.69	-1.92	-1.98	-4.48	-2.15	-3.02	-2.70	-1.89	-6.37	-100000000.00	-2.90	
, 	-2.70	-2.97	-0.46	-5.64	-1.42	-4.31	0.40	-2.80	-0.18	0.79	-3.83	-2.79	-2.00	-2.41	-0.76	-6.29	0.50	-0.16	-3.67	-2.18	-2.09	-3.66	-4.36	-0.30	-5.61	0.63	-3.77	-0.29	-1.57	-1.84	-5.26	-3.30	-5.16	-3.24	0.24	1.14	-3.10	-0.62	-3.14	-4.89	-3.41	-0.76	-3.24	-1.09	-8.60	-1.54	-100000000.00	0.13	
'' 	-4.82	-1.41	-1.27	0.22	-3.49	-0.62	-0.96	-3.35	-0.63	-2.76	-2.68	-1.06	-4.13	-5.77	-0.14	-0.63	-0.77	-3.13	-2.43	-1.88	-1.43	1.18	-4.28	0.89	-2.14	-0.41	0.13	-4.50	-2.49	-2.65	-3.01	-0.13	-1.04	-2.69	1.16	-1.93	-0.49	-0.81	-0.34	-1.92	-1.58	-2.88	-2.67	-3.27	-4.26	-1.92	-100000000.00	-0.59	
VBP 	-6.25	-3.38	-5.46	-5.15	-2.45	-1.81	0.05	-3.41	0.54	-4.30	0.39	-2.38	-2.54	-4.21	-2.46	-4.50	-1.85	-0.99	-3.30	-7.80	-4.58	-2.00	-3.15	-1.24	-4.90	-0.98	-3.44	1.01	1.14	-3.03	-2.95	-1.20	-1.70	-2.78	-1.12	-0.30	0.79	-4.34	-1.69	-2.05	-7.21	0.56	-4.86	-3.80	-3.39	-5.54	-100000000.00	-0.62	
WDT 	-4.28	-4.72	-4.76	-1.64	-3.58	-0.79	-3.78	-2.86	-2.26	-3.17	-4.77	-3.29	-0.17	-3.80	-3.01	-4.13	0.24	-0.95	-5.37	-5.04	-3.76	-1.12	-0.91	-0.73	-3.22	-3.41	-0.24	0.46	-2.74	-3.20	-3.34	-2.18	-1.16	-3.66	-3.42	-1.34	-1.82	-0.41	-0.00	-1.32	-2.19	-2.87	-3.66	-3.15	-4.17	-2.69	-100000000.00	-0.40	
JJ 	0.54	-0.89	-0.33	-0.82	-0.53	-1.35	-1.61	-0.32	-2.49	-0.83	-4.02	-0.02	1.86	-0.24	-1.60	-0.08	-1.97	-1.62	-1.30	-3.79	-0.25	-3.41	-0.32	-0.98	-6.98	-0.24	-0.01	-1.85	-1.19	-0.41	0.21	-0.39	-6.45	0.55	0.77	0.65	-5.30	1.14	-0.53	-3.49	-3.31	-3.29	-0.96	-1.04	-2.11	-3.85	-100000000.00	-1.20	
WP 	-3.66	-2.66	-3.33	-2.78	-1.32	-1.60	0.64	-0.86	-2.04	-1.97	-2.32	-0.64	-1.25	-1.43	-2.82	-3.35	0.27	-2.71	-1.85	-2.78	-2.88	-2.45	0.31	-2.02	-2.42	-1.49	-4.01	0.32	-2.47	-0.74	-2.88	-1.70	-2.82	-2.49	-3.82	-3.59	-2.04	0.05	-2.35	-0.58	-3.57	-1.15	-3.19	-2.17	-3.11	-1.76	-100000000.00	-1.66	
VBZ 	-2.88	-3.80	-5.62	-4.41	-3.09	-0.17	-2.36	-1.58	1.91	-1.79	-0.61	-3.39	-0.82	-1.49	-3.49	-3.50	0.80	-1.27	-1.00	-3.25	-3.53	-1.83	-3.65	-1.65	-3.63	-0.72	-2.39	-3.02	1.97	-3.53	-1.05	-0.97	-4.84	-3.25	-4.80	-1.23	1.23	-3.69	-1.98	-2.64	-4.86	-4.01	-2.09	-3.13	-2.98	-7.13	-100000000.00	-0.22	
DT 	-4.22	-2.03	-1.03	-0.39	-0.52	-0.27	-1.47	-0.63	-2.02	-1.10	-2.52	-0.30	-2.11	-1.01	-0.07	-6.61	-0.44	-1.89	-0.01	-2.70	-2.04	-2.68	0.69	-2.10	-4.74	-1.16	-0.69	-1.47	-1.81	0.91	-0.24	1.61	0.32	-1.84	0.69	-3.17	-3.49	1.76	-0.72	-2.06	-2.79	-3.50	-4.30	-2.76	-0.83	-6.44	-100000000.00	-0.27	
" 	0.05	-0.88	-2.41	-2.27	-1.46	-0.38	0.93	-2.27	-0.59	-0.48	-2.86	-1.13	-1.16	-2.58	-0.62	-3.86	-0.03	-1.46	-2.79	-4.24	0.90	1.25	-2.16	0.02	-0.65	-2.35	0.33	-2.74	-3.73	-2.16	-2.51	-2.10	-3.52	-4.13	-3.06	-1.33	-3.79	-1.15	-1.25	-3.64	-3.94	-2.77	-3.45	-2.01	-2.68	-4.45	-100000000.00	-0.02	
RP 	-5.66	0.80	1.11	-4.73	1.03	-2.41	-3.48	1.23	-3.65	-2.21	-5.05	-0.83	-0.36	-5.11	-1.94	-3.61	-2.18	-1.59	-4.75	-4.59	-3.02	-1.02	-6.36	-0.99	-3.51	-1.67	-5.45	-2.36	0.07	0.04	-3.72	-4.78	-2.57	-3.69	-1.85	-2.35	-6.27	-4.53	-1.27	-1.77	-6.04	-4.38	-3.09	-3.73	-4.88	-5.39	-100000000.00	-3.20	
$ 	-2.91	-1.70	-0.94	-6.65	-0.77	-2.62	-2.16	-2.02	-2.59	-0.13	-3.02	-0.48	-0.43	-2.71	-0.64	0.05	-0.07	-2.55	-0.65	-6.41	-0.11	-0.97	0.45	-0.69	-0.34	-1.10	-0.61	-2.13	-2.37	-0.36	-2.68	-0.31	-3.45	-1.45	-3.94	-1.55	-2.35	0.34	-2.00	-2.87	-1.74	-3.81	-2.27	-3.16	-4.75	-2.99	-100000000.00	0.51	
NN 	0.96	-0.49	-1.09	0.35	0.15	0.72	-2.37	-1.30	-2.37	0.68	-1.37	-0.37	0.41	-0.93	-1.64	-4.65	-1.16	-0.92	-1.69	-1.20	0.79	-2.03	-1.66	-2.09	-7.75	-2.95	0.43	-2.20	-3.08	-0.16	-2.03	-2.01	-3.96	-3.85	-0.87	-0.53	-5.94	0.16	1.50	-5.31	-5.24	-2.13	0.12	0.09	-1.68	-10.71	-100000000.00	-0.60	
) 	-4.45	-2.16	-3.79	-5.27	-1.66	-4.74	-4.83	-4.59	-6.14	-0.97	-5.86	-1.49	-3.74	-2.33	0.53	-4.44	-1.85	-3.10	-2.62	-3.62	-1.32	-3.62	-4.75	0.06	0.01	-3.06	-3.41	-2.78	-6.37	-1.91	-5.24	-4.45	-5.78	-3.70	-5.35	1.10	-2.35	-2.25	-2.48	-5.42	-4.91	-1.39	-7.20	-8.78	-4.26	-4.97	-100000000.00	-0.48	
( 	0.09	-4.17	-1.47	-2.91	-3.55	-3.43	-2.43	-5.07	-2.57	-1.77	-2.02	-1.68	-2.22	-0.82	-4.02	-5.53	-0.01	-2.46	-4.40	-2.02	-0.97	-2.53	-2.49	-0.45	-2.94	-3.75	-2.31	-0.86	-2.25	-2.35	-2.79	-4.49	-6.08	-4.15	-5.72	0.35	-3.96	-4.74	-2.20	-3.03	-5.80	-1.89	-2.06	-2.77	-6.84	-3.85	-100000000.00	1.28	
FW 	-5.84	-5.34	-4.21	-3.12	-6.60	-2.26	-2.47	-1.90	-2.84	-2.59	-3.78	-7.59	-4.77	-4.33	-5.52	-2.42	-3.07	-1.88	-3.78	-1.46	-6.52	-1.49	-6.39	-0.66	-2.33	-5.70	-2.91	-3.68	-6.05	-2.96	-1.04	-3.02	-3.44	-2.77	-4.29	-3.05	-3.31	-12.10	-0.24	-2.33	-2.97	-2.84	-4.76	-5.34	-3.03	-2.37	-100000000.00	-0.92	
POS 	-3.01	-6.09	-2.82	-3.45	-1.01	-2.35	1.26	-1.84	0.11	-0.63	-5.00	-4.58	-2.37	-3.65	-3.91	-3.97	1.45	-4.11	-3.83	-6.03	-3.93	-1.83	-4.11	-2.07	-5.60	-3.06	-2.62	-0.23	-1.53	-2.54	-2.80	-2.82	-2.83	-1.50	-3.52	-2.20	-1.07	-2.61	-2.46	-2.91	-3.81	-1.60	-4.28	-3.23	-4.36	-5.22	-100000000.00	2.20	
. 	-3.11	-1.04	-1.74	-5.23	-1.35	-5.84	-3.41	-0.80	-5.58	-0.18	-4.23	-0.91	-0.59	-1.51	-0.19	-6.91	-0.61	-0.84	-3.93	-4.49	-1.09	-2.28	-4.61	-0.81	-0.08	-0.88	-2.70	0.52	-1.56	-1.80	-2.48	-2.67	-3.38	-7.77	-1.07	0.67	-2.53	-2.03	-2.08	-4.56	-5.11	-0.77	-4.93	-2.07	-7.11	-2.55	-100000000.00	1.40	
TO 	-2.21	-2.14	-0.43	-3.01	-1.05	-2.65	-4.36	-0.22	-5.14	-1.03	-3.98	0.20	-3.25	-2.85	-0.38	-5.89	-1.13	-2.22	-2.92	-4.74	-5.32	-3.64	-3.63	-1.42	-4.67	-0.75	-1.70	-1.24	-2.70	-1.35	-1.76	-3.44	-6.47	-3.90	-0.88	0.65	-2.99	0.10	-1.89	-3.05	-4.81	-3.53	-2.32	-1.65	-5.96	-8.30	-100000000.00	-1.54	
-X- 	-0.35	-0.14	-2.25	-2.85	-1.54	-1.66	-1.66	-1.45	-0.83	-2.02	-2.48	-2.40	-1.48	-2.23	0.30	-2.18	-0.94	-1.40	-2.57	-0.68	-1.54	-0.50	-2.22	2.00	-1.47	-2.19	-2.27	-1.46	-1.89	-1.60	0.21	-0.09	1.66	-0.31	-0.30	-2.49	0.35	-2.16	0.84	1.11	0.78	-2.18	-1.88	1.55	-1.06	0.35	-100000000.00	-4.13	
LS 	-2.47	-2.84	-5.43	-1.13	-3.65	-2.83	-1.09	-4.50	-1.86	-4.69	-1.38	-2.70	-6.20	-3.02	-4.32	-4.84	-3.41	-3.00	-3.35	-3.83	-1.96	-0.17	-4.53	-1.55	-3.55	-5.47	1.24	-6.01	-4.10	-3.11	-0.10	-5.16	-1.15	-1.04	-2.66	-5.53	-3.03	-4.29	-1.26	-1.17	-4.01	-4.46	-2.37	-4.92	-2.51	-2.66	-100000000.00	-4.67	
RB 	-2.49	-0.55	0.65	-1.30	-0.13	-1.03	-1.25	0.19	-1.37	-2.34	-1.80	0.24	-0.94	-0.44	-1.09	-3.95	-0.43	0.05	-1.59	-7.16	-2.02	-3.06	-0.92	-1.12	-3.83	-1.75	-2.78	-0.54	-0.48	0.02	-0.75	-1.45	-5.70	-2.18	-1.04	-0.53	-2.66	-1.06	-1.73	-1.58	0.66	-3.96	-1.93	-2.08	-2.62	-6.30	-100000000.00	-1.20	
: 	-5.71	-2.42	-1.35	-3.32	-1.69	-4.00	-4.15	-1.83	-3.77	0.21	-3.19	-1.07	-2.49	-3.53	-2.83	-3.44	0.06	-1.91	-2.69	-7.92	-0.19	-2.58	-6.15	-1.92	-3.55	-2.13	-3.17	-2.70	-3.74	-0.65	-4.90	-5.71	-3.63	-3.24	-2.41	0.11	-3.91	-1.39	-2.43	-3.36	-6.39	-0.49	-6.93	-1.72	-4.23	-5.99	-100000000.00	-0.31	
NNS 	1.46	-0.85	-0.88	-0.77	-0.73	-2.11	-2.42	-1.23	-1.35	1.14	-2.39	-1.79	-0.72	-2.35	-2.19	-4.48	-0.11	-2.69	-1.43	-2.91	0.43	-3.09	-2.66	-2.20	-6.26	-4.11	-0.53	-4.98	-2.40	-0.34	-0.68	0.25	-4.39	-2.41	-2.65	-0.73	-5.12	-1.11	0.73	-4.41	-3.07	-4.33	-0.73	0.16	-2.62	-10.33	-100000000.00	-1.21	
PRP 	-5.37	-1.17	-0.37	-2.14	0.56	-1.73	0.21	-1.23	-1.48	-2.44	0.16	-0.03	-3.03	-1.51	-4.38	-4.60	-0.96	-3.28	-5.12	-6.19	-0.82	-1.28	-1.58	-0.15	-3.83	-1.93	-0.51	-2.15	-5.87	0.65	0.60	-1.24	-2.53	-4.23	-2.56	-3.14	-1.50	1.05	-2.66	-2.60	-3.16	-5.63	-2.60	-5.16	-2.96	-3.98	-100000000.00	-1.79	
VB 	-4.60	-2.15	-3.28	-0.13	-3.72	-0.52	-2.42	-2.15	-1.95	-3.21	-1.24	-2.17	-1.92	-1.51	-2.20	-1.14	-1.50	0.11	-3.70	-2.29	-5.28	-1.30	0.51	-0.99	-4.55	0.29	-0.46	-2.15	-0.28	-3.27	-2.61	0.84	-0.71	-2.89	0.14	-2.41	-3.59	-3.38	-2.70	-2.04	1.72	-3.25	-1.55	-1.16	-5.28	-1.85	-100000000.00	-1.75	
WRB 	-3.35	-1.55	-1.94	-1.65	-0.71	-0.82	-2.16	-2.21	-2.13	-0.19	-2.27	0.11	-5.13	-2.72	-0.86	-2.28	-0.73	-3.32	-3.44	-4.18	-2.76	-0.54	-2.95	0.02	-2.43	-1.75	-5.24	-1.90	-2.00	-0.78	-3.36	-1.56	-3.46	-1.85	-5.05	-1.27	-2.45	-0.78	0.35	-1.38	-4.01	-5.60	-2.46	-2.05	-4.69	-1.34	-100000000.00	-0.92	
CC 	-4.05	-2.30	-2.80	-2.40	-0.86	-0.09	-3.97	-1.50	-3.14	1.05	-4.11	-2.16	-3.44	-2.17	-1.27	-4.51	-0.39	-1.73	-5.31	-4.48	-1.20	-0.83	-2.55	-2.22	-4.11	-1.24	-0.54	-1.54	-1.49	0.22	-3.63	-4.18	-2.74	-5.53	-0.43	0.43	-1.14	-1.72	-1.68	-2.50	-4.36	-0.69	-3.06	-1.70	-2.31	-7.65	-100000000.00	0.25	
PDT 	-3.62	-0.58	-3.63	-2.48	-0.85	-5.73	-2.81	-1.00	-4.29	-2.53	-4.90	-1.55	-4.21	-3.28	-2.51	-3.01	-3.43	-3.77	-1.18	-1.97	-1.08	-0.67	-4.10	0.08	-1.67	-0.75	-2.84	-1.78	-3.87	-1.56	-1.04	-2.19	-1.36	-0.13	-3.06	-3.43	-1.66	0.67	-0.97	-1.24	-1.35	-2.71	-2.82	-2.51	-5.22	-1.83	-100000000.00	-1.38	
RBS 	-0.54	-4.50	-1.13	-7.67	-2.12	-2.21	-1.26	-3.78	-4.06	-3.88	-0.45	-0.64	-0.56	-3.86	-1.86	-2.39	-1.96	-3.83	-4.78	-3.61	-0.68	-0.59	-2.23	1.77	-3.29	-1.33	-5.02	-8.38	-5.49	-1.46	-3.41	-0.62	-2.90	-1.53	-2.64	-4.35	-2.18	-0.05	-1.11	0.05	-4.31	-3.67	-4.50	-4.85	-3.65	-2.91	-100000000.00	-8.37	
RBR 	-4.64	-2.13	-0.25	-2.82	-0.10	-3.20	-1.43	-2.04	-1.26	-2.85	-1.29	-0.82	-1.04	-3.34	-0.83	-3.66	-0.31	-3.32	-4.22	-5.50	-5.60	-1.68	-1.53	0.52	-1.45	-0.40	-1.15	-0.28	-1.89	-1.53	-3.04	-1.63	-2.34	-1.97	-4.53	-2.88	-4.64	-0.89	-1.18	-0.38	-2.17	-3.90	-2.81	-3.64	-2.34	-2.04	-100000000.00	-1.12	
CD 	-1.28	-1.40	-1.06	-0.94	-2.39	-0.64	-1.42	-2.28	-1.90	-0.55	-4.85	-1.03	-0.86	-0.83	-3.35	3.33	-1.16	-0.51	-0.36	-2.46	0.21	-4.29	-0.06	-2.70	-8.37	-0.77	-0.23	-2.04	-1.93	-0.55	-1.97	-1.24	-2.80	-5.72	-7.73	-1.06	-8.05	-0.54	0.09	0.20	-8.76	-1.62	-2.50	-1.56	-1.85	-4.22	-100000000.00	-0.54	
EX 	-1.76	-1.10	0.13	-0.53	-2.48	-1.99	-2.31	-0.67	-0.97	-1.36	-0.74	-0.64	-0.88	-0.90	-2.87	-2.64	-0.73	-3.26	-4.50	-4.45	-3.63	-2.45	-4.56	-1.23	-1.72	-2.36	-3.06	-2.80	-1.13	-1.32	-1.23	0.76	-1.75	-2.23	-0.44	-3.45	-2.75	-1.13	-1.18	-0.81	-1.97	-2.88	-1.32	-3.34	-3.63	-1.52	-100000000.00	-1.66	
IN 	-4.07	-1.30	-1.31	-1.39	0.11	-0.34	-2.53	0.28	-1.43	-1.09	-4.89	-0.76	-1.33	0.01	-0.59	-3.34	0.21	-0.94	-1.83	-5.05	-2.18	-3.90	-1.79	-2.17	-8.02	-1.42	-1.82	0.51	-1.41	-0.36	-3.23	-1.03	-3.99	-2.38	0.90	-0.65	-1.54	-0.86	-2.89	-1.62	-5.43	-2.01	-0.49	-0.32	-4.17	-9.97	-100000000.00	-0.61	
WP$ 	-0.73	-2.03	-1.71	-5.66	-2.19	0.77	-0.95	-2.88	-0.56	-1.78	0.23	-1.91	-1.31	-1.68	-1.70	0.71	-1.85	-1.33	-2.62	-1.25	-0.68	-2.57	-2.46	0.36	-1.15	-2.03	-2.21	-0.18	-1.70	-2.85	-2.52	-2.82	-0.55	0.16	-0.02	-3.11	-0.96	-2.36	-1.94	0.03	-0.57	-1.22	-2.09	-1.67	-1.65	-0.12	-100000000.00	-2.11	
NN|SYM 	-1.48	-4.14	-3.67	-7.60	-3.88	-2.82	-1.75	-4.09	-0.58	-3.76	-2.07	-3.42	-4.70	-4.17	-2.59	-2.34	-6.21	-0.33	-2.44	-2.59	-2.67	0.90	-4.52	0.50	-1.49	-3.80	-4.92	-5.31	-3.44	-3.61	-1.45	-3.71	-0.29	0.46	-2.54	-5.77	-1.03	-3.74	-0.19	-0.88	-2.98	-2.99	-2.95	-2.95	-4.07	-2.32	-100000000.00	-6.07	
MD 	-1.29	-3.18	-2.01	-4.59	-4.34	-1.30	-2.55	-2.42	1.31	-1.53	-1.80	-2.39	-1.58	-2.20	-1.11	-4.21	-0.72	-1.83	-5.44	-6.14	-2.78	-0.32	-4.30	-0.86	-2.35	-1.69	-2.51	-0.73	0.16	-2.52	-0.89	-1.65	-3.38	-2.32	-4.60	-1.71	-0.46	-3.71	-2.47	-0.68	-3.89	-1.88	-4.73	-6.05	-5.17	-3.12	-100000000.00	-0.51	
NNPS 	-5.05	-3.51	-3.50	-3.31	-2.79	-2.37	-3.12	-1.81	-3.09	-2.94	-4.85	-2.70	-1.35	-2.68	-3.79	-4.84	-3.28	-0.59	-2.13	-7.63	-3.71	-1.78	-5.02	-1.06	-4.05	-8.46	-2.43	-6.69	-5.82	-2.06	-3.15	-2.36	-3.33	-2.17	-6.63	-1.33	-4.83	-1.99	-0.44	-3.87	-5.20	-2.90	-4.97	-6.43	-4.11	-8.48	-100000000.00	0.06	
JJS 	-0.29	-6.03	-2.11	-1.53	-1.34	-2.81	-1.54	-3.68	-3.56	-2.00	-2.79	-4.09	-1.61	-2.75	-3.44	-3.17	-5.35	-4.61	-3.12	-4.53	-1.32	-1.38	-2.34	-2.48	-4.03	-4.80	-5.95	-4.55	-4.50	-2.44	-2.30	-3.55	-2.29	-1.78	-4.06	-4.19	-1.58	-1.17	-0.58	-1.35	-3.91	-6.05	-4.00	-6.70	-4.36	-3.05	-100000000.00	-6.09	
JJR 	-2.71	-1.62	-0.15	-0.74	-1.40	-3.84	-2.31	-1.17	-4.24	-1.82	-5.08	-0.13	-1.39	-3.05	-2.78	-3.28	-2.93	-7.02	0.00	-4.41	-8.04	-1.42	-1.48	-0.23	-3.31	-0.77	-2.28	-1.68	-2.17	0.02	-0.51	-1.77	-5.02	-4.43	-4.51	-2.21	-2.83	-1.34	-1.84	-1.00	-3.41	-3.39	-4.39	-6.37	-2.73	-5.41	-100000000.00	-2.47	
SYM 	-2.08	-2.61	-5.33	-0.91	-6.78	-6.77	-2.62	-1.97	-4.71	-0.78	-5.23	-5.42	-5.79	-2.36	-4.95	-3.01	-1.46	-0.99	-3.79	-4.71	-4.33	-0.95	-6.77	-1.16	-3.61	-4.23	-5.22	-2.97	-1.25	-4.42	-4.65	-1.99	-3.27	-3.66	-5.65	-0.71	-4.47	-3.51	-0.64	-2.06	-3.47	-5.37	-3.55	-3.64	-4.43	-1.00	-100000000.00	-0.94	
UH 	-4.01	-5.93	-5.31	-2.12	-7.12	-1.25	0.15	-2.87	-5.14	-7.17	-1.40	-6.68	-12.06	-0.58	-3.80	-4.68	-10.51	-6.39	-7.20	-3.15	-7.21	-2.50	-6.65	-0.56	-2.48	-4.80	-7.35	-8.90	-3.00	-5.64	-2.18	-6.60	-2.39	-2.62	-4.23	-11.06	-4.36	-2.03	-1.87	0.23	-4.90	-7.57	-3.73	-2.77	-3.80	-2.72	-100000000.00	-6.03	
stop_tag 	-5.41	-9.54	-1.35	-0.88	-2.63	-4.67	-1.61	-5.42	-8.95	0.18	-7.43	-2.65	-2.68	-2.70	-1.65	-5.42	0.09	-1.73	-5.59	-3.08	-1.35	-1.54	-6.34	-1.65	-6.88	-2.06	-2.31	-1.03	-4.59	-1.84	-8.95	-4.64	-7.92	-5.69	-9.62	0.70	-6.39	-2.88	-2.67	-3.01	-8.28	-2.23	-10.75	-8.57	0.26	-8.80	-100000000.00	-0.33	
NNP 	-0.37	-1.32	-0.43	-0.71	-0.96	-1.21	-0.75	-1.64	-1.81	-0.87	-3.22	-0.46	-0.67	-0.98	-1.90	-2.81	-1.03	-0.63	-0.82	-1.14	0.85	-3.12	-0.95	-0.87	-7.62	-2.74	-0.36	-1.97	-4.01	-0.55	-0.42	0.55	-6.95	-5.52	-3.18	-0.88	-6.85	-0.59	-2.07	-4.84	-2.20	-1.41	-2.74	-1.37	-1.52	-2.20	-100000000.00	0.87	
Mean train loss after  0 batches of 10  epochs =0.0306806564331
Mean train loss after  100 batches of 10  epochs =0.019995241542
Mean train loss after  200 batches of 10  epochs =0.0144537277492
Mean train loss after  300 batches of 10  epochs =0.014804580948
Mean train loss after  400 batches of 10  epochs =0.0133282114238
Mean train loss after  500 batches of 10  epochs =0.0149238242479
Mean train loss after  600 batches of 10  epochs =0.0145738369582
Mean train loss after  700 batches of 10  epochs =0.0136231413155
Mean train loss after  800 batches of 10  epochs =0.0130216437918
Mean train loss after  900 batches of 10  epochs =0.0129110240303
Mean train loss after  1000 batches of 10  epochs =0.0131186861465
Mean train loss after  1100 batches of 10  epochs =0.0128301140345
Mean train loss after  1200 batches of 10  epochs =0.0127525440098
Mean train loss after  1300 batches of 10  epochs =0.0128029701863
Mean train loss after  1400 batches of 10  epochs =0.012453069743
Mean train loss after  1500 batches of 10  epochs =0.0126201319949
Mean train loss after  1600 batches of 10  epochs =0.0122727658833
Mean train loss after  1700 batches of 10  epochs =0.0128128233542
Mean train loss after  1800 batches of 10  epochs =0.0126179254959
Mean train loss after  1900 batches of 10  epochs =0.0129419467612
Mean train loss after  2000 batches of 10  epochs =0.0130421875174
Mean train loss after  2100 batches of 10  epochs =0.01304368611
Mean train loss after  2200 batches of 10  epochs =0.0128840999002
Mean train loss after  2300 batches of 10  epochs =0.0128905071107
Mean train loss after  2400 batches of 10  epochs =0.0129926267623
Mean train loss after  2500 batches of 10  epochs =0.0130636098118
Mean train loss after  2600 batches of 10  epochs =0.0129811283067
Mean train loss after  2700 batches of 10  epochs =0.0132626333182
Mean train loss after  2800 batches of 10  epochs =0.0138399352502
Mean train loss after  2900 batches of 10  epochs =0.0137045770094
Mean train loss after  3000 batches of 10  epochs =0.0136970068326
Mean train loss after  3100 batches of 10  epochs =0.013730357364
Mean train loss after  3200 batches of 10  epochs =0.0134456889581
Mean train loss after  3300 batches of 10  epochs =0.0132892158242
Mean train loss after  3400 batches of 10  epochs =0.0130799233404
Mean train loss after  3500 batches of 10  epochs =0.0128947645098
Mean train loss after  3600 batches of 10  epochs =0.0129345436586
Mean train loss after  3700 batches of 10  epochs =0.0128298534488
Mean train loss after  3800 batches of 10  epochs =0.0130333597115
Mean train loss after  3900 batches of 10  epochs =0.0131219967844
Mean train loss after  4000 batches of 10  epochs =0.0129960504766
Mean train loss after  4100 batches of 10  epochs =0.0132136410114
Mean train loss after  4200 batches of 10  epochs =0.0131506898879
Mean train loss after  4300 batches of 10  epochs =0.0130496097248
Mean train loss after  4400 batches of 10  epochs =0.0132411636879
Mean train loss after  4500 batches of 10  epochs =0.0132990391951
Mean train loss after  4600 batches of 10  epochs =0.0133594835532
Mean train loss after  4700 batches of 10  epochs =0.0134008666081
Mean train loss after  4800 batches of 10  epochs =0.0134142066761
Mean train loss after  4900 batches of 10  epochs =0.013566207595
Mean train loss after  5000 batches of 10  epochs =0.0134451210767
Mean train loss after  5100 batches of 10  epochs =0.013401042609
Mean train loss after  5200 batches of 10  epochs =0.0133736735039
Mean train loss after  5300 batches of 10  epochs =0.0134522250566
Mean train loss after  5400 batches of 10  epochs =0.0134227625856
Mean train loss after  5500 batches of 10  epochs =0.013772996992
Mean train loss after  5600 batches of 10  epochs =0.013884777102
Mean train loss after  5700 batches of 10  epochs =0.0138836900129
Mean train loss after  5800 batches of 10  epochs =0.0142410635462
Mean train loss after  5900 batches of 10  epochs =0.0143307845012
Mean train loss after  6000 batches of 10  epochs =0.0143615573058
Mean train loss after  6100 batches of 10  epochs =0.0143335645897
Mean train loss after  6200 batches of 10  epochs =0.0144142589195
Mean train loss after  6300 batches of 10  epochs =0.0145838144003
Mean train loss after  6400 batches of 10  epochs =0.0147003059365
Mean train loss after  6500 batches of 10  epochs =0.0147269035494
Mean train loss after  6600 batches of 10  epochs =0.0149134196772
Mean train loss after  6700 batches of 10  epochs =0.0150032721959
Mean train loss after  6800 batches of 10  epochs =0.0149344798709
Mean train loss after  6900 batches of 10  epochs =0.0148704034439
Mean train loss after  7000 batches of 10  epochs =0.0149212669217
Mean train loss after  7100 batches of 10  epochs =0.015150118764
Mean train loss after  7200 batches of 10  epochs =0.015182017994
Mean train loss after  7300 batches of 10  epochs =0.0152191965187
Mean train loss after  7400 batches of 10  epochs =0.0152059357635
Mean train loss after  7500 batches of 10  epochs =0.0152553949926
Mean train loss after  7600 batches of 10  epochs =0.015362714045
Mean train loss after  7700 batches of 10  epochs =0.0154634309062
Mean train loss after  7800 batches of 10  epochs =0.0154957551007
Mean train loss after  7900 batches of 10  epochs =0.015501952691
Mean train loss after  8000 batches of 10  epochs =0.015480818138
Mean train loss after  8100 batches of 10  epochs =0.0155977350593
Mean train loss after  8200 batches of 10  epochs =0.0156030093974
Mean train loss after  8300 batches of 10  epochs =0.0155802038086
Mean train loss after  8400 batches of 10  epochs =0.0156905301555
Mean train loss after  8500 batches of 10  epochs =0.0156389705543
Mean train loss after  8600 batches of 10  epochs =0.0157008850877
Mean train loss after  8700 batches of 10  epochs =0.0157416433351
Mean train loss after  8800 batches of 10  epochs =0.0157097590423
Mean train loss after  8900 batches of 10  epochs =0.0156963155654
Mean train loss after  9000 batches of 10  epochs =0.0158493662685
Mean train loss after  9100 batches of 10  epochs =0.0158719072968
Mean train loss after  9200 batches of 10  epochs =0.0159752225246
Mean train loss after  9300 batches of 10  epochs =0.0160460092584
Mean train loss after  9400 batches of 10  epochs =0.0160672057798
Mean train loss after  9500 batches of 10  epochs =0.0161478097881
Mean train loss after  9600 batches of 10  epochs =0.0161764047701
Mean train loss after  9700 batches of 10  epochs =0.0162537585066
Mean train loss after  9800 batches of 10  epochs =0.0162573519346
Mean train loss after  9900 batches of 10  epochs =0.0162606390677
Mean train loss after  10000 batches of 10  epochs =0.0163094811631
Mean train loss after  10100 batches of 10  epochs =0.0164049017346
Mean train loss after  10200 batches of 10  epochs =0.0165821584524
Mean train loss after  10300 batches of 10  epochs =0.0167442494981
Mean train loss after  10400 batches of 10  epochs =0.0166978627365
Mean train loss after  10500 batches of 10  epochs =0.0169282899803
Mean train loss after  10600 batches of 10  epochs =0.016954433445
Mean train loss after  10700 batches of 10  epochs =0.0170217172324
Mean train loss after  10800 batches of 10  epochs =0.0170755032591
Mean train loss after  10900 batches of 10  epochs =0.0170353067336
Mean train loss after  11000 batches of 10  epochs =0.0170199045464
Mean train loss after  11100 batches of 10  epochs =0.0170007210108
Mean train loss after  11200 batches of 10  epochs =0.017036220533
Mean train loss after  11300 batches of 10  epochs =0.0170550988484
Mean train loss after  11400 batches of 10  epochs =0.0171009484887
Mean train loss after  11500 batches of 10  epochs =0.0171819690573
Mean train loss after  11600 batches of 10  epochs =0.017256630602
Mean train loss after  11700 batches of 10  epochs =0.017225800585
Mean train loss after  11800 batches of 10  epochs =0.0172722594203
Mean train loss after  11900 batches of 10  epochs =0.0172936904434
Mean train loss after  12000 batches of 10  epochs =0.0173381999329
Mean train loss after  12100 batches of 10  epochs =0.0174349281609
Mean train loss after  12200 batches of 10  epochs =0.0174051133972
Mean train loss after  12300 batches of 10  epochs =0.017427880523
Mean train loss after  12400 batches of 10  epochs =0.0175734048213
Mean train loss after  12500 batches of 10  epochs =0.0176392214961
Mean train loss after  12600 batches of 10  epochs =0.0176259162791
Mean train loss after  12700 batches of 10  epochs =0.0176195677728
Mean train loss after  12800 batches of 10  epochs =0.0176927277089
Mean train loss after  12900 batches of 10  epochs =0.0177417657881
Mean train loss after  13000 batches of 10  epochs =0.0177339250639
Mean train loss after  13100 batches of 10  epochs =0.0177294743413
Mean train loss after  13200 batches of 10  epochs =0.0177519751598
Mean train loss after  13300 batches of 10  epochs =0.0178419247353
Mean train loss after  13400 batches of 10  epochs =0.0179343988619
Mean train loss after  13500 batches of 10  epochs =0.0180439773641
Mean train loss after  13600 batches of 10  epochs =0.0180871853562
Mean train loss after  13700 batches of 10  epochs =0.0180332983009
Mean train loss after  13800 batches of 10  epochs =0.018044705941
Mean train loss after  13900 batches of 10  epochs =0.0181031173832
Mean train loss after  14000 batches of 10  epochs =0.0181311687508
Mean train loss after  14100 batches of 10  epochs =0.0181913020759
Mean train loss after  14200 batches of 10  epochs =0.0182373517054
Mean train loss after  14300 batches of 10  epochs =0.0182538903113
Mean train loss after  14400 batches of 10  epochs =0.0182825665131
Mean train loss after  14500 batches of 10  epochs =0.0184280903211
Mean train loss after  14600 batches of 10  epochs =0.0185327700007
Mean train loss after  14700 batches of 10  epochs =0.0185488634177
Mean train loss after  14800 batches of 10  epochs =0.0186168361789
Mean train loss after  14900 batches of 10  epochs =0.018619286732
Epoch 10 : Mean train epoch loss =0.0186985784871
Epoch 10 Epoch val loss = 20873.7416252
Epoch 10 Epoch val perplexity = 1.5306605034151002
SCORES =  (92.47, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 11---------------------

=================================
fscore(z) =  [119.83207] || goldscore = [119.83195]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-6.29	-1.03	0.03	-3.93	-0.53	-2.15	-1.17	-1.68	-2.08	-2.29	-3.37	-0.16	-0.86	-1.46	-1.09	-3.58	-2.46	-4.13	-4.03	-4.46	-2.68	-3.32	0.58	-1.47	-4.04	-3.71	-5.62	-2.66	-3.07	0.33	-0.81	0.44	-1.46	-3.53	-2.06	-4.56	-4.23	0.10	-3.02	-2.35	-5.27	-3.57	-5.00	-3.65	-2.83	-4.55	-100000000.00	-3.27	
VBG 	-1.93	-4.59	-0.26	-0.13	-0.73	-0.14	-2.51	-0.76	-3.66	-3.03	-4.74	0.04	-0.31	-1.59	-2.01	-5.13	-0.35	-2.91	-3.77	-7.82	-1.84	-2.02	-1.10	0.34	-3.84	-1.18	-2.19	-0.14	-3.48	-0.73	-2.78	-0.69	-4.79	-2.03	-1.22	-1.56	-4.82	0.28	-1.59	-2.32	-2.79	-1.92	-0.66	-2.81	-3.30	-8.42	-100000000.00	-1.96	
VBD 	-3.73	-4.38	-4.63	-1.74	-2.03	0.92	-2.40	-1.72	1.68	-2.23	0.12	-2.39	-1.87	-1.55	-2.34	-3.66	-0.22	-0.11	-2.76	-3.11	-1.82	-2.61	-6.52	-1.39	-5.99	-0.28	-2.92	-0.12	1.04	-2.38	-0.77	-0.80	-3.95	-1.28	-1.30	-1.83	0.20	-3.57	-0.61	-4.78	-4.76	-1.04	-1.42	-1.17	-6.17	-4.21	-100000000.00	0.09	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-3.14	-2.11	-0.84	-0.83	-2.44	-1.31	-4.15	0.80	-2.00	-2.07	-3.03	0.71	-0.84	-1.29	-1.94	-5.40	-0.71	-2.36	-1.56	-2.46	-1.69	-3.31	-3.53	-0.55	-5.06	0.78	-2.33	-0.66	-1.88	-0.39	-1.55	-0.97	-4.01	-2.38	-1.94	-2.80	-4.42	-1.77	-1.98	-2.11	-4.80	-2.27	-3.16	-2.85	-2.16	-6.47	-100000000.00	-2.99	
, 	-2.95	-3.09	-0.49	-5.87	-1.53	-4.48	0.37	-2.79	-0.24	0.76	-4.05	-2.87	-2.08	-2.64	-0.80	-6.43	0.45	-0.37	-3.79	-2.29	-2.10	-3.73	-4.66	-0.35	-5.87	0.65	-3.93	-0.32	-1.78	-2.04	-5.48	-3.43	-5.34	-3.27	0.27	1.03	-3.16	-0.68	-3.16	-4.91	-3.61	-0.90	-3.35	-1.22	-8.83	-1.66	-100000000.00	0.10	
'' 	-4.85	-1.58	-1.28	0.02	-3.62	-0.49	-1.10	-3.46	-0.76	-2.97	-2.83	-1.21	-4.27	-5.80	-0.33	-0.67	-0.65	-3.25	-2.70	-2.00	-1.67	1.29	-4.38	0.89	-2.17	-0.52	0.05	-4.65	-2.68	-2.89	-3.03	-0.16	-1.12	-2.72	1.03	-2.08	-0.52	-0.85	-0.35	-1.92	-1.66	-3.02	-2.78	-3.39	-4.36	-2.03	-100000000.00	-0.69	
VBP 	-6.52	-3.53	-5.75	-5.17	-2.55	-1.87	0.03	-3.75	0.51	-4.42	0.35	-2.65	-2.66	-4.52	-2.54	-4.71	-1.96	-1.28	-3.41	-8.10	-4.82	-2.04	-3.32	-1.24	-5.03	-1.08	-3.70	0.96	1.13	-3.05	-3.07	-1.35	-1.78	-2.85	-1.48	-0.33	0.79	-4.50	-1.79	-2.10	-7.56	0.46	-5.08	-4.04	-3.58	-5.72	-100000000.00	-0.68	
WDT 	-4.51	-4.80	-4.92	-1.66	-3.88	-0.67	-3.78	-3.04	-2.36	-3.41	-4.93	-3.51	-0.18	-3.96	-3.15	-4.21	0.24	-1.00	-5.51	-5.40	-3.80	-1.12	-1.03	-0.73	-3.31	-3.60	-0.35	0.42	-3.04	-3.53	-3.42	-2.25	-1.31	-3.71	-3.56	-1.39	-1.98	-0.55	-0.11	-1.32	-2.28	-2.98	-3.78	-3.36	-4.30	-2.83	-100000000.00	-0.35	
JJ 	0.51	-0.91	-0.34	-0.77	-0.67	-1.41	-1.65	-0.38	-2.64	-0.91	-4.34	-0.02	1.88	-0.28	-1.68	-0.20	-2.07	-1.80	-1.46	-3.89	-0.37	-3.46	-0.26	-0.99	-7.19	-0.34	-0.16	-2.07	-1.24	-0.65	0.17	-0.47	-6.63	0.53	0.87	0.75	-5.51	1.25	-0.50	-3.61	-3.41	-3.47	-1.04	-1.21	-2.21	-3.83	-100000000.00	-1.14	
WP 	-3.83	-2.77	-3.48	-2.86	-1.47	-1.73	0.58	-0.88	-2.28	-1.97	-2.45	-0.69	-1.33	-1.41	-3.05	-3.45	0.14	-2.98	-2.01	-3.00	-3.07	-2.45	0.27	-2.02	-2.52	-1.63	-4.35	0.30	-2.69	-0.83	-3.09	-1.87	-2.90	-2.60	-4.01	-3.69	-2.13	0.06	-2.38	-0.63	-3.68	-1.20	-3.37	-2.23	-3.26	-1.87	-100000000.00	-1.74	
VBZ 	-3.03	-4.02	-5.76	-4.63	-3.23	-0.25	-2.57	-1.83	1.84	-1.89	-0.56	-3.77	-1.05	-1.67	-3.82	-3.76	0.80	-1.54	-1.16	-3.33	-3.70	-1.87	-3.72	-1.66	-3.74	-0.91	-2.59	-3.17	2.02	-3.80	-1.16	-1.00	-5.13	-3.33	-5.13	-1.21	1.34	-3.84	-2.10	-2.72	-5.12	-4.13	-2.27	-3.27	-3.16	-7.45	-100000000.00	-0.21	
DT 	-4.32	-2.17	-1.01	-0.45	-0.54	-0.39	-1.57	-0.71	-2.06	-1.15	-2.58	-0.29	-2.22	-1.06	-0.15	-6.78	-0.44	-2.07	0.01	-2.84	-2.07	-2.78	0.69	-2.10	-4.90	-1.20	-0.86	-1.63	-1.93	0.90	-0.28	1.62	0.33	-1.84	0.75	-3.21	-3.77	1.71	-0.84	-2.18	-2.84	-3.72	-4.43	-2.94	-0.88	-6.68	-100000000.00	-0.39	
" 	0.07	-0.97	-2.43	-2.46	-1.56	-0.73	1.01	-2.51	-0.61	-0.53	-3.12	-1.23	-1.20	-2.82	-0.69	-3.90	0.01	-1.56	-2.83	-4.46	0.93	1.35	-2.29	0.02	-0.68	-2.40	0.51	-2.82	-3.76	-2.24	-2.53	-2.20	-3.65	-4.17	-3.25	-1.48	-3.89	-1.22	-1.28	-3.64	-4.13	-2.79	-3.60	-2.09	-2.80	-4.64	-100000000.00	0.09	
RP 	-5.78	0.91	1.20	-5.01	0.88	-2.59	-3.56	1.17	-3.80	-2.48	-5.23	-0.90	-0.48	-5.39	-1.99	-3.84	-2.25	-1.80	-4.98	-4.78	-3.15	-1.07	-6.60	-0.99	-3.64	-1.77	-5.69	-2.42	0.09	-0.00	-3.85	-4.94	-2.70	-3.83	-2.02	-2.50	-6.28	-4.80	-1.33	-1.81	-6.27	-4.60	-3.13	-3.93	-5.13	-5.52	-100000000.00	-3.26	
$ 	-2.94	-1.87	-1.05	-6.82	-0.85	-2.61	-2.21	-2.19	-2.68	-0.04	-3.17	-0.53	-0.46	-2.82	-0.68	-0.19	-0.19	-2.66	-0.69	-6.57	-0.07	-0.97	0.34	-0.69	-0.51	-1.18	-0.60	-2.24	-2.47	-0.50	-2.83	-0.35	-3.67	-1.58	-4.08	-1.67	-2.43	0.40	-2.01	-2.87	-1.95	-4.03	-2.39	-3.31	-4.87	-3.16	-100000000.00	0.48	
NN 	0.94	-0.43	-1.07	0.31	0.07	0.71	-2.73	-1.34	-2.46	0.66	-1.58	-0.38	0.41	-0.96	-1.63	-4.80	-1.26	-0.98	-1.75	-1.19	0.75	-2.23	-1.66	-2.10	-7.87	-3.07	0.36	-2.23	-3.16	-0.13	-2.13	-2.12	-4.26	-3.93	-0.91	-0.68	-6.17	0.08	1.46	-5.37	-5.48	-2.16	0.07	0.02	-1.73	-11.10	-100000000.00	-0.57	
) 	-4.57	-2.27	-3.95	-5.53	-1.73	-4.81	-5.07	-4.69	-6.33	-1.07	-5.97	-1.60	-3.89	-2.36	0.50	-4.62	-1.91	-3.29	-2.81	-3.97	-1.63	-3.65	-4.95	0.05	-0.01	-3.16	-3.59	-2.78	-6.67	-2.06	-5.32	-4.64	-5.98	-3.82	-5.66	1.13	-2.57	-2.43	-2.52	-5.47	-5.24	-1.54	-7.37	-9.24	-4.63	-5.23	-100000000.00	-0.49	
( 	-0.03	-4.33	-1.48	-3.11	-3.61	-3.51	-2.51	-5.30	-2.76	-1.80	-2.01	-1.82	-2.30	-0.80	-4.29	-5.75	-0.06	-2.63	-4.59	-2.23	-1.14	-2.59	-2.61	-0.47	-3.34	-4.00	-2.49	-0.90	-2.46	-2.37	-2.94	-4.70	-6.17	-4.27	-5.98	0.28	-4.25	-4.97	-2.23	-3.11	-5.96	-2.06	-2.33	-3.02	-7.16	-4.12	-100000000.00	1.29	
FW 	-6.17	-5.49	-4.37	-3.38	-7.01	-2.35	-2.64	-1.93	-3.07	-2.62	-4.10	-7.94	-5.01	-4.55	-5.77	-2.70	-3.22	-2.06	-3.91	-1.62	-6.73	-1.52	-6.59	-0.66	-2.45	-5.82	-3.06	-3.70	-6.18	-3.22	-1.18	-3.12	-3.55	-2.92	-4.59	-3.28	-3.39	-12.46	-0.32	-2.35	-3.13	-3.17	-4.93	-5.52	-3.32	-2.68	-100000000.00	-1.05	
POS 	-3.27	-6.34	-2.96	-3.85	-1.08	-2.51	1.41	-2.08	-0.00	-0.77	-5.07	-4.87	-2.56	-3.86	-4.00	-4.26	1.41	-4.38	-4.07	-6.14	-4.11	-1.94	-4.30	-2.07	-5.64	-3.28	-3.11	-0.20	-1.77	-2.61	-2.98	-3.05	-3.08	-1.72	-3.76	-2.36	-1.18	-2.71	-2.47	-2.93	-3.99	-1.72	-4.53	-3.47	-4.72	-5.36	-100000000.00	2.34	
. 	-3.18	-1.15	-1.71	-5.32	-1.48	-5.92	-3.66	-0.92	-6.07	-0.15	-4.45	-1.28	-0.58	-1.67	-0.21	-6.99	-0.67	-0.95	-4.06	-4.58	-1.21	-2.33	-4.84	-0.82	-0.24	-0.95	-2.93	0.49	-1.60	-1.85	-2.67	-2.74	-3.50	-7.86	-1.17	0.65	-2.60	-2.10	-2.12	-4.57	-5.27	-0.80	-5.25	-2.09	-7.51	-2.65	-100000000.00	1.37	
TO 	-2.23	-2.22	-0.47	-3.33	-1.14	-2.82	-4.56	-0.26	-5.32	-1.04	-4.31	0.13	-3.32	-3.06	-0.44	-6.05	-1.23	-2.29	-3.08	-4.88	-5.52	-3.73	-3.76	-1.44	-4.83	-0.70	-1.71	-1.24	-2.97	-1.37	-1.97	-3.56	-6.70	-4.13	-0.98	0.69	-3.08	0.05	-2.00	-3.17	-4.96	-3.63	-2.34	-1.75	-6.19	-8.60	-100000000.00	-1.60	
-X- 	-0.35	-0.15	-2.25	-2.83	-1.54	-1.66	-1.66	-1.45	-0.83	-2.03	-2.49	-2.40	-1.48	-2.24	0.30	-2.18	-0.96	-1.41	-2.57	-0.68	-1.54	-0.50	-2.24	2.00	-1.47	-2.20	-2.30	-1.50	-1.89	-1.60	0.21	-0.11	1.65	-0.31	-0.31	-2.52	0.35	-2.17	0.84	1.11	0.77	-2.18	-1.88	1.53	-1.07	0.35	-100000000.00	-4.13	
LS 	-2.63	-2.94	-5.50	-1.16	-3.84	-2.94	-1.14	-4.59	-1.92	-5.01	-1.50	-2.77	-6.35	-3.04	-4.47	-4.94	-3.59	-3.06	-3.61	-3.94	-2.06	-0.17	-4.66	-1.55	-3.59	-5.65	1.31	-6.14	-4.28	-3.29	-0.19	-5.34	-1.18	-1.09	-2.73	-5.75	-3.03	-4.58	-1.26	-1.18	-4.10	-4.60	-2.43	-5.00	-2.77	-2.78	-100000000.00	-4.91	
RB 	-2.66	-0.55	0.63	-1.46	-0.04	-1.08	-1.49	0.16	-1.45	-2.51	-1.85	0.14	-1.10	-0.50	-1.16	-4.16	-0.48	0.03	-1.75	-7.28	-2.19	-3.10	-0.97	-1.13	-3.90	-1.87	-2.86	-0.49	-0.63	-0.05	-0.73	-1.44	-5.96	-2.17	-1.07	-0.76	-2.86	-1.27	-1.83	-1.73	0.59	-4.25	-1.98	-2.21	-2.75	-6.61	-100000000.00	-1.17	
: 	-5.78	-2.54	-1.42	-3.57	-1.72	-4.19	-4.25	-2.00	-3.96	0.25	-3.43	-1.18	-2.70	-3.74	-2.86	-3.56	0.09	-1.94	-2.72	-8.11	-0.35	-2.60	-6.19	-1.92	-3.77	-2.28	-3.42	-2.89	-3.85	-0.78	-5.14	-5.82	-3.74	-3.32	-2.43	0.08	-4.10	-1.57	-2.46	-3.38	-6.56	-0.56	-7.22	-1.94	-4.40	-6.30	-100000000.00	-0.35	
NNS 	1.49	-1.01	-0.90	-0.85	-0.91	-2.17	-2.51	-1.25	-1.38	1.13	-2.71	-1.99	-0.73	-2.44	-2.24	-4.64	-0.07	-2.79	-1.56	-2.94	0.47	-3.12	-2.80	-2.21	-6.51	-4.25	-0.54	-5.22	-2.49	-0.46	-0.87	0.22	-4.47	-2.50	-2.91	-0.73	-5.43	-1.25	0.80	-4.47	-3.32	-4.45	-0.75	0.01	-2.79	-10.48	-100000000.00	-1.30	
PRP 	-5.60	-1.17	-0.41	-2.26	0.54	-1.89	0.18	-1.30	-1.62	-2.62	0.12	-0.04	-3.17	-1.53	-4.68	-4.78	-1.02	-3.54	-5.20	-6.41	-0.92	-1.33	-1.72	-0.15	-3.96	-2.05	-0.57	-2.40	-6.05	0.60	0.60	-1.37	-2.73	-4.37	-2.74	-3.38	-1.62	1.02	-2.76	-2.64	-3.27	-5.84	-2.66	-5.54	-3.14	-4.22	-100000000.00	-1.95	
VB 	-4.73	-2.14	-3.43	-0.24	-3.79	-0.73	-2.54	-2.24	-2.07	-3.46	-1.34	-2.22	-1.99	-1.56	-2.38	-1.31	-1.62	0.27	-4.04	-2.47	-5.40	-1.43	0.53	-1.00	-4.70	0.34	-0.52	-2.33	-0.36	-3.57	-2.72	0.77	-0.81	-3.05	0.10	-2.47	-3.78	-3.61	-2.75	-2.12	1.76	-3.43	-1.75	-1.27	-5.63	-2.13	-100000000.00	-1.77	
WRB 	-3.52	-1.69	-2.00	-1.85	-0.65	-1.03	-2.23	-2.34	-2.19	-0.20	-2.49	0.01	-5.20	-2.89	-0.97	-2.43	-0.83	-3.47	-3.62	-4.35	-3.00	-0.55	-3.12	0.02	-2.47	-1.95	-5.55	-1.99	-2.04	-0.82	-3.48	-1.63	-3.51	-1.98	-5.11	-1.33	-2.53	-0.76	0.26	-1.41	-4.26	-5.81	-2.61	-2.13	-4.78	-1.57	-100000000.00	-0.89	
CC 	-4.21	-2.39	-2.92	-2.45	-0.94	-0.07	-4.07	-1.69	-3.39	1.07	-4.33	-2.34	-3.60	-2.42	-1.32	-4.69	-0.46	-1.69	-5.47	-4.70	-1.33	-0.89	-2.77	-2.24	-4.29	-1.26	-0.69	-1.69	-1.47	0.23	-3.77	-4.43	-2.78	-5.62	-0.53	0.52	-1.22	-1.79	-1.72	-2.53	-4.68	-0.73	-3.24	-1.80	-2.38	-7.95	-100000000.00	0.16	
PDT 	-3.76	-0.69	-3.73	-2.59	-1.18	-5.87	-2.83	-1.06	-4.38	-2.64	-5.04	-1.61	-4.29	-3.38	-2.64	-3.09	-3.47	-4.02	-1.31	-2.05	-1.25	-0.67	-4.15	0.08	-1.69	-0.84	-3.09	-1.82	-4.00	-1.60	-1.10	-2.32	-1.40	-0.18	-3.21	-3.51	-1.74	0.75	-0.98	-1.26	-1.40	-2.76	-2.94	-2.63	-5.28	-1.87	-100000000.00	-1.43	
RBS 	-0.51	-4.60	-1.12	-7.89	-2.16	-2.26	-1.38	-3.96	-4.13	-4.00	-0.69	-0.69	-0.74	-4.10	-1.99	-2.42	-1.96	-3.93	-5.04	-3.77	-0.62	-0.62	-2.40	1.77	-3.29	-1.46	-5.25	-8.46	-5.54	-1.53	-3.45	-0.70	-2.94	-1.60	-2.72	-4.59	-2.21	-0.04	-1.11	0.03	-4.41	-3.76	-4.53	-4.95	-3.81	-2.98	-100000000.00	-8.46	
RBR 	-4.70	-2.18	-0.25	-3.08	-0.15	-3.36	-1.57	-2.11	-1.34	-2.95	-1.48	-0.86	-1.07	-3.48	-0.92	-3.82	-0.28	-3.55	-4.41	-5.67	-5.89	-1.69	-1.64	0.52	-1.57	-0.53	-1.28	-0.39	-1.94	-1.55	-3.13	-1.65	-2.47	-2.15	-4.69	-2.93	-4.71	-0.90	-1.21	-0.39	-2.56	-4.17	-2.99	-3.84	-2.63	-2.29	-100000000.00	-1.21	
CD 	-1.39	-1.44	-1.15	-0.97	-2.47	-0.58	-1.46	-2.42	-1.90	-0.48	-5.18	-1.06	-1.02	-0.79	-3.42	3.49	-1.18	-0.40	-0.29	-2.74	0.21	-4.35	-0.12	-2.71	-8.66	-0.85	-0.15	-2.18	-2.05	-0.72	-2.08	-1.36	-3.12	-5.89	-7.96	-1.05	-8.19	-0.48	0.15	0.13	-9.27	-1.70	-2.51	-1.62	-1.86	-4.43	-100000000.00	-0.77	
EX 	-1.83	-1.16	0.18	-0.57	-2.58	-1.92	-2.39	-0.65	-1.10	-1.46	-0.81	-0.70	-0.97	-0.92	-2.95	-2.68	-0.79	-3.29	-4.65	-4.58	-3.68	-2.45	-4.65	-1.23	-1.75	-2.37	-3.30	-2.88	-1.12	-1.49	-1.25	0.72	-1.83	-2.29	-0.51	-3.52	-2.79	-1.10	-1.19	-0.84	-2.13	-3.03	-1.38	-3.44	-3.73	-1.64	-100000000.00	-1.74	
IN 	-4.27	-1.44	-1.48	-1.54	0.11	-0.32	-2.71	0.32	-1.53	-1.17	-5.06	-0.67	-1.30	-0.07	-0.50	-3.59	0.22	-1.00	-1.97	-5.16	-2.21	-3.97	-1.94	-2.18	-8.21	-1.53	-1.93	0.57	-1.65	-0.38	-3.44	-1.02	-4.36	-2.33	0.81	-0.79	-1.64	-0.95	-2.97	-1.88	-5.66	-2.15	-0.66	-0.28	-4.26	-10.34	-100000000.00	-0.60	
WP$ 	-0.75	-2.06	-1.82	-5.77	-2.24	0.81	-0.97	-2.91	-0.60	-1.90	0.18	-1.96	-1.38	-1.77	-1.76	0.69	-2.00	-1.43	-2.68	-1.35	-0.71	-2.57	-2.51	0.36	-1.16	-2.10	-2.27	-0.10	-1.74	-2.88	-2.52	-2.86	-0.55	0.15	-0.04	-3.25	-0.96	-2.47	-1.96	0.03	-0.60	-1.29	-2.10	-1.71	-1.70	-0.16	-100000000.00	-2.12	
NN|SYM 	-1.57	-4.19	-3.85	-7.79	-3.92	-3.04	-1.75	-4.17	-0.66	-3.85	-2.15	-3.53	-4.81	-4.25	-2.66	-2.36	-6.28	-0.34	-2.67	-2.68	-2.71	0.85	-4.60	0.50	-1.50	-3.97	-5.15	-5.41	-3.53	-3.68	-1.46	-3.79	-0.33	0.42	-2.57	-5.92	-1.09	-3.90	-0.19	-0.90	-3.02	-3.12	-2.97	-3.01	-4.19	-2.40	-100000000.00	-6.21	
MD 	-1.51	-3.35	-2.05	-4.76	-4.63	-1.53	-2.66	-2.64	1.32	-1.74	-1.90	-2.59	-1.65	-2.28	-1.16	-4.31	-0.83	-1.83	-5.67	-6.23	-2.88	-0.35	-4.54	-0.86	-2.51	-1.85	-2.72	-0.80	0.17	-2.57	-0.87	-1.82	-3.48	-2.45	-4.82	-1.80	-0.39	-3.75	-2.50	-0.74	-3.99	-1.98	-4.93	-6.24	-5.35	-3.30	-100000000.00	-0.49	
NNPS 	-5.23	-3.87	-3.61	-3.55	-2.93	-2.51	-3.29	-2.04	-3.21	-3.13	-5.11	-2.88	-1.49	-2.76	-3.92	-5.02	-3.42	-0.72	-2.43	-7.89	-3.84	-1.79	-5.12	-1.06	-4.28	-8.69	-2.61	-6.79	-6.18	-2.18	-3.32	-2.49	-3.59	-2.40	-6.78	-1.52	-5.04	-2.05	-0.44	-3.94	-5.44	-3.10	-5.08	-6.77	-4.31	-8.68	-100000000.00	0.07	
JJS 	-0.32	-6.23	-2.19	-1.79	-1.40	-2.90	-1.69	-3.93	-3.57	-1.93	-2.98	-4.22	-1.59	-2.78	-3.56	-3.29	-5.45	-4.72	-3.26	-4.72	-1.32	-1.43	-2.49	-2.48	-4.10	-4.91	-6.17	-4.61	-4.86	-2.49	-2.38	-3.56	-2.43	-1.93	-4.19	-4.45	-1.83	-1.24	-0.67	-1.37	-4.11	-6.27	-4.11	-6.81	-4.51	-3.29	-100000000.00	-6.18	
JJR 	-2.83	-1.64	-0.13	-0.78	-1.36	-3.99	-2.48	-1.14	-4.44	-1.92	-5.38	-0.18	-1.40	-3.24	-2.82	-3.51	-3.05	-7.36	-0.12	-4.59	-8.35	-1.43	-1.54	-0.23	-3.42	-0.75	-2.35	-1.84	-2.46	0.05	-0.51	-1.81	-5.11	-4.52	-4.72	-2.37	-2.96	-1.51	-1.87	-1.07	-3.68	-3.47	-4.51	-6.57	-2.80	-5.58	-100000000.00	-2.54	
SYM 	-2.26	-2.78	-5.59	-0.94	-6.88	-6.87	-2.83	-2.18	-4.81	-0.80	-5.39	-5.66	-5.99	-2.55	-5.09	-3.18	-1.55	-1.02	-4.06	-5.00	-4.60	-1.01	-6.91	-1.16	-3.68	-4.37	-5.42	-3.09	-1.32	-4.61	-4.83	-2.09	-3.45	-3.80	-5.86	-0.66	-4.62	-3.54	-0.67	-2.22	-3.57	-5.52	-3.72	-3.95	-4.60	-1.10	-100000000.00	-1.05	
UH 	-4.31	-6.19	-5.52	-2.28	-7.39	-1.30	0.01	-3.05	-5.27	-7.33	-1.55	-6.96	-12.32	-0.64	-4.00	-4.86	-10.79	-6.53	-7.44	-3.20	-7.39	-2.52	-6.96	-0.56	-2.66	-4.91	-7.85	-9.13	-3.13	-5.90	-2.36	-6.89	-2.52	-2.76	-4.42	-11.22	-4.38	-2.11	-1.89	0.17	-5.06	-7.81	-3.92	-2.91	-3.99	-2.82	-100000000.00	-6.11	
stop_tag 	-5.75	-9.99	-1.28	-0.88	-2.78	-4.88	-1.72	-5.67	-9.18	0.06	-8.05	-2.80	-2.92	-2.92	-2.47	-5.63	0.04	-1.86	-5.68	-3.13	-1.53	-1.69	-6.63	-1.64	-7.26	-2.15	-2.40	-1.24	-4.84	-2.06	-9.19	-4.89	-8.12	-5.88	-9.73	0.62	-7.05	-3.17	-2.85	-3.17	-8.88	-2.38	-11.36	-9.09	0.19	-9.58	-100000000.00	-0.44	
NNP 	-0.43	-1.33	-0.51	-0.86	-0.87	-1.28	-0.74	-1.71	-1.84	-0.86	-3.58	-0.51	-0.66	-1.07	-2.09	-3.06	-1.02	-0.69	-0.85	-1.34	0.87	-3.25	-0.93	-0.94	-7.91	-2.86	-0.42	-1.99	-4.32	-0.66	-0.35	0.64	-7.41	-5.80	-3.56	-0.93	-7.14	-0.61	-2.11	-4.95	-2.34	-1.47	-2.80	-1.45	-1.51	-2.34	-100000000.00	0.81	
Mean train loss after  0 batches of 11  epochs =1.74386160714e-05
Mean train loss after  100 batches of 11  epochs =0.0165097151881
Mean train loss after  200 batches of 11  epochs =0.0140598966985
Mean train loss after  300 batches of 11  epochs =0.0116124445715
Mean train loss after  400 batches of 11  epochs =0.0109907790866
Mean train loss after  500 batches of 11  epochs =0.0112907735195
Mean train loss after  600 batches of 11  epochs =0.0102902731154
Mean train loss after  700 batches of 11  epochs =0.00991951939655
Mean train loss after  800 batches of 11  epochs =0.0102908915405
Mean train loss after  900 batches of 11  epochs =0.0103270286047
Mean train loss after  1000 batches of 11  epochs =0.0109537431995
Mean train loss after  1100 batches of 11  epochs =0.0110395828821
Mean train loss after  1200 batches of 11  epochs =0.011109026421
Mean train loss after  1300 batches of 11  epochs =0.0108895920368
Mean train loss after  1400 batches of 11  epochs =0.0109470011414
Mean train loss after  1500 batches of 11  epochs =0.0105221572653
Mean train loss after  1600 batches of 11  epochs =0.0106470278628
Mean train loss after  1700 batches of 11  epochs =0.0106297164777
Mean train loss after  1800 batches of 11  epochs =0.0110500943731
Mean train loss after  1900 batches of 11  epochs =0.0111936793744
Mean train loss after  2000 batches of 11  epochs =0.0112659503813
Mean train loss after  2100 batches of 11  epochs =0.0116294550283
Mean train loss after  2200 batches of 11  epochs =0.0117335989664
Mean train loss after  2300 batches of 11  epochs =0.0118954968995
Mean train loss after  2400 batches of 11  epochs =0.0115972366026
Mean train loss after  2500 batches of 11  epochs =0.011506307856
Mean train loss after  2600 batches of 11  epochs =0.0116532160251
Mean train loss after  2700 batches of 11  epochs =0.0115895333848
Mean train loss after  2800 batches of 11  epochs =0.011471388269
Mean train loss after  2900 batches of 11  epochs =0.011702190013
Mean train loss after  3000 batches of 11  epochs =0.0120602769751
Mean train loss after  3100 batches of 11  epochs =0.0121403041681
Mean train loss after  3200 batches of 11  epochs =0.0123652813941
Mean train loss after  3300 batches of 11  epochs =0.0120321574843
Mean train loss after  3400 batches of 11  epochs =0.011975676624
Mean train loss after  3500 batches of 11  epochs =0.0118574922395
Mean train loss after  3600 batches of 11  epochs =0.0118725118326
Mean train loss after  3700 batches of 11  epochs =0.0117877209611
Mean train loss after  3800 batches of 11  epochs =0.0117733710955
Mean train loss after  3900 batches of 11  epochs =0.0118057245729
Mean train loss after  4000 batches of 11  epochs =0.011759864398
Mean train loss after  4100 batches of 11  epochs =0.0116951719927
Mean train loss after  4200 batches of 11  epochs =0.01170334104
Mean train loss after  4300 batches of 11  epochs =0.0118600922264
Mean train loss after  4400 batches of 11  epochs =0.0119096590865
Mean train loss after  4500 batches of 11  epochs =0.0118821315693
Mean train loss after  4600 batches of 11  epochs =0.0119260750135
Mean train loss after  4700 batches of 11  epochs =0.0119656621978
Mean train loss after  4800 batches of 11  epochs =0.0119279382637
Mean train loss after  4900 batches of 11  epochs =0.0120945712277
Mean train loss after  5000 batches of 11  epochs =0.0120405180881
Mean train loss after  5100 batches of 11  epochs =0.0120197302999
Mean train loss after  5200 batches of 11  epochs =0.0120633459271
Mean train loss after  5300 batches of 11  epochs =0.0121086754471
Mean train loss after  5400 batches of 11  epochs =0.0123208229408
Mean train loss after  5500 batches of 11  epochs =0.01244841494
Mean train loss after  5600 batches of 11  epochs =0.0124468825813
Mean train loss after  5700 batches of 11  epochs =0.0123693525289
Mean train loss after  5800 batches of 11  epochs =0.0123936474773
Mean train loss after  5900 batches of 11  epochs =0.0124484167771
Mean train loss after  6000 batches of 11  epochs =0.0123980527774
Mean train loss after  6100 batches of 11  epochs =0.0125729854967
Mean train loss after  6200 batches of 11  epochs =0.0125110094219
Mean train loss after  6300 batches of 11  epochs =0.0127814808214
Mean train loss after  6400 batches of 11  epochs =0.0127710018822
Mean train loss after  6500 batches of 11  epochs =0.01285511886
Mean train loss after  6600 batches of 11  epochs =0.0128162325335
Mean train loss after  6700 batches of 11  epochs =0.0129760054276
Mean train loss after  6800 batches of 11  epochs =0.0129698173678
Mean train loss after  6900 batches of 11  epochs =0.0130154115925
Mean train loss after  7000 batches of 11  epochs =0.0130287520081
Mean train loss after  7100 batches of 11  epochs =0.0130460044281
Mean train loss after  7200 batches of 11  epochs =0.0131516468879
Mean train loss after  7300 batches of 11  epochs =0.0131607544737
Mean train loss after  7400 batches of 11  epochs =0.0132043399791
Mean train loss after  7500 batches of 11  epochs =0.0132430470711
Mean train loss after  7600 batches of 11  epochs =0.0131593367168
Mean train loss after  7700 batches of 11  epochs =0.0131248313259
Mean train loss after  7800 batches of 11  epochs =0.0131327528738
Mean train loss after  7900 batches of 11  epochs =0.0132118960947
Mean train loss after  8000 batches of 11  epochs =0.0132100727533
Mean train loss after  8100 batches of 11  epochs =0.0132639027961
Mean train loss after  8200 batches of 11  epochs =0.0133100981753
Mean train loss after  8300 batches of 11  epochs =0.0134346900769
Mean train loss after  8400 batches of 11  epochs =0.0134709646352
Mean train loss after  8500 batches of 11  epochs =0.013446653532
Mean train loss after  8600 batches of 11  epochs =0.0134099681086
Mean train loss after  8700 batches of 11  epochs =0.0134357533899
Mean train loss after  8800 batches of 11  epochs =0.0135793000856
Mean train loss after  8900 batches of 11  epochs =0.0135196458159
Mean train loss after  9000 batches of 11  epochs =0.0136733697636
Mean train loss after  9100 batches of 11  epochs =0.0136740303655
Mean train loss after  9200 batches of 11  epochs =0.0138724488811
Mean train loss after  9300 batches of 11  epochs =0.0138878565402
Mean train loss after  9400 batches of 11  epochs =0.0138185234135
Mean train loss after  9500 batches of 11  epochs =0.0138103021353
Mean train loss after  9600 batches of 11  epochs =0.0138757352035
Mean train loss after  9700 batches of 11  epochs =0.0139172098542
Mean train loss after  9800 batches of 11  epochs =0.0138876169682
Mean train loss after  9900 batches of 11  epochs =0.0138646712594
Mean train loss after  10000 batches of 11  epochs =0.0138482160495
Mean train loss after  10100 batches of 11  epochs =0.0139767787324
Mean train loss after  10200 batches of 11  epochs =0.0140934569512
Mean train loss after  10300 batches of 11  epochs =0.0141319788303
Mean train loss after  10400 batches of 11  epochs =0.0141365971335
Mean train loss after  10500 batches of 11  epochs =0.0141392656823
Mean train loss after  10600 batches of 11  epochs =0.0140733045059
Mean train loss after  10700 batches of 11  epochs =0.0142079707893
Mean train loss after  10800 batches of 11  epochs =0.0142721208234
Mean train loss after  10900 batches of 11  epochs =0.014264879443
Mean train loss after  11000 batches of 11  epochs =0.0143225305571
Mean train loss after  11100 batches of 11  epochs =0.014292695218
Mean train loss after  11200 batches of 11  epochs =0.014386396715
Mean train loss after  11300 batches of 11  epochs =0.0145378200635
Mean train loss after  11400 batches of 11  epochs =0.0146000967988
Mean train loss after  11500 batches of 11  epochs =0.0146550383485
Mean train loss after  11600 batches of 11  epochs =0.0146922757192
Mean train loss after  11700 batches of 11  epochs =0.0147803022072
Mean train loss after  11800 batches of 11  epochs =0.0147724179145
Mean train loss after  11900 batches of 11  epochs =0.0147331548286
Mean train loss after  12000 batches of 11  epochs =0.0146963142431
Mean train loss after  12100 batches of 11  epochs =0.014722879464
Mean train loss after  12200 batches of 11  epochs =0.0147519332725
Mean train loss after  12300 batches of 11  epochs =0.0148994247549
Mean train loss after  12400 batches of 11  epochs =0.0150036872123
Mean train loss after  12500 batches of 11  epochs =0.0150181625991
Mean train loss after  12600 batches of 11  epochs =0.0150037246603
Mean train loss after  12700 batches of 11  epochs =0.0150649975092
Mean train loss after  12800 batches of 11  epochs =0.0151528668826
Mean train loss after  12900 batches of 11  epochs =0.0152502878975
Mean train loss after  13000 batches of 11  epochs =0.0153201121902
Mean train loss after  13100 batches of 11  epochs =0.0154298622283
Mean train loss after  13200 batches of 11  epochs =0.0155693102671
Mean train loss after  13300 batches of 11  epochs =0.0155709903994
Mean train loss after  13400 batches of 11  epochs =0.0155674116221
Mean train loss after  13500 batches of 11  epochs =0.0156496894218
Mean train loss after  13600 batches of 11  epochs =0.0156517645744
Mean train loss after  13700 batches of 11  epochs =0.0156384707142
Mean train loss after  13800 batches of 11  epochs =0.0156813617182
Mean train loss after  13900 batches of 11  epochs =0.0157603323567
Mean train loss after  14000 batches of 11  epochs =0.0157702543028
Mean train loss after  14100 batches of 11  epochs =0.0157990389711
Mean train loss after  14200 batches of 11  epochs =0.0157985881784
Mean train loss after  14300 batches of 11  epochs =0.0158929036135
Mean train loss after  14400 batches of 11  epochs =0.0158932802174
Mean train loss after  14500 batches of 11  epochs =0.0159070967161
Mean train loss after  14600 batches of 11  epochs =0.0160210773057
Mean train loss after  14700 batches of 11  epochs =0.0160619861865
Mean train loss after  14800 batches of 11  epochs =0.016100755834
Mean train loss after  14900 batches of 11  epochs =0.0161771723353
Epoch 11 : Mean train epoch loss =0.0162336692878
Epoch 11 Epoch val loss = 21314.060775
Epoch 11 Epoch val perplexity = 1.5444675420803882
SCORES =  (92.4, 100.0, 100.0, 100.0)
Saved Model
