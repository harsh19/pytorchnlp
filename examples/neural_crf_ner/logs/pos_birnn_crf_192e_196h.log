--*-*-*-*
Namespace(batch_size=1, data_dir='data/processed_data/', debug=False, emb_size=192, hidden_size=196, min_frequency=2, mode='train', model_name='pos_birnn_crf_192e_196h', model_type='birnn_crf', num_epochs=12, optimizer_type='ADAM', print_batch_freq=100, save_epoch_freq=1, saved_model_path=None, start_tag='start_tag', stop_tag='stop_tag', task='pos')
====================================================================================================
Creating Data Handler object
split_lens =  {'test': 0, 'train': 14986, 'val': 3465}
tag_dct =  {'PRP$': 0, 'VBG': 1, 'VBD': 2, 'start_tag': 3, 'VBN': 4, ',': 5, "''": 6, 'VBP': 7, 'WDT': 8, 'JJ': 9, 'WP': 10, 'VBZ': 11, 'DT': 12, '"': 13, 'RP': 14, '$': 15, 'NN': 16, ')': 17, '(': 18, 'FW': 19, 'POS': 20, '.': 21, 'TO': 22, '-X-': 23, 'LS': 24, 'RB': 25, ':': 26, 'NNS': 27, 'PRP': 28, 'VB': 29, 'WRB': 30, 'CC': 31, 'PDT': 32, 'RBS': 33, 'RBR': 34, 'CD': 35, 'EX': 36, 'IN': 37, 'WP$': 38, 'NN|SYM': 39, 'MD': 40, 'NNPS': 41, 'JJS': 42, 'JJR': 43, 'SYM': 44, 'UH': 45, 'stop_tag': 46, 'NNP': 47}
:---- create model birnn_crf
RNNEncoder:  ['embeddings', 'encoder']
RNNEncoder:  ['embeddings', 'encoder']
BiRNNModel:  ['encoder', 'revcoder']
NeuralCRF modules:  []
BiRNNCRF:  ['rnn_model', 'W', 'neural_crf']

 ------------- Epoch = 0---------------------

=================================
fscore(z) =  [30.397884] || goldscore = [-13.535538]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-1.72	0.84	0.19	-1.82	-0.26	0.66	1.41	-1.10	0.20	0.72	2.16	0.23	0.97	-0.20	1.36	-1.28	0.22	0.80	-1.44	1.99	1.25	-0.59	-1.17	-1.66	-0.40	2.19	-1.09	0.48	2.87	0.72	1.13	0.90	-0.04	0.45	-0.24	0.09	-0.48	-0.65	-0.28	-0.00	-0.30	0.00	0.73	1.40	-0.45	0.45	-100000000.00	0.24	
VBG 	-0.26	0.21	0.65	-0.46	0.24	0.82	-2.37	0.47	1.96	-1.24	-1.11	-0.05	0.79	-0.45	0.27	-0.13	0.86	1.07	-1.01	-1.99	-2.11	0.34	-0.44	-0.19	-1.56	1.22	0.44	0.32	-1.23	2.32	-1.58	0.91	0.04	0.20	0.27	-0.52	0.26	-1.59	-0.82	-1.45	0.74	-0.84	-0.89	1.90	-1.15	0.15	-100000000.00	-0.39	
VBD 	0.39	1.69	0.20	0.45	-2.25	0.46	0.64	0.08	0.37	0.99	0.01	0.22	3.06	-0.17	1.16	-0.51	-0.63	0.28	0.74	-0.09	0.16	1.53	1.17	0.79	0.85	-0.98	0.66	0.60	1.08	-0.13	-1.89	-2.00	-1.12	1.25	1.31	0.32	-0.66	-0.16	-0.88	0.37	1.93	-0.59	1.54	-1.03	1.44	0.67	-100000000.00	-0.19	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	0.21	-0.01	-1.14	-0.90	0.68	-1.18	-0.54	-0.64	0.37	-0.11	0.14	-0.78	0.61	0.60	-0.15	-0.83	-0.89	-0.15	0.62	0.82	0.04	-0.26	0.67	0.15	-0.18	-0.33	0.61	-0.01	-0.72	1.60	0.47	-0.32	-0.94	0.41	0.50	0.59	-0.91	-0.15	0.10	-0.21	-1.56	-0.40	-1.13	0.76	1.35	-1.40	-100000000.00	-0.03	
, 	0.69	-0.25	1.65	1.14	-0.14	0.95	-0.14	1.11	0.73	1.20	1.63	-0.53	-1.09	0.99	-1.12	-0.15	0.41	-0.46	0.10	-0.35	1.55	0.82	0.09	-0.69	2.05	-1.34	-0.88	-0.53	-0.43	-0.17	0.32	1.64	-0.69	1.48	-1.41	1.41	-0.09	0.42	-1.54	-0.21	0.56	1.69	2.00	-0.32	0.86	-0.96	-100000000.00	1.10	
'' 	1.61	1.43	-0.97	-0.23	-2.02	-0.56	0.25	-1.41	-0.94	-1.83	-0.22	-0.22	-1.30	-1.51	0.71	0.22	0.62	0.18	-0.99	-0.38	-0.62	0.02	-0.29	-0.03	-1.17	0.95	-0.47	-0.88	0.09	1.26	0.49	0.61	-0.37	0.54	-0.62	0.65	-0.61	-0.07	0.17	0.39	-1.98	-1.69	0.43	-1.87	-0.44	-1.27	-100000000.00	0.92	
VBP 	-0.85	1.17	-2.54	-0.88	-0.49	-0.17	-0.01	2.88	-0.95	-0.53	0.52	0.60	-0.39	0.99	-1.86	1.71	-1.83	1.70	2.38	0.13	-1.13	0.84	-0.20	-1.86	-0.76	0.86	-1.04	-0.36	-1.30	0.62	0.32	0.19	-0.20	0.26	1.22	-0.38	-0.44	-1.51	0.43	0.75	-0.04	0.29	-0.33	-0.20	-0.20	-0.11	-100000000.00	0.48	
WDT 	-1.49	-0.41	-0.96	-2.37	-1.55	-0.71	-0.67	0.13	-1.04	0.39	0.21	-1.00	0.39	0.14	0.86	-0.06	-0.96	1.03	0.66	-0.44	1.87	-0.68	0.22	0.23	1.01	0.57	0.82	1.20	-1.57	-0.06	1.07	0.50	-0.63	0.46	0.57	-0.72	-1.80	-1.09	1.17	-0.33	-1.45	-0.51	-0.46	1.10	-0.11	-0.37	-100000000.00	0.68	
JJ 	-0.06	2.54	0.66	0.51	0.42	-1.38	-1.65	-0.02	-0.02	-0.53	-1.15	0.72	-0.47	-0.79	-0.47	-0.48	0.86	-0.46	-0.49	-0.65	-0.04	0.13	-1.49	1.17	-0.19	-0.76	-0.64	-0.26	0.06	0.64	1.08	0.82	0.16	-1.07	-0.22	0.37	1.04	0.89	-0.66	-0.19	1.79	-0.42	-1.46	1.10	-0.61	0.30	-100000000.00	-1.43	
WP 	-1.00	-0.11	1.34	1.23	1.17	0.09	-2.15	-3.18	-1.24	-0.06	-1.82	-1.91	-0.61	-0.87	-0.26	-0.96	-2.33	0.56	1.54	-0.14	1.73	-0.34	-1.02	0.00	1.28	-0.51	-0.73	2.49	1.12	-1.23	-0.44	-0.12	-0.54	2.68	-0.50	-0.21	1.01	-0.61	0.55	1.29	1.55	0.01	-0.84	-0.84	-1.38	-0.49	-100000000.00	1.25	
VBZ 	1.67	-0.72	1.36	-0.34	0.52	0.17	0.04	0.31	0.04	0.55	1.36	0.98	-0.44	-0.29	0.36	-1.44	0.39	-1.55	-0.18	-0.43	0.18	-0.23	0.38	1.30	0.09	0.06	0.76	-0.49	-0.46	-0.46	0.26	-0.53	-1.80	0.09	-0.44	0.18	1.53	0.42	-0.27	0.59	0.09	-0.21	-0.05	-0.41	-0.25	-0.04	-100000000.00	0.76	
DT 	-1.02	-0.06	0.75	0.60	0.05	2.56	-0.55	0.95	0.89	0.87	-0.46	0.50	-0.46	-0.09	1.17	0.16	-0.49	-0.74	0.14	1.00	0.31	0.74	1.24	0.37	0.24	0.21	-0.89	-0.99	-0.43	1.17	-1.29	1.07	0.65	-1.31	0.97	-0.26	-0.36	0.23	0.89	0.69	-0.90	1.35	0.89	0.19	-0.16	0.81	-100000000.00	-1.83	
" 	-1.47	0.63	-0.47	0.34	1.03	0.70	-0.85	-0.30	-1.75	-1.98	1.93	0.16	-2.48	-0.25	2.61	0.27	-0.45	-0.48	-1.62	0.80	-0.53	2.11	0.81	1.59	-0.30	0.14	-0.70	0.02	-0.47	-0.71	0.38	-1.43	0.37	0.36	1.18	0.14	-0.60	-0.31	-0.56	3.57	0.38	0.50	-1.63	0.05	-0.74	-0.60	-100000000.00	0.18	
RP 	-0.87	-0.37	-0.27	0.09	-0.13	0.32	0.32	0.61	-1.49	0.13	1.36	-0.47	0.40	-0.03	0.73	0.22	0.52	-1.12	-0.08	1.52	-2.12	1.29	-1.08	0.03	-0.30	1.69	-1.58	1.06	-0.18	1.13	-0.36	0.65	-0.38	0.43	-1.90	0.56	0.86	1.00	1.08	1.11	-1.10	1.14	0.30	1.43	0.51	1.30	-100000000.00	-0.91	
$ 	0.01	0.64	1.72	-0.34	-1.09	-1.41	-1.14	-0.54	-1.19	-0.72	-1.37	0.47	0.35	-0.31	0.34	0.28	0.61	0.89	0.51	1.90	0.96	-0.06	-0.59	1.17	-0.69	0.35	0.14	0.73	0.14	-0.78	0.96	0.43	0.05	-0.97	-0.43	-2.16	1.39	-1.23	1.38	0.38	1.12	0.09	0.29	0.74	1.53	0.49	-100000000.00	-0.85	
NN 	1.06	-0.34	-0.11	0.28	-0.94	0.49	0.68	0.03	0.68	0.29	-1.78	-0.21	-1.35	-0.19	1.89	0.63	1.17	-0.76	-1.18	-0.01	0.80	0.40	-0.36	-1.77	0.68	-0.60	0.72	-1.57	0.88	0.31	0.04	0.58	-0.72	-1.74	-0.01	0.41	-0.26	0.17	-0.07	-0.47	0.56	1.20	1.46	-1.40	0.12	0.06	-100000000.00	-0.91	
) 	-1.50	0.20	-0.64	-0.48	-0.49	-1.44	-1.39	0.65	-0.29	-0.02	-0.48	-1.96	-1.20	-1.59	-0.38	-0.52	-0.23	-0.80	1.76	0.71	1.53	-0.80	-1.29	-1.73	-0.59	-0.64	-0.45	-0.45	-1.07	0.73	2.58	0.19	-0.87	0.43	0.72	-2.93	0.77	-0.13	0.88	0.20	-0.63	1.43	0.93	0.85	-0.65	-0.77	-100000000.00	-1.55	
( 	0.35	-0.48	-2.12	0.06	1.59	-0.28	0.39	-2.39	1.16	0.61	1.09	0.50	0.22	-0.27	-0.40	0.77	-0.04	-0.34	-0.69	-0.07	-0.69	0.87	0.50	1.11	-0.98	-1.14	-1.10	-0.68	0.51	-0.10	0.37	1.00	0.25	0.29	1.10	0.58	0.91	0.15	-0.86	-0.04	0.38	-0.15	0.23	0.50	0.45	-1.06	-100000000.00	-0.14	
FW 	-0.66	-1.47	0.32	-1.60	-0.64	-0.88	0.43	1.08	0.31	0.87	-0.81	-1.71	-0.33	-0.39	0.40	0.80	1.57	-0.70	1.68	1.68	1.02	0.18	2.49	1.32	0.17	0.35	-0.44	-1.31	-0.15	1.80	-0.57	1.90	-0.16	1.42	1.75	0.26	0.47	1.24	0.75	0.29	-0.69	0.53	0.17	0.36	-0.40	-0.32	-100000000.00	-1.39	
POS 	1.30	1.21	-0.11	-0.48	-0.17	-0.43	-1.55	-1.32	-0.59	0.66	-2.06	0.55	1.49	-0.16	-0.01	-0.02	-0.16	1.11	2.17	1.15	-0.70	0.89	-1.13	-0.46	-0.61	0.01	-1.01	-1.15	1.82	0.14	-0.44	-1.28	0.75	0.22	-0.92	-0.16	-0.29	-1.45	-0.56	-0.47	0.55	-0.86	1.54	-1.34	-0.21	0.21	-100000000.00	-3.25	
. 	-0.11	1.87	0.30	-0.87	1.06	-1.93	-0.15	0.94	1.28	-2.28	0.82	0.17	-2.61	0.94	-0.24	1.17	-0.94	-0.19	0.77	-0.25	0.09	0.01	1.74	1.25	0.80	1.04	1.00	0.66	-0.64	0.31	-0.98	-2.36	-0.87	1.10	0.89	-0.89	0.36	-1.09	-0.27	-0.44	0.15	-0.17	-1.25	0.50	-1.65	1.43	-100000000.00	0.11	
TO 	-0.44	-1.01	1.54	-0.48	-1.31	-0.22	1.36	0.97	-0.33	1.79	-0.74	-0.14	1.74	-1.93	0.19	-1.02	-0.10	0.62	1.07	-0.91	-0.42	-0.16	0.39	-0.49	-1.34	-1.57	-1.23	-1.37	0.35	0.52	-0.09	1.05	0.05	0.11	1.06	-1.79	-0.01	-1.57	-1.19	0.32	-1.04	-1.18	0.78	0.52	0.42	0.95	-100000000.00	-1.39	
-X- 	-0.15	0.54	-0.09	0.52	-0.74	-0.51	0.42	0.29	1.83	0.53	-0.57	-2.16	-0.21	-0.75	-0.70	0.48	0.15	0.76	-0.69	0.29	-0.69	0.94	-1.00	0.92	0.15	0.56	0.86	1.11	1.61	-0.55	0.10	0.93	1.94	0.56	-0.01	-0.08	1.77	-0.59	1.00	0.60	2.27	0.28	1.41	0.34	-0.29	-1.02	-100000000.00	0.16	
LS 	0.01	1.20	-0.38	-0.08	0.88	1.21	-0.37	0.54	-0.11	-0.63	0.14	-0.02	-0.94	-0.49	-0.45	-1.86	-1.79	0.02	0.93	-0.56	0.30	-0.09	-0.87	0.23	-0.55	0.90	-0.40	-0.21	2.71	0.58	-0.41	1.07	0.47	0.72	-0.47	0.56	-0.47	-0.59	0.96	-1.18	0.55	0.66	-0.04	-0.27	0.38	-1.79	-100000000.00	0.55	
RB 	0.07	0.14	-0.53	-0.25	-1.49	0.45	-0.76	-0.52	0.68	1.09	-2.85	0.80	1.90	-0.65	0.94	0.87	-1.91	0.07	0.06	-1.20	0.46	-0.42	-0.11	0.47	0.26	0.23	-0.22	0.53	-1.79	-0.81	0.07	-0.47	0.81	1.78	1.43	0.03	-0.06	0.59	-0.60	0.45	0.79	-0.94	-0.25	0.84	-0.40	-0.16	-100000000.00	-1.12	
: 	1.17	-0.28	-0.19	-0.14	0.30	1.62	-0.55	-0.90	1.06	-0.05	-0.10	0.85	-0.53	-0.68	0.30	0.32	1.61	0.09	1.31	-0.67	0.12	-0.96	0.24	0.59	0.28	1.23	0.09	0.64	1.48	0.44	-1.36	0.34	-1.02	0.53	-0.52	1.41	0.96	-0.71	-1.29	0.75	-0.35	-1.78	0.85	0.33	0.02	-1.27	-100000000.00	-3.09	
NNS 	-2.24	0.53	0.01	0.99	1.18	-0.09	-0.48	-0.35	0.50	-0.37	0.18	0.04	0.39	1.21	0.68	-1.21	0.17	-0.21	0.10	1.41	0.65	-0.92	-2.35	-1.03	-0.58	0.17	2.84	1.09	1.48	-0.17	-0.50	-0.98	-0.14	0.36	-0.23	-1.33	-1.27	-0.20	1.18	0.40	0.42	-1.24	-0.76	2.02	-0.25	-0.10	-100000000.00	1.79	
PRP 	-1.41	0.52	-2.14	-0.38	-0.95	1.70	0.27	0.78	-0.59	0.42	-1.07	0.30	-1.26	1.35	-2.37	-0.08	-1.02	-0.08	0.66	1.72	0.75	-0.80	-0.18	0.00	-0.09	1.64	0.04	-0.39	1.06	-0.16	-1.40	-0.61	-0.10	0.01	-0.76	-2.40	-0.03	2.07	-0.48	-2.30	0.24	-2.34	0.19	-0.98	-0.14	1.24	-100000000.00	-1.26	
VB 	1.64	-1.69	0.45	0.24	-1.34	-0.78	0.74	-1.40	1.89	-0.01	0.27	0.58	-0.46	-1.04	1.08	-1.51	0.11	0.29	-0.46	-0.20	-0.13	-0.75	0.81	-1.11	-0.55	0.36	-1.15	-0.92	-0.06	0.57	-0.60	-0.65	0.58	-0.72	0.38	1.27	-1.20	0.66	-0.27	-1.64	1.17	0.25	-0.01	0.44	-0.29	-1.61	-100000000.00	1.15	
WRB 	-0.50	0.03	-1.62	-0.93	-0.49	-1.52	-1.00	-0.34	-0.01	-1.15	0.65	-0.41	1.50	-0.68	-2.27	1.00	0.47	1.39	-0.34	0.08	0.95	-0.91	1.15	0.80	1.17	0.68	0.64	-0.82	-0.33	-1.02	-0.99	1.27	-0.42	-1.42	1.20	-0.75	-0.70	-0.15	1.20	0.99	-2.25	-1.88	-1.02	-1.22	0.83	0.02	-100000000.00	1.98	
CC 	-1.16	1.15	0.21	-0.41	1.73	-0.78	-0.75	-1.78	-0.57	1.31	-1.47	0.85	0.56	0.51	-0.11	0.35	0.10	1.43	0.13	0.16	-0.12	0.35	-0.83	-0.00	0.22	0.08	0.40	-0.47	0.83	0.38	-2.20	0.74	-1.08	0.21	-0.03	-2.19	-0.29	-0.82	-0.39	1.54	-0.89	0.21	1.10	-3.06	1.46	-0.40	-100000000.00	0.39	
PDT 	0.55	0.02	0.23	0.41	-0.23	0.91	0.51	-1.19	0.71	0.30	1.54	0.32	-0.74	-2.20	1.34	-1.27	0.18	-1.80	-0.32	-0.42	-0.98	-0.36	1.37	0.99	-0.79	-1.13	-0.15	-2.60	-0.92	-0.64	-0.44	0.39	-0.64	-1.64	-0.54	0.09	-0.85	-0.46	-0.70	1.80	-1.44	1.52	0.82	-1.28	-0.77	0.04	-100000000.00	-1.83	
RBS 	2.25	1.18	0.02	-0.15	0.29	0.42	-0.08	1.76	-1.20	-0.42	0.50	-1.35	0.88	-0.41	-0.40	-0.22	0.39	0.49	1.20	-0.47	2.47	0.32	-1.11	-0.48	-0.39	-0.55	2.83	1.03	0.48	-1.17	-0.11	-1.04	0.54	-0.72	-0.07	0.05	-0.70	-0.36	0.56	-0.42	-1.76	0.49	0.13	1.92	-1.47	-1.60	-100000000.00	-0.11	
RBR 	-0.54	-1.22	-0.76	1.52	1.16	-1.30	0.72	-0.06	0.21	0.56	-2.54	1.97	-0.23	1.10	1.16	-0.58	0.68	0.34	-0.34	0.31	0.45	-0.99	-1.62	-0.38	0.64	0.46	-1.01	-0.09	2.09	1.60	1.08	0.24	-1.63	-0.94	-0.13	0.91	-0.44	-0.56	-0.35	-1.38	0.77	-0.42	0.23	1.44	0.50	0.12	-100000000.00	-1.00	
CD 	0.58	-0.42	-0.16	-0.01	0.85	0.94	0.07	-0.30	-0.31	-0.72	-0.28	1.28	1.03	1.10	0.46	0.33	-0.94	0.21	-1.08	-0.58	0.56	-0.38	0.25	0.25	0.37	-1.27	-0.14	-0.12	-1.43	-0.31	-0.02	-1.63	-0.37	-1.41	-0.70	-2.16	-0.84	-0.72	0.32	-0.09	-0.04	0.53	-0.57	0.31	0.51	0.23	-100000000.00	0.53	
EX 	1.75	1.17	-1.96	0.47	2.51	-0.05	0.80	0.17	0.08	-0.06	-0.48	-1.67	-0.55	0.16	0.32	0.75	-0.64	0.13	0.11	-0.09	-2.58	-0.42	-0.05	-0.50	-0.35	-0.30	-0.37	-0.94	1.23	2.10	0.04	-1.01	0.60	-0.78	1.67	0.15	-0.67	-1.15	-1.57	-2.29	0.22	-0.13	0.35	0.47	1.20	0.31	-100000000.00	-1.51	
IN 	-0.77	1.57	0.41	1.39	0.53	-0.68	1.47	-0.85	0.64	-1.83	-0.09	1.57	0.68	0.49	1.16	0.40	0.73	0.96	-1.70	-2.38	1.34	-0.29	-0.45	0.28	1.70	-0.84	-0.81	-0.60	-0.24	-1.30	1.33	0.42	0.53	-1.39	-0.50	0.08	-0.85	0.33	0.92	-1.74	0.30	-0.64	1.72	1.15	1.36	-0.09	-100000000.00	1.45	
WP$ 	-0.88	-0.77	-0.53	-0.49	-0.46	0.51	0.92	0.62	-0.04	-0.67	1.29	-0.08	0.08	0.12	1.42	-0.12	0.91	-0.26	0.27	0.27	-1.34	0.61	2.09	1.43	-0.67	0.95	0.09	-0.39	-1.90	-0.88	0.58	0.83	0.48	-2.06	-0.41	0.76	0.67	2.76	-1.75	0.56	-0.33	-1.15	-0.74	1.09	-0.57	-2.24	-100000000.00	0.69	
NN|SYM 	-0.33	0.98	-0.50	-0.21	-0.40	0.03	1.95	-0.03	-0.26	0.53	0.37	0.06	1.27	-2.72	-1.51	-0.02	-0.49	0.77	-0.21	-0.32	0.66	-2.15	-0.99	-0.74	1.20	-1.43	0.32	0.32	-1.33	2.09	0.09	1.18	2.18	-0.61	1.87	-0.02	-0.79	1.68	0.71	-0.14	0.20	0.93	0.58	1.71	1.18	-1.63	-100000000.00	-0.57	
MD 	-1.11	0.61	-0.29	-2.19	1.31	-0.07	2.42	1.12	-0.63	-0.84	-1.23	-0.69	-0.26	1.55	0.34	-1.19	0.01	0.98	-0.76	1.03	-0.12	-2.39	-0.53	0.93	1.25	-0.19	-0.37	0.10	0.36	-1.46	-1.47	-1.20	0.67	-1.15	1.14	-0.59	0.59	0.43	-0.06	-0.65	-3.12	-1.65	0.38	-1.21	0.34	0.08	-100000000.00	-0.42	
NNPS 	0.50	0.34	-0.21	-0.30	-1.66	-0.21	1.05	1.25	0.88	0.51	-0.88	-1.07	0.60	-0.19	-0.35	1.87	-0.10	-0.91	1.02	-1.72	-0.24	1.63	-0.94	-0.59	1.05	-0.02	0.85	2.05	-1.30	-0.57	0.35	0.02	0.68	1.25	1.54	1.60	-2.29	-0.65	-1.57	0.72	0.50	-0.32	-1.59	-0.22	0.87	0.21	-100000000.00	0.44	
JJS 	0.98	-1.32	0.00	-3.01	-1.11	1.35	-1.67	-1.60	-0.86	-2.07	-0.57	-0.67	-1.29	0.67	0.30	-1.24	0.60	-0.50	2.23	-0.69	-1.65	0.14	1.63	0.80	-0.24	-0.12	-0.25	0.36	-0.33	-1.54	0.50	0.77	0.82	-0.18	-0.32	0.70	-0.67	-0.10	-1.07	0.45	2.32	0.84	-1.29	2.85	-1.33	-1.43	-100000000.00	2.02	
JJR 	0.48	-0.34	-0.09	0.23	-0.20	-1.52	-0.22	-1.57	1.65	-0.08	0.22	-0.30	-2.25	-2.07	0.05	0.94	2.12	-0.14	0.70	0.78	1.59	-0.61	-0.78	-0.21	-0.31	0.22	-0.11	0.55	0.45	1.03	0.31	-1.37	1.03	0.33	0.46	-0.46	1.41	0.52	-1.11	-0.40	1.63	2.00	0.59	0.20	0.92	1.29	-100000000.00	-0.16	
SYM 	-1.04	-1.15	-0.09	-1.42	-0.33	-0.86	0.85	1.95	-1.80	1.01	0.23	-1.23	-1.22	0.29	-1.99	-0.23	-0.36	0.44	0.02	-1.57	0.41	0.28	1.29	-1.34	-1.94	-1.11	-0.35	1.59	-1.16	0.73	1.13	0.40	1.15	0.50	0.64	0.17	-0.04	-0.36	0.51	0.73	0.45	-1.43	-0.48	-1.20	0.62	-0.78	-100000000.00	-0.13	
UH 	0.26	1.41	0.74	-0.49	0.92	1.48	0.07	-0.08	1.68	0.69	0.71	0.95	0.30	0.49	0.31	1.92	-0.57	-1.43	0.03	1.02	-1.17	1.55	-1.30	-0.07	-0.37	1.13	-1.00	0.09	-0.06	-1.45	-0.50	-0.78	-0.64	-0.66	-1.16	-1.76	-0.93	-0.36	0.14	0.84	-2.47	0.02	0.18	0.90	0.48	-0.12	-100000000.00	0.09	
stop_tag 	-0.53	0.51	-0.39	-0.52	1.42	-1.31	2.80	1.69	-0.43	0.92	0.55	-0.31	-0.73	-0.78	-0.02	-0.42	1.98	-1.37	-0.76	1.13	-0.26	-0.90	-0.04	1.25	-0.09	0.75	1.16	1.29	1.05	-1.14	0.15	0.67	-0.52	0.94	-1.55	-1.77	-0.42	-0.10	0.62	-0.21	0.12	0.63	-1.08	-0.97	-0.59	1.28	-100000000.00	-1.02	
NNP 	-1.03	0.06	-1.16	1.19	1.46	0.63	1.14	1.10	-1.38	-0.26	-0.06	-0.68	1.10	0.96	-0.41	0.62	1.52	-0.63	-0.71	-0.14	-1.69	0.52	0.71	0.88	0.55	-1.87	0.47	-1.17	-1.12	1.78	-1.28	-1.29	-0.45	0.13	0.73	-0.02	0.44	-0.87	-0.21	-0.55	-0.73	-0.67	2.31	0.68	0.84	-1.26	-100000000.00	1.51	
Mean train loss after  0 batches of 0  epochs =6.27620315552
Mean train loss after  100 batches of 0  epochs =3.14508075445
Mean train loss after  200 batches of 0  epochs =2.55012973192
Mean train loss after  300 batches of 0  epochs =2.20689495822
Mean train loss after  400 batches of 0  epochs =1.99583842863
Mean train loss after  500 batches of 0  epochs =1.86896483593
Mean train loss after  600 batches of 0  epochs =1.75660795798
Mean train loss after  700 batches of 0  epochs =1.65392376544
Mean train loss after  800 batches of 0  epochs =1.58134489754
Mean train loss after  900 batches of 0  epochs =1.50141931732
Mean train loss after  1000 batches of 0  epochs =1.44423189788
Mean train loss after  1100 batches of 0  epochs =1.38769996586
Mean train loss after  1200 batches of 0  epochs =1.34072949539
Mean train loss after  1300 batches of 0  epochs =1.30880401142
Mean train loss after  1400 batches of 0  epochs =1.27586774808
Mean train loss after  1500 batches of 0  epochs =1.25107739415
Mean train loss after  1600 batches of 0  epochs =1.22807184424
Mean train loss after  1700 batches of 0  epochs =1.20795649839
Mean train loss after  1800 batches of 0  epochs =1.18318406663
Mean train loss after  1900 batches of 0  epochs =1.16047168579
Mean train loss after  2000 batches of 0  epochs =1.13580654484
Mean train loss after  2100 batches of 0  epochs =1.11463588905
Mean train loss after  2200 batches of 0  epochs =1.09562428001
Mean train loss after  2300 batches of 0  epochs =1.07430464899
Mean train loss after  2400 batches of 0  epochs =1.05291205609
Mean train loss after  2500 batches of 0  epochs =1.03794969607
Mean train loss after  2600 batches of 0  epochs =1.02308314007
Mean train loss after  2700 batches of 0  epochs =1.00913784408
Mean train loss after  2800 batches of 0  epochs =0.994419294354
Mean train loss after  2900 batches of 0  epochs =0.979748972401
Mean train loss after  3000 batches of 0  epochs =0.967466827372
Mean train loss after  3100 batches of 0  epochs =0.956245766273
Mean train loss after  3200 batches of 0  epochs =0.944091000264
Mean train loss after  3300 batches of 0  epochs =0.931978644394
Mean train loss after  3400 batches of 0  epochs =0.919286906025
Mean train loss after  3500 batches of 0  epochs =0.908630050598
Mean train loss after  3600 batches of 0  epochs =0.898402816387
Mean train loss after  3700 batches of 0  epochs =0.88957277613
Mean train loss after  3800 batches of 0  epochs =0.88004521072
Mean train loss after  3900 batches of 0  epochs =0.871367531305
Mean train loss after  4000 batches of 0  epochs =0.860973062666
Mean train loss after  4100 batches of 0  epochs =0.849780571089
Mean train loss after  4200 batches of 0  epochs =0.84037833499
Mean train loss after  4300 batches of 0  epochs =0.83189351458
Mean train loss after  4400 batches of 0  epochs =0.822416827143
Mean train loss after  4500 batches of 0  epochs =0.81561432168
Mean train loss after  4600 batches of 0  epochs =0.808109746565
Mean train loss after  4700 batches of 0  epochs =0.800197672533
Mean train loss after  4800 batches of 0  epochs =0.794104821731
Mean train loss after  4900 batches of 0  epochs =0.788071219394
Mean train loss after  5000 batches of 0  epochs =0.78051320466
Mean train loss after  5100 batches of 0  epochs =0.773551636829
Mean train loss after  5200 batches of 0  epochs =0.766960991906
Mean train loss after  5300 batches of 0  epochs =0.762124075199
Mean train loss after  5400 batches of 0  epochs =0.75702709933
Mean train loss after  5500 batches of 0  epochs =0.75100928579
Mean train loss after  5600 batches of 0  epochs =0.7450379991
Mean train loss after  5700 batches of 0  epochs =0.742077928875
Mean train loss after  5800 batches of 0  epochs =0.736439820078
Mean train loss after  5900 batches of 0  epochs =0.73182586358
Mean train loss after  6000 batches of 0  epochs =0.726404930886
Mean train loss after  6100 batches of 0  epochs =0.722170617339
Mean train loss after  6200 batches of 0  epochs =0.716396328372
Mean train loss after  6300 batches of 0  epochs =0.711879045464
Mean train loss after  6400 batches of 0  epochs =0.706189119272
Mean train loss after  6500 batches of 0  epochs =0.702166481001
Mean train loss after  6600 batches of 0  epochs =0.698223405281
Mean train loss after  6700 batches of 0  epochs =0.69283015859
Mean train loss after  6800 batches of 0  epochs =0.689685127515
Mean train loss after  6900 batches of 0  epochs =0.685273081041
Mean train loss after  7000 batches of 0  epochs =0.68168520929
Mean train loss after  7100 batches of 0  epochs =0.677330936748
Mean train loss after  7200 batches of 0  epochs =0.672944552452
Mean train loss after  7300 batches of 0  epochs =0.66997117107
Mean train loss after  7400 batches of 0  epochs =0.666050876124
Mean train loss after  7500 batches of 0  epochs =0.661901466899
Mean train loss after  7600 batches of 0  epochs =0.657958476665
Mean train loss after  7700 batches of 0  epochs =0.654466548874
Mean train loss after  7800 batches of 0  epochs =0.650551556801
Mean train loss after  7900 batches of 0  epochs =0.647529780323
Mean train loss after  8000 batches of 0  epochs =0.644776238804
Mean train loss after  8100 batches of 0  epochs =0.640885062453
Mean train loss after  8200 batches of 0  epochs =0.637475983932
Mean train loss after  8300 batches of 0  epochs =0.634372542835
Mean train loss after  8400 batches of 0  epochs =0.631736429707
Mean train loss after  8500 batches of 0  epochs =0.628021382597
Mean train loss after  8600 batches of 0  epochs =0.624680690561
Mean train loss after  8700 batches of 0  epochs =0.621868365459
Mean train loss after  8800 batches of 0  epochs =0.619289546771
Mean train loss after  8900 batches of 0  epochs =0.615789498018
Mean train loss after  9000 batches of 0  epochs =0.612991152122
Mean train loss after  9100 batches of 0  epochs =0.610279683954
Mean train loss after  9200 batches of 0  epochs =0.60726553089
Mean train loss after  9300 batches of 0  epochs =0.603881416999
Mean train loss after  9400 batches of 0  epochs =0.600841668577
Mean train loss after  9500 batches of 0  epochs =0.59785372158
Mean train loss after  9600 batches of 0  epochs =0.595485972158
Mean train loss after  9700 batches of 0  epochs =0.592693227518
Mean train loss after  9800 batches of 0  epochs =0.590539055393
Mean train loss after  9900 batches of 0  epochs =0.587530810589
Mean train loss after  10000 batches of 0  epochs =0.585209712435
Mean train loss after  10100 batches of 0  epochs =0.58230492505
Mean train loss after  10200 batches of 0  epochs =0.57941141355
Mean train loss after  10300 batches of 0  epochs =0.576514320307
Mean train loss after  10400 batches of 0  epochs =0.574548390587
Mean train loss after  10500 batches of 0  epochs =0.572488136307
Mean train loss after  10600 batches of 0  epochs =0.570267395227
Mean train loss after  10700 batches of 0  epochs =0.568408528109
Mean train loss after  10800 batches of 0  epochs =0.565889074306
Mean train loss after  10900 batches of 0  epochs =0.563276068635
Mean train loss after  11000 batches of 0  epochs =0.561313183566
Mean train loss after  11100 batches of 0  epochs =0.559407433891
Mean train loss after  11200 batches of 0  epochs =0.556666648259
Mean train loss after  11300 batches of 0  epochs =0.555019653435
Mean train loss after  11400 batches of 0  epochs =0.553440407405
Mean train loss after  11500 batches of 0  epochs =0.550953918071
Mean train loss after  11600 batches of 0  epochs =0.549440875727
Mean train loss after  11700 batches of 0  epochs =0.547631191613
Mean train loss after  11800 batches of 0  epochs =0.545520049581
Mean train loss after  11900 batches of 0  epochs =0.543404296409
Mean train loss after  12000 batches of 0  epochs =0.541061786622
Mean train loss after  12100 batches of 0  epochs =0.539252889769
Mean train loss after  12200 batches of 0  epochs =0.537022011452
Mean train loss after  12300 batches of 0  epochs =0.535077075579
Mean train loss after  12400 batches of 0  epochs =0.532978644274
Mean train loss after  12500 batches of 0  epochs =0.531532647523
Mean train loss after  12600 batches of 0  epochs =0.529763923917
Mean train loss after  12700 batches of 0  epochs =0.528293545994
Mean train loss after  12800 batches of 0  epochs =0.52655369653
Mean train loss after  12900 batches of 0  epochs =0.525269631304
Mean train loss after  13000 batches of 0  epochs =0.523492006722
Mean train loss after  13100 batches of 0  epochs =0.521953833829
Mean train loss after  13200 batches of 0  epochs =0.520708641342
Mean train loss after  13300 batches of 0  epochs =0.518851864731
Mean train loss after  13400 batches of 0  epochs =0.517879883678
Mean train loss after  13500 batches of 0  epochs =0.516295384843
Mean train loss after  13600 batches of 0  epochs =0.51488544798
Mean train loss after  13700 batches of 0  epochs =0.513729778588
Mean train loss after  13800 batches of 0  epochs =0.512363326877
Mean train loss after  13900 batches of 0  epochs =0.510615753861
Mean train loss after  14000 batches of 0  epochs =0.509190125844
Mean train loss after  14100 batches of 0  epochs =0.507254923945
Mean train loss after  14200 batches of 0  epochs =0.506046912834
Mean train loss after  14300 batches of 0  epochs =0.504293151692
Mean train loss after  14400 batches of 0  epochs =0.502729526279
Mean train loss after  14500 batches of 0  epochs =0.501483697931
Mean train loss after  14600 batches of 0  epochs =0.499852974401
Mean train loss after  14700 batches of 0  epochs =0.498378537491
Mean train loss after  14800 batches of 0  epochs =0.497354690738
Mean train loss after  14900 batches of 0  epochs =0.495745606158
Epoch 0 : Mean train epoch loss =0.494352580374
Epoch 0 Epoch val loss = 14542.0704131
Epoch 0 Epoch val perplexity = 1.345238287963611
SCORES =  (91.0, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 1---------------------

=================================
fscore(z) =  [4.137534] || goldscore = [3.5361018]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-2.49	1.07	0.17	-1.56	0.05	-0.18	0.69	-0.95	-0.07	-0.20	1.26	0.27	0.54	-0.34	1.32	-2.29	-0.41	-0.02	-2.30	0.96	0.35	-1.22	-1.27	-1.94	-1.09	1.16	-2.11	-0.57	1.67	0.89	0.17	0.46	-0.28	-0.10	-0.54	-1.15	-1.28	-0.14	-0.69	-0.44	-1.37	-1.23	-0.08	0.27	-1.36	-0.32	-100000000.00	-0.82	
VBG 	-0.95	-0.49	0.32	-0.03	0.27	1.00	-3.00	0.53	0.84	-1.66	-1.94	-0.01	0.39	-0.57	-0.29	-1.03	0.42	0.41	-2.47	-3.62	-2.34	-0.32	-0.60	-0.56	-2.77	0.30	-0.21	0.30	-2.39	1.53	-2.15	0.55	-1.02	-0.32	-0.67	-1.07	-0.82	-0.79	-1.17	-2.24	-0.51	-1.08	-1.09	0.71	-2.02	-1.41	-100000000.00	-0.71	
VBD 	-0.85	-0.34	-1.88	-0.93	-2.30	0.37	-0.47	-0.67	0.70	-0.97	0.33	-0.78	1.56	-0.35	-0.43	-1.43	0.27	0.10	-0.28	-0.70	-0.71	0.37	-0.61	-0.11	-1.00	-0.28	-0.51	0.75	1.23	-0.97	-2.55	-1.41	-2.89	0.68	-0.13	-0.89	-0.41	-1.70	-1.54	-1.03	0.41	-0.43	1.02	-1.27	-0.03	-0.52	-100000000.00	0.59	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-1.09	-0.03	-0.73	-0.91	-0.42	-1.01	-1.67	-0.18	-0.26	-1.27	-0.66	-0.33	0.47	-0.08	-0.26	-1.87	-0.46	-1.08	0.07	-0.48	-0.64	-1.24	-0.43	-0.43	-1.34	0.26	0.03	0.11	-1.24	1.05	-0.39	-0.80	-2.54	-0.02	-0.01	-0.95	-2.16	-0.75	-0.35	-1.04	-2.85	-0.96	-1.85	-0.28	0.80	-3.48	-100000000.00	-1.38	
, 	-0.30	-0.41	1.14	-0.10	-0.09	0.21	-0.81	0.53	0.48	0.80	0.46	-0.92	-1.23	0.45	-1.04	-1.55	0.50	-0.32	-0.51	-0.74	0.98	-0.07	-1.11	-1.11	0.87	-1.05	-2.00	-0.30	-0.47	-0.28	-1.27	1.05	-2.26	1.13	-1.38	1.26	-0.80	-0.08	-2.45	-1.15	-0.15	1.19	1.14	-0.35	-0.65	-0.94	-100000000.00	1.09	
'' 	0.84	0.81	-1.46	-0.67	-2.53	-0.43	-0.02	-1.96	-1.51	-2.80	-0.81	-0.82	-2.86	-2.24	0.39	-0.10	0.23	-0.46	-1.46	-0.76	-1.21	0.03	-1.05	-0.14	-1.52	0.47	-0.62	-1.46	-0.91	0.69	0.11	-0.15	-0.69	0.26	-1.03	-0.68	-0.88	-0.37	0.00	0.21	-2.51	-2.16	0.03	-2.32	-1.01	-1.58	-100000000.00	-0.15	
VBP 	-2.43	-0.03	-4.66	-2.46	-1.45	-0.58	-0.47	1.14	-0.62	-1.93	0.54	-0.74	-0.67	-0.00	-2.41	0.86	-1.62	0.99	1.07	-1.61	-2.85	0.11	-1.17	-2.28	-1.91	0.14	-1.62	0.55	-0.62	-1.05	-0.88	-0.64	-1.33	-0.44	0.18	-0.93	-0.34	-3.25	0.02	0.11	-1.09	0.44	-1.27	-1.59	-0.56	-1.42	-100000000.00	-0.17	
WDT 	-2.52	-1.42	-1.94	-2.77	-2.39	-0.65	-1.28	-0.75	-1.73	-0.81	-0.57	-2.04	-0.71	-0.52	0.30	-0.79	-0.25	0.53	-0.47	-1.36	0.60	-1.02	-0.21	0.09	0.53	-0.52	0.29	0.93	-2.62	-0.61	0.38	0.07	-0.93	-0.07	-0.16	-1.37	-2.42	-1.32	0.91	-0.61	-2.39	-1.45	-1.07	0.15	-1.00	-1.00	-100000000.00	0.17	
JJ 	0.13	1.17	0.36	0.55	0.35	-1.03	-2.25	0.24	-0.46	0.02	-2.00	0.61	-0.25	-0.77	-0.70	-0.71	-0.43	-0.64	-0.70	-1.53	0.11	-1.01	-1.37	0.51	-1.93	-0.08	-0.39	-0.86	-0.58	0.53	0.54	0.49	-1.02	-0.75	0.16	-0.06	-0.73	0.53	-1.14	-1.39	0.45	-1.38	-1.43	0.40	-0.96	-0.97	-100000000.00	-0.84	
WP 	-1.86	-0.90	0.43	0.44	0.47	-0.07	-2.18	-3.48	-2.01	-0.60	-2.43	-1.97	-0.70	-0.85	-0.80	-1.56	-1.75	-0.06	0.72	-0.82	0.92	-0.71	-1.35	-0.15	0.81	-1.11	-1.20	1.85	0.44	-1.19	-1.29	-1.02	-1.05	2.24	-1.02	-1.22	0.63	-0.58	0.26	1.02	0.94	-0.12	-1.50	-1.07	-2.11	-1.09	-100000000.00	0.58	
VBZ 	0.10	-1.54	-1.03	-2.32	-0.69	0.17	-0.80	0.07	0.48	-0.53	1.33	-0.12	-0.30	-0.68	-1.06	-2.42	0.92	-1.59	-0.54	-1.23	-0.80	-0.98	-0.97	0.82	-1.37	0.23	0.03	-0.84	0.10	-1.31	-0.63	-0.65	-3.20	-0.63	-1.59	-0.38	1.62	-1.19	-0.67	-0.14	-1.07	-1.43	-0.74	-1.53	-1.29	-1.62	-100000000.00	0.70	
DT 	-2.00	0.31	0.70	0.46	0.06	1.94	-0.88	0.78	0.05	-0.21	-1.05	0.62	-0.99	-0.02	1.17	-1.22	-0.64	-0.91	-0.01	0.08	-0.24	-0.02	0.92	-0.17	-0.78	-0.05	-0.83	-1.20	-0.59	1.14	-1.12	0.94	0.81	-2.36	0.83	-1.04	-1.83	0.61	0.21	-0.20	-1.29	-0.30	-0.12	-1.59	-0.28	-0.81	-100000000.00	-1.72	
" 	-1.73	0.42	-1.00	-0.31	0.49	0.57	-0.78	-0.95	-2.18	-1.92	1.30	-0.14	-2.52	-0.96	2.06	-0.38	-0.39	-0.92	-1.84	-0.11	-0.86	2.20	0.21	1.40	-0.76	-0.41	-0.72	-0.51	-1.19	-0.79	-0.13	-1.73	-0.26	-0.09	0.44	-0.70	-1.23	-0.83	-0.91	3.21	-0.17	0.05	-2.28	-0.60	-1.42	-1.32	-100000000.00	-0.14	
RP 	-2.04	0.10	0.29	-1.49	0.19	-0.66	-0.29	0.55	-2.57	-0.65	0.28	-0.68	0.08	-1.03	0.38	-0.74	-0.17	-1.47	-1.11	0.39	-3.14	0.83	-2.72	-0.17	-0.92	0.71	-2.83	-0.40	-0.57	1.03	-1.29	-0.91	-1.15	-0.09	-2.84	-0.66	0.32	-0.37	0.74	0.66	-2.32	0.17	-0.57	0.66	-0.37	0.44	-100000000.00	-2.06	
$ 	-0.63	0.22	0.91	-2.52	-1.23	-1.99	-1.56	-1.33	-1.80	-1.03	-2.01	-0.02	-0.13	-1.06	0.04	-0.15	0.22	0.26	0.34	1.27	0.44	-0.41	-0.62	1.03	-1.07	0.21	-0.39	-0.24	-0.41	-1.30	0.39	-0.46	-0.44	-1.32	-1.04	-2.39	0.87	-1.13	1.13	0.11	0.26	-0.58	-0.20	0.20	0.64	0.04	-100000000.00	-1.52	
NN 	0.84	0.27	-0.72	0.43	-0.37	0.20	-0.32	-0.29	-0.30	0.94	-2.16	-0.26	-0.79	-0.43	0.84	-0.66	0.49	-0.79	-1.12	-0.50	0.67	-0.79	-0.52	-2.70	-1.39	-1.58	0.35	-1.33	-0.52	0.35	-0.53	0.10	-2.04	-2.39	-0.70	-0.31	-2.25	-0.00	-0.41	-2.12	-0.61	-0.31	1.40	-0.71	0.20	-2.95	-100000000.00	-0.22	
) 	-2.45	-0.38	-1.50	-2.28	-0.73	-2.70	-2.17	-0.58	-1.57	-0.15	-1.38	-2.07	-1.62	-1.82	-0.36	-1.91	-0.24	-1.57	1.24	-0.20	0.91	-1.65	-2.46	-1.90	-0.57	-1.42	-1.36	-0.60	-2.09	0.28	1.75	-1.12	-2.11	-0.14	-0.10	-2.78	-0.12	-0.74	0.29	-0.47	-1.68	0.95	-0.32	-0.57	-1.52	-2.05	-100000000.00	-1.44	
( 	-0.04	-0.74	-2.41	-0.23	0.69	-1.09	-0.39	-3.59	0.01	0.10	0.68	-0.09	-0.24	-0.73	-1.49	-0.06	0.09	-1.08	-1.12	-0.29	-1.20	0.25	-0.42	0.90	-1.91	-1.63	-1.41	-0.62	0.32	-0.62	-0.06	-0.27	-0.67	-0.25	0.00	0.37	0.09	-0.75	-1.45	-0.63	-0.66	-0.22	-0.20	-0.17	-0.90	-2.30	-100000000.00	-0.02	
FW 	-1.89	-3.02	-1.28	-1.55	-2.27	-1.04	-0.11	0.06	-0.69	-0.58	-1.65	-3.02	-1.68	-1.55	-0.41	0.24	0.60	-0.90	1.11	1.67	-0.46	-0.21	0.77	1.12	-0.33	-1.46	-1.16	-2.35	-1.35	0.18	-1.29	0.40	-0.85	0.91	0.80	-0.70	-0.18	-1.13	0.48	-0.05	-1.72	-0.14	-0.47	-0.89	-1.16	-1.05	-100000000.00	-0.99	
POS 	0.22	0.02	-1.01	-1.61	-1.00	-0.86	-1.42	-2.27	-0.94	-0.45	-2.76	-0.71	0.68	-0.92	-0.78	-0.70	-0.37	0.12	1.13	0.25	-1.20	0.67	-2.48	-0.60	-1.10	-0.93	-1.51	-0.94	1.03	-0.55	-1.51	-2.63	-0.08	-0.27	-1.66	-1.08	-0.72	-1.99	-0.93	-0.87	-0.52	-1.34	0.74	-2.38	-1.22	-0.82	-100000000.00	-2.16	
. 	-1.55	1.28	0.13	-2.42	0.77	-2.93	-1.30	0.22	0.51	-2.05	-0.42	-0.04	-2.57	0.57	-0.17	-0.53	-0.61	-0.34	-0.32	-2.14	-0.51	-0.98	0.57	0.87	0.94	0.73	-0.19	0.61	-0.84	0.10	-2.24	-3.47	-2.01	-0.05	0.61	-0.90	-0.24	-1.51	-1.33	-1.27	-1.16	-0.24	-2.06	0.09	-3.45	0.05	-100000000.00	0.02	
TO 	-0.94	-0.82	1.15	-0.50	-1.01	-1.41	-0.02	0.77	-2.10	1.14	-2.01	-0.11	0.89	-2.03	0.03	-2.52	-0.14	-0.32	0.02	-1.84	-1.91	-1.14	-0.93	-0.89	-2.69	-1.57	-1.88	-1.33	0.04	0.38	-1.06	-0.35	-1.58	-0.59	0.75	-1.82	-0.69	-1.51	-1.75	-0.58	-2.12	-1.32	0.03	-0.06	-0.74	-0.73	-100000000.00	-1.29	
-X- 	-0.33	0.14	-0.68	0.23	-1.23	-1.07	0.33	0.00	1.68	-0.33	-0.72	-2.63	-0.90	-1.17	-0.84	0.36	-0.61	0.38	-0.83	0.12	-1.07	0.81	-1.28	0.86	0.04	-0.11	0.47	0.45	1.19	-1.02	-0.09	0.40	1.83	0.51	-0.19	-0.92	1.66	-1.18	0.93	0.54	2.10	-0.07	1.32	0.19	-0.57	-1.12	-100000000.00	-0.68	
LS 	-0.82	0.12	-2.01	-1.17	-0.31	-0.07	-0.76	-0.44	-0.60	-2.27	-0.29	-1.05	-2.88	-1.23	-0.96	-2.37	-3.33	-0.94	0.17	-1.03	-0.54	-0.27	-1.98	0.13	-0.84	-0.64	-0.14	-1.39	1.84	-0.39	-0.87	-0.24	-0.01	0.40	-1.06	-1.68	-0.85	-2.47	0.74	-1.42	-0.05	-0.37	-0.44	-1.05	-0.34	-2.30	-100000000.00	-1.14	
RB 	-0.46	0.13	-0.22	-0.11	-0.91	0.28	-1.48	-0.29	-0.05	-0.95	-2.71	0.71	1.08	-0.63	0.47	-0.28	-0.80	-0.03	-0.89	-3.28	-0.26	-1.48	-0.68	-0.11	-0.85	-0.40	-1.34	0.04	-1.51	-0.31	-0.30	-0.54	-0.96	1.15	0.83	-0.62	-0.70	-0.21	-1.14	-0.57	0.90	-1.73	-0.69	-0.40	-0.85	-1.80	-100000000.00	-1.00	
: 	0.13	-0.21	-0.63	-1.07	-0.19	0.78	-1.49	-1.15	0.41	-0.51	-1.07	0.35	-1.29	-0.86	-0.44	-0.62	1.26	-0.18	0.45	-2.37	-0.45	-1.62	-0.99	0.26	-0.40	0.31	-1.01	0.52	0.23	0.19	-2.34	-1.13	-2.15	-0.05	-1.17	0.94	-0.02	-1.40	-1.77	0.10	-1.61	-1.91	0.06	-0.00	-1.08	-2.69	-100000000.00	-2.53	
NNS 	-1.51	0.58	-0.32	0.85	0.50	-0.20	-1.37	-0.33	0.10	0.88	-0.70	-0.39	0.37	0.63	0.38	-2.35	0.83	-0.60	-0.31	0.44	0.56	-2.04	-2.39	-1.78	-2.48	-1.62	1.87	-1.10	-0.02	-0.01	-0.88	-0.92	-1.21	-0.32	-1.09	-0.21	-3.01	-0.30	1.10	-0.77	-0.45	-1.68	-0.41	1.52	-0.28	-2.51	-100000000.00	-0.29	
PRP 	-2.49	0.43	-1.38	-0.28	-0.81	0.87	0.04	0.53	-0.99	-0.83	-0.96	0.22	-1.86	1.15	-3.28	-0.99	-0.95	-1.03	-0.49	0.36	0.35	-1.39	-0.34	-0.36	-0.77	0.74	-0.11	-0.99	0.13	0.21	-1.09	-0.72	-1.19	-0.71	-1.68	-3.01	-0.68	1.50	-1.06	-2.85	-0.49	-3.74	-0.46	-2.15	-0.54	0.28	-100000000.00	-1.81	
VB 	-0.02	-1.91	-0.96	-0.04	-2.25	-0.82	0.24	-1.92	0.89	-1.14	-0.26	-0.39	-1.07	-1.31	0.18	-2.14	-0.24	0.23	-1.35	-0.86	-1.34	-1.39	1.05	-1.41	-1.42	0.74	-0.71	-1.41	-0.38	-0.62	-1.67	-0.33	-0.37	-1.30	-0.11	-0.54	-1.86	-0.94	-0.61	-2.24	1.98	-1.00	-0.54	-0.11	-1.37	-2.56	-100000000.00	-0.51	
WRB 	-1.05	-0.55	-1.82	-1.03	-0.53	-1.40	-1.42	-0.99	-0.47	-1.35	0.08	-0.30	0.45	-1.03	-2.69	0.42	0.48	0.74	-1.27	-0.64	0.41	-1.25	0.11	0.62	0.69	0.08	-0.30	-0.69	-0.65	-0.97	-1.54	0.38	-0.96	-1.90	0.56	-1.05	-1.21	-0.64	0.97	0.72	-2.94	-2.76	-1.47	-1.90	0.09	-0.52	-100000000.00	1.17	
CC 	-1.80	0.34	-0.27	-0.55	1.32	-0.60	-1.93	-2.18	-1.44	0.71	-2.35	0.32	-0.42	0.05	-0.43	-0.61	0.29	1.00	-0.80	-1.24	-1.22	-0.49	-1.78	-0.30	-0.92	0.05	0.24	-0.26	0.43	-0.02	-3.51	-0.31	-2.56	-0.49	-0.84	-2.03	-0.56	-0.93	-0.90	0.78	-1.68	0.19	0.51	-2.99	0.87	-1.74	-100000000.00	0.33	
PDT 	-0.11	-0.64	-0.44	-1.02	-0.50	-0.36	0.24	-1.61	0.17	-1.02	1.04	-0.43	-2.86	-3.01	1.08	-1.77	-1.11	-2.60	-0.67	-0.91	-1.87	-0.51	0.23	0.91	-1.01	-1.22	-0.68	-3.29	-1.74	-0.92	-0.59	-0.53	-0.97	-1.96	-1.00	-0.90	-1.17	-0.57	-0.86	1.67	-1.78	1.06	0.43	-1.75	-1.46	-0.20	-100000000.00	-1.97	
RBS 	2.19	0.44	-0.34	-1.48	-0.42	-0.44	-0.30	1.14	-1.40	-1.89	0.20	-1.54	0.92	-1.03	-0.69	-0.47	-0.64	-0.11	0.60	-0.89	2.14	0.15	-1.70	-0.53	-0.62	-1.24	2.04	-0.20	-0.29	-1.50	-0.43	-1.46	0.25	-0.99	-0.45	-1.29	-0.93	-0.83	0.43	-0.52	-2.15	-0.09	-0.10	1.46	-1.87	-1.90	-100000000.00	-1.63	
RBR 	-1.68	-1.45	-0.59	0.84	0.60	-1.90	0.26	-0.36	-0.64	-0.41	-3.12	1.40	-0.37	0.64	1.01	-1.19	0.62	-0.55	-1.58	-0.24	-0.70	-1.24	-2.08	-0.49	0.35	0.43	-1.62	0.04	1.24	1.13	0.41	-0.28	-2.05	-1.35	-0.75	-0.12	-0.90	-0.74	-0.59	-1.56	-0.04	-1.30	-0.21	0.70	-0.23	-0.25	-100000000.00	-1.47	
CD 	-0.22	-0.19	-0.08	-0.06	-0.06	0.48	-0.57	-0.70	-1.24	-1.00	-1.49	0.39	0.82	0.48	-0.40	0.96	-0.56	0.23	-1.02	-1.00	0.17	-2.04	0.28	-0.98	-2.02	-0.88	-0.15	-0.92	-1.87	-0.13	-0.64	-1.53	-2.12	-2.40	-2.63	-1.29	-3.33	-0.51	-0.30	-0.56	-1.89	0.02	-0.56	-0.23	-0.09	-0.28	-100000000.00	-0.03	
EX 	1.18	0.76	-1.86	-0.30	1.87	-0.49	0.49	0.04	-0.24	-1.00	-1.01	-2.20	-1.31	0.10	0.01	0.29	-0.78	-0.68	-0.76	-0.49	-3.44	-0.64	-0.98	-0.63	-0.58	-0.99	-1.51	-1.54	0.38	1.51	-0.14	-0.97	0.28	-1.06	1.34	-0.70	-0.93	-1.11	-1.78	-2.42	-0.16	-0.63	0.08	0.13	0.58	-0.01	-100000000.00	-1.93	
IN 	-1.74	0.98	0.25	0.98	0.62	-0.53	0.05	-0.63	-0.22	-1.26	-1.56	1.06	0.04	0.52	1.08	-0.50	0.81	0.76	-1.76	-3.66	0.42	-1.06	-0.82	-0.45	-0.12	-0.52	-0.85	0.00	-0.37	-0.72	-0.37	0.02	-1.35	-1.97	-0.35	-0.19	-1.49	-0.11	-0.04	-3.02	-0.58	-0.76	1.33	0.98	0.43	-3.01	-100000000.00	0.61	
WP$ 	-1.35	-1.34	-1.14	-2.06	-0.92	0.51	0.79	0.04	-0.39	-1.29	0.97	-0.45	-0.81	-0.31	1.18	-0.29	-0.14	-0.90	-0.11	-0.02	-1.83	0.53	1.42	1.38	-0.79	0.36	-0.53	-0.42	-2.73	-1.18	0.35	-0.19	0.33	-2.16	-0.64	-0.17	0.53	2.15	-1.89	0.50	-0.68	-1.65	-0.97	0.89	-0.99	-2.38	-100000000.00	-0.05	
NN|SYM 	-0.55	0.40	-1.24	-1.89	-1.16	-0.75	1.81	-0.48	-0.61	-0.74	0.06	-0.56	0.57	-3.28	-1.73	-0.18	-1.84	0.72	-0.67	-0.60	0.15	-2.21	-1.40	-0.78	1.03	-2.25	-0.43	-0.62	-2.01	1.36	-0.12	0.31	2.05	-0.72	1.63	-1.51	-0.93	0.63	0.61	-0.21	-0.14	0.34	0.41	1.46	0.66	-1.83	-100000000.00	-1.82	
MD 	-2.31	-0.20	-1.08	-3.77	0.02	-0.54	1.61	0.30	-0.28	-1.67	-1.41	-1.38	-0.61	0.83	-0.15	-1.98	0.08	0.42	-1.77	-0.12	-0.72	-2.86	-2.10	0.67	0.70	-0.77	-1.15	0.26	0.48	-1.64	-1.78	-1.46	-0.25	-1.57	0.11	-1.41	0.43	-0.49	-0.40	-1.08	-4.23	-2.30	-0.52	-2.39	-0.52	-0.71	-100000000.00	-0.37	
NNPS 	-1.10	-0.77	-0.90	-0.77	-2.33	-1.29	0.41	0.58	0.07	-0.24	-1.94	-2.24	0.61	-1.10	-1.21	0.99	-1.17	-1.63	0.65	-2.94	-1.76	0.97	-2.02	-0.88	0.03	-2.79	0.24	-0.79	-2.97	-1.29	-0.71	-0.55	-0.60	0.70	0.47	0.53	-3.44	-0.55	-1.75	0.20	-0.86	-0.91	-2.55	-1.73	-0.10	-1.50	-100000000.00	1.08	
JJS 	0.91	-3.10	-0.64	-2.68	-1.93	0.24	-1.87	-2.80	-1.35	-2.00	-1.16	-1.51	-1.24	0.14	-0.53	-1.87	-1.16	-1.37	1.14	-1.62	-1.44	-0.18	0.50	0.66	-0.60	-2.01	-1.62	-1.33	-1.56	-2.47	-0.09	0.37	0.26	-0.64	-1.08	-0.57	-1.12	-0.23	-1.31	0.22	1.48	-0.32	-1.85	2.02	-2.07	-1.87	-100000000.00	-0.44	
JJR 	-0.43	-0.33	-0.03	0.09	-1.15	-1.73	-0.75	-1.76	0.75	-0.96	-0.53	-0.34	-1.95	-2.45	-0.32	0.31	0.78	-1.34	0.43	-0.17	0.17	-0.98	-1.28	-0.37	-0.83	0.20	-0.82	-0.03	-0.61	0.85	0.20	-1.21	0.58	-0.10	-0.20	-0.70	0.94	0.26	-1.39	-0.70	0.63	1.08	-0.09	-0.66	0.52	0.45	-100000000.00	-1.17	
SYM 	-2.08	-2.13	-1.41	-1.10	-1.58	-2.60	0.36	1.15	-2.71	0.47	-0.47	-2.36	-2.97	-0.59	-2.63	-0.94	-0.35	-0.15	-1.17	-2.54	-0.58	-0.20	0.16	-1.55	-2.68	-2.10	-1.19	0.74	-1.82	-0.56	0.45	-0.09	0.42	-0.03	-0.00	-0.10	-0.41	-1.22	0.17	0.33	-0.38	-2.57	-1.20	-2.03	-0.18	-1.23	-100000000.00	0.05	
UH 	-0.96	-0.56	-1.54	-0.56	-0.80	1.22	-0.30	-1.34	0.83	-2.56	0.03	-0.77	-2.30	0.23	-0.31	1.41	-3.68	-2.65	-1.05	0.28	-2.47	1.29	-2.89	-0.21	-1.06	-1.24	-2.46	-2.51	-1.13	-3.31	-1.11	-2.78	-1.29	-1.04	-2.15	-4.51	-1.46	-1.53	-0.09	0.60	-3.40	-1.52	-0.34	-0.21	-0.50	-0.93	-100000000.00	-1.83	
stop_tag 	-1.96	-1.62	-1.28	-0.52	0.25	-2.02	2.25	0.13	-2.37	0.15	-1.00	-1.55	-1.07	-1.04	-1.30	-2.14	0.86	-1.29	-2.24	-0.01	-0.71	-0.83	-0.85	0.96	-1.94	-0.60	0.68	0.53	0.10	-1.69	-1.29	-1.17	-2.24	-0.31	-3.04	-0.73	-1.85	-1.01	-0.53	-1.66	-1.52	-0.31	-2.62	-3.03	-0.25	-0.32	-100000000.00	-0.25	
NNP 	-1.08	0.29	-0.32	1.02	0.59	0.60	0.49	0.08	-1.33	-0.26	-0.98	-0.34	0.78	0.90	-0.62	-0.47	0.37	-0.61	-0.55	0.05	-1.10	-1.15	0.54	-0.07	-1.59	-2.24	0.60	-1.31	-2.08	1.01	-1.09	-0.91	-2.98	-0.75	-0.72	-0.48	-1.69	-0.27	-0.81	-2.31	-1.34	-0.27	0.81	-0.10	0.75	-1.21	-100000000.00	1.77	
Mean train loss after  0 batches of 1  epochs =0.601432323456
Mean train loss after  100 batches of 1  epochs =0.162236138142
Mean train loss after  200 batches of 1  epochs =0.147777066209
Mean train loss after  300 batches of 1  epochs =0.179324833521
Mean train loss after  400 batches of 1  epochs =0.172545971897
Mean train loss after  500 batches of 1  epochs =0.174306087146
Mean train loss after  600 batches of 1  epochs =0.171030621955
Mean train loss after  700 batches of 1  epochs =0.173027080187
Mean train loss after  800 batches of 1  epochs =0.175994424475
Mean train loss after  900 batches of 1  epochs =0.180537679009
Mean train loss after  1000 batches of 1  epochs =0.179258008415
Mean train loss after  1100 batches of 1  epochs =0.176473831209
Mean train loss after  1200 batches of 1  epochs =0.178764833043
Mean train loss after  1300 batches of 1  epochs =0.179933201261
Mean train loss after  1400 batches of 1  epochs =0.177199546872
Mean train loss after  1500 batches of 1  epochs =0.176238545755
Mean train loss after  1600 batches of 1  epochs =0.174142999036
Mean train loss after  1700 batches of 1  epochs =0.172397297603
Mean train loss after  1800 batches of 1  epochs =0.17290399932
Mean train loss after  1900 batches of 1  epochs =0.171928208744
Mean train loss after  2000 batches of 1  epochs =0.173481189573
Mean train loss after  2100 batches of 1  epochs =0.173005211684
Mean train loss after  2200 batches of 1  epochs =0.173052035363
Mean train loss after  2300 batches of 1  epochs =0.172933586802
Mean train loss after  2400 batches of 1  epochs =0.173150699253
Mean train loss after  2500 batches of 1  epochs =0.175101033088
Mean train loss after  2600 batches of 1  epochs =0.175356106097
Mean train loss after  2700 batches of 1  epochs =0.175535014099
Mean train loss after  2800 batches of 1  epochs =0.175430057745
Mean train loss after  2900 batches of 1  epochs =0.175931005208
Mean train loss after  3000 batches of 1  epochs =0.176724900262
Mean train loss after  3100 batches of 1  epochs =0.176679023192
Mean train loss after  3200 batches of 1  epochs =0.177094137894
Mean train loss after  3300 batches of 1  epochs =0.177997626822
Mean train loss after  3400 batches of 1  epochs =0.177511272253
Mean train loss after  3500 batches of 1  epochs =0.178049877614
Mean train loss after  3600 batches of 1  epochs =0.179303600228
Mean train loss after  3700 batches of 1  epochs =0.179757804856
Mean train loss after  3800 batches of 1  epochs =0.179191258842
Mean train loss after  3900 batches of 1  epochs =0.180160283209
Mean train loss after  4000 batches of 1  epochs =0.181012752946
Mean train loss after  4100 batches of 1  epochs =0.181632930395
Mean train loss after  4200 batches of 1  epochs =0.180802213324
Mean train loss after  4300 batches of 1  epochs =0.181630427949
Mean train loss after  4400 batches of 1  epochs =0.181575011367
Mean train loss after  4500 batches of 1  epochs =0.181141744133
Mean train loss after  4600 batches of 1  epochs =0.181057652625
Mean train loss after  4700 batches of 1  epochs =0.180768109055
Mean train loss after  4800 batches of 1  epochs =0.180699249219
Mean train loss after  4900 batches of 1  epochs =0.180434236341
Mean train loss after  5000 batches of 1  epochs =0.180345523485
Mean train loss after  5100 batches of 1  epochs =0.181166951361
Mean train loss after  5200 batches of 1  epochs =0.181116121408
Mean train loss after  5300 batches of 1  epochs =0.181569655131
Mean train loss after  5400 batches of 1  epochs =0.180673411008
Mean train loss after  5500 batches of 1  epochs =0.180960562616
Mean train loss after  5600 batches of 1  epochs =0.181269169632
Mean train loss after  5700 batches of 1  epochs =0.181221088389
Mean train loss after  5800 batches of 1  epochs =0.180911437895
Mean train loss after  5900 batches of 1  epochs =0.181048359305
Mean train loss after  6000 batches of 1  epochs =0.181271463742
Mean train loss after  6100 batches of 1  epochs =0.181572673493
Mean train loss after  6200 batches of 1  epochs =0.182227415533
Mean train loss after  6300 batches of 1  epochs =0.182514869141
Mean train loss after  6400 batches of 1  epochs =0.182818478559
Mean train loss after  6500 batches of 1  epochs =0.183410866203
Mean train loss after  6600 batches of 1  epochs =0.183069579205
Mean train loss after  6700 batches of 1  epochs =0.183982274096
Mean train loss after  6800 batches of 1  epochs =0.184425617781
Mean train loss after  6900 batches of 1  epochs =0.184831919914
Mean train loss after  7000 batches of 1  epochs =0.184945151038
Mean train loss after  7100 batches of 1  epochs =0.185167866698
Mean train loss after  7200 batches of 1  epochs =0.185538986385
Mean train loss after  7300 batches of 1  epochs =0.185608312461
Mean train loss after  7400 batches of 1  epochs =0.185112701856
Mean train loss after  7500 batches of 1  epochs =0.185975331357
Mean train loss after  7600 batches of 1  epochs =0.186028726844
Mean train loss after  7700 batches of 1  epochs =0.1861493482
Mean train loss after  7800 batches of 1  epochs =0.185848031354
Mean train loss after  7900 batches of 1  epochs =0.186318807316
Mean train loss after  8000 batches of 1  epochs =0.185859596329
Mean train loss after  8100 batches of 1  epochs =0.185617808524
Mean train loss after  8200 batches of 1  epochs =0.186096615437
Mean train loss after  8300 batches of 1  epochs =0.186043729212
Mean train loss after  8400 batches of 1  epochs =0.185852588842
Mean train loss after  8500 batches of 1  epochs =0.186433386823
Mean train loss after  8600 batches of 1  epochs =0.186170515688
Mean train loss after  8700 batches of 1  epochs =0.185949798715
Mean train loss after  8800 batches of 1  epochs =0.185994556412
Mean train loss after  8900 batches of 1  epochs =0.185674828079
Mean train loss after  9000 batches of 1  epochs =0.185684300468
Mean train loss after  9100 batches of 1  epochs =0.1853615348
Mean train loss after  9200 batches of 1  epochs =0.185439737167
Mean train loss after  9300 batches of 1  epochs =0.18547263582
Mean train loss after  9400 batches of 1  epochs =0.185433274091
Mean train loss after  9500 batches of 1  epochs =0.185758572539
Mean train loss after  9600 batches of 1  epochs =0.185904361945
Mean train loss after  9700 batches of 1  epochs =0.186130057308
Mean train loss after  9800 batches of 1  epochs =0.186035788961
Mean train loss after  9900 batches of 1  epochs =0.185801080468
Mean train loss after  10000 batches of 1  epochs =0.186296032074
Mean train loss after  10100 batches of 1  epochs =0.186098601321
Mean train loss after  10200 batches of 1  epochs =0.186031511079
Mean train loss after  10300 batches of 1  epochs =0.185597615168
Mean train loss after  10400 batches of 1  epochs =0.185531091343
Mean train loss after  10500 batches of 1  epochs =0.185275347967
Mean train loss after  10600 batches of 1  epochs =0.185283111452
Mean train loss after  10700 batches of 1  epochs =0.185410104878
Mean train loss after  10800 batches of 1  epochs =0.185609776034
Mean train loss after  10900 batches of 1  epochs =0.185616453858
Mean train loss after  11000 batches of 1  epochs =0.185675219674
Mean train loss after  11100 batches of 1  epochs =0.185574022033
Mean train loss after  11200 batches of 1  epochs =0.186035374135
Mean train loss after  11300 batches of 1  epochs =0.18609051719
Mean train loss after  11400 batches of 1  epochs =0.185952164284
Mean train loss after  11500 batches of 1  epochs =0.185926446011
Mean train loss after  11600 batches of 1  epochs =0.185951736182
Mean train loss after  11700 batches of 1  epochs =0.186370502545
Mean train loss after  11800 batches of 1  epochs =0.186238779847
Mean train loss after  11900 batches of 1  epochs =0.186018349274
Mean train loss after  12000 batches of 1  epochs =0.185992768857
Mean train loss after  12100 batches of 1  epochs =0.185898383877
Mean train loss after  12200 batches of 1  epochs =0.185982334621
Mean train loss after  12300 batches of 1  epochs =0.185810617961
Mean train loss after  12400 batches of 1  epochs =0.185663430695
Mean train loss after  12500 batches of 1  epochs =0.185423688178
Mean train loss after  12600 batches of 1  epochs =0.185850382165
Mean train loss after  12700 batches of 1  epochs =0.186026341656
Mean train loss after  12800 batches of 1  epochs =0.18603286011
Mean train loss after  12900 batches of 1  epochs =0.186194673407
Mean train loss after  13000 batches of 1  epochs =0.186503335051
Mean train loss after  13100 batches of 1  epochs =0.186413838164
Mean train loss after  13200 batches of 1  epochs =0.186598939941
Mean train loss after  13300 batches of 1  epochs =0.186577398049
Mean train loss after  13400 batches of 1  epochs =0.186380631177
Mean train loss after  13500 batches of 1  epochs =0.186321856946
Mean train loss after  13600 batches of 1  epochs =0.186143662956
Mean train loss after  13700 batches of 1  epochs =0.186086016506
Mean train loss after  13800 batches of 1  epochs =0.186364952788
Mean train loss after  13900 batches of 1  epochs =0.186294978845
Mean train loss after  14000 batches of 1  epochs =0.18648883136
Mean train loss after  14100 batches of 1  epochs =0.186489398832
Mean train loss after  14200 batches of 1  epochs =0.186634069914
Mean train loss after  14300 batches of 1  epochs =0.186659397099
Mean train loss after  14400 batches of 1  epochs =0.186707130222
Mean train loss after  14500 batches of 1  epochs =0.186753341309
Mean train loss after  14600 batches of 1  epochs =0.18685251901
Mean train loss after  14700 batches of 1  epochs =0.186753033987
Mean train loss after  14800 batches of 1  epochs =0.186652021838
Mean train loss after  14900 batches of 1  epochs =0.186815853812
Epoch 1 : Mean train epoch loss =0.186779654267
Epoch 1 Epoch val loss = 12649.4176631
Epoch 1 Epoch val perplexity = 1.294303069009319
SCORES =  (92.34, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 2---------------------

=================================
fscore(z) =  [273.63132] || goldscore = [271.0312]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-3.03	1.05	0.03	-1.76	0.09	-0.58	0.29	-0.88	-0.38	-0.43	0.88	0.23	0.46	-0.48	1.25	-3.15	-0.54	-0.67	-3.17	0.29	0.13	-1.82	-1.20	-2.10	-1.46	0.83	-2.81	-0.92	0.88	0.91	-0.21	0.18	-0.26	-0.74	-0.77	-1.59	-1.94	0.08	-0.94	-0.99	-1.78	-1.90	-0.76	-0.15	-1.79	-0.78	-100000000.00	-1.23	
VBG 	-1.19	-0.92	0.17	0.15	0.21	0.98	-3.26	0.47	0.22	-1.75	-2.29	-0.20	0.17	-0.72	-0.40	-1.62	0.42	0.18	-2.82	-4.44	-2.50	-1.15	-0.71	-1.05	-3.66	0.00	-0.60	0.23	-2.46	1.25	-2.33	0.43	-1.61	-0.68	-1.26	-1.19	-1.37	-0.64	-1.28	-3.04	-1.08	-1.14	-1.05	0.08	-2.30	-2.26	-100000000.00	-0.76	
VBD 	-1.59	-0.91	-2.58	-1.21	-2.22	0.37	-0.97	-0.97	0.73	-1.18	0.53	-1.19	1.16	-0.58	-0.68	-2.01	0.43	-0.11	-0.64	-0.98	-1.10	-0.55	-1.59	-0.62	-1.54	-0.13	-0.97	0.79	1.24	-1.24	-2.68	-1.27	-3.97	0.44	-0.48	-1.14	-0.26	-2.07	-1.78	-2.05	-0.28	-0.43	0.57	-1.23	-0.70	-1.44	-100000000.00	0.62	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-1.48	-0.19	-0.74	-0.76	-0.85	-1.00	-1.96	0.09	-0.43	-1.35	-0.94	-0.15	0.38	-0.22	-0.28	-2.25	-0.38	-1.44	-0.11	-1.08	-0.85	-2.15	-0.82	-0.98	-1.99	0.38	-0.02	0.04	-1.38	0.80	-0.54	-0.89	-3.23	-0.18	-0.03	-1.26	-2.92	-0.65	-0.46	-1.97	-3.11	-1.23	-1.98	-0.66	0.60	-4.68	-100000000.00	-1.64	
, 	-0.45	-0.58	1.04	-1.02	-0.14	-0.55	-0.78	0.27	0.32	0.75	0.03	-0.93	-1.26	0.19	-0.90	-2.39	0.51	-0.20	-1.26	-0.77	0.90	-0.84	-1.87	-1.47	0.18	-0.98	-2.71	-0.30	-0.49	-0.27	-2.07	0.69	-3.55	0.77	-1.32	1.29	-0.95	-0.23	-3.11	-2.40	-0.44	1.05	0.43	-0.47	-1.49	-0.93	-100000000.00	1.03	
'' 	0.14	0.47	-1.58	-0.75	-2.73	-0.28	-0.18	-2.44	-1.93	-3.50	-1.20	-1.47	-3.78	-2.98	-0.08	-0.34	0.28	-0.67	-2.07	-1.04	-1.70	0.09	-1.49	-0.30	-1.79	0.21	-0.82	-1.75	-1.63	0.15	-0.41	-0.24	-1.06	-0.16	-1.69	-1.32	-1.09	-0.57	-0.22	-0.15	-2.85	-2.28	-0.39	-2.82	-1.51	-1.88	-100000000.00	-0.43	
VBP 	-3.40	-0.58	-5.19	-2.83	-1.80	-0.64	-0.54	0.23	-0.38	-2.42	0.47	-1.17	-0.95	-0.47	-2.36	0.42	-1.61	0.85	0.63	-2.63	-3.64	-0.48	-1.45	-2.61	-2.61	0.10	-2.13	0.86	-0.42	-1.48	-1.26	-1.02	-1.72	-0.91	-0.29	-0.88	-0.19	-4.09	-0.20	-0.70	-1.63	0.37	-2.06	-1.74	-0.81	-2.15	-100000000.00	-0.38	
WDT 	-2.84	-1.79	-2.41	-2.74	-2.73	-0.65	-1.66	-1.16	-2.24	-1.14	-0.89	-2.51	-1.10	-0.78	-0.14	-1.39	-0.00	0.40	-1.20	-2.05	-0.22	-1.38	-0.51	-0.10	0.14	-0.91	0.21	0.81	-2.70	-1.07	-0.17	-0.12	-0.98	-0.36	-0.43	-1.35	-2.74	-1.41	0.72	-1.24	-2.97	-1.67	-1.41	-0.45	-1.53	-1.39	-100000000.00	0.07	
JJ 	0.13	1.03	0.26	0.60	0.24	-0.98	-2.33	0.31	-0.78	-0.00	-2.53	0.51	-0.16	-0.83	-0.58	-0.69	-0.68	-0.66	-0.90	-1.76	0.13	-2.02	-1.43	-0.12	-2.81	-0.06	-0.35	-1.07	-0.70	0.44	0.45	0.42	-1.63	-0.58	0.43	-0.12	-1.74	0.59	-1.15	-2.59	-0.14	-1.78	-1.32	0.13	-1.17	-1.53	-100000000.00	-0.69	
WP 	-2.13	-1.02	0.11	-0.06	0.17	-0.37	-2.18	-3.46	-2.17	-0.91	-2.82	-1.86	-0.72	-0.79	-1.03	-1.99	-1.56	-0.48	0.06	-1.22	0.71	-1.06	-1.43	-0.34	0.37	-1.21	-1.70	1.64	-0.07	-1.17	-1.63	-1.26	-1.37	1.90	-1.27	-1.68	0.30	-0.57	0.02	0.65	0.52	-0.07	-1.95	-1.37	-2.62	-1.46	-100000000.00	0.33	
VBZ 	-0.48	-1.67	-1.85	-2.85	-1.08	0.18	-1.17	-0.18	0.58	-0.81	1.18	-0.63	-0.24	-1.03	-1.73	-2.85	1.02	-1.55	-0.62	-1.32	-1.16	-1.34	-1.67	0.35	-2.16	0.37	-0.43	-1.10	0.28	-1.65	-0.99	-0.65	-4.39	-0.94	-2.65	-0.58	1.78	-1.80	-0.87	-0.95	-1.40	-2.11	-0.88	-1.94	-1.50	-2.41	-100000000.00	0.64	
DT 	-2.23	0.30	0.61	0.40	0.04	1.67	-1.23	0.61	-0.17	-0.36	-1.21	0.56	-1.20	-0.05	1.15	-1.94	-0.61	-1.20	-0.05	-0.37	-0.61	-0.76	0.79	-0.63	-1.47	-0.13	-0.78	-1.32	-0.49	1.17	-0.97	0.99	0.94	-2.34	0.74	-1.29	-2.60	0.74	-0.19	-0.82	-1.47	-1.18	-0.82	-1.89	-0.19	-1.48	-100000000.00	-1.62	
" 	-1.82	0.21	-1.10	-0.93	0.32	0.38	-0.78	-1.33	-2.11	-1.78	1.09	-0.22	-2.49	-1.23	1.60	-0.82	-0.40	-1.21	-2.11	-0.65	-0.84	2.15	-0.05	1.15	-1.07	-0.76	-0.72	-0.62	-1.50	-0.88	-0.50	-1.95	-0.92	-0.50	-0.07	-1.14	-1.61	-0.92	-1.23	2.74	-0.53	-0.20	-2.74	-1.18	-1.82	-1.70	-100000000.00	-0.19	
RP 	-2.97	0.51	0.53	-2.13	0.32	-1.00	-0.63	0.57	-3.35	-0.98	-0.40	-0.72	0.03	-1.88	0.21	-1.34	-0.45	-1.50	-1.94	-0.40	-3.93	0.44	-3.87	-0.52	-1.61	0.26	-3.98	-0.84	-0.63	0.97	-1.85	-1.36	-1.43	-0.53	-3.26	-1.11	-0.17	-1.17	0.46	-0.04	-3.14	-0.37	-0.78	-0.01	-0.94	-0.15	-100000000.00	-2.30	
$ 	-0.88	0.20	0.59	-3.20	-1.18	-2.64	-1.90	-1.72	-2.09	-1.09	-2.33	-0.03	-0.27	-1.76	-0.04	-0.49	0.07	-0.09	0.09	0.90	0.12	-0.65	-0.76	0.91	-1.38	0.14	-0.75	-0.43	-0.66	-1.40	0.01	-0.46	-1.04	-1.72	-1.42	-2.41	0.66	-1.04	0.98	-0.21	-0.16	-0.92	-0.67	-0.17	0.19	-0.30	-100000000.00	-1.47	
NN 	0.80	0.33	-0.79	0.53	-0.22	0.19	-0.61	-0.39	-0.69	0.96	-2.22	-0.23	-0.66	-0.45	0.49	-1.18	0.39	-0.88	-1.02	-0.59	0.65	-1.92	-0.56	-3.35	-2.76	-1.89	0.24	-1.26	-0.90	0.30	-0.68	-0.10	-2.73	-2.59	-0.98	-0.26	-3.87	-0.10	-0.33	-3.63	-1.01	-0.67	1.30	-0.39	0.13	-4.47	-100000000.00	-0.24	
) 	-2.85	-0.42	-1.59	-3.06	-0.68	-3.20	-2.71	-1.21	-2.26	-0.21	-1.97	-2.16	-1.86	-2.28	-0.23	-2.48	-0.25	-2.02	0.79	-0.75	0.50	-2.04	-3.01	-2.06	-0.52	-1.81	-1.85	-0.74	-2.81	-0.17	1.20	-1.62	-3.11	-0.49	-0.80	-2.79	-0.71	-1.09	-0.11	-1.03	-2.12	0.70	-0.93	-1.52	-1.87	-2.98	-100000000.00	-1.43	
( 	-0.28	-0.90	-2.35	-0.57	0.14	-1.27	-0.53	-4.63	-0.59	-0.05	0.28	-0.31	-0.69	-1.03	-2.33	-0.89	0.08	-1.48	-1.35	-0.47	-1.20	-0.33	-1.11	0.68	-2.38	-1.97	-1.69	-0.62	-0.16	-0.91	-0.73	-1.04	-1.30	-0.89	-0.77	0.32	-0.47	-1.52	-1.89	-1.19	-1.62	-0.35	-0.20	-0.65	-1.79	-3.00	-100000000.00	-0.02	
FW 	-2.82	-3.90	-1.33	-1.48	-3.18	-1.26	-0.42	-0.26	-1.27	-0.85	-2.24	-4.05	-2.78	-1.93	-1.14	-0.15	-0.19	-1.00	0.68	1.45	-1.60	-0.68	-0.03	0.94	-0.88	-1.95	-1.44	-2.45	-2.14	-0.04	-1.70	-0.20	-1.68	0.59	0.04	-1.02	-0.63	-2.06	0.21	-0.50	-2.34	-0.50	-1.05	-1.75	-1.37	-1.57	-100000000.00	-0.77	
POS 	-0.80	-0.74	-1.59	-2.01	-1.16	-1.05	-1.24	-2.28	-1.10	-0.71	-2.85	-1.44	0.27	-1.61	-1.32	-1.19	-0.51	-0.45	0.58	-0.25	-1.61	0.60	-3.24	-0.85	-1.44	-1.28	-2.15	-0.88	0.74	-0.81	-1.78	-2.89	-0.67	-0.77	-2.20	-1.51	-0.90	-2.18	-1.10	-1.38	-1.07	-1.31	0.34	-3.06	-1.89	-1.33	-100000000.00	-1.74	
. 	-1.69	1.11	0.09	-3.30	0.70	-3.38	-1.95	-0.04	-0.09	-2.03	-0.94	-0.21	-2.48	0.06	-0.16	-1.33	-0.55	-0.56	-1.02	-2.43	-0.87	-1.73	-0.14	0.45	0.95	0.66	-0.73	0.63	-0.90	0.08	-2.45	-3.51	-2.51	-1.19	0.50	-0.88	-0.41	-1.76	-1.86	-2.47	-2.02	-0.37	-2.99	-0.08	-4.81	-0.04	-100000000.00	-0.01	
TO 	-0.93	-0.78	0.97	-0.87	-0.90	-1.71	-1.37	0.75	-3.38	0.90	-2.63	-0.13	0.61	-2.09	0.04	-3.32	-0.14	-0.81	-0.50	-2.54	-2.96	-1.89	-1.86	-1.21	-3.39	-1.49	-1.94	-1.42	-0.16	0.42	-1.43	-0.84	-2.81	-1.34	0.67	-1.85	-0.80	-1.51	-2.26	-1.41	-2.22	-1.45	-0.70	-0.17	-1.33	-1.48	-100000000.00	-1.29	
-X- 	-0.46	-0.22	-1.08	-0.33	-1.58	-1.33	0.16	-0.19	1.42	-0.78	-0.91	-3.02	-1.24	-1.49	-1.09	0.24	-1.12	0.26	-1.08	-0.06	-1.23	0.67	-1.51	0.78	-0.10	-0.43	0.08	-0.14	0.98	-1.29	-0.24	0.08	1.60	0.33	-0.41	-1.23	1.50	-1.58	0.79	0.42	1.99	-0.33	1.07	-0.12	-0.85	-1.33	-100000000.00	-1.05	
LS 	-1.30	-0.76	-2.78	-1.14	-0.97	-0.56	-0.98	-1.06	-0.85	-2.99	-0.67	-1.73	-3.89	-1.72	-1.43	-2.93	-3.34	-1.56	-0.28	-1.46	-1.25	-0.48	-2.58	-0.06	-1.04	-1.08	-0.01	-2.07	1.44	-0.91	-1.30	-0.72	-0.42	0.15	-1.32	-2.59	-1.14	-3.27	0.55	-1.83	-0.63	-0.75	-0.82	-1.35	-0.76	-2.79	-100000000.00	-1.74	
RB 	-0.65	0.20	-0.12	-0.02	-0.62	0.18	-1.80	-0.40	-0.20	-1.37	-2.62	0.54	0.84	-0.73	0.33	-0.74	-0.55	-0.08	-1.22	-3.73	-0.51	-2.24	-0.97	-0.59	-1.80	-0.54	-1.96	-0.06	-1.52	-0.24	-0.65	-0.57	-1.28	0.99	0.60	-0.58	-0.97	-0.54	-1.37	-1.61	0.96	-2.06	-0.85	-0.51	-0.95	-2.55	-100000000.00	-1.07	
: 	-0.32	-0.33	-0.82	-1.73	-0.36	0.27	-2.17	-1.31	-0.22	-0.57	-1.48	0.29	-1.79	-0.95	-0.52	-0.94	1.15	-0.37	0.09	-3.02	-0.58	-1.96	-1.51	-0.06	-0.50	0.06	-1.37	0.41	-0.54	0.14	-2.86	-1.86	-2.89	-0.38	-1.40	0.86	-0.61	-1.69	-1.97	-0.33	-2.38	-2.05	-0.77	-0.11	-1.29	-3.29	-100000000.00	-2.41	
NNS 	-1.30	0.47	-0.28	0.75	0.43	-0.35	-1.47	-0.27	-0.08	1.12	-0.94	-0.47	0.37	0.51	0.25	-2.97	0.84	-0.70	-0.45	0.04	0.54	-2.86	-2.36	-2.57	-3.80	-1.93	1.66	-1.63	-0.50	0.04	-0.95	-0.91	-1.66	-0.52	-1.52	-0.19	-4.32	-0.27	1.06	-2.41	-0.94	-1.92	-0.25	1.34	-0.33	-3.73	-100000000.00	-0.46	
PRP 	-3.19	0.30	-1.19	-0.40	-0.89	0.39	-0.04	0.35	-1.27	-1.13	-0.86	0.23	-2.30	0.71	-3.87	-1.72	-1.03	-1.65	-1.15	-0.36	0.12	-1.71	-0.44	-0.64	-1.37	0.54	-0.49	-1.22	-0.60	0.36	-0.95	-0.79	-1.67	-1.18	-1.83	-3.05	-0.85	1.47	-1.24	-3.45	-0.77	-4.44	-0.72	-2.94	-1.06	-0.06	-100000000.00	-1.96	
VB 	-0.88	-1.83	-1.30	-0.04	-2.25	-0.77	0.03	-1.97	0.39	-1.70	-0.43	-0.68	-1.06	-1.26	0.04	-2.70	-0.38	0.11	-1.67	-1.23	-1.52	-1.96	1.13	-1.73	-2.13	0.68	-0.64	-1.49	-0.42	-1.01	-1.98	-0.22	-0.71	-1.67	-0.27	-1.05	-2.27	-1.38	-0.75	-2.91	2.19	-1.42	-0.82	-0.36	-1.97	-2.62	-100000000.00	-0.92	
WRB 	-1.53	-0.77	-1.79	-1.20	-0.51	-1.33	-1.89	-1.24	-0.59	-1.38	-0.39	-0.28	0.15	-1.60	-2.80	0.05	0.38	0.41	-1.80	-1.15	0.28	-1.50	-0.58	0.37	0.22	-0.11	-1.07	-0.80	-1.09	-0.85	-1.91	-0.13	-1.29	-2.38	-0.05	-1.08	-1.63	-0.61	0.69	0.24	-3.43	-3.22	-1.89	-2.39	-0.24	-0.86	-100000000.00	0.81	
CC 	-2.07	0.10	-0.43	-0.68	1.08	-0.55	-2.54	-2.18	-2.11	0.63	-2.39	0.09	-0.62	-0.22	-0.47	-1.24	0.35	0.59	-1.39	-1.32	-1.35	-1.05	-2.26	-0.60	-1.62	0.03	0.08	-0.25	-0.04	0.00	-4.23	-0.84	-3.52	-1.21	-0.87	-1.97	-0.63	-1.08	-1.20	-0.09	-2.00	0.02	-0.15	-2.83	0.04	-2.70	-100000000.00	0.34	
PDT 	-0.74	-1.00	-0.71	-1.11	-0.80	-1.26	0.01	-1.65	-0.16	-1.29	0.61	-0.86	-3.47	-3.37	0.78	-2.04	-1.60	-3.16	-0.84	-1.21	-2.69	-0.76	-0.10	0.75	-1.31	-1.20	-1.36	-3.37	-2.10	-0.93	-0.71	-1.15	-1.37	-2.31	-1.32	-1.24	-1.58	-0.54	-1.04	1.41	-1.94	0.79	0.03	-2.11	-2.06	-0.39	-100000000.00	-2.28	
RBS 	2.13	0.09	-0.41	-2.44	-0.48	-0.66	-0.58	0.57	-1.75	-2.75	-0.10	-1.48	0.87	-1.55	-1.00	-0.80	-0.68	-0.86	0.05	-1.23	2.00	0.01	-2.61	-0.66	-1.03	-1.30	1.17	-1.17	-1.04	-1.52	-0.52	-1.45	-0.18	-1.29	-0.87	-2.09	-1.23	-0.87	0.20	-0.82	-2.64	-0.70	-0.63	0.93	-2.09	-2.21	-100000000.00	-3.14	
RBR 	-2.44	-1.56	-0.52	0.39	0.43	-2.01	-0.11	-0.46	-1.05	-0.69	-3.53	1.14	-0.40	0.50	0.80	-1.80	0.65	-1.17	-2.47	-0.89	-1.74	-1.57	-2.04	-0.69	0.03	0.47	-1.74	0.13	0.98	0.92	0.13	-0.40	-2.48	-1.70	-1.25	-0.35	-1.54	-0.78	-0.87	-2.10	-0.62	-2.04	-0.73	0.14	-0.61	-0.74	-100000000.00	-1.38	
CD 	-0.42	-0.13	-0.10	-0.19	-0.33	0.38	-0.55	-0.96	-1.34	-0.90	-1.78	0.22	0.80	0.39	-0.74	1.17	-0.66	0.17	-0.97	-1.21	-0.02	-2.95	0.22	-1.50	-2.99	-0.85	-0.18	-1.00	-1.96	-0.11	-1.12	-1.44	-2.85	-2.62	-3.58	-1.17	-4.65	-0.49	-0.34	-0.52	-2.83	-0.17	-0.55	-0.34	-0.18	-1.02	-100000000.00	-0.17	
EX 	0.81	0.70	-1.79	-0.77	1.45	-0.42	0.24	0.01	-0.38	-1.19	-1.40	-2.15	-1.53	0.06	-0.22	-0.04	-0.83	-1.31	-1.34	-0.65	-4.04	-0.93	-1.65	-0.72	-0.75	-1.22	-2.48	-1.70	0.26	1.16	-0.45	-0.80	0.04	-1.30	1.14	-1.27	-1.11	-0.99	-1.90	-2.66	-0.44	-0.79	-0.24	-0.08	0.31	-0.23	-100000000.00	-2.08	
IN 	-1.99	0.69	0.12	0.86	0.60	-0.54	-0.35	-0.55	-0.53	-1.08	-2.29	0.91	-0.18	0.48	1.05	-0.94	0.78	0.63	-1.70	-3.66	-0.08	-1.85	-0.94	-1.10	-1.08	-0.45	-0.93	0.22	-0.34	-0.61	-1.21	-0.21	-1.76	-2.00	-0.27	-0.23	-1.57	-0.22	-0.34	-4.37	-1.14	-0.78	1.22	0.82	0.19	-4.51	-100000000.00	0.54	
WP$ 	-1.72	-1.53	-1.36	-2.77	-1.22	0.44	0.57	-0.39	-0.77	-1.50	0.65	-0.51	-1.08	-0.72	0.95	-0.45	-0.63	-1.27	-0.43	-0.25	-2.27	0.37	0.94	1.30	-1.05	0.17	-0.92	-0.34	-3.21	-1.46	0.13	-0.56	0.14	-2.32	-0.83	-0.51	0.29	1.83	-1.99	0.35	-0.87	-1.91	-1.25	0.64	-1.34	-2.58	-100000000.00	-0.33	
NN|SYM 	-1.09	-0.42	-2.33	-3.05	-2.06	-1.48	1.52	-0.79	-1.11	-1.82	-0.34	-1.42	-0.14	-3.67	-2.10	-0.51	-3.12	0.72	-1.38	-1.10	-0.45	-2.37	-1.89	-0.87	0.62	-3.00	-1.29	-1.77	-2.64	0.82	-0.48	-0.47	1.76	-1.08	0.97	-2.54	-1.40	-0.38	0.38	-0.45	-0.59	-0.48	0.08	0.74	0.13	-2.09	-100000000.00	-3.33	
MD 	-2.38	-0.50	-1.20	-3.83	-0.49	-0.60	1.01	0.07	-0.04	-1.82	-1.56	-1.53	-0.66	0.38	-0.60	-2.51	0.07	0.08	-2.44	-0.89	-1.49	-3.22	-3.06	0.43	0.35	-0.86	-1.91	0.27	0.41	-1.67	-1.78	-1.58	-0.94	-1.98	-0.63	-1.65	0.39	-0.84	-0.69	-1.39	-4.22	-2.45	-1.12	-3.14	-1.03	-1.34	-100000000.00	-0.38	
NNPS 	-1.36	-0.97	-0.96	-1.15	-2.35	-1.40	0.11	0.18	-0.50	-0.46	-2.59	-2.25	0.50	-1.22	-1.47	0.48	-1.47	-2.02	0.50	-3.77	-2.38	0.46	-2.45	-1.25	-0.89	-4.37	-0.23	-2.00	-3.80	-1.26	-1.29	-0.76	-1.18	0.38	-0.25	0.28	-4.42	-0.48	-1.79	-0.59	-1.58	-0.92	-3.01	-2.74	-0.78	-2.28	-100000000.00	1.08	
JJS 	0.77	-3.85	-0.84	-2.47	-1.90	-0.04	-2.02	-3.27	-1.65	-1.89	-1.45	-1.85	-1.21	-0.57	-0.81	-2.20	-1.69	-1.83	0.37	-2.29	-1.29	-0.69	-0.43	0.34	-1.11	-2.31	-2.57	-1.84	-2.13	-2.45	-0.35	0.09	-0.22	-1.02	-1.62	-1.17	-1.53	-0.35	-1.52	-0.40	0.76	-0.76	-2.43	1.31	-2.41	-2.30	-100000000.00	-1.51	
JJR 	-0.95	-0.23	-0.08	0.01	-1.26	-1.96	-1.02	-1.61	0.16	-1.21	-0.98	-0.25	-1.86	-2.40	-0.73	-0.17	0.17	-2.01	0.38	-0.76	-0.89	-1.41	-1.26	-0.65	-1.37	0.04	-1.39	-0.33	-0.72	0.72	0.13	-1.14	-0.01	-0.50	-0.59	-0.80	0.26	0.11	-1.63	-1.50	0.10	0.44	-0.76	-1.42	0.33	-0.40	-100000000.00	-1.43	
SYM 	-2.46	-2.55	-1.81	-0.93	-2.18	-3.41	0.04	0.55	-3.35	0.28	-0.99	-2.93	-4.01	-1.26	-3.12	-1.39	-0.26	-0.24	-1.94	-3.24	-1.42	-0.67	-0.63	-1.63	-3.25	-2.36	-1.54	0.34	-2.01	-1.00	0.15	-0.67	-0.19	-0.43	-0.57	-0.14	-0.92	-2.04	-0.03	-0.12	-0.57	-3.07	-1.59	-2.55	-0.63	-1.31	-100000000.00	-0.00	
UH 	-1.79	-1.83	-2.65	-0.57	-1.56	1.15	-0.55	-1.88	0.45	-4.06	-0.40	-1.69	-3.94	0.03	-0.89	0.98	-5.29	-3.34	-2.09	0.07	-3.30	0.83	-3.69	-0.52	-1.69	-2.60	-3.51	-3.67	-1.38	-4.24	-1.61	-3.87	-1.73	-1.28	-2.81	-6.31	-2.42	-1.64	-0.27	0.25	-4.01	-2.37	-0.82	-1.08	-1.01	-0.92	-100000000.00	-2.73	
stop_tag 	-2.66	-3.12	-1.36	-0.52	-0.10	-2.51	2.16	-0.82	-3.72	-0.00	-1.88	-1.68	-1.12	-1.51	-1.49	-2.76	0.65	-1.44	-2.77	-0.40	-0.90	-0.98	-1.11	0.62	-2.31	-1.15	0.29	0.36	-0.63	-1.68	-1.79	-2.12	-3.37	-0.87	-4.37	-0.65	-2.60	-1.19	-0.91	-1.86	-2.46	-0.33	-3.46	-4.23	-0.01	-0.93	-100000000.00	-0.16	
NNP 	-1.02	0.38	-0.19	0.72	0.50	0.58	0.35	-0.11	-1.36	-0.13	-1.28	-0.27	0.70	0.84	-0.65	-0.85	0.20	-0.57	-0.60	0.17	-0.85	-2.11	0.55	-0.76	-2.29	-2.21	0.55	-1.35	-2.35	0.90	-0.98	-0.86	-4.39	-1.08	-1.36	-0.54	-3.52	-0.17	-1.12	-3.60	-1.34	-0.19	0.30	-0.27	0.54	-1.19	-100000000.00	1.79	
Mean train loss after  0 batches of 2  epochs =0.0928617204939
Mean train loss after  100 batches of 2  epochs =0.11671667084
Mean train loss after  200 batches of 2  epochs =0.101574538609
Mean train loss after  300 batches of 2  epochs =0.0968278273322
Mean train loss after  400 batches of 2  epochs =0.0981039356296
Mean train loss after  500 batches of 2  epochs =0.0948381549331
Mean train loss after  600 batches of 2  epochs =0.0950877680626
Mean train loss after  700 batches of 2  epochs =0.0919200356699
Mean train loss after  800 batches of 2  epochs =0.0982449660813
Mean train loss after  900 batches of 2  epochs =0.097718230338
Mean train loss after  1000 batches of 2  epochs =0.0970145494175
Mean train loss after  1100 batches of 2  epochs =0.0987423667153
Mean train loss after  1200 batches of 2  epochs =0.0987051409894
Mean train loss after  1300 batches of 2  epochs =0.0986144657544
Mean train loss after  1400 batches of 2  epochs =0.0988372884163
Mean train loss after  1500 batches of 2  epochs =0.0987165434145
Mean train loss after  1600 batches of 2  epochs =0.098464441076
Mean train loss after  1700 batches of 2  epochs =0.0989845134334
Mean train loss after  1800 batches of 2  epochs =0.0989149636718
Mean train loss after  1900 batches of 2  epochs =0.098080998645
Mean train loss after  2000 batches of 2  epochs =0.0987112014065
Mean train loss after  2100 batches of 2  epochs =0.0985718923154
Mean train loss after  2200 batches of 2  epochs =0.0988523099617
Mean train loss after  2300 batches of 2  epochs =0.0985183089143
Mean train loss after  2400 batches of 2  epochs =0.0984650282012
Mean train loss after  2500 batches of 2  epochs =0.0979771215685
Mean train loss after  2600 batches of 2  epochs =0.0978379674556
Mean train loss after  2700 batches of 2  epochs =0.0983303855906
Mean train loss after  2800 batches of 2  epochs =0.0980162296641
Mean train loss after  2900 batches of 2  epochs =0.0971517028622
Mean train loss after  3000 batches of 2  epochs =0.0978115820062
Mean train loss after  3100 batches of 2  epochs =0.0976780598816
Mean train loss after  3200 batches of 2  epochs =0.0982295476592
Mean train loss after  3300 batches of 2  epochs =0.0989864599669
Mean train loss after  3400 batches of 2  epochs =0.0981260043284
Mean train loss after  3500 batches of 2  epochs =0.0990138282597
Mean train loss after  3600 batches of 2  epochs =0.100033621279
Mean train loss after  3700 batches of 2  epochs =0.100520697573
Mean train loss after  3800 batches of 2  epochs =0.101248647708
Mean train loss after  3900 batches of 2  epochs =0.101693508099
Mean train loss after  4000 batches of 2  epochs =0.101763430713
Mean train loss after  4100 batches of 2  epochs =0.101849510692
Mean train loss after  4200 batches of 2  epochs =0.102123124183
Mean train loss after  4300 batches of 2  epochs =0.101987480477
Mean train loss after  4400 batches of 2  epochs =0.103044771301
Mean train loss after  4500 batches of 2  epochs =0.103403162788
Mean train loss after  4600 batches of 2  epochs =0.103901627203
Mean train loss after  4700 batches of 2  epochs =0.104260142002
Mean train loss after  4800 batches of 2  epochs =0.104138730808
Mean train loss after  4900 batches of 2  epochs =0.103953867367
Mean train loss after  5000 batches of 2  epochs =0.104526063631
Mean train loss after  5100 batches of 2  epochs =0.104892863347
Mean train loss after  5200 batches of 2  epochs =0.105053340662
Mean train loss after  5300 batches of 2  epochs =0.104668677805
Mean train loss after  5400 batches of 2  epochs =0.104855341517
Mean train loss after  5500 batches of 2  epochs =0.104776759778
Mean train loss after  5600 batches of 2  epochs =0.104514053556
Mean train loss after  5700 batches of 2  epochs =0.104801275584
Mean train loss after  5800 batches of 2  epochs =0.104274846621
Mean train loss after  5900 batches of 2  epochs =0.104403286058
Mean train loss after  6000 batches of 2  epochs =0.104683266043
Mean train loss after  6100 batches of 2  epochs =0.105023554029
Mean train loss after  6200 batches of 2  epochs =0.105832761279
Mean train loss after  6300 batches of 2  epochs =0.105904092688
Mean train loss after  6400 batches of 2  epochs =0.105969465214
Mean train loss after  6500 batches of 2  epochs =0.106013552373
Mean train loss after  6600 batches of 2  epochs =0.106167511315
Mean train loss after  6700 batches of 2  epochs =0.106270503849
Mean train loss after  6800 batches of 2  epochs =0.106526899806
Mean train loss after  6900 batches of 2  epochs =0.106831301183
Mean train loss after  7000 batches of 2  epochs =0.106626400936
Mean train loss after  7100 batches of 2  epochs =0.107172880125
Mean train loss after  7200 batches of 2  epochs =0.107110869597
Mean train loss after  7300 batches of 2  epochs =0.107125351615
Mean train loss after  7400 batches of 2  epochs =0.107642809135
Mean train loss after  7500 batches of 2  epochs =0.108028003148
Mean train loss after  7600 batches of 2  epochs =0.108371354911
Mean train loss after  7700 batches of 2  epochs =0.108294360442
Mean train loss after  7800 batches of 2  epochs =0.108252273607
Mean train loss after  7900 batches of 2  epochs =0.108370907693
Mean train loss after  8000 batches of 2  epochs =0.108423193181
Mean train loss after  8100 batches of 2  epochs =0.108366460113
Mean train loss after  8200 batches of 2  epochs =0.10881043219
Mean train loss after  8300 batches of 2  epochs =0.10866509728
Mean train loss after  8400 batches of 2  epochs =0.108796974555
Mean train loss after  8500 batches of 2  epochs =0.108546695429
Mean train loss after  8600 batches of 2  epochs =0.108463737598
Mean train loss after  8700 batches of 2  epochs =0.108455371481
Mean train loss after  8800 batches of 2  epochs =0.108573677667
Mean train loss after  8900 batches of 2  epochs =0.108774537331
Mean train loss after  9000 batches of 2  epochs =0.109312679432
Mean train loss after  9100 batches of 2  epochs =0.109585958894
Mean train loss after  9200 batches of 2  epochs =0.109994736438
Mean train loss after  9300 batches of 2  epochs =0.109915172192
Mean train loss after  9400 batches of 2  epochs =0.109950872012
Mean train loss after  9500 batches of 2  epochs =0.110022952511
Mean train loss after  9600 batches of 2  epochs =0.110219770821
Mean train loss after  9700 batches of 2  epochs =0.110315053026
Mean train loss after  9800 batches of 2  epochs =0.110419749595
Mean train loss after  9900 batches of 2  epochs =0.110482671764
Mean train loss after  10000 batches of 2  epochs =0.110802001903
Mean train loss after  10100 batches of 2  epochs =0.110770415334
Mean train loss after  10200 batches of 2  epochs =0.110807088566
Mean train loss after  10300 batches of 2  epochs =0.110669753286
Mean train loss after  10400 batches of 2  epochs =0.110803556099
Mean train loss after  10500 batches of 2  epochs =0.111006358329
Mean train loss after  10600 batches of 2  epochs =0.111272432232
Mean train loss after  10700 batches of 2  epochs =0.11148587511
Mean train loss after  10800 batches of 2  epochs =0.11155634081
Mean train loss after  10900 batches of 2  epochs =0.111572079524
Mean train loss after  11000 batches of 2  epochs =0.111633787811
Mean train loss after  11100 batches of 2  epochs =0.111686801924
Mean train loss after  11200 batches of 2  epochs =0.111750124001
Mean train loss after  11300 batches of 2  epochs =0.111666285854
Mean train loss after  11400 batches of 2  epochs =0.111640681185
Mean train loss after  11500 batches of 2  epochs =0.11199693482
Mean train loss after  11600 batches of 2  epochs =0.112127472394
Mean train loss after  11700 batches of 2  epochs =0.112135698776
Mean train loss after  11800 batches of 2  epochs =0.112500736106
Mean train loss after  11900 batches of 2  epochs =0.112731061085
Mean train loss after  12000 batches of 2  epochs =0.112687092974
Mean train loss after  12100 batches of 2  epochs =0.112854493217
Mean train loss after  12200 batches of 2  epochs =0.113084375491
Mean train loss after  12300 batches of 2  epochs =0.113390448111
Mean train loss after  12400 batches of 2  epochs =0.113592883139
Mean train loss after  12500 batches of 2  epochs =0.113674448482
Mean train loss after  12600 batches of 2  epochs =0.113797067077
Mean train loss after  12700 batches of 2  epochs =0.11414414966
Mean train loss after  12800 batches of 2  epochs =0.114443414294
Mean train loss after  12900 batches of 2  epochs =0.114702150215
Mean train loss after  13000 batches of 2  epochs =0.114818374643
Mean train loss after  13100 batches of 2  epochs =0.115097631077
Mean train loss after  13200 batches of 2  epochs =0.115078608535
Mean train loss after  13300 batches of 2  epochs =0.115341834181
Mean train loss after  13400 batches of 2  epochs =0.115472233849
Mean train loss after  13500 batches of 2  epochs =0.115458543997
Mean train loss after  13600 batches of 2  epochs =0.115626747158
Mean train loss after  13700 batches of 2  epochs =0.115542572441
Mean train loss after  13800 batches of 2  epochs =0.115703938891
Mean train loss after  13900 batches of 2  epochs =0.11566331225
Mean train loss after  14000 batches of 2  epochs =0.115695996449
Mean train loss after  14100 batches of 2  epochs =0.115945658474
Mean train loss after  14200 batches of 2  epochs =0.116091185924
Mean train loss after  14300 batches of 2  epochs =0.116185272526
Mean train loss after  14400 batches of 2  epochs =0.116282572985
Mean train loss after  14500 batches of 2  epochs =0.116318197445
Mean train loss after  14600 batches of 2  epochs =0.116334731457
Mean train loss after  14700 batches of 2  epochs =0.116604185349
Mean train loss after  14800 batches of 2  epochs =0.116688517384
Mean train loss after  14900 batches of 2  epochs =0.116808857911
Epoch 2 : Mean train epoch loss =0.116767066532
Epoch 2 Epoch val loss = 12902.6254056
Epoch 2 Epoch val perplexity = 1.3010040356103518
SCORES =  (92.75, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 3---------------------

=================================
fscore(z) =  [167.50679] || goldscore = [166.73271]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-3.81	1.03	0.02	-1.87	0.10	-0.67	-0.18	-0.88	-0.60	-0.62	0.41	0.24	0.35	-0.61	1.16	-3.53	-0.67	-1.31	-3.60	-0.14	0.09	-2.25	-1.16	-2.22	-1.83	0.57	-3.33	-1.24	0.36	0.80	-0.59	0.13	-0.24	-1.16	-0.95	-2.05	-2.37	0.17	-1.14	-1.51	-2.25	-2.45	-1.10	-0.41	-2.16	-1.16	-100000000.00	-1.46	
VBG 	-1.30	-1.23	0.13	0.20	0.09	0.95	-3.48	0.44	-0.30	-1.82	-2.62	-0.30	0.10	-0.92	-0.53	-1.95	0.35	-0.02	-3.00	-5.00	-2.66	-1.45	-0.89	-1.28	-4.28	-0.20	-0.80	0.13	-2.55	1.03	-2.56	0.26	-1.84	-0.96	-1.53	-1.23	-1.72	-0.57	-1.41	-3.50	-1.74	-1.26	-1.05	-0.36	-2.50	-2.99	-100000000.00	-0.91	
VBD 	-1.80	-1.28	-2.94	-1.36	-2.27	0.33	-1.06	-1.05	0.77	-1.28	0.58	-1.39	1.00	-0.83	-1.01	-2.34	0.38	-0.21	-0.87	-1.16	-1.30	-1.26	-2.21	-1.18	-2.16	-0.05	-1.10	0.88	1.31	-1.37	-2.67	-1.31	-4.76	0.43	-0.74	-1.17	-0.19	-2.38	-1.93	-2.75	-0.99	-0.42	0.34	-1.11	-1.22	-1.75	-100000000.00	0.65	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-1.88	-0.43	-0.78	-0.70	-1.06	-1.06	-2.47	0.08	-0.69	-1.41	-1.18	-0.11	0.29	-0.41	-0.35	-2.39	-0.26	-1.58	-0.24	-1.54	-0.90	-2.76	-1.20	-1.50	-2.51	0.50	-0.10	0.01	-1.43	0.78	-0.58	-0.82	-3.53	-0.40	-0.04	-1.58	-3.29	-0.78	-0.65	-2.29	-3.54	-1.24	-2.26	-0.86	0.36	-5.66	-100000000.00	-1.85	
, 	-0.57	-0.67	0.99	-1.34	-0.26	-1.16	-0.75	0.12	0.21	0.72	-0.40	-1.00	-1.33	-0.12	-0.76	-3.15	0.48	-0.16	-1.52	-0.86	0.74	-1.32	-2.65	-1.58	-0.33	-1.00	-3.32	-0.27	-0.57	-0.31	-2.67	0.20	-4.04	0.51	-1.32	1.28	-1.05	-0.40	-3.46	-3.13	-1.11	0.96	-0.47	-0.57	-2.51	-0.98	-100000000.00	1.03	
'' 	-0.38	-0.03	-1.58	-0.81	-3.06	-0.26	-0.33	-2.85	-2.33	-3.95	-1.64	-1.97	-4.67	-3.55	-0.14	-0.60	0.32	-0.92	-2.34	-1.34	-1.85	0.17	-2.06	-0.33	-2.13	-0.14	-1.29	-2.03	-1.99	-0.30	-0.77	-0.31	-1.32	-0.39	-2.14	-1.86	-1.32	-0.59	-0.36	-0.30	-3.13	-2.46	-0.81	-3.24	-1.88	-2.24	-100000000.00	-0.60	
VBP 	-3.94	-0.99	-6.04	-3.26	-2.17	-0.71	-0.64	-0.30	-0.20	-2.88	0.37	-1.65	-1.08	-0.80	-2.33	0.09	-1.69	0.65	0.06	-3.30	-4.19	-1.11	-1.79	-2.97	-3.21	0.04	-2.50	0.95	-0.37	-1.68	-1.53	-1.14	-2.29	-1.09	-0.69	-0.86	-0.10	-4.21	-0.38	-1.26	-2.15	0.36	-2.65	-2.17	-1.02	-2.61	-100000000.00	-0.47	
WDT 	-3.05	-2.13	-2.75	-2.66	-3.09	-0.74	-1.75	-1.49	-2.51	-1.53	-1.16	-3.02	-1.24	-0.98	-0.42	-1.74	0.11	-0.03	-1.56	-2.46	-0.58	-1.64	-0.62	-0.21	-0.38	-1.37	0.03	0.82	-2.83	-1.32	-0.67	-0.30	-1.16	-0.55	-0.98	-1.42	-2.98	-1.46	0.56	-1.64	-3.27	-1.84	-1.95	-1.07	-2.04	-1.78	-100000000.00	0.01	
JJ 	0.10	0.87	0.25	0.53	0.05	-1.06	-2.36	0.29	-1.09	-0.13	-2.89	0.48	-0.09	-0.90	-0.49	-0.71	-0.71	-0.63	-0.93	-1.94	0.16	-2.45	-1.41	-0.62	-3.67	-0.04	-0.41	-1.19	-0.86	0.25	0.43	0.29	-2.02	-0.44	0.57	-0.02	-2.68	0.65	-1.16	-3.07	-0.53	-2.08	-1.27	-0.04	-1.18	-1.83	-100000000.00	-0.74	
WP 	-2.60	-1.21	-0.13	-0.40	0.00	-0.50	-2.15	-3.53	-2.40	-1.05	-3.15	-1.82	-0.74	-0.80	-1.33	-2.28	-1.40	-0.94	-0.39	-1.60	0.28	-1.28	-1.51	-0.41	0.01	-1.38	-2.09	1.56	-0.54	-1.23	-2.04	-1.46	-1.80	1.45	-1.38	-1.96	-0.08	-0.48	-0.18	0.27	0.12	-0.18	-2.26	-1.48	-2.95	-1.69	-100000000.00	0.27	
VBZ 	-1.02	-1.80	-2.49	-3.04	-1.25	0.21	-1.53	-0.30	0.65	-0.96	1.20	-1.06	-0.34	-1.45	-2.19	-3.13	1.04	-1.67	-0.84	-1.34	-1.37	-1.65	-2.02	-0.09	-2.82	0.29	-0.91	-1.26	0.48	-1.86	-1.40	-0.78	-5.11	-1.12	-3.38	-0.75	1.89	-2.21	-1.04	-1.41	-1.92	-2.42	-1.03	-2.15	-1.58	-3.23	-100000000.00	0.58	
DT 	-2.50	0.30	0.60	0.38	0.01	1.67	-1.24	0.54	-0.32	-0.51	-1.51	0.50	-1.31	-0.16	1.09	-2.44	-0.68	-1.42	-0.07	-0.89	-0.71	-1.42	0.75	-1.09	-2.30	-0.18	-0.79	-1.46	-0.48	1.06	-0.76	0.97	1.00	-2.41	0.78	-1.44	-3.31	0.84	-0.48	-1.08	-1.61	-1.68	-1.39	-2.14	-0.07	-2.04	-100000000.00	-1.57	
" 	-1.85	0.08	-1.22	-1.19	0.20	0.24	-0.74	-1.63	-2.06	-1.74	0.74	-0.38	-2.51	-1.71	1.33	-1.15	-0.45	-1.44	-2.25	-1.12	-0.80	2.16	-0.39	1.10	-1.29	-1.01	-0.92	-0.82	-1.75	-0.93	-0.87	-2.24	-1.43	-0.83	-0.57	-1.54	-1.93	-1.10	-1.47	2.33	-0.94	-0.45	-3.14	-1.57	-2.30	-2.00	-100000000.00	-0.16	
RP 	-3.65	0.75	0.60	-2.58	0.42	-1.25	-0.75	0.49	-3.77	-1.22	-0.91	-0.76	-0.01	-2.55	-0.04	-1.81	-0.73	-1.50	-2.26	-1.07	-4.43	0.04	-4.85	-0.75	-2.16	0.00	-4.75	-1.11	-0.64	0.87	-2.23	-1.83	-1.59	-0.79	-3.59	-1.43	-0.46	-1.50	0.28	-0.53	-3.74	-0.72	-1.29	-0.49	-1.36	-0.67	-100000000.00	-2.48	
$ 	-0.99	0.12	0.24	-3.71	-1.11	-2.85	-2.09	-1.99	-2.37	-1.10	-2.70	-0.00	-0.36	-2.20	-0.15	-0.78	-0.06	-0.34	-0.04	0.59	0.10	-0.81	-0.87	0.90	-1.67	-0.02	-0.83	-0.69	-0.76	-1.41	-0.41	-0.74	-1.49	-2.03	-1.80	-2.39	0.36	-0.95	0.78	-0.55	-0.62	-1.30	-1.01	-0.46	-0.12	-0.56	-100000000.00	-1.42	
NN 	0.80	0.38	-0.86	0.55	-0.15	0.22	-0.80	-0.49	-0.90	1.01	-2.29	-0.22	-0.66	-0.52	0.27	-1.68	0.35	-0.89	-1.09	-0.71	0.62	-2.55	-0.55	-3.78	-3.46	-2.06	0.24	-1.35	-1.24	0.24	-0.79	-0.17	-3.46	-2.65	-1.16	-0.31	-4.79	-0.14	-0.32	-4.10	-1.56	-0.90	1.23	-0.34	0.02	-5.23	-100000000.00	-0.29	
) 	-3.48	-0.58	-1.77	-3.48	-0.70	-3.87	-3.16	-1.83	-2.94	-0.25	-2.59	-2.21	-2.02	-2.73	-0.23	-2.96	-0.33	-2.31	0.57	-1.22	0.28	-2.41	-3.24	-2.30	-0.51	-2.00	-2.36	-0.82	-3.21	-0.22	0.89	-1.99	-3.52	-0.83	-1.24	-2.78	-1.14	-1.51	-0.38	-1.46	-2.86	0.59	-1.14	-2.13	-2.28	-3.80	-100000000.00	-1.42	
( 	-0.74	-0.97	-2.32	-0.75	-0.26	-1.66	-0.58	-5.01	-1.02	-0.04	0.28	-0.46	-0.98	-1.32	-2.94	-1.35	0.01	-1.66	-1.58	-0.61	-1.23	-0.69	-1.67	0.62	-2.77	-2.14	-1.89	-0.62	-0.30	-1.07	-1.07	-1.56	-1.89	-1.02	-1.41	0.24	-0.89	-1.86	-2.06	-1.54	-2.32	-0.47	-0.30	-0.77	-2.48	-3.58	-100000000.00	-0.04	
FW 	-3.52	-4.22	-1.52	-1.57	-3.70	-1.32	-0.69	-0.48	-1.63	-1.02	-2.56	-4.68	-2.95	-2.66	-1.58	-0.54	-0.40	-1.11	0.36	1.13	-2.31	-0.96	-0.72	0.71	-1.55	-2.45	-1.64	-2.49	-2.79	-0.38	-2.00	-0.62	-2.33	0.34	-0.48	-1.31	-1.02	-2.46	0.04	-0.69	-2.65	-0.94	-1.36	-2.34	-1.62	-2.10	-100000000.00	-0.78	
POS 	-1.38	-1.33	-1.94	-2.29	-1.41	-1.16	-1.07	-2.40	-1.26	-0.83	-2.92	-1.91	-0.02	-2.24	-1.56	-1.33	-0.49	-0.99	0.26	-0.81	-1.99	0.50	-4.17	-0.98	-1.66	-1.73	-3.00	-0.87	0.53	-0.97	-2.13	-3.03	-1.14	-1.13	-2.59	-1.85	-0.98	-2.28	-1.24	-1.70	-1.48	-1.45	-0.09	-3.42	-2.34	-1.77	-100000000.00	-1.51	
. 	-2.19	1.00	0.12	-3.58	0.62	-3.73	-2.15	-0.31	-0.63	-2.03	-1.38	-0.31	-2.62	-0.36	-0.20	-2.13	-0.58	-0.79	-1.67	-2.70	-1.08	-2.30	-0.42	0.01	0.90	0.63	-1.12	0.66	-1.13	0.03	-2.81	-3.56	-3.64	-1.95	0.40	-0.92	-0.59	-1.88	-2.32	-3.42	-2.67	-0.38	-3.04	-0.15	-5.29	-0.10	-100000000.00	-0.07	
TO 	-0.98	-0.85	0.91	-1.06	-0.91	-1.93	-2.32	0.66	-4.06	0.83	-3.08	-0.21	0.14	-2.29	-0.00	-3.98	-0.16	-1.01	-0.65	-2.72	-3.59	-2.31	-2.40	-1.53	-4.08	-1.47	-2.17	-1.53	-0.24	0.46	-1.92	-1.01	-3.80	-1.68	0.53	-1.81	-0.92	-1.46	-2.64	-2.31	-2.46	-1.53	-0.83	-0.25	-1.89	-2.29	-100000000.00	-1.33	
-X- 	-0.69	-0.68	-1.59	-0.48	-1.95	-1.64	0.10	-0.51	1.23	-1.28	-1.01	-3.23	-1.75	-1.75	-1.27	0.15	-1.52	0.01	-1.25	-0.31	-1.37	0.55	-1.78	0.78	-0.17	-1.15	-0.36	-0.44	0.57	-1.61	-0.40	-0.37	1.39	0.27	-0.48	-1.43	1.37	-1.84	0.74	0.37	1.66	-0.75	0.86	-0.38	-0.96	-1.43	-100000000.00	-1.43	
LS 	-1.83	-1.04	-3.34	-1.14	-1.55	-0.96	-1.18	-1.38	-1.14	-3.52	-1.07	-2.11	-4.65	-1.95	-1.72	-3.27	-3.51	-1.93	-0.58	-1.93	-1.74	-0.59	-3.07	-0.08	-1.53	-1.34	0.06	-2.56	1.19	-1.27	-1.65	-1.17	-0.78	-0.05	-1.55	-3.07	-1.35	-4.07	0.34	-2.00	-1.09	-1.07	-1.09	-1.63	-1.10	-2.98	-100000000.00	-2.18	
RB 	-0.82	0.20	-0.08	-0.03	-0.53	0.16	-2.15	-0.41	-0.46	-1.60	-2.67	0.53	0.61	-0.76	0.20	-1.12	-0.53	-0.15	-1.45	-4.56	-0.68	-2.87	-1.20	-1.00	-2.44	-0.73	-2.22	-0.13	-1.53	-0.06	-0.73	-0.52	-1.60	0.82	0.46	-0.66	-1.29	-0.72	-1.63	-1.97	0.95	-2.19	-1.06	-0.62	-0.93	-2.92	-100000000.00	-1.17	
: 	-1.01	-0.62	-0.86	-1.94	-0.46	-0.08	-2.80	-1.46	-0.53	-0.64	-1.75	0.21	-1.94	-1.04	-0.66	-1.42	1.19	-0.48	-0.20	-3.61	-0.69	-2.20	-1.72	-0.15	-0.67	-0.09	-1.64	0.25	-0.99	-0.01	-3.41	-2.59	-3.44	-0.70	-1.88	0.88	-0.98	-1.79	-2.11	-0.62	-3.11	-2.21	-1.41	-0.52	-1.32	-3.97	-100000000.00	-2.42	
NNS 	-1.24	0.52	-0.26	0.65	0.37	-0.44	-1.49	-0.28	-0.20	1.21	-1.09	-0.60	0.45	0.35	0.08	-3.24	0.91	-0.78	-0.57	-0.08	0.60	-3.48	-2.40	-3.05	-4.51	-2.19	1.56	-1.94	-0.86	0.08	-0.98	-1.01	-2.01	-0.70	-1.85	-0.26	-5.18	-0.31	1.04	-2.65	-1.03	-2.21	-0.14	1.28	-0.55	-4.60	-100000000.00	-0.60	
PRP 	-3.56	0.25	-1.20	-0.50	-0.87	0.32	-0.11	0.22	-1.47	-1.43	-0.85	0.26	-2.46	0.41	-4.39	-2.39	-1.12	-2.14	-1.67	-0.86	-0.16	-2.03	-0.55	-0.86	-1.85	0.45	-0.74	-1.29	-0.98	0.42	-0.88	-0.82	-1.81	-1.40	-2.06	-3.12	-0.86	1.47	-1.45	-3.83	-1.13	-4.80	-0.93	-3.48	-1.10	-0.40	-100000000.00	-2.03	
VB 	-1.35	-1.88	-1.47	-0.06	-2.27	-0.90	-0.24	-2.17	-0.05	-1.86	-0.62	-0.88	-1.13	-1.32	-0.09	-3.03	-0.57	0.05	-1.92	-1.61	-1.76	-2.29	1.17	-2.05	-2.52	0.63	-0.59	-1.55	-0.42	-1.41	-2.22	-0.22	-1.35	-1.93	-0.25	-1.25	-2.81	-1.72	-0.85	-3.29	2.32	-1.68	-1.01	-0.53	-2.51	-2.66	-100000000.00	-1.09	
WRB 	-1.94	-0.84	-1.83	-1.42	-0.59	-1.42	-1.97	-1.47	-0.75	-1.42	-0.87	-0.36	-0.21	-1.96	-3.01	-0.08	0.32	0.29	-2.25	-1.48	0.10	-1.75	-0.86	0.26	-0.18	-0.30	-1.71	-0.89	-1.10	-0.83	-2.17	-0.41	-1.67	-2.67	-0.56	-1.06	-1.72	-0.65	0.40	-0.04	-3.75	-3.57	-2.14	-2.52	-0.66	-1.18	-100000000.00	0.64	
CC 	-2.43	-0.12	-0.69	-0.96	0.96	-0.57	-3.06	-2.31	-2.48	0.65	-2.50	-0.15	-1.06	-0.59	-0.51	-1.71	0.39	0.52	-1.67	-1.78	-1.50	-1.28	-2.95	-0.71	-2.06	-0.01	-0.20	-0.28	-0.27	-0.07	-4.89	-1.32	-4.25	-1.67	-0.99	-2.03	-0.74	-1.12	-1.57	-0.47	-2.30	-0.07	-0.59	-2.69	-0.38	-3.38	-100000000.00	0.34	
PDT 	-1.10	-1.27	-0.94	-1.27	-1.06	-1.73	-0.24	-1.66	-0.57	-1.43	0.20	-1.11	-3.81	-3.66	0.44	-2.22	-1.63	-3.43	-1.14	-1.43	-3.22	-0.97	-0.93	0.64	-1.54	-1.25	-1.71	-3.49	-2.59	-1.00	-0.96	-1.28	-1.70	-2.42	-1.65	-1.51	-1.91	-0.56	-1.24	1.24	-2.31	0.66	-0.30	-2.40	-2.36	-0.64	-100000000.00	-2.36	
RBS 	1.95	-0.41	-0.59	-3.18	-0.83	-1.07	-0.78	0.09	-1.81	-3.46	-0.63	-1.45	0.85	-2.03	-1.35	-1.09	-0.89	-1.60	-0.37	-1.58	1.92	-0.19	-2.98	-0.67	-1.40	-1.89	0.70	-1.70	-1.34	-1.53	-0.68	-1.71	-0.64	-1.42	-1.32	-2.99	-1.40	-0.96	0.03	-0.97	-2.99	-1.39	-1.07	0.50	-2.46	-2.62	-100000000.00	-4.15	
RBR 	-3.05	-1.58	-0.46	-0.15	0.39	-2.27	-0.48	-0.64	-1.37	-0.96	-3.89	0.95	-0.57	0.37	0.77	-2.09	0.66	-1.61	-3.12	-1.32	-2.49	-1.84	-1.98	-0.76	-0.38	0.51	-1.79	0.23	0.76	0.68	-0.08	-0.49	-2.88	-2.00	-1.58	-0.56	-1.86	-0.92	-1.01	-2.40	-1.20	-2.42	-1.32	-0.32	-1.05	-1.14	-100000000.00	-1.36	
CD 	-0.68	-0.30	-0.16	-0.23	-0.52	0.39	-0.51	-1.03	-1.56	-0.90	-2.16	0.10	0.69	0.29	-0.95	1.37	-0.76	0.13	-0.93	-1.39	-0.03	-3.29	0.23	-1.52	-4.09	-0.87	-0.13	-1.05	-2.06	-0.12	-1.29	-1.40	-3.10	-2.84	-4.22	-1.19	-5.49	-0.47	-0.32	-0.52	-3.52	-0.27	-0.61	-0.45	-0.32	-1.47	-100000000.00	-0.21	
EX 	0.45	0.63	-1.70	-1.11	1.18	-0.48	0.11	0.04	-0.41	-1.27	-1.61	-2.14	-1.77	-0.05	-0.36	-0.20	-0.84	-1.82	-1.75	-0.79	-4.32	-1.09	-2.21	-0.79	-0.96	-1.23	-3.08	-1.84	0.21	0.95	-0.57	-0.68	-0.18	-1.56	0.91	-1.90	-1.34	-0.98	-2.00	-2.81	-0.69	-1.24	-0.36	-0.25	-0.01	-0.37	-100000000.00	-2.14	
IN 	-2.22	0.56	0.05	0.78	0.56	-0.56	-0.71	-0.53	-0.84	-1.11	-2.87	0.84	-0.37	0.30	1.02	-1.40	0.77	0.66	-1.82	-3.79	-0.50	-2.58	-0.93	-1.72	-1.79	-0.43	-1.07	0.22	-0.36	-0.48	-1.48	-0.29	-2.06	-2.11	-0.25	-0.23	-1.66	-0.23	-0.83	-5.39	-1.80	-0.74	0.87	0.80	-0.12	-5.86	-100000000.00	0.59	
WP$ 	-2.08	-1.82	-1.68	-3.51	-1.56	0.27	0.50	-0.81	-1.09	-1.77	0.39	-0.62	-1.68	-1.10	0.71	-0.61	-0.86	-1.70	-0.58	-0.47	-2.39	0.31	0.39	1.30	-1.14	-0.19	-1.34	-0.42	-3.62	-1.71	-0.04	-1.16	-0.01	-2.36	-0.94	-0.79	0.12	1.20	-2.08	0.24	-1.20	-2.09	-1.46	0.42	-1.51	-2.68	-100000000.00	-0.43	
NN|SYM 	-1.38	-1.12	-3.08	-4.20	-2.76	-2.10	1.42	-1.15	-1.37	-2.59	-0.76	-2.11	-0.72	-4.06	-2.27	-0.73	-4.09	0.71	-1.83	-1.54	-0.90	-2.39	-2.44	-0.87	0.32	-3.66	-1.77	-2.53	-2.99	0.28	-0.75	-1.19	1.18	-1.24	0.70	-3.48	-1.62	-0.86	0.26	-0.54	-1.05	-1.20	-0.21	0.17	-0.37	-2.52	-100000000.00	-4.20	
MD 	-2.59	-0.81	-1.33	-4.18	-0.75	-0.66	0.54	-0.24	0.04	-2.04	-1.55	-1.78	-0.64	0.14	-0.61	-2.91	-0.00	-0.36	-3.12	-1.37	-1.90	-3.44	-3.60	0.12	-0.20	-1.04	-2.56	0.24	0.40	-1.90	-1.84	-1.53	-1.60	-2.16	-1.35	-1.84	0.37	-1.27	-0.88	-1.68	-4.40	-2.48	-1.57	-3.67	-1.47	-1.81	-100000000.00	-0.42	
NNPS 	-2.03	-1.08	-1.25	-1.39	-2.31	-1.53	-0.14	-0.32	-0.60	-0.71	-3.02	-2.32	0.44	-1.36	-1.75	0.17	-1.62	-2.07	0.38	-4.22	-2.65	0.06	-2.96	-1.51	-1.53	-5.29	-0.45	-2.48	-4.27	-1.25	-1.56	-1.10	-1.57	0.10	-0.91	0.12	-4.97	-0.49	-1.77	-0.89	-2.45	-0.88	-3.39	-3.55	-1.08	-3.32	-100000000.00	1.03	
JJS 	0.40	-4.42	-1.32	-2.39	-1.95	-0.47	-2.19	-3.74	-1.82	-2.04	-1.95	-2.02	-1.26	-1.06	-1.15	-2.55	-2.05	-2.27	0.06	-2.59	-1.13	-0.88	-0.80	0.13	-1.71	-2.82	-3.38	-1.98	-2.84	-2.56	-0.51	-0.53	-0.62	-1.26	-2.07	-1.73	-1.83	-0.60	-1.65	-0.81	0.45	-1.26	-2.83	0.76	-2.66	-2.76	-100000000.00	-2.31	
JJR 	-1.35	-0.31	-0.09	-0.04	-1.32	-2.18	-1.25	-1.48	-0.30	-1.36	-1.24	-0.21	-1.85	-2.38	-0.82	-0.46	-0.24	-2.49	0.28	-1.19	-1.41	-1.67	-1.26	-0.83	-2.03	-0.10	-1.77	-0.68	-0.86	0.60	0.12	-1.05	-0.51	-0.84	-0.78	-0.83	-0.15	0.16	-1.76	-2.01	-0.32	0.04	-1.24	-1.73	0.13	-1.08	-100000000.00	-1.61	
SYM 	-3.11	-2.89	-2.26	-0.77	-2.56	-4.05	-0.29	0.13	-4.03	0.10	-1.63	-3.44	-5.05	-1.79	-3.52	-1.72	-0.23	-0.33	-2.25	-3.78	-2.12	-1.04	-1.30	-1.88	-3.49	-2.85	-2.11	-0.06	-2.06	-1.36	-0.26	-1.14	-0.86	-0.77	-1.17	-0.18	-1.58	-2.04	-0.19	-0.45	-0.99	-3.35	-2.06	-3.00	-1.17	-1.61	-100000000.00	-0.08	
UH 	-2.49	-2.63	-3.47	-0.71	-2.08	1.05	-0.76	-2.40	-0.10	-5.22	-0.74	-2.18	-5.25	0.03	-1.27	0.60	-6.76	-3.95	-2.87	-0.26	-4.07	0.30	-4.42	-0.69	-2.41	-3.51	-4.23	-4.40	-1.54	-4.76	-1.84	-4.84	-2.50	-1.53	-3.28	-7.73	-2.99	-1.86	-0.41	-0.07	-4.50	-3.06	-1.09	-1.45	-1.54	-0.95	-100000000.00	-3.58	
stop_tag 	-3.46	-4.08	-1.36	-0.52	-0.61	-2.82	1.92	-1.42	-4.66	-0.11	-2.67	-1.82	-1.44	-1.85	-1.74	-3.38	0.65	-1.64	-3.17	-0.77	-1.06	-1.29	-1.66	0.09	-2.67	-1.51	0.02	0.23	-1.49	-1.71	-2.43	-2.79	-4.45	-1.39	-5.44	-0.66	-3.78	-1.81	-1.25	-2.05	-3.42	-0.43	-4.40	-5.18	0.13	-2.02	-100000000.00	-0.16	
NNP 	-0.92	0.31	-0.17	0.54	0.43	0.60	0.25	-0.23	-1.41	-0.15	-1.68	-0.31	0.70	0.87	-0.62	-1.21	0.11	-0.63	-0.59	0.06	-0.84	-2.60	0.42	-1.48	-2.93	-2.19	0.41	-1.29	-2.56	0.83	-1.00	-0.76	-5.44	-1.30	-1.59	-0.54	-4.71	-0.15	-1.28	-3.97	-1.32	-0.28	-0.00	-0.52	0.42	-1.20	-100000000.00	1.87	
Mean train loss after  0 batches of 3  epochs =0.0516052246094
Mean train loss after  100 batches of 3  epochs =0.0682448527256
Mean train loss after  200 batches of 3  epochs =0.0747894766695
Mean train loss after  300 batches of 3  epochs =0.0751197785754
Mean train loss after  400 batches of 3  epochs =0.0695533762685
Mean train loss after  500 batches of 3  epochs =0.0694316475044
Mean train loss after  600 batches of 3  epochs =0.0688339651769
Mean train loss after  700 batches of 3  epochs =0.0672309877257
Mean train loss after  800 batches of 3  epochs =0.0668120627402
Mean train loss after  900 batches of 3  epochs =0.0651005409946
Mean train loss after  1000 batches of 3  epochs =0.0659644378523
Mean train loss after  1100 batches of 3  epochs =0.0662315490338
Mean train loss after  1200 batches of 3  epochs =0.0654242160462
Mean train loss after  1300 batches of 3  epochs =0.0668269090304
Mean train loss after  1400 batches of 3  epochs =0.0672053784604
Mean train loss after  1500 batches of 3  epochs =0.0666609239332
Mean train loss after  1600 batches of 3  epochs =0.0658845266031
Mean train loss after  1700 batches of 3  epochs =0.0671246743324
Mean train loss after  1800 batches of 3  epochs =0.0659871873074
Mean train loss after  1900 batches of 3  epochs =0.0660801812781
Mean train loss after  2000 batches of 3  epochs =0.065941404745
Mean train loss after  2100 batches of 3  epochs =0.0655608610807
Mean train loss after  2200 batches of 3  epochs =0.0661951227262
Mean train loss after  2300 batches of 3  epochs =0.066268700713
Mean train loss after  2400 batches of 3  epochs =0.0670233896246
Mean train loss after  2500 batches of 3  epochs =0.0667568940721
Mean train loss after  2600 batches of 3  epochs =0.0672524942713
Mean train loss after  2700 batches of 3  epochs =0.0662862398732
Mean train loss after  2800 batches of 3  epochs =0.0660854694873
Mean train loss after  2900 batches of 3  epochs =0.0653947575244
Mean train loss after  3000 batches of 3  epochs =0.0652600300793
Mean train loss after  3100 batches of 3  epochs =0.0654982002605
Mean train loss after  3200 batches of 3  epochs =0.0654969877706
Mean train loss after  3300 batches of 3  epochs =0.065752916397
Mean train loss after  3400 batches of 3  epochs =0.0655880119616
Mean train loss after  3500 batches of 3  epochs =0.0660023443353
Mean train loss after  3600 batches of 3  epochs =0.0653099792381
Mean train loss after  3700 batches of 3  epochs =0.0655146975408
Mean train loss after  3800 batches of 3  epochs =0.0652872506539
Mean train loss after  3900 batches of 3  epochs =0.0651450604165
Mean train loss after  4000 batches of 3  epochs =0.0657822165506
Mean train loss after  4100 batches of 3  epochs =0.0660289342694
Mean train loss after  4200 batches of 3  epochs =0.0658765265548
Mean train loss after  4300 batches of 3  epochs =0.0663297452087
Mean train loss after  4400 batches of 3  epochs =0.066535205024
Mean train loss after  4500 batches of 3  epochs =0.0666407083523
Mean train loss after  4600 batches of 3  epochs =0.0673008803463
Mean train loss after  4700 batches of 3  epochs =0.0673628307394
Mean train loss after  4800 batches of 3  epochs =0.0672928878609
Mean train loss after  4900 batches of 3  epochs =0.0673649325662
Mean train loss after  5000 batches of 3  epochs =0.067252047596
Mean train loss after  5100 batches of 3  epochs =0.0674882656677
Mean train loss after  5200 batches of 3  epochs =0.0676870301961
Mean train loss after  5300 batches of 3  epochs =0.0676411236406
Mean train loss after  5400 batches of 3  epochs =0.068060806495
Mean train loss after  5500 batches of 3  epochs =0.0680298952583
Mean train loss after  5600 batches of 3  epochs =0.0681793321765
Mean train loss after  5700 batches of 3  epochs =0.0679323635741
Mean train loss after  5800 batches of 3  epochs =0.0678209856409
Mean train loss after  5900 batches of 3  epochs =0.0680712401841
Mean train loss after  6000 batches of 3  epochs =0.0681268701375
Mean train loss after  6100 batches of 3  epochs =0.0682121328706
Mean train loss after  6200 batches of 3  epochs =0.0682718038163
Mean train loss after  6300 batches of 3  epochs =0.0683662684017
Mean train loss after  6400 batches of 3  epochs =0.0685105599513
Mean train loss after  6500 batches of 3  epochs =0.0687340631302
Mean train loss after  6600 batches of 3  epochs =0.0690924468786
Mean train loss after  6700 batches of 3  epochs =0.0690633924924
Mean train loss after  6800 batches of 3  epochs =0.0695445074444
Mean train loss after  6900 batches of 3  epochs =0.0696949830395
Mean train loss after  7000 batches of 3  epochs =0.0695707584525
Mean train loss after  7100 batches of 3  epochs =0.0696402297149
Mean train loss after  7200 batches of 3  epochs =0.0695009905001
Mean train loss after  7300 batches of 3  epochs =0.0695210053101
Mean train loss after  7400 batches of 3  epochs =0.0695588413502
Mean train loss after  7500 batches of 3  epochs =0.0698578167234
Mean train loss after  7600 batches of 3  epochs =0.0702280815048
Mean train loss after  7700 batches of 3  epochs =0.0702402138932
Mean train loss after  7800 batches of 3  epochs =0.0705457079808
Mean train loss after  7900 batches of 3  epochs =0.0706993358262
Mean train loss after  8000 batches of 3  epochs =0.0707650643064
Mean train loss after  8100 batches of 3  epochs =0.0705720914261
Mean train loss after  8200 batches of 3  epochs =0.0707576501145
Mean train loss after  8300 batches of 3  epochs =0.0708542637571
Mean train loss after  8400 batches of 3  epochs =0.0708551419178
Mean train loss after  8500 batches of 3  epochs =0.070628334411
Mean train loss after  8600 batches of 3  epochs =0.0706450618159
Mean train loss after  8700 batches of 3  epochs =0.0705171752171
Mean train loss after  8800 batches of 3  epochs =0.0705104853959
Mean train loss after  8900 batches of 3  epochs =0.0709187207175
Mean train loss after  9000 batches of 3  epochs =0.0709208863758
Mean train loss after  9100 batches of 3  epochs =0.0710980539763
Mean train loss after  9200 batches of 3  epochs =0.0711944232457
Mean train loss after  9300 batches of 3  epochs =0.0712711347703
Mean train loss after  9400 batches of 3  epochs =0.0714489807231
Mean train loss after  9500 batches of 3  epochs =0.0716277868933
Mean train loss after  9600 batches of 3  epochs =0.0715945043953
Mean train loss after  9700 batches of 3  epochs =0.0716421333088
Mean train loss after  9800 batches of 3  epochs =0.0717220553525
Mean train loss after  9900 batches of 3  epochs =0.0720189311192
Mean train loss after  10000 batches of 3  epochs =0.0719587896561
Mean train loss after  10100 batches of 3  epochs =0.0720549797807
Mean train loss after  10200 batches of 3  epochs =0.0721162257291
Mean train loss after  10300 batches of 3  epochs =0.0722913260746
Mean train loss after  10400 batches of 3  epochs =0.0724080074364
Mean train loss after  10500 batches of 3  epochs =0.0723604346817
Mean train loss after  10600 batches of 3  epochs =0.0725966232557
Mean train loss after  10700 batches of 3  epochs =0.0727306966649
Mean train loss after  10800 batches of 3  epochs =0.0727336990184
Mean train loss after  10900 batches of 3  epochs =0.0728429070902
Mean train loss after  11000 batches of 3  epochs =0.0729354137545
Mean train loss after  11100 batches of 3  epochs =0.0729286983854
Mean train loss after  11200 batches of 3  epochs =0.0732510752167
Mean train loss after  11300 batches of 3  epochs =0.0733261777737
Mean train loss after  11400 batches of 3  epochs =0.0736299894579
Mean train loss after  11500 batches of 3  epochs =0.0738407412725
Mean train loss after  11600 batches of 3  epochs =0.0740726750396
Mean train loss after  11700 batches of 3  epochs =0.0743595826477
Mean train loss after  11800 batches of 3  epochs =0.0745861005927
Mean train loss after  11900 batches of 3  epochs =0.0747798566828
Mean train loss after  12000 batches of 3  epochs =0.0748224499715
Mean train loss after  12100 batches of 3  epochs =0.0747831361449
Mean train loss after  12200 batches of 3  epochs =0.0748431636761
Mean train loss after  12300 batches of 3  epochs =0.0748645955993
Mean train loss after  12400 batches of 3  epochs =0.0748523220283
Mean train loss after  12500 batches of 3  epochs =0.0747499043014
Mean train loss after  12600 batches of 3  epochs =0.074866170247
Mean train loss after  12700 batches of 3  epochs =0.074999896193
Mean train loss after  12800 batches of 3  epochs =0.0749107626725
Mean train loss after  12900 batches of 3  epochs =0.0748109392979
Mean train loss after  13000 batches of 3  epochs =0.0749168810956
Mean train loss after  13100 batches of 3  epochs =0.0752884865768
Mean train loss after  13200 batches of 3  epochs =0.0750767847573
Mean train loss after  13300 batches of 3  epochs =0.0752321571443
Mean train loss after  13400 batches of 3  epochs =0.075418101335
Mean train loss after  13500 batches of 3  epochs =0.0753808354707
Mean train loss after  13600 batches of 3  epochs =0.0755053085617
Mean train loss after  13700 batches of 3  epochs =0.0755279047095
Mean train loss after  13800 batches of 3  epochs =0.075786319871
Mean train loss after  13900 batches of 3  epochs =0.0757434782788
Mean train loss after  14000 batches of 3  epochs =0.0757432553947
Mean train loss after  14100 batches of 3  epochs =0.0757130543235
Mean train loss after  14200 batches of 3  epochs =0.0756061294767
Mean train loss after  14300 batches of 3  epochs =0.0756424353172
Mean train loss after  14400 batches of 3  epochs =0.0759602727761
Mean train loss after  14500 batches of 3  epochs =0.0761660203833
Mean train loss after  14600 batches of 3  epochs =0.0764916823279
Mean train loss after  14700 batches of 3  epochs =0.0766575255274
Mean train loss after  14800 batches of 3  epochs =0.0767222748418
Mean train loss after  14900 batches of 3  epochs =0.0769384869348
Epoch 3 : Mean train epoch loss =0.0769750104379
Epoch 3 Epoch val loss = 13897.6693709
Epoch 3 Epoch val perplexity = 1.3276749311648504
SCORES =  (92.76, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 4---------------------

=================================
fscore(z) =  [175.08907] || goldscore = [174.7064]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-4.44	1.01	-0.06	-2.02	0.04	-0.98	-0.51	-0.96	-0.72	-0.73	-0.06	0.15	0.30	-0.68	1.21	-3.87	-0.95	-1.72	-3.89	-0.54	-0.26	-2.47	-1.16	-2.24	-2.08	0.46	-3.90	-1.35	0.04	0.91	-0.91	-0.16	-0.21	-1.58	-1.30	-2.40	-2.74	0.16	-1.29	-1.82	-2.69	-2.78	-1.52	-0.81	-2.55	-1.47	-100000000.00	-1.63	
VBG 	-1.45	-1.50	-0.01	0.26	0.05	0.92	-3.69	0.46	-0.79	-1.98	-2.84	-0.25	0.01	-1.09	-0.56	-2.18	0.35	-0.21	-3.06	-5.31	-2.85	-1.85	-1.07	-1.33	-4.64	-0.22	-1.01	0.10	-2.68	0.97	-2.70	0.16	-2.12	-1.15	-1.86	-1.46	-1.92	-0.60	-1.49	-3.70	-2.10	-1.39	-1.06	-0.79	-2.86	-3.47	-100000000.00	-1.03	
VBD 	-2.03	-1.62	-3.13	-1.58	-2.36	0.38	-1.39	-1.20	0.77	-1.35	0.58	-1.69	0.91	-1.09	-1.26	-2.55	0.45	-0.41	-1.07	-1.28	-1.49	-1.79	-2.54	-1.38	-2.38	-0.01	-1.42	0.96	1.32	-1.42	-2.68	-1.29	-5.25	0.42	-1.04	-1.30	-0.18	-2.58	-2.06	-3.09	-1.36	-0.59	0.16	-1.16	-1.58	-1.97	-100000000.00	0.63	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.15	-0.46	-0.84	-0.71	-1.32	-1.13	-3.07	0.12	-0.91	-1.54	-1.29	-0.02	0.23	-0.49	-0.46	-2.66	-0.28	-1.75	-0.25	-1.75	-1.02	-3.11	-1.47	-1.65	-2.76	0.61	-0.14	0.00	-1.45	0.65	-0.68	-0.89	-3.84	-0.55	-0.05	-1.75	-3.41	-0.82	-0.77	-2.67	-3.92	-1.33	-2.46	-1.09	0.04	-6.11	-100000000.00	-2.02	
, 	-0.67	-0.84	0.91	-2.15	-0.28	-1.83	-0.84	-0.12	0.07	0.75	-0.89	-1.10	-1.36	-0.33	-0.74	-3.69	0.42	-0.03	-1.83	-0.95	0.53	-1.77	-2.86	-1.78	-0.47	-1.14	-3.87	-0.33	-0.64	-0.35	-3.20	-0.01	-4.59	0.23	-1.32	1.37	-1.35	-0.38	-3.81	-3.55	-1.37	0.85	-0.96	-0.64	-3.02	-1.03	-100000000.00	0.98	
'' 	-0.83	-0.57	-1.87	-0.84	-3.78	-0.28	-0.45	-3.34	-2.70	-4.47	-1.91	-2.25	-5.27	-3.99	-0.39	-0.82	0.38	-1.19	-2.62	-1.67	-2.24	0.24	-2.34	-0.35	-2.34	-0.32	-1.37	-2.29	-2.42	-0.66	-1.13	-0.56	-1.63	-0.70	-2.50	-2.66	-1.40	-0.72	-0.47	-0.40	-3.54	-2.62	-0.98	-3.73	-2.20	-2.71	-100000000.00	-0.79	
VBP 	-4.63	-1.42	-6.60	-3.42	-2.61	-0.72	-0.66	-0.74	-0.17	-3.11	0.42	-2.12	-1.27	-1.21	-2.30	-0.25	-1.75	0.54	-0.39	-4.03	-4.33	-1.29	-2.02	-3.08	-3.45	-0.06	-2.84	0.97	-0.33	-1.84	-1.78	-1.29	-2.80	-1.33	-0.92	-0.79	-0.04	-4.47	-0.52	-1.67	-2.62	0.27	-3.17	-2.33	-1.26	-2.93	-100000000.00	-0.63	
WDT 	-3.34	-2.39	-2.94	-2.70	-3.37	-0.75	-1.79	-1.72	-2.98	-1.78	-1.31	-3.43	-1.54	-1.14	-0.86	-1.96	0.15	-0.17	-2.04	-2.81	-0.84	-1.71	-0.71	-0.27	-0.54	-1.58	-0.27	0.77	-2.96	-1.68	-0.99	-0.46	-1.33	-0.89	-1.24	-1.36	-3.21	-1.45	0.47	-1.85	-3.66	-2.02	-2.34	-1.46	-2.26	-2.09	-100000000.00	-0.04	
JJ 	-0.02	0.83	0.34	0.51	0.01	-1.16	-2.39	0.31	-1.35	-0.30	-3.23	0.30	-0.12	-0.97	-0.42	-0.84	-0.80	-0.62	-1.04	-2.04	0.19	-2.76	-1.41	-0.87	-4.17	-0.05	-0.46	-1.27	-0.93	0.27	0.38	0.25	-2.30	-0.34	0.57	0.05	-3.12	0.68	-1.16	-3.34	-0.77	-2.20	-1.29	-0.05	-1.29	-2.04	-100000000.00	-0.70	
WP 	-2.99	-1.28	-0.36	-0.43	-0.29	-0.86	-2.13	-3.58	-2.73	-1.14	-3.29	-1.77	-0.78	-0.83	-1.50	-2.54	-1.44	-1.16	-0.78	-2.07	-0.07	-1.43	-1.46	-0.50	-0.28	-1.53	-2.54	1.57	-1.01	-1.25	-2.35	-1.70	-1.98	1.15	-1.53	-2.21	-0.33	-0.52	-0.31	0.07	-0.30	-0.28	-2.56	-1.54	-3.28	-2.04	-100000000.00	0.25	
VBZ 	-1.38	-1.91	-2.86	-3.21	-1.56	0.21	-1.90	-0.58	0.62	-1.19	1.25	-1.34	-0.31	-1.79	-2.46	-3.22	1.07	-1.76	-0.85	-1.74	-1.49	-1.89	-2.49	-0.41	-3.17	0.22	-1.31	-1.32	0.55	-2.35	-1.60	-0.84	-5.47	-1.36	-3.80	-0.95	1.93	-2.53	-1.15	-1.77	-2.44	-2.62	-1.20	-2.35	-1.85	-3.82	-100000000.00	0.49	
DT 	-2.80	0.28	0.56	0.37	-0.01	1.52	-1.33	0.47	-0.49	-0.59	-1.82	0.42	-1.40	-0.37	1.08	-3.22	-0.71	-1.60	-0.20	-1.49	-0.90	-1.91	0.75	-1.37	-2.93	-0.32	-0.88	-1.60	-0.47	1.10	-0.82	0.96	0.92	-2.38	0.81	-1.70	-3.94	0.96	-0.62	-1.50	-1.70	-2.04	-1.72	-2.24	-0.01	-2.51	-100000000.00	-1.63	
" 	-2.00	-0.09	-1.30	-1.53	0.13	-0.04	-0.75	-1.78	-1.99	-1.83	0.57	-0.51	-2.55	-2.02	1.13	-1.29	-0.43	-1.53	-2.59	-1.53	-0.77	2.15	-0.62	0.86	-1.50	-1.23	-0.99	-1.01	-2.06	-1.08	-1.20	-2.47	-1.80	-1.19	-0.99	-1.76	-2.27	-1.23	-1.64	1.92	-1.25	-0.68	-3.48	-1.94	-2.59	-2.30	-100000000.00	-0.10	
RP 	-4.04	0.96	0.64	-3.02	0.48	-1.55	-1.05	0.46	-4.30	-1.50	-1.18	-0.89	-0.03	-3.19	-0.13	-2.23	-0.90	-1.62	-2.80	-1.46	-4.87	-0.18	-5.70	-0.90	-2.49	-0.22	-5.56	-1.32	-0.61	0.94	-2.61	-2.13	-1.79	-1.00	-3.88	-1.75	-0.87	-2.12	0.07	-1.05	-4.17	-0.95	-1.44	-0.98	-1.68	-1.07	-100000000.00	-2.63	
$ 	-1.16	0.15	-0.01	-4.08	-1.11	-3.00	-2.39	-2.20	-2.79	-1.07	-3.16	-0.10	-0.39	-2.61	-0.24	-1.06	-0.24	-0.57	-0.26	0.27	-0.14	-0.92	-0.98	0.82	-1.95	0.02	-0.98	-0.89	-0.91	-1.40	-0.60	-0.94	-1.86	-2.27	-2.11	-2.41	0.09	-1.06	0.59	-0.76	-1.00	-1.59	-1.24	-0.85	-0.41	-0.81	-100000000.00	-1.41	
NN 	0.81	0.33	-0.94	0.44	-0.15	0.14	-1.06	-0.46	-1.09	1.10	-2.39	-0.35	-0.66	-0.58	0.07	-2.10	0.27	-1.05	-1.14	-0.68	0.63	-2.91	-0.57	-3.95	-3.89	-2.27	0.16	-1.36	-1.38	0.18	-0.89	-0.23	-3.99	-2.78	-1.35	-0.40	-5.38	-0.07	-0.28	-4.60	-1.86	-0.98	1.14	-0.31	-0.02	-5.91	-100000000.00	-0.31	
) 	-3.68	-0.84	-1.98	-4.11	-0.70	-4.20	-3.46	-2.25	-3.55	-0.32	-3.08	-2.09	-2.38	-2.97	-0.24	-3.36	-0.40	-2.48	0.16	-1.64	0.06	-2.55	-3.48	-2.36	-0.46	-2.31	-2.70	-1.03	-3.57	-0.44	0.55	-2.30	-4.13	-1.16	-1.61	-2.77	-1.41	-1.98	-0.54	-1.71	-3.40	0.53	-1.49	-2.72	-2.57	-4.09	-100000000.00	-1.52	
( 	-0.95	-1.04	-2.36	-1.36	-0.66	-1.94	-0.70	-5.20	-1.62	-0.12	0.22	-0.61	-1.09	-1.65	-3.42	-1.68	-0.04	-1.91	-1.92	-0.68	-1.27	-0.91	-2.08	0.47	-2.87	-2.42	-2.20	-0.72	-0.52	-1.30	-1.28	-1.77	-2.33	-1.33	-1.99	0.19	-1.33	-2.26	-2.16	-1.74	-3.20	-0.50	-0.39	-0.89	-3.08	-4.12	-100000000.00	-0.02	
FW 	-4.27	-5.04	-1.65	-1.67	-4.35	-1.43	-0.94	-0.62	-2.00	-1.26	-2.79	-5.18	-3.02	-2.91	-2.08	-0.91	-0.73	-1.21	0.11	0.98	-3.07	-1.17	-1.22	0.58	-1.88	-3.00	-1.79	-2.56	-3.18	-0.78	-2.33	-1.13	-3.08	0.10	-1.04	-1.52	-1.57	-3.14	-0.09	-0.92	-3.33	-1.15	-1.69	-2.97	-1.95	-2.62	-100000000.00	-0.70	
POS 	-1.85	-1.78	-2.34	-2.52	-1.52	-1.45	-0.96	-2.41	-1.40	-1.07	-3.07	-2.24	-0.35	-2.90	-1.97	-1.62	-0.59	-1.44	-0.32	-1.23	-2.27	0.43	-4.98	-1.08	-1.97	-2.04	-3.64	-0.90	0.31	-1.14	-2.56	-3.43	-1.45	-1.40	-2.79	-2.06	-1.11	-2.48	-1.38	-1.96	-1.81	-1.46	-0.48	-3.72	-2.61	-2.01	-100000000.00	-1.30	
. 	-2.39	0.81	0.11	-3.96	0.46	-3.95	-2.47	-0.44	-1.50	-2.14	-1.96	-0.51	-2.68	-0.77	-0.17	-2.97	-0.63	-0.86	-2.21	-3.59	-1.42	-2.66	-0.74	-0.16	0.89	0.69	-1.55	0.67	-1.45	0.01	-3.10	-3.62	-3.80	-2.83	0.27	-0.90	-0.81	-2.00	-2.71	-4.10	-3.00	-0.54	-3.64	-0.17	-6.10	-0.19	-100000000.00	-0.01	
TO 	-0.98	-0.87	0.98	-1.37	-0.91	-2.29	-2.91	0.58	-4.65	0.77	-3.45	-0.25	-0.02	-2.60	0.00	-4.52	-0.19	-1.29	-1.01	-3.08	-4.21	-2.73	-2.73	-1.76	-4.58	-1.55	-2.28	-1.61	-0.51	0.43	-1.95	-1.01	-4.59	-1.83	0.53	-1.88	-1.08	-1.44	-2.84	-2.85	-2.75	-1.66	-1.19	-0.58	-2.33	-2.77	-100000000.00	-1.37	
-X- 	-0.84	-0.81	-1.81	-0.98	-2.10	-1.80	0.07	-0.69	1.12	-1.57	-1.07	-3.28	-2.04	-2.00	-1.32	0.12	-1.81	-0.17	-1.33	-0.41	-1.54	0.51	-1.90	0.78	-0.21	-1.49	-0.65	-0.67	0.33	-1.75	-0.47	-0.58	1.32	0.26	-0.51	-1.76	1.35	-2.07	0.74	0.37	1.50	-0.90	0.78	-0.44	-1.04	-1.44	-100000000.00	-1.69	
LS 	-2.25	-1.30	-3.59	-1.10	-1.88	-1.40	-1.39	-1.73	-1.28	-4.07	-1.26	-2.47	-5.24	-2.15	-1.88	-3.52	-3.51	-2.23	-0.86	-2.09	-2.13	-0.64	-3.49	-0.11	-1.72	-1.70	0.18	-2.97	0.99	-1.79	-1.84	-1.40	-1.00	-0.24	-1.79	-3.39	-1.45	-4.67	0.23	-2.06	-1.44	-1.36	-1.27	-2.02	-1.38	-3.16	-100000000.00	-2.51	
RB 	-0.87	0.10	-0.08	-0.13	-0.44	0.05	-2.71	-0.48	-0.53	-1.67	-2.64	0.53	0.51	-0.80	0.15	-1.49	-0.55	-0.30	-1.73	-5.16	-0.86	-3.23	-1.37	-1.22	-2.68	-0.95	-2.51	-0.12	-1.62	-0.15	-0.89	-0.57	-2.04	0.67	0.37	-0.71	-1.35	-0.81	-1.78	-2.18	0.85	-2.36	-1.28	-0.67	-1.10	-3.33	-100000000.00	-1.19	
: 	-1.51	-0.76	-1.07	-2.29	-0.61	-0.61	-3.26	-1.50	-1.02	-0.66	-1.99	0.16	-2.30	-1.15	-0.70	-1.92	1.22	-0.46	-0.43	-4.19	-0.72	-2.33	-2.14	-0.26	-0.79	-0.22	-2.12	0.12	-1.35	-0.09	-3.82	-3.06	-3.98	-0.97	-2.24	0.85	-1.40	-2.09	-2.20	-1.02	-3.56	-2.26	-2.02	-0.80	-1.65	-4.33	-100000000.00	-2.54	
NNS 	-1.20	0.47	-0.24	0.60	0.33	-0.51	-1.50	-0.33	-0.28	1.26	-1.31	-0.66	0.33	0.12	-0.08	-3.53	0.90	-0.78	-0.69	-0.23	0.42	-3.86	-2.49	-3.19	-4.74	-2.39	1.44	-2.27	-1.05	0.04	-0.95	-1.07	-2.23	-0.86	-2.10	-0.15	-6.13	-0.29	0.97	-3.06	-1.31	-2.35	-0.07	1.25	-0.75	-5.08	-100000000.00	-0.52	
PRP 	-4.07	0.19	-1.23	-0.71	-0.83	0.12	-0.18	0.13	-1.63	-1.45	-1.00	0.28	-2.68	0.19	-4.97	-2.78	-1.35	-2.53	-2.02	-1.31	-0.34	-2.27	-0.55	-1.15	-2.27	0.29	-0.86	-1.42	-1.40	0.44	-0.90	-1.02	-1.88	-1.77	-2.36	-3.29	-0.97	1.48	-1.59	-4.06	-1.38	-5.30	-1.08	-3.81	-1.12	-0.71	-100000000.00	-2.18	
VB 	-1.79	-1.95	-1.80	-0.06	-2.35	-0.90	-0.38	-2.22	-0.52	-2.10	-0.72	-1.16	-1.25	-1.36	-0.18	-3.32	-0.61	-0.02	-2.29	-1.64	-2.19	-2.47	1.14	-2.21	-2.69	0.68	-0.71	-1.65	-0.46	-1.80	-2.38	-0.23	-1.66	-2.19	-0.29	-1.37	-3.18	-1.91	-1.00	-3.46	2.37	-2.06	-1.09	-0.75	-3.03	-2.72	-100000000.00	-1.33	
WRB 	-2.03	-0.94	-1.87	-1.57	-0.53	-1.77	-2.14	-1.72	-0.97	-1.47	-1.15	-0.38	-0.40	-2.16	-3.07	-0.32	0.28	-0.00	-2.69	-1.80	-0.04	-1.82	-1.18	0.18	-0.52	-0.43	-2.26	-1.03	-1.23	-0.76	-2.41	-0.69	-1.82	-2.89	-0.83	-1.07	-1.79	-0.58	0.26	-0.30	-4.06	-3.78	-2.47	-2.80	-1.14	-1.35	-100000000.00	0.53	
CC 	-2.64	-0.25	-0.98	-1.14	0.76	-0.70	-3.62	-2.39	-2.89	0.66	-2.62	-0.34	-1.49	-0.99	-0.68	-2.18	0.33	0.39	-1.99	-1.96	-1.66	-1.55	-3.28	-0.92	-2.41	-0.06	-0.67	-0.35	-0.58	-0.11	-5.32	-1.70	-4.78	-2.17	-1.00	-2.09	-0.84	-1.16	-1.75	-0.76	-2.50	-0.10	-1.03	-2.63	-0.65	-4.00	-100000000.00	0.32	
PDT 	-1.57	-1.40	-1.10	-1.42	-1.21	-2.15	-0.41	-1.80	-0.66	-1.56	0.06	-1.33	-4.04	-3.96	0.31	-2.38	-1.87	-3.69	-1.32	-1.59	-3.45	-1.06	-0.99	0.59	-1.74	-1.24	-2.24	-3.48	-2.78	-1.04	-1.10	-1.42	-1.83	-2.61	-1.92	-1.73	-2.12	-0.57	-1.34	1.06	-2.53	0.47	-0.62	-2.82	-2.73	-0.78	-100000000.00	-2.45	
RBS 	1.86	-1.04	-0.62	-4.17	-0.95	-1.23	-0.90	-0.50	-1.91	-4.11	-0.73	-1.40	0.88	-2.50	-1.70	-1.27	-0.91	-2.12	-0.60	-1.89	1.90	-0.25	-3.37	-0.69	-1.67	-2.44	0.10	-1.98	-1.71	-1.56	-0.73	-1.77	-0.88	-1.64	-1.74	-3.70	-1.55	-0.94	-0.09	-1.04	-3.23	-1.68	-1.34	-0.08	-2.74	-2.91	-100000000.00	-4.72	
RBR 	-3.22	-1.66	-0.58	-0.49	0.33	-2.37	-0.79	-0.68	-1.83	-1.22	-4.16	0.83	-0.58	0.21	0.68	-2.40	0.74	-1.87	-3.58	-1.61	-3.14	-1.94	-1.96	-0.81	-0.58	0.43	-1.83	0.31	0.71	0.55	-0.45	-0.54	-3.12	-2.31	-2.02	-0.71	-2.15	-0.94	-1.15	-2.51	-1.36	-2.68	-1.59	-0.75	-1.25	-1.35	-100000000.00	-1.41	
CD 	-0.76	-0.28	-0.31	-0.22	-0.68	0.38	-0.51	-1.17	-1.60	-0.80	-2.60	0.06	0.69	0.21	-1.07	1.61	-0.94	0.11	-0.91	-1.69	-0.06	-3.68	0.21	-1.74	-4.87	-0.91	-0.19	-1.18	-2.19	-0.20	-1.67	-1.41	-3.24	-3.18	-5.10	-1.25	-6.15	-0.53	-0.35	-0.54	-4.14	-0.48	-0.87	-0.56	-0.42	-1.99	-100000000.00	-0.24	
EX 	-0.06	0.62	-1.66	-1.15	0.98	-0.66	-0.13	0.02	-0.49	-1.40	-1.74	-2.15	-1.96	-0.32	-0.57	-0.51	-0.87	-1.93	-2.14	-0.92	-4.47	-1.23	-2.73	-0.81	-1.08	-1.30	-3.47	-1.89	0.13	0.78	-0.66	-0.60	-0.35	-1.77	0.62	-2.37	-1.62	-0.95	-2.09	-2.88	-1.15	-1.52	-0.63	-0.53	-0.40	-0.50	-100000000.00	-2.19	
IN 	-2.43	0.45	0.02	0.54	0.47	-0.63	-1.21	-0.49	-0.93	-1.15	-3.12	0.83	-0.48	0.25	1.00	-1.62	0.86	0.53	-1.78	-4.06	-0.99	-3.03	-0.94	-1.88	-2.34	-0.40	-1.33	0.32	-0.27	-0.55	-1.56	-0.39	-2.22	-2.25	-0.20	-0.30	-1.74	-0.34	-1.03	-5.78	-2.22	-0.75	0.78	0.75	-0.42	-6.63	-100000000.00	0.52	
WP$ 	-2.30	-1.95	-1.84	-3.99	-1.81	0.22	0.39	-1.11	-1.32	-2.05	0.20	-0.65	-2.15	-1.42	0.57	-0.66	-1.06	-1.89	-0.70	-0.68	-2.60	0.29	0.09	1.30	-1.22	-0.45	-1.80	-0.38	-3.76	-1.92	-0.27	-1.57	-0.10	-2.36	-1.03	-0.96	0.04	0.89	-2.12	0.21	-1.39	-2.26	-1.57	0.21	-1.63	-2.70	-100000000.00	-0.55	
NN|SYM 	-1.75	-1.43	-3.52	-5.39	-3.03	-2.50	1.22	-1.33	-1.59	-3.23	-0.88	-2.57	-1.39	-4.29	-2.38	-0.92	-4.68	0.68	-2.15	-1.86	-1.25	-2.39	-2.69	-0.87	0.14	-4.07	-2.17	-3.07	-3.40	-0.28	-0.89	-1.78	0.88	-1.33	0.38	-4.36	-1.72	-1.34	0.17	-0.55	-1.35	-1.60	-0.39	-0.22	-0.71	-2.65	-100000000.00	-4.72	
MD 	-2.82	-0.99	-1.31	-4.56	-1.07	-0.69	0.25	-0.60	0.08	-2.17	-1.66	-1.82	-0.63	-0.21	-0.75	-3.28	0.03	-0.70	-3.54	-1.78	-2.09	-3.57	-4.04	-0.10	-0.58	-1.17	-2.96	0.10	0.30	-1.99	-1.87	-1.47	-2.01	-2.44	-1.73	-1.99	0.32	-1.55	-1.07	-1.88	-4.49	-2.44	-1.97	-4.07	-1.89	-2.29	-100000000.00	-0.39	
NNPS 	-2.45	-1.17	-1.48	-1.69	-2.41	-1.79	-0.42	-0.61	-0.86	-0.89	-3.24	-2.40	0.34	-1.51	-1.86	-0.10	-1.67	-2.23	0.29	-4.85	-2.87	-0.30	-3.30	-1.66	-1.78	-5.97	-0.69	-2.92	-4.55	-1.37	-1.90	-1.27	-1.94	-0.11	-1.41	-0.05	-5.42	-0.63	-1.79	-1.22	-3.02	-1.17	-3.64	-4.13	-1.28	-4.02	-100000000.00	1.04	
JJS 	0.15	-4.89	-1.81	-2.35	-2.06	-0.93	-2.33	-4.08	-1.95	-2.20	-2.16	-2.21	-1.36	-1.42	-1.37	-2.98	-2.57	-2.65	-0.19	-3.06	-1.07	-1.11	-1.05	-0.03	-1.99	-3.43	-3.93	-2.33	-3.09	-2.57	-0.67	-0.80	-1.05	-1.52	-2.47	-1.94	-2.18	-0.77	-1.74	-1.02	-0.08	-1.64	-3.14	0.18	-2.93	-3.30	-100000000.00	-2.84	
JJR 	-1.57	-0.33	-0.04	-0.36	-1.36	-2.24	-1.41	-1.40	-0.66	-1.46	-1.43	-0.11	-1.77	-2.38	-1.04	-0.68	-0.46	-3.08	0.27	-1.56	-2.08	-1.87	-1.31	-0.97	-2.43	-0.08	-1.91	-0.96	-0.93	0.56	-0.06	-1.04	-0.81	-1.09	-1.20	-0.97	-0.55	0.08	-1.94	-2.37	-0.45	-0.26	-1.55	-2.10	-0.11	-1.21	-100000000.00	-1.79	
SYM 	-3.63	-3.05	-2.59	-0.64	-2.85	-4.13	-0.80	-0.18	-4.43	-0.03	-2.07	-4.09	-5.73	-2.27	-3.94	-2.11	-0.19	-0.38	-2.49	-4.20	-2.71	-1.32	-1.61	-1.94	-3.78	-3.13	-2.42	-0.34	-2.07	-1.93	-0.66	-1.49	-1.41	-1.11	-1.71	-0.31	-1.91	-2.21	-0.33	-0.73	-1.03	-3.50	-2.30	-3.52	-1.60	-1.72	-100000000.00	-0.18	
UH 	-3.06	-2.94	-3.80	-0.88	-2.45	0.88	-1.04	-2.67	-0.63	-5.92	-0.96	-2.63	-6.10	-0.08	-1.47	0.32	-7.44	-4.33	-3.23	-0.55	-4.51	0.10	-4.88	-0.77	-2.61	-4.04	-4.93	-4.96	-1.67	-5.30	-2.10	-5.52	-2.92	-1.67	-3.59	-8.62	-3.25	-2.16	-0.54	-0.24	-4.77	-3.50	-1.28	-1.82	-1.87	-1.09	-100000000.00	-4.03	
stop_tag 	-4.27	-4.81	-1.44	-0.52	-1.12	-3.35	1.83	-2.06	-5.68	-0.19	-3.87	-2.18	-1.70	-2.30	-2.14	-3.99	0.62	-2.19	-3.66	-0.99	-1.16	-1.41	-2.08	-0.35	-2.84	-1.89	-0.41	0.05	-1.98	-1.82	-3.14	-3.33	-5.53	-1.84	-6.48	-0.74	-4.46	-2.25	-1.49	-2.32	-4.41	-0.44	-5.38	-5.86	0.23	-2.77	-100000000.00	-0.26	
NNP 	-0.94	0.33	-0.15	0.43	0.35	0.60	0.16	-0.45	-1.50	-0.18	-1.82	-0.43	0.79	0.82	-0.67	-1.44	-0.00	-0.62	-0.65	0.05	-0.79	-3.21	0.35	-1.94	-3.41	-2.23	0.35	-1.27	-2.64	0.78	-1.04	-0.69	-6.04	-1.45	-1.76	-0.58	-5.59	-0.20	-1.45	-4.17	-1.40	-0.33	-0.09	-0.57	0.36	-1.42	-100000000.00	1.85	
Mean train loss after  0 batches of 4  epochs =0.0318883260091
Mean train loss after  100 batches of 4  epochs =0.0442333241471
Mean train loss after  200 batches of 4  epochs =0.0440684797494
Mean train loss after  300 batches of 4  epochs =0.0454997357968
Mean train loss after  400 batches of 4  epochs =0.043744796355
Mean train loss after  500 batches of 4  epochs =0.0416095679239
Mean train loss after  600 batches of 4  epochs =0.0431419441446
Mean train loss after  700 batches of 4  epochs =0.0415576596216
Mean train loss after  800 batches of 4  epochs =0.0410302561342
Mean train loss after  900 batches of 4  epochs =0.0423548305934
Mean train loss after  1000 batches of 4  epochs =0.0421192240799
Mean train loss after  1100 batches of 4  epochs =0.0409612554839
Mean train loss after  1200 batches of 4  epochs =0.0409316668933
Mean train loss after  1300 batches of 4  epochs =0.0405226789895
Mean train loss after  1400 batches of 4  epochs =0.0412909092093
Mean train loss after  1500 batches of 4  epochs =0.0414535870894
Mean train loss after  1600 batches of 4  epochs =0.0407175315736
Mean train loss after  1700 batches of 4  epochs =0.0398616787658
Mean train loss after  1800 batches of 4  epochs =0.0395641214563
Mean train loss after  1900 batches of 4  epochs =0.0397712736525
Mean train loss after  2000 batches of 4  epochs =0.0394780573596
Mean train loss after  2100 batches of 4  epochs =0.0396157580172
Mean train loss after  2200 batches of 4  epochs =0.0391665393438
Mean train loss after  2300 batches of 4  epochs =0.0394059188245
Mean train loss after  2400 batches of 4  epochs =0.0396163129973
Mean train loss after  2500 batches of 4  epochs =0.0392237979565
Mean train loss after  2600 batches of 4  epochs =0.0390847761721
Mean train loss after  2700 batches of 4  epochs =0.040125420589
Mean train loss after  2800 batches of 4  epochs =0.0401690076068
Mean train loss after  2900 batches of 4  epochs =0.0404548599354
Mean train loss after  3000 batches of 4  epochs =0.0400245501983
Mean train loss after  3100 batches of 4  epochs =0.0402605544843
Mean train loss after  3200 batches of 4  epochs =0.0404925972837
Mean train loss after  3300 batches of 4  epochs =0.0408038314338
Mean train loss after  3400 batches of 4  epochs =0.0411519808395
Mean train loss after  3500 batches of 4  epochs =0.0413076139826
Mean train loss after  3600 batches of 4  epochs =0.041821786403
Mean train loss after  3700 batches of 4  epochs =0.041464926046
Mean train loss after  3800 batches of 4  epochs =0.04219362463
Mean train loss after  3900 batches of 4  epochs =0.0423151594173
Mean train loss after  4000 batches of 4  epochs =0.0426582707261
Mean train loss after  4100 batches of 4  epochs =0.042497852198
Mean train loss after  4200 batches of 4  epochs =0.0427940004189
Mean train loss after  4300 batches of 4  epochs =0.0425446532233
Mean train loss after  4400 batches of 4  epochs =0.0433643298249
Mean train loss after  4500 batches of 4  epochs =0.0432948087027
Mean train loss after  4600 batches of 4  epochs =0.043422908919
Mean train loss after  4700 batches of 4  epochs =0.043673024157
Mean train loss after  4800 batches of 4  epochs =0.0439951835013
Mean train loss after  4900 batches of 4  epochs =0.0438246356979
Mean train loss after  5000 batches of 4  epochs =0.0442403399588
Mean train loss after  5100 batches of 4  epochs =0.0445221861759
Mean train loss after  5200 batches of 4  epochs =0.0448507541929
Mean train loss after  5300 batches of 4  epochs =0.0448290253984
Mean train loss after  5400 batches of 4  epochs =0.0452461082888
Mean train loss after  5500 batches of 4  epochs =0.0454469583936
Mean train loss after  5600 batches of 4  epochs =0.0458994719945
Mean train loss after  5700 batches of 4  epochs =0.0459166052744
Mean train loss after  5800 batches of 4  epochs =0.0460865808921
Mean train loss after  5900 batches of 4  epochs =0.0460210470823
Mean train loss after  6000 batches of 4  epochs =0.0462709489918
Mean train loss after  6100 batches of 4  epochs =0.0461732271378
Mean train loss after  6200 batches of 4  epochs =0.0468264263611
Mean train loss after  6300 batches of 4  epochs =0.0469197428
Mean train loss after  6400 batches of 4  epochs =0.0470013249116
Mean train loss after  6500 batches of 4  epochs =0.0471347338286
Mean train loss after  6600 batches of 4  epochs =0.0471354126181
Mean train loss after  6700 batches of 4  epochs =0.0472664446086
Mean train loss after  6800 batches of 4  epochs =0.0471157025371
Mean train loss after  6900 batches of 4  epochs =0.0473803108578
Mean train loss after  7000 batches of 4  epochs =0.047449839209
Mean train loss after  7100 batches of 4  epochs =0.0476112389647
Mean train loss after  7200 batches of 4  epochs =0.0476517043612
Mean train loss after  7300 batches of 4  epochs =0.0477986218525
Mean train loss after  7400 batches of 4  epochs =0.0477309420256
Mean train loss after  7500 batches of 4  epochs =0.0480225660583
Mean train loss after  7600 batches of 4  epochs =0.0478162267261
Mean train loss after  7700 batches of 4  epochs =0.0480440529402
Mean train loss after  7800 batches of 4  epochs =0.0479625034721
Mean train loss after  7900 batches of 4  epochs =0.0477926958655
Mean train loss after  8000 batches of 4  epochs =0.047926790097
Mean train loss after  8100 batches of 4  epochs =0.0481106754496
Mean train loss after  8200 batches of 4  epochs =0.0485815617917
Mean train loss after  8300 batches of 4  epochs =0.0488465070743
Mean train loss after  8400 batches of 4  epochs =0.0487850301586
Mean train loss after  8500 batches of 4  epochs =0.0490351211979
Mean train loss after  8600 batches of 4  epochs =0.0489116582585
Mean train loss after  8700 batches of 4  epochs =0.0490262229753
Mean train loss after  8800 batches of 4  epochs =0.0488719076861
Mean train loss after  8900 batches of 4  epochs =0.0488896038888
Mean train loss after  9000 batches of 4  epochs =0.048847536118
Mean train loss after  9100 batches of 4  epochs =0.0488403595653
Mean train loss after  9200 batches of 4  epochs =0.0488913333596
Mean train loss after  9300 batches of 4  epochs =0.049028051504
Mean train loss after  9400 batches of 4  epochs =0.0490787025626
Mean train loss after  9500 batches of 4  epochs =0.0492648170965
Mean train loss after  9600 batches of 4  epochs =0.0491026845004
Mean train loss after  9700 batches of 4  epochs =0.0492971399825
Mean train loss after  9800 batches of 4  epochs =0.0492700066719
Mean train loss after  9900 batches of 4  epochs =0.0492963394897
Mean train loss after  10000 batches of 4  epochs =0.0495486596842
Mean train loss after  10100 batches of 4  epochs =0.0496253205598
Mean train loss after  10200 batches of 4  epochs =0.049537682142
Mean train loss after  10300 batches of 4  epochs =0.0497606415348
Mean train loss after  10400 batches of 4  epochs =0.0497372997847
Mean train loss after  10500 batches of 4  epochs =0.0499505383671
Mean train loss after  10600 batches of 4  epochs =0.0498716653037
Mean train loss after  10700 batches of 4  epochs =0.0498780553958
Mean train loss after  10800 batches of 4  epochs =0.0500210309066
Mean train loss after  10900 batches of 4  epochs =0.0502886276556
Mean train loss after  11000 batches of 4  epochs =0.0502059545496
Mean train loss after  11100 batches of 4  epochs =0.0502779372764
Mean train loss after  11200 batches of 4  epochs =0.0503144545885
Mean train loss after  11300 batches of 4  epochs =0.0503245587022
Mean train loss after  11400 batches of 4  epochs =0.050491399047
Mean train loss after  11500 batches of 4  epochs =0.0507016556602
Mean train loss after  11600 batches of 4  epochs =0.0507926572353
Mean train loss after  11700 batches of 4  epochs =0.0509305885854
Mean train loss after  11800 batches of 4  epochs =0.0510213630371
Mean train loss after  11900 batches of 4  epochs =0.0512102336187
Mean train loss after  12000 batches of 4  epochs =0.0511560580405
Mean train loss after  12100 batches of 4  epochs =0.0512275389152
Mean train loss after  12200 batches of 4  epochs =0.051279704362
Mean train loss after  12300 batches of 4  epochs =0.0515586482576
Mean train loss after  12400 batches of 4  epochs =0.0515634012949
Mean train loss after  12500 batches of 4  epochs =0.0516370351849
Mean train loss after  12600 batches of 4  epochs =0.0517095837081
Mean train loss after  12700 batches of 4  epochs =0.0517343416605
Mean train loss after  12800 batches of 4  epochs =0.0519147998645
Mean train loss after  12900 batches of 4  epochs =0.051976189374
Mean train loss after  13000 batches of 4  epochs =0.0523309996812
Mean train loss after  13100 batches of 4  epochs =0.0522633954642
Mean train loss after  13200 batches of 4  epochs =0.0523249107695
Mean train loss after  13300 batches of 4  epochs =0.0523128709558
Mean train loss after  13400 batches of 4  epochs =0.0523707458464
Mean train loss after  13500 batches of 4  epochs =0.0524590110795
Mean train loss after  13600 batches of 4  epochs =0.0525338051055
Mean train loss after  13700 batches of 4  epochs =0.0527414973771
Mean train loss after  13800 batches of 4  epochs =0.0530952379579
Mean train loss after  13900 batches of 4  epochs =0.0532347004694
Mean train loss after  14000 batches of 4  epochs =0.0533470071601
Mean train loss after  14100 batches of 4  epochs =0.0533123064274
Mean train loss after  14200 batches of 4  epochs =0.0532855762342
Mean train loss after  14300 batches of 4  epochs =0.0533553291821
Mean train loss after  14400 batches of 4  epochs =0.053514892094
Mean train loss after  14500 batches of 4  epochs =0.0537819804959
Mean train loss after  14600 batches of 4  epochs =0.053800566404
Mean train loss after  14700 batches of 4  epochs =0.0537325224262
Mean train loss after  14800 batches of 4  epochs =0.0538383115896
Mean train loss after  14900 batches of 4  epochs =0.0539963671116
Epoch 4 : Mean train epoch loss =0.0540252858635
Epoch 4 Epoch val loss = 15437.2050571
Epoch 4 Epoch val perplexity = 1.3700216602145494
SCORES =  (92.69, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 5---------------------

=================================
fscore(z) =  [159.43658] || goldscore = [159.43607]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-4.73	0.96	-0.18	-2.04	0.07	-1.28	-0.78	-1.01	-0.89	-0.96	-0.34	0.18	-0.06	-0.61	1.14	-4.12	-1.10	-2.04	-4.33	-0.89	-0.29	-2.63	-1.17	-2.27	-2.37	0.36	-4.28	-1.39	-0.20	0.95	-1.05	-0.36	-0.28	-1.77	-1.31	-2.66	-3.05	0.22	-1.35	-2.02	-2.98	-2.98	-1.85	-0.92	-2.88	-1.67	-100000000.00	-1.69	
VBG 	-1.66	-1.77	-0.10	0.12	-0.12	0.90	-3.92	0.35	-1.11	-2.11	-3.06	-0.40	0.03	-1.28	-0.72	-2.54	0.30	-0.36	-3.34	-5.86	-2.99	-2.08	-1.30	-1.36	-5.08	-0.34	-1.20	0.14	-2.89	0.83	-2.76	0.20	-2.64	-1.42	-2.08	-1.50	-2.29	-0.71	-1.56	-3.82	-2.44	-1.46	-1.21	-1.06	-3.09	-3.95	-100000000.00	-1.16	
VBD 	-2.41	-1.80	-3.45	-1.61	-2.38	0.36	-1.71	-1.29	0.80	-1.40	0.69	-1.79	0.77	-1.30	-1.38	-2.92	0.38	-0.51	-1.25	-1.80	-1.78	-2.13	-3.05	-1.51	-2.90	-0.00	-1.71	1.02	1.40	-1.61	-2.67	-1.41	-5.87	0.26	-1.29	-1.41	-0.03	-2.73	-2.15	-3.44	-1.82	-0.65	-0.06	-1.09	-2.01	-2.06	-100000000.00	0.58	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.52	-0.58	-0.94	-0.70	-1.52	-1.16	-3.31	0.08	-0.98	-1.55	-1.62	0.04	0.11	-0.66	-0.55	-3.03	-0.27	-1.81	-0.42	-1.89	-1.10	-3.29	-1.77	-1.72	-3.25	0.54	-0.27	-0.03	-1.64	0.64	-0.78	-0.83	-4.41	-0.61	-0.12	-1.88	-3.49	-0.84	-0.88	-2.97	-4.38	-1.41	-2.52	-1.29	-0.25	-6.52	-100000000.00	-2.04	
, 	-1.00	-0.96	0.89	-2.59	-0.40	-2.23	-0.88	-0.44	-0.30	0.79	-1.22	-1.12	-1.51	-0.63	-0.72	-4.20	0.36	0.07	-2.20	-1.29	0.55	-2.14	-3.03	-1.85	-0.83	-1.19	-4.21	-0.40	-0.84	-0.42	-3.52	-0.15	-4.97	-0.22	-1.35	1.39	-1.72	-0.47	-3.88	-3.75	-1.81	0.81	-1.57	-0.76	-3.52	-1.16	-100000000.00	0.99	
'' 	-0.99	-0.64	-1.95	-0.93	-3.93	-0.33	-0.54	-3.41	-2.76	-4.62	-2.07	-2.35	-5.54	-4.24	-0.48	-0.98	0.47	-1.47	-2.85	-1.80	-2.47	0.32	-2.50	-0.36	-2.52	-0.42	-1.78	-2.49	-2.50	-0.82	-1.25	-0.54	-1.77	-0.86	-2.56	-3.18	-1.44	-0.71	-0.55	-0.45	-3.61	-2.77	-1.03	-3.82	-2.40	-2.86	-100000000.00	-0.96	
VBP 	-4.94	-1.69	-7.01	-3.65	-2.70	-0.82	-0.78	-1.24	-0.10	-3.46	0.30	-2.21	-1.39	-1.41	-2.28	-0.56	-1.89	0.54	-0.72	-4.47	-4.73	-1.52	-2.20	-3.11	-3.68	-0.11	-3.06	0.94	-0.31	-1.93	-2.06	-1.41	-3.25	-1.51	-1.20	-0.69	0.05	-4.75	-0.65	-1.92	-3.04	0.19	-3.66	-2.45	-1.57	-3.20	-100000000.00	-0.71	
WDT 	-3.66	-2.62	-3.30	-2.64	-3.55	-0.74	-1.85	-1.92	-3.09	-2.09	-1.62	-3.67	-1.57	-1.27	-1.13	-2.30	0.07	-0.23	-2.35	-3.15	-1.01	-1.77	-0.91	-0.29	-0.73	-1.85	-0.43	0.78	-3.20	-1.93	-1.19	-0.59	-1.64	-1.16	-1.54	-1.40	-3.38	-1.45	0.43	-1.91	-4.01	-2.28	-2.50	-1.80	-2.53	-2.43	-100000000.00	-0.10	
JJ 	-0.10	0.87	0.33	0.44	-0.15	-1.26	-2.45	0.18	-1.51	-0.47	-3.35	0.30	-0.08	-1.08	-0.56	-0.87	-0.84	-0.72	-1.06	-2.20	0.18	-3.18	-1.58	-1.09	-4.86	-0.02	-0.53	-1.30	-1.06	0.20	0.36	0.23	-2.69	-0.26	0.71	0.07	-3.66	0.67	-1.16	-3.66	-1.03	-2.35	-1.20	-0.24	-1.29	-2.12	-100000000.00	-0.76	
WP 	-3.21	-1.37	-0.56	-0.62	-0.51	-1.20	-2.11	-3.64	-2.89	-1.25	-3.54	-1.70	-0.84	-0.85	-1.67	-2.69	-1.37	-1.34	-1.02	-2.36	-0.27	-1.46	-1.42	-0.51	-0.50	-1.60	-2.76	1.49	-1.03	-1.37	-2.71	-1.97	-2.17	0.84	-1.74	-2.49	-0.50	-0.46	-0.36	-0.08	-0.50	-0.33	-2.76	-1.64	-3.61	-2.16	-100000000.00	0.19	
VBZ 	-1.58	-2.08	-3.26	-3.41	-1.75	0.13	-2.13	-0.64	0.64	-1.30	1.26	-1.63	-0.37	-1.98	-2.63	-3.48	1.08	-1.87	-0.96	-1.72	-1.75	-2.21	-2.80	-0.59	-3.44	-0.01	-1.50	-1.51	0.55	-2.55	-1.89	-0.94	-5.96	-1.68	-4.34	-0.98	1.92	-2.95	-1.28	-2.09	-2.78	-2.91	-1.28	-2.38	-1.93	-4.39	-100000000.00	0.44	
DT 	-3.11	0.22	0.56	0.27	-0.06	1.46	-1.52	0.41	-0.76	-0.73	-1.81	0.32	-1.58	-0.49	1.18	-3.69	-0.73	-1.73	-0.32	-1.76	-0.96	-2.15	0.81	-1.46	-3.54	-0.44	-0.88	-1.77	-0.37	1.08	-0.76	0.95	1.02	-2.36	0.79	-1.91	-4.41	0.91	-0.84	-1.56	-1.91	-2.45	-2.18	-2.41	-0.00	-2.87	-100000000.00	-1.60	
" 	-2.25	-0.19	-1.47	-1.80	0.03	-0.25	-0.76	-2.02	-1.96	-1.83	0.25	-0.56	-2.57	-2.34	1.13	-1.51	-0.57	-1.62	-2.82	-1.83	-0.83	2.04	-0.73	0.77	-1.71	-1.36	-1.03	-1.26	-2.29	-1.17	-1.48	-2.77	-2.24	-1.44	-1.21	-2.01	-2.57	-1.51	-1.76	1.61	-1.44	-0.89	-3.73	-2.12	-2.94	-2.64	-100000000.00	-0.01	
RP 	-4.38	1.06	0.69	-3.31	0.54	-1.81	-1.32	0.40	-4.63	-1.83	-1.55	-0.99	-0.07	-3.74	-0.25	-2.54	-1.03	-1.78	-3.10	-1.93	-5.22	-0.33	-6.27	-0.92	-2.83	-0.36	-6.16	-1.53	-0.63	0.86	-2.92	-2.34	-2.00	-1.38	-3.97	-1.96	-1.13	-2.47	-0.07	-1.24	-4.55	-1.35	-1.63	-1.17	-2.09	-1.43	-100000000.00	-2.87	
$ 	-1.39	0.02	-0.12	-4.50	-1.17	-3.22	-2.56	-2.39	-3.03	-1.09	-3.40	-0.15	-0.46	-3.03	-0.29	-1.31	-0.33	-0.82	-0.36	-0.03	-0.17	-1.01	-1.03	0.78	-2.27	0.00	-1.01	-1.01	-1.07	-1.43	-0.83	-1.01	-2.24	-2.37	-2.43	-2.54	-0.20	-1.04	0.50	-0.92	-1.25	-1.90	-1.46	-1.14	-0.78	-1.04	-100000000.00	-1.35	
NN 	0.77	0.39	-0.96	0.41	-0.11	0.20	-1.22	-0.55	-1.32	1.11	-2.56	-0.31	-0.69	-0.63	-0.05	-2.46	0.22	-1.12	-1.17	-0.73	0.57	-3.24	-0.55	-4.00	-4.25	-2.39	0.12	-1.41	-1.54	0.20	-0.93	-0.19	-4.55	-2.87	-1.48	-0.33	-5.93	-0.07	-0.28	-4.96	-2.11	-1.12	1.13	-0.47	-0.10	-6.44	-100000000.00	-0.53	
) 	-3.96	-0.98	-2.35	-4.45	-0.75	-4.60	-3.73	-2.45	-3.92	-0.38	-3.30	-2.13	-2.46	-3.12	-0.16	-3.56	-0.49	-2.73	-0.17	-1.89	-0.18	-2.69	-3.75	-2.39	-0.55	-2.70	-3.06	-1.13	-4.02	-0.64	0.35	-2.61	-4.59	-1.47	-2.19	-2.75	-1.77	-2.45	-0.67	-1.92	-3.84	0.55	-1.87	-3.21	-2.93	-4.49	-100000000.00	-1.53	
( 	-1.10	-1.15	-2.45	-1.64	-1.02	-2.08	-1.06	-5.56	-2.00	-0.16	0.05	-0.88	-1.31	-1.80	-3.80	-1.96	-0.10	-1.98	-2.20	-1.04	-1.41	-1.07	-2.29	0.40	-3.17	-2.56	-2.20	-0.73	-0.73	-1.53	-1.68	-2.05	-2.93	-1.68	-2.64	0.14	-1.82	-2.53	-2.23	-1.99	-3.93	-0.67	-0.43	-0.93	-3.73	-4.67	-100000000.00	-0.08	
FW 	-4.83	-5.34	-1.89	-1.85	-4.94	-1.75	-1.08	-0.76	-2.20	-1.32	-3.03	-5.70	-3.34	-3.14	-2.46	-1.19	-0.88	-1.28	0.03	0.78	-3.72	-1.35	-1.66	0.50	-2.18	-3.49	-2.05	-2.78	-3.38	-0.99	-2.59	-1.28	-3.66	-0.02	-1.52	-1.77	-1.89	-3.67	-0.16	-1.18	-3.71	-1.34	-1.93	-3.50	-2.26	-3.08	-100000000.00	-0.72	
POS 	-2.28	-2.07	-2.55	-2.87	-1.81	-1.95	-0.84	-2.43	-1.56	-1.31	-3.22	-2.58	-0.67	-3.33	-2.22	-1.78	-0.62	-1.73	-0.61	-1.52	-2.58	0.35	-5.71	-1.10	-2.26	-2.30	-4.13	-0.93	0.11	-1.31	-2.82	-3.52	-1.72	-1.64	-3.01	-2.24	-1.30	-2.65	-1.47	-2.10	-2.18	-1.52	-0.76	-3.97	-3.09	-2.29	-100000000.00	-1.15	
. 	-2.71	0.77	-0.05	-4.24	0.47	-4.30	-3.03	-0.78	-1.92	-2.11	-2.75	-0.66	-2.72	-0.97	-0.17	-3.69	-0.71	-1.00	-2.54	-4.00	-1.83	-3.08	-1.27	-0.37	0.94	0.62	-1.98	0.70	-1.44	-0.08	-3.52	-3.75	-4.16	-3.52	0.22	-0.93	-1.12	-2.12	-3.06	-4.47	-3.43	-0.64	-3.79	-0.49	-6.69	-0.33	-100000000.00	-0.00	
TO 	-1.16	-1.02	0.98	-1.87	-0.99	-2.57	-3.57	0.59	-5.25	0.73	-3.75	-0.29	-0.09	-2.73	-0.03	-4.79	-0.21	-1.50	-1.34	-3.23	-4.57	-2.87	-3.09	-1.83	-5.04	-1.56	-2.30	-1.61	-0.84	0.41	-2.24	-1.28	-5.32	-2.08	0.28	-1.96	-1.18	-1.42	-2.93	-3.29	-2.79	-1.72	-1.62	-0.74	-2.93	-3.25	-100000000.00	-1.48	
-X- 	-0.85	-0.85	-1.90	-1.29	-2.16	-1.87	0.06	-0.75	1.08	-1.66	-1.07	-3.29	-2.11	-2.06	-1.33	0.12	-1.94	-0.25	-1.35	-0.47	-1.62	0.45	-1.94	0.78	-0.21	-1.60	-0.85	-0.82	0.21	-1.80	-0.48	-0.69	1.32	0.26	-0.51	-1.91	1.34	-2.15	0.74	0.37	1.45	-0.94	0.75	-0.45	-1.12	-1.44	-100000000.00	-1.81	
LS 	-2.43	-1.49	-4.09	-1.28	-2.33	-1.93	-1.46	-2.02	-1.55	-4.55	-1.59	-2.73	-5.57	-2.36	-2.04	-3.71	-3.55	-2.64	-1.10	-2.30	-2.43	-0.72	-3.67	-0.11	-1.97	-2.10	0.29	-3.39	0.82	-2.13	-2.04	-1.77	-1.18	-0.44	-1.86	-3.80	-1.66	-5.37	0.15	-2.10	-1.62	-1.67	-1.36	-2.12	-1.47	-3.47	-100000000.00	-2.90	
RB 	-1.06	0.06	-0.09	-0.15	-0.51	0.08	-3.17	-0.44	-0.68	-1.86	-2.75	0.46	0.41	-0.93	0.07	-1.78	-0.50	-0.34	-2.02	-5.61	-1.05	-3.37	-1.62	-1.28	-3.14	-1.08	-2.90	-0.08	-1.77	-0.15	-1.09	-0.62	-2.51	0.58	0.25	-0.71	-1.38	-0.91	-1.91	-2.59	0.89	-2.57	-1.39	-0.86	-1.24	-3.59	-100000000.00	-1.29	
: 	-1.95	-0.89	-1.11	-2.49	-0.72	-0.90	-3.59	-1.57	-1.14	-0.78	-2.19	0.12	-2.30	-1.20	-0.96	-2.19	1.15	-0.57	-0.73	-4.46	-0.84	-2.52	-2.49	-0.32	-0.94	-0.29	-2.36	0.02	-1.78	-0.24	-4.16	-3.40	-4.43	-1.24	-2.50	0.90	-1.74	-2.34	-2.26	-1.32	-4.14	-2.35	-2.64	-1.11	-1.78	-4.73	-100000000.00	-2.54	
NNS 	-1.20	0.34	-0.31	0.43	0.31	-0.59	-1.57	-0.36	-0.42	1.34	-1.45	-0.77	0.38	-0.03	-0.23	-3.86	0.97	-0.88	-0.76	-0.46	0.53	-4.08	-2.61	-3.23	-5.16	-2.53	1.38	-2.61	-1.26	0.10	-0.93	-1.09	-2.58	-1.06	-2.39	-0.31	-6.66	-0.30	0.97	-3.42	-1.53	-2.63	-0.09	1.27	-0.85	-5.59	-100000000.00	-0.67	
PRP 	-4.57	0.02	-1.17	-1.15	-0.87	0.06	-0.22	0.17	-1.83	-1.75	-1.02	0.21	-2.94	0.00	-5.31	-3.13	-1.35	-2.92	-2.22	-1.64	-0.60	-2.44	-0.63	-1.19	-2.55	0.23	-1.07	-1.62	-2.00	0.35	-0.91	-1.17	-2.30	-2.07	-2.51	-3.48	-1.03	1.52	-1.64	-4.18	-1.54	-5.73	-1.28	-4.16	-1.21	-0.96	-100000000.00	-2.38	
VB 	-2.27	-2.13	-2.04	-0.10	-2.46	-1.02	-0.63	-2.34	-0.79	-2.16	-0.84	-1.48	-1.39	-1.47	-0.25	-3.61	-0.69	-0.10	-2.65	-1.91	-2.62	-2.61	1.15	-2.24	-2.85	0.67	-0.69	-1.79	-0.48	-2.08	-2.50	-0.24	-1.98	-2.42	-0.36	-1.52	-3.43	-2.18	-1.03	-3.59	2.28	-2.13	-1.16	-0.89	-3.43	-2.79	-100000000.00	-1.46	
WRB 	-2.32	-1.00	-1.88	-1.61	-0.47	-1.84	-2.38	-1.85	-1.24	-1.50	-1.34	-0.38	-0.64	-2.18	-3.17	-0.42	0.32	-0.24	-2.85	-2.04	-0.19	-1.85	-1.58	0.17	-0.78	-0.59	-2.74	-1.18	-1.55	-0.69	-2.62	-0.76	-2.10	-3.03	-1.24	-1.08	-2.15	-0.55	0.14	-0.45	-4.24	-3.99	-2.71	-3.15	-1.43	-1.59	-100000000.00	0.26	
CC 	-2.83	-0.34	-1.13	-1.26	0.60	-0.82	-4.10	-2.55	-3.08	0.66	-2.71	-0.57	-1.74	-1.21	-0.71	-2.77	0.38	0.14	-2.27	-2.28	-1.68	-1.86	-3.40	-0.96	-2.54	-0.14	-0.99	-0.44	-0.75	-0.15	-5.55	-2.14	-5.08	-2.62	-1.07	-2.04	-0.90	-1.29	-1.87	-1.07	-2.84	-0.21	-1.43	-2.63	-1.08	-4.46	-100000000.00	0.29	
PDT 	-1.76	-1.58	-1.33	-1.57	-1.25	-2.45	-0.62	-1.87	-0.98	-1.76	-0.13	-1.57	-4.49	-4.15	0.06	-2.51	-1.98	-3.88	-1.45	-1.71	-3.75	-1.10	-1.07	0.59	-1.90	-1.30	-2.61	-3.51	-3.00	-1.03	-1.37	-1.56	-2.00	-2.74	-2.18	-1.89	-2.25	-0.54	-1.38	0.92	-2.76	0.33	-0.90	-3.10	-3.03	-0.88	-100000000.00	-2.44	
RBS 	1.83	-1.64	-0.66	-4.95	-1.19	-1.41	-1.03	-0.90	-2.17	-4.38	-1.03	-1.42	0.88	-2.91	-1.79	-1.50	-0.96	-2.44	-0.98	-2.20	1.86	-0.32	-3.60	-0.69	-1.85	-2.60	-0.30	-2.51	-2.22	-1.57	-0.79	-1.76	-1.21	-1.83	-2.01	-4.14	-1.72	-0.98	-0.15	-1.10	-3.45	-2.06	-1.53	-0.43	-3.15	-3.11	-100000000.00	-5.18	
RBR 	-3.59	-1.66	-0.52	-0.78	0.25	-2.49	-1.01	-0.74	-2.18	-1.42	-4.47	0.68	-0.69	-0.07	0.66	-2.73	0.67	-2.28	-3.88	-2.00	-3.65	-1.96	-1.99	-0.81	-0.97	0.40	-2.09	0.22	0.39	0.52	-0.60	-0.60	-3.36	-2.54	-2.45	-0.90	-2.43	-0.95	-1.27	-2.53	-1.85	-3.08	-1.92	-0.90	-1.48	-1.50	-100000000.00	-1.38	
CD 	-0.94	-0.38	-0.36	-0.27	-0.97	0.37	-0.53	-1.33	-1.83	-0.85	-2.88	-0.01	0.69	0.06	-1.33	1.78	-0.98	0.16	-0.97	-1.78	-0.07	-3.94	0.32	-1.95	-5.15	-0.88	-0.21	-1.24	-2.21	-0.26	-1.94	-1.46	-3.49	-3.45	-5.73	-1.28	-6.72	-0.56	-0.34	-0.53	-4.92	-0.61	-1.11	-0.72	-0.45	-2.43	-100000000.00	-0.28	
EX 	-0.37	0.53	-1.53	-1.34	0.81	-0.89	-0.26	-0.04	-0.55	-1.47	-1.87	-2.17	-2.04	-0.30	-0.79	-0.68	-0.84	-2.32	-2.48	-1.13	-4.65	-1.28	-3.29	-0.82	-1.30	-1.36	-3.68	-2.04	0.06	0.47	-0.72	-0.41	-0.52	-1.83	0.30	-2.62	-1.79	-0.91	-2.17	-2.90	-1.37	-1.67	-0.71	-0.69	-0.75	-0.72	-100000000.00	-2.32	
IN 	-2.79	0.44	0.06	0.41	0.41	-0.78	-1.49	-0.33	-1.02	-1.28	-3.45	0.69	-0.62	0.16	1.03	-2.14	0.97	0.47	-1.90	-4.12	-1.19	-3.30	-1.03	-1.98	-2.61	-0.45	-1.46	0.27	-0.30	-0.56	-1.78	-0.48	-2.54	-2.29	-0.18	-0.42	-1.84	-0.37	-1.21	-5.97	-2.65	-0.73	0.77	0.74	-0.76	-7.39	-100000000.00	0.49	
WP$ 	-2.34	-2.01	-2.00	-4.36	-1.94	0.22	0.36	-1.29	-1.39	-2.18	0.10	-0.69	-2.41	-1.55	0.49	-0.67	-1.20	-1.97	-0.88	-0.80	-2.72	0.25	-0.19	1.30	-1.26	-0.62	-2.08	-0.33	-3.81	-2.06	-0.36	-1.72	-0.11	-2.37	-1.05	-1.15	-0.07	0.46	-2.12	0.21	-1.45	-2.38	-1.61	0.09	-1.75	-2.70	-100000000.00	-0.56	
NN|SYM 	-1.84	-1.64	-3.88	-6.17	-3.35	-2.81	1.11	-1.74	-1.69	-3.62	-1.07	-2.89	-1.87	-4.53	-2.46	-1.00	-5.09	0.70	-2.56	-2.13	-1.53	-2.40	-2.91	-0.87	-0.05	-4.34	-2.53	-3.61	-3.58	-0.71	-1.03	-2.18	0.71	-1.35	0.18	-4.79	-1.78	-1.73	0.15	-0.56	-1.56	-1.99	-0.51	-0.46	-1.06	-2.71	-100000000.00	-5.14	
MD 	-3.00	-1.18	-1.43	-4.51	-1.50	-0.79	0.01	-0.75	0.15	-2.35	-1.64	-1.97	-0.65	-0.35	-0.93	-3.60	-0.07	-0.99	-3.85	-2.16	-2.23	-3.64	-4.30	-0.16	-0.80	-1.28	-3.26	0.18	0.34	-2.07	-1.87	-1.60	-2.40	-2.64	-2.03	-2.07	0.21	-1.80	-1.16	-2.10	-4.64	-2.42	-2.23	-4.35	-2.29	-2.71	-100000000.00	-0.52	
NNPS 	-2.78	-1.27	-1.78	-1.93	-2.40	-2.01	-0.58	-1.04	-1.01	-0.94	-3.61	-2.51	0.32	-1.78	-1.92	-0.42	-2.00	-2.32	0.23	-5.32	-3.32	-0.49	-3.86	-1.70	-1.90	-6.39	-0.92	-3.44	-4.79	-1.50	-2.12	-1.37	-2.27	-0.43	-1.91	-0.21	-5.81	-0.59	-1.76	-1.67	-3.37	-1.34	-3.94	-4.61	-1.67	-4.74	-100000000.00	0.98	
JJS 	0.13	-5.16	-2.16	-2.39	-2.12	-1.22	-2.43	-4.30	-2.18	-2.29	-2.38	-2.39	-1.37	-1.81	-1.48	-3.18	-2.74	-3.00	-0.48	-3.39	-1.14	-1.25	-1.56	-0.08	-2.14	-3.74	-4.19	-2.48	-3.37	-2.60	-0.85	-1.19	-1.31	-1.67	-2.87	-2.20	-2.38	-0.87	-1.84	-1.20	-0.22	-1.87	-3.40	-0.13	-3.17	-3.61	-100000000.00	-3.21	
JJR 	-2.00	-0.32	-0.13	-0.50	-1.46	-2.32	-1.59	-1.27	-1.04	-1.56	-1.61	-0.07	-1.74	-2.47	-1.17	-0.90	-0.67	-3.45	0.16	-2.08	-2.51	-2.00	-1.33	-0.99	-2.71	-0.22	-2.16	-1.07	-1.14	0.49	-0.08	-1.05	-1.25	-1.28	-1.63	-0.99	-0.93	0.01	-2.06	-2.49	-0.81	-0.61	-1.85	-2.33	-0.26	-1.69	-100000000.00	-1.93	
SYM 	-3.87	-3.19	-3.08	-0.57	-3.39	-4.43	-1.07	-0.56	-4.73	-0.09	-2.36	-4.55	-6.38	-2.71	-4.19	-2.45	-0.29	-0.46	-2.83	-4.52	-3.17	-1.32	-2.09	-1.96	-3.96	-3.36	-2.74	-0.52	-2.18	-2.36	-0.84	-1.68	-1.85	-1.45	-2.15	-0.40	-2.25	-2.48	-0.47	-0.97	-1.19	-3.91	-2.44	-3.97	-1.91	-1.74	-100000000.00	-0.19	
UH 	-3.44	-3.37	-4.10	-1.00	-2.80	0.84	-1.17	-2.97	-0.86	-6.74	-1.11	-3.14	-6.75	-0.24	-1.70	0.10	-8.05	-4.53	-3.51	-0.83	-4.77	-0.02	-5.31	-0.77	-2.90	-4.59	-5.71	-5.60	-1.89	-5.63	-2.27	-6.05	-3.19	-1.83	-3.79	-9.33	-3.39	-2.38	-0.62	-0.42	-5.09	-3.85	-1.53	-2.20	-2.23	-1.20	-100000000.00	-4.17	
stop_tag 	-4.74	-5.48	-1.53	-0.52	-1.33	-3.68	1.80	-2.64	-6.47	-0.23	-4.58	-2.37	-1.88	-2.57	-2.41	-4.47	0.59	-2.39	-3.91	-1.26	-1.34	-1.53	-2.60	-0.65	-3.51	-2.08	-0.57	-0.09	-2.53	-2.00	-3.49	-3.71	-6.31	-2.30	-7.22	-0.86	-5.24	-2.45	-1.68	-2.60	-5.17	-0.58	-6.13	-6.29	0.22	-3.65	-100000000.00	-0.32	
NNP 	-0.83	0.23	-0.23	0.32	0.40	0.55	0.09	-0.56	-1.56	-0.22	-1.98	-0.50	0.76	0.78	-0.78	-1.59	-0.05	-0.62	-0.71	-0.10	-0.84	-3.39	0.37	-2.06	-3.74	-2.28	0.24	-1.22	-2.94	0.60	-0.95	-0.84	-6.88	-1.87	-2.10	-0.71	-6.12	-0.12	-1.50	-4.55	-1.36	-0.36	-0.50	-0.78	0.29	-1.74	-100000000.00	1.89	
Mean train loss after  0 batches of 5  epochs =6.48498535156e-05
Mean train loss after  100 batches of 5  epochs =0.0334165614153
Mean train loss after  200 batches of 5  epochs =0.038815624808
Mean train loss after  300 batches of 5  epochs =0.0361985141997
Mean train loss after  400 batches of 5  epochs =0.034276285605
Mean train loss after  500 batches of 5  epochs =0.0364476123928
Mean train loss after  600 batches of 5  epochs =0.0348672107777
Mean train loss after  700 batches of 5  epochs =0.0346755663687
Mean train loss after  800 batches of 5  epochs =0.0364618062018
Mean train loss after  900 batches of 5  epochs =0.0354660508643
Mean train loss after  1000 batches of 5  epochs =0.0348961914088
Mean train loss after  1100 batches of 5  epochs =0.0329557092608
Mean train loss after  1200 batches of 5  epochs =0.0325229169718
Mean train loss after  1300 batches of 5  epochs =0.0320567933788
Mean train loss after  1400 batches of 5  epochs =0.0316344076672
Mean train loss after  1500 batches of 5  epochs =0.0319110208264
Mean train loss after  1600 batches of 5  epochs =0.0315349440071
Mean train loss after  1700 batches of 5  epochs =0.0311477218409
Mean train loss after  1800 batches of 5  epochs =0.0308746277074
Mean train loss after  1900 batches of 5  epochs =0.0304924656158
Mean train loss after  2000 batches of 5  epochs =0.0306377934332
Mean train loss after  2100 batches of 5  epochs =0.0308102413624
Mean train loss after  2200 batches of 5  epochs =0.0313583189069
Mean train loss after  2300 batches of 5  epochs =0.0316908394887
Mean train loss after  2400 batches of 5  epochs =0.0319174868531
Mean train loss after  2500 batches of 5  epochs =0.0317549390011
Mean train loss after  2600 batches of 5  epochs =0.0317224519688
Mean train loss after  2700 batches of 5  epochs =0.0320065888088
Mean train loss after  2800 batches of 5  epochs =0.0315413089561
Mean train loss after  2900 batches of 5  epochs =0.031522588832
Mean train loss after  3000 batches of 5  epochs =0.0312052224402
Mean train loss after  3100 batches of 5  epochs =0.0314360487395
Mean train loss after  3200 batches of 5  epochs =0.0312938614178
Mean train loss after  3300 batches of 5  epochs =0.031879330453
Mean train loss after  3400 batches of 5  epochs =0.0322509194281
Mean train loss after  3500 batches of 5  epochs =0.0321211008427
Mean train loss after  3600 batches of 5  epochs =0.0321182982121
Mean train loss after  3700 batches of 5  epochs =0.0324356244225
Mean train loss after  3800 batches of 5  epochs =0.0323659251593
Mean train loss after  3900 batches of 5  epochs =0.0325214681062
Mean train loss after  4000 batches of 5  epochs =0.0322292993717
Mean train loss after  4100 batches of 5  epochs =0.0328443659215
Mean train loss after  4200 batches of 5  epochs =0.0329953623119
Mean train loss after  4300 batches of 5  epochs =0.0331063245948
Mean train loss after  4400 batches of 5  epochs =0.0335872767993
Mean train loss after  4500 batches of 5  epochs =0.0335926396839
Mean train loss after  4600 batches of 5  epochs =0.0335292880027
Mean train loss after  4700 batches of 5  epochs =0.03373561743
Mean train loss after  4800 batches of 5  epochs =0.0335205605357
Mean train loss after  4900 batches of 5  epochs =0.0336103790851
Mean train loss after  5000 batches of 5  epochs =0.0338621205407
Mean train loss after  5100 batches of 5  epochs =0.0338794485007
Mean train loss after  5200 batches of 5  epochs =0.0341489901293
Mean train loss after  5300 batches of 5  epochs =0.0343564684515
Mean train loss after  5400 batches of 5  epochs =0.0345959101042
Mean train loss after  5500 batches of 5  epochs =0.0350268973222
Mean train loss after  5600 batches of 5  epochs =0.0350294384209
Mean train loss after  5700 batches of 5  epochs =0.035236699388
Mean train loss after  5800 batches of 5  epochs =0.0354252942547
Mean train loss after  5900 batches of 5  epochs =0.035184965774
Mean train loss after  6000 batches of 5  epochs =0.0351214371526
Mean train loss after  6100 batches of 5  epochs =0.035255872122
Mean train loss after  6200 batches of 5  epochs =0.0354605966138
Mean train loss after  6300 batches of 5  epochs =0.0354277005945
Mean train loss after  6400 batches of 5  epochs =0.0356219943752
Mean train loss after  6500 batches of 5  epochs =0.0355029619444
Mean train loss after  6600 batches of 5  epochs =0.03550075041
Mean train loss after  6700 batches of 5  epochs =0.0355128831138
Mean train loss after  6800 batches of 5  epochs =0.0355309810768
Mean train loss after  6900 batches of 5  epochs =0.0353604250695
Mean train loss after  7000 batches of 5  epochs =0.0353017356661
Mean train loss after  7100 batches of 5  epochs =0.0353967760914
Mean train loss after  7200 batches of 5  epochs =0.0352983286264
Mean train loss after  7300 batches of 5  epochs =0.0352975253255
Mean train loss after  7400 batches of 5  epochs =0.0353692516082
Mean train loss after  7500 batches of 5  epochs =0.0354535405121
Mean train loss after  7600 batches of 5  epochs =0.0355700418979
Mean train loss after  7700 batches of 5  epochs =0.0355915018427
Mean train loss after  7800 batches of 5  epochs =0.0356612489176
Mean train loss after  7900 batches of 5  epochs =0.0357325017864
Mean train loss after  8000 batches of 5  epochs =0.0360110966673
Mean train loss after  8100 batches of 5  epochs =0.0360798028525
Mean train loss after  8200 batches of 5  epochs =0.0362893483792
Mean train loss after  8300 batches of 5  epochs =0.0361878788969
Mean train loss after  8400 batches of 5  epochs =0.0361908644144
Mean train loss after  8500 batches of 5  epochs =0.0362991199829
Mean train loss after  8600 batches of 5  epochs =0.0362268104358
Mean train loss after  8700 batches of 5  epochs =0.036257083974
Mean train loss after  8800 batches of 5  epochs =0.0363592855398
Mean train loss after  8900 batches of 5  epochs =0.0366089242401
Mean train loss after  9000 batches of 5  epochs =0.0366434043805
Mean train loss after  9100 batches of 5  epochs =0.0366087450182
Mean train loss after  9200 batches of 5  epochs =0.036838032888
Mean train loss after  9300 batches of 5  epochs =0.036798688867
Mean train loss after  9400 batches of 5  epochs =0.0369058902372
Mean train loss after  9500 batches of 5  epochs =0.0371787547816
Mean train loss after  9600 batches of 5  epochs =0.0373619269578
Mean train loss after  9700 batches of 5  epochs =0.0374966519342
Mean train loss after  9800 batches of 5  epochs =0.0376270026866
Mean train loss after  9900 batches of 5  epochs =0.0375123170977
Mean train loss after  10000 batches of 5  epochs =0.0377146545066
Mean train loss after  10100 batches of 5  epochs =0.0379063455509
Mean train loss after  10200 batches of 5  epochs =0.0379249581584
Mean train loss after  10300 batches of 5  epochs =0.0379613111346
Mean train loss after  10400 batches of 5  epochs =0.0379788164071
Mean train loss after  10500 batches of 5  epochs =0.0381005827556
Mean train loss after  10600 batches of 5  epochs =0.0380909408359
Mean train loss after  10700 batches of 5  epochs =0.0382373906429
Mean train loss after  10800 batches of 5  epochs =0.0382225137054
Mean train loss after  10900 batches of 5  epochs =0.0384720009087
Mean train loss after  11000 batches of 5  epochs =0.0383865323814
Mean train loss after  11100 batches of 5  epochs =0.0385566773838
Mean train loss after  11200 batches of 5  epochs =0.0385989578788
Mean train loss after  11300 batches of 5  epochs =0.0384944648296
Mean train loss after  11400 batches of 5  epochs =0.0385873879557
Mean train loss after  11500 batches of 5  epochs =0.0387470609174
Mean train loss after  11600 batches of 5  epochs =0.0387471592881
Mean train loss after  11700 batches of 5  epochs =0.0387848041626
Mean train loss after  11800 batches of 5  epochs =0.0387469393721
Mean train loss after  11900 batches of 5  epochs =0.0389007450337
Mean train loss after  12000 batches of 5  epochs =0.0389084792058
Mean train loss after  12100 batches of 5  epochs =0.038994761551
Mean train loss after  12200 batches of 5  epochs =0.0389882387403
Mean train loss after  12300 batches of 5  epochs =0.0389480512593
Mean train loss after  12400 batches of 5  epochs =0.0391202125961
Mean train loss after  12500 batches of 5  epochs =0.0393166598022
Mean train loss after  12600 batches of 5  epochs =0.039488813762
Mean train loss after  12700 batches of 5  epochs =0.0394969989168
Mean train loss after  12800 batches of 5  epochs =0.0395035261976
Mean train loss after  12900 batches of 5  epochs =0.0394394010579
Mean train loss after  13000 batches of 5  epochs =0.0394774514862
Mean train loss after  13100 batches of 5  epochs =0.0395030738965
Mean train loss after  13200 batches of 5  epochs =0.0395617071379
Mean train loss after  13300 batches of 5  epochs =0.0396081284875
Mean train loss after  13400 batches of 5  epochs =0.0395546732423
Mean train loss after  13500 batches of 5  epochs =0.0396520760411
Mean train loss after  13600 batches of 5  epochs =0.039707593809
Mean train loss after  13700 batches of 5  epochs =0.0399845577279
Mean train loss after  13800 batches of 5  epochs =0.0400332616519
Mean train loss after  13900 batches of 5  epochs =0.0401567331453
Mean train loss after  14000 batches of 5  epochs =0.0403401555015
Mean train loss after  14100 batches of 5  epochs =0.040417459493
Mean train loss after  14200 batches of 5  epochs =0.0405937911837
Mean train loss after  14300 batches of 5  epochs =0.040653721517
Mean train loss after  14400 batches of 5  epochs =0.0408508999631
Mean train loss after  14500 batches of 5  epochs =0.0409064445703
Mean train loss after  14600 batches of 5  epochs =0.0410545249451
Mean train loss after  14700 batches of 5  epochs =0.0410666632281
Mean train loss after  14800 batches of 5  epochs =0.0411074601654
Mean train loss after  14900 batches of 5  epochs =0.0411074334682
Epoch 5 : Mean train epoch loss =0.0412414866466
Epoch 5 Epoch val loss = 16743.1877205
Epoch 5 Epoch val perplexity = 1.4070014048658497
SCORES =  (92.61, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 6---------------------

=================================
fscore(z) =  [137.56604] || goldscore = [137.5637]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-5.03	0.87	-0.20	-2.29	0.01	-1.61	-1.08	-1.08	-1.00	-1.05	-0.63	0.14	-0.07	-0.66	1.17	-4.53	-1.22	-2.42	-4.58	-1.22	-0.34	-2.71	-1.10	-2.30	-2.54	0.12	-4.72	-1.50	-0.59	1.02	-1.23	-0.40	-0.26	-2.02	-1.43	-2.80	-3.26	0.17	-1.39	-2.15	-3.22	-3.23	-2.10	-1.22	-3.10	-1.96	-100000000.00	-1.82	
VBG 	-1.78	-2.11	-0.06	0.27	-0.19	0.88	-4.14	0.44	-1.36	-2.29	-3.33	-0.48	-0.04	-1.39	-0.85	-2.80	0.19	-0.43	-3.44	-6.29	-3.17	-2.23	-1.45	-1.37	-5.38	-0.52	-1.50	0.10	-3.08	0.64	-2.87	0.16	-3.03	-1.64	-2.27	-1.59	-2.61	-0.70	-1.64	-3.90	-2.69	-1.59	-1.16	-1.32	-3.25	-4.32	-100000000.00	-1.41	
VBD 	-2.53	-2.16	-3.73	-1.69	-2.57	0.33	-1.84	-1.36	0.69	-1.58	0.66	-2.00	0.69	-1.61	-1.50	-3.07	0.45	-0.48	-1.57	-2.16	-2.06	-2.47	-3.43	-1.59	-3.13	-0.01	-2.05	1.10	1.45	-1.72	-2.68	-1.41	-6.35	0.17	-1.53	-1.62	0.05	-2.88	-2.22	-3.65	-2.21	-0.67	-0.32	-1.03	-2.32	-2.64	-100000000.00	0.59	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.82	-0.64	-0.94	-0.90	-1.58	-1.16	-3.51	0.13	-1.08	-1.70	-1.84	0.09	0.03	-0.82	-0.62	-3.34	-0.35	-1.96	-0.59	-2.08	-1.22	-3.40	-1.97	-1.75	-3.59	0.64	-0.51	-0.14	-1.65	0.51	-0.86	-0.93	-4.73	-0.75	-0.16	-1.82	-3.68	-0.84	-1.00	-3.19	-4.73	-1.50	-2.64	-1.47	-0.49	-6.87	-100000000.00	-2.10	
, 	-1.67	-1.33	0.78	-3.10	-0.44	-2.64	-0.90	-0.66	-0.47	0.80	-1.69	-1.15	-1.52	-1.02	-0.73	-4.51	0.30	0.26	-2.44	-1.48	0.38	-2.43	-3.41	-1.87	-1.32	-1.24	-4.35	-0.38	-0.94	-0.59	-4.07	-0.44	-5.40	-0.51	-1.30	1.37	-1.83	-0.46	-3.94	-3.90	-1.87	0.70	-1.99	-0.83	-4.14	-1.26	-100000000.00	1.02	
'' 	-1.20	-0.69	-2.01	-1.24	-4.07	-0.35	-0.65	-3.48	-2.83	-4.81	-2.24	-2.47	-5.85	-4.57	-0.57	-1.08	0.51	-1.74	-3.10	-1.94	-2.75	0.37	-2.77	-0.36	-2.66	-0.54	-1.77	-2.66	-2.56	-0.99	-1.33	-0.54	-1.86	-0.97	-2.60	-3.46	-1.51	-0.75	-0.58	-0.49	-3.66	-2.93	-1.15	-3.88	-2.59	-3.03	-100000000.00	-1.17	
VBP 	-5.39	-1.86	-7.44	-4.16	-2.89	-0.85	-0.78	-1.63	-0.05	-3.70	0.31	-2.47	-1.61	-1.78	-2.28	-0.84	-2.00	0.49	-1.01	-4.94	-4.85	-1.60	-2.28	-3.11	-3.83	-0.30	-3.23	1.11	-0.23	-2.16	-2.31	-1.54	-3.60	-1.72	-1.46	-0.77	0.20	-5.19	-0.73	-2.11	-3.36	0.04	-3.95	-2.55	-1.79	-3.36	-100000000.00	-0.83	
WDT 	-3.72	-2.82	-3.54	-2.58	-3.67	-0.78	-1.99	-2.07	-3.47	-2.27	-1.95	-3.95	-1.73	-1.47	-1.22	-2.60	0.13	-0.38	-2.77	-3.47	-1.26	-1.84	-1.23	-0.31	-1.00	-2.16	-0.46	0.83	-3.28	-2.23	-1.69	-0.72	-1.75	-1.39	-1.83	-1.52	-3.54	-1.56	0.36	-1.98	-4.22	-2.42	-2.71	-2.25	-2.84	-2.76	-100000000.00	-0.04	
JJ 	-0.25	0.91	0.22	0.44	-0.21	-1.32	-2.52	0.16	-1.58	-0.61	-3.61	0.33	-0.06	-1.19	-0.58	-0.92	-0.91	-0.75	-1.14	-2.32	0.10	-3.40	-1.65	-1.16	-5.02	-0.09	-0.52	-1.29	-1.12	0.24	0.41	0.29	-3.03	-0.17	0.60	0.10	-4.12	0.58	-1.19	-3.85	-1.21	-2.58	-1.23	-0.18	-1.31	-2.59	-100000000.00	-0.88	
WP 	-3.41	-1.39	-0.72	-0.84	-0.60	-1.28	-2.08	-3.63	-3.04	-1.32	-3.74	-1.72	-0.89	-1.02	-1.87	-2.90	-1.46	-1.53	-1.35	-2.61	-0.44	-1.50	-1.33	-0.52	-0.68	-1.67	-2.96	1.51	-1.21	-1.43	-2.85	-2.24	-2.38	0.60	-1.79	-2.65	-0.71	-0.44	-0.46	-0.16	-0.65	-0.38	-2.93	-1.62	-3.88	-2.25	-100000000.00	0.12	
VBZ 	-1.75	-2.34	-3.53	-3.80	-2.06	0.18	-2.30	-0.86	0.72	-1.48	1.29	-2.09	-0.41	-2.30	-3.02	-3.67	0.95	-2.06	-1.14	-1.80	-1.81	-2.37	-3.02	-0.70	-3.88	-0.01	-1.86	-1.67	0.53	-2.83	-2.04	-1.01	-6.18	-1.85	-4.86	-0.99	1.74	-3.25	-1.35	-2.39	-2.96	-3.06	-1.49	-2.49	-2.02	-4.92	-100000000.00	0.34	
DT 	-3.43	0.27	0.57	0.13	-0.13	1.33	-1.56	0.50	-0.98	-0.69	-1.88	0.24	-1.74	-0.68	1.09	-4.10	-0.71	-1.76	-0.40	-1.95	-1.06	-2.27	0.80	-1.50	-3.86	-0.50	-0.91	-1.90	-0.54	0.99	-0.75	0.98	1.05	-2.43	0.80	-1.89	-4.90	0.99	-0.99	-1.79	-1.97	-2.82	-2.54	-2.54	0.11	-3.17	-100000000.00	-1.72	
" 	-2.30	-0.40	-1.64	-1.97	-0.04	-0.50	-0.76	-2.23	-1.96	-1.88	-0.04	-0.64	-2.64	-2.81	0.98	-1.77	-0.59	-1.69	-2.90	-2.07	-0.83	2.05	-0.84	0.73	-1.86	-1.52	-0.95	-1.42	-2.51	-1.22	-1.69	-2.90	-2.57	-1.77	-1.56	-2.04	-2.78	-1.63	-1.81	1.27	-1.55	-1.01	-4.06	-2.32	-3.18	-2.95	-100000000.00	-0.00	
RP 	-4.82	1.10	0.77	-3.40	0.52	-2.09	-1.62	0.32	-5.15	-2.03	-1.90	-1.09	-0.12	-4.08	-0.35	-2.89	-1.18	-1.87	-3.36	-2.08	-5.37	-0.61	-6.76	-0.94	-3.16	-0.50	-6.78	-1.73	-0.67	0.85	-3.31	-2.52	-2.22	-1.65	-4.14	-2.13	-1.22	-2.77	-0.22	-1.34	-4.87	-1.61	-1.78	-1.54	-2.19	-1.77	-100000000.00	-2.96	
$ 	-1.50	-0.08	-0.22	-4.78	-1.16	-3.43	-2.70	-2.61	-3.34	-1.14	-3.60	-0.16	-0.52	-3.32	-0.39	-1.48	-0.43	-0.93	-0.30	-0.32	-0.21	-1.10	-0.96	0.74	-2.54	-0.10	-1.13	-1.23	-1.15	-1.49	-1.23	-0.97	-2.58	-2.58	-2.64	-2.56	-0.45	-1.06	0.38	-1.06	-1.47	-2.17	-1.66	-1.36	-1.04	-1.26	-100000000.00	-1.32	
NN 	0.84	0.31	-1.00	0.29	-0.17	0.19	-1.48	-0.66	-1.33	1.19	-2.71	-0.45	-0.72	-0.66	-0.20	-2.66	0.08	-1.10	-1.25	-0.80	0.62	-3.50	-0.57	-4.04	-4.52	-2.54	-0.01	-1.50	-1.65	0.22	-0.97	-0.24	-4.61	-3.13	-1.59	-0.33	-6.08	-0.09	-0.28	-5.20	-2.25	-1.29	1.03	-0.50	-0.15	-6.79	-100000000.00	-0.52	
) 	-4.16	-1.10	-2.71	-4.90	-0.90	-4.94	-3.90	-2.80	-4.40	-0.52	-3.56	-2.05	-2.63	-3.19	-0.02	-3.81	-0.64	-3.01	-0.48	-2.07	-0.28	-2.87	-4.18	-2.43	-0.47	-2.82	-3.37	-1.29	-4.40	-0.65	-0.05	-2.83	-4.87	-1.82	-2.53	-2.70	-1.99	-2.79	-0.90	-2.17	-4.44	0.42	-2.33	-3.71	-3.36	-4.73	-100000000.00	-1.54	
( 	-1.28	-1.35	-2.61	-2.20	-1.46	-2.18	-1.16	-5.99	-2.35	-0.16	-0.02	-0.87	-1.53	-1.80	-4.18	-2.32	-0.09	-2.00	-2.42	-1.12	-1.83	-1.28	-2.44	0.35	-3.47	-2.67	-2.19	-0.87	-0.85	-1.70	-1.94	-2.21	-3.34	-1.95	-3.16	0.09	-2.11	-2.78	-2.27	-2.12	-4.52	-0.71	-0.53	-0.99	-4.20	-5.10	-100000000.00	-0.10	
FW 	-5.40	-5.70	-2.18	-2.12	-5.31	-2.07	-1.16	-0.81	-2.36	-1.44	-3.28	-6.08	-4.00	-3.35	-2.71	-1.48	-1.15	-1.35	-0.04	0.65	-4.17	-1.45	-1.98	0.48	-2.58	-3.83	-2.09	-2.76	-3.63	-1.32	-2.82	-1.35	-3.88	-0.22	-1.81	-1.91	-2.31	-4.14	-0.28	-1.33	-3.96	-1.71	-2.17	-3.73	-2.44	-3.45	-100000000.00	-0.73	
POS 	-2.76	-2.34	-2.75	-3.28	-1.97	-2.39	-0.72	-2.46	-1.70	-1.46	-3.24	-2.91	-0.95	-3.99	-2.50	-1.96	-0.64	-2.04	-1.07	-1.83	-2.84	0.30	-6.16	-1.11	-2.32	-2.55	-4.31	-0.99	0.02	-1.40	-3.11	-3.68	-1.85	-1.85	-3.15	-2.41	-1.49	-2.78	-1.54	-2.18	-2.42	-1.55	-1.09	-4.10	-3.30	-2.45	-100000000.00	-1.06	
. 	-2.84	0.71	-0.14	-4.58	0.35	-4.77	-3.25	-1.03	-2.34	-2.32	-3.53	-0.83	-2.94	-1.24	-0.25	-3.93	-0.72	-1.13	-2.75	-4.24	-2.01	-3.43	-1.72	-0.45	0.84	0.63	-2.30	0.73	-1.54	-0.09	-3.77	-3.84	-4.71	-4.03	0.16	-0.98	-1.31	-2.18	-3.24	-4.71	-3.66	-0.64	-4.00	-0.59	-7.25	-0.41	-100000000.00	0.08	
TO 	-1.17	-1.07	0.99	-2.12	-0.96	-2.73	-4.00	0.57	-5.56	0.73	-4.08	-0.41	-0.29	-2.91	-0.13	-5.07	-0.22	-1.73	-1.78	-3.63	-4.98	-3.01	-3.37	-1.88	-5.41	-1.74	-2.36	-1.72	-0.87	0.41	-2.52	-1.61	-5.75	-2.37	0.24	-2.00	-1.29	-1.37	-2.96	-3.53	-2.94	-1.82	-1.78	-0.94	-3.32	-3.53	-100000000.00	-1.52	
-X- 	-0.85	-0.89	-1.94	-1.45	-2.17	-1.95	0.06	-0.81	1.06	-1.76	-1.07	-3.29	-2.16	-2.09	-1.34	0.12	-2.02	-0.29	-1.37	-0.47	-1.65	0.45	-1.98	0.78	-0.21	-1.67	-0.95	-0.93	0.12	-1.81	-0.50	-0.75	1.31	0.26	-0.51	-1.96	1.33	-2.23	0.74	0.37	1.44	-0.97	0.71	-0.45	-1.13	-1.44	-100000000.00	-1.98	
LS 	-2.67	-1.85	-4.28	-1.20	-2.59	-2.19	-1.53	-2.31	-1.81	-4.83	-1.81	-3.03	-5.90	-2.44	-2.20	-3.90	-3.53	-3.15	-1.47	-2.55	-2.66	-0.75	-3.86	-0.12	-2.11	-2.36	0.33	-3.66	0.65	-2.30	-2.22	-2.21	-1.30	-0.58	-2.02	-4.14	-1.77	-6.22	0.08	-2.13	-1.78	-1.91	-1.48	-2.28	-1.80	-3.74	-100000000.00	-3.29	
RB 	-1.26	0.13	-0.08	-0.26	-0.62	0.04	-3.35	-0.65	-0.74	-1.92	-2.68	0.46	0.36	-1.08	-0.03	-2.07	-0.48	-0.37	-2.10	-6.02	-1.24	-3.43	-1.87	-1.32	-3.33	-1.20	-3.10	-0.10	-1.88	-0.25	-1.23	-0.73	-2.82	0.48	0.22	-0.87	-1.54	-0.98	-1.98	-2.76	0.86	-2.75	-1.56	-0.97	-1.25	-4.05	-100000000.00	-1.34	
: 	-2.56	-1.18	-1.38	-2.75	-0.87	-1.22	-3.87	-1.83	-1.53	-0.86	-2.37	0.13	-2.31	-1.28	-0.99	-2.53	1.15	-0.64	-0.97	-4.73	-0.95	-2.61	-2.80	-0.36	-1.00	-0.34	-2.56	-0.10	-2.07	-0.36	-4.49	-3.84	-4.85	-1.55	-2.72	0.89	-1.82	-2.50	-2.27	-1.51	-4.54	-2.51	-3.21	-1.28	-1.92	-5.14	-100000000.00	-2.63	
NNS 	-1.18	0.32	-0.51	0.35	0.35	-0.70	-1.62	-0.45	-0.45	1.35	-1.53	-0.87	0.36	-0.09	-0.26	-4.05	1.06	-1.00	-0.84	-0.54	0.53	-4.20	-2.74	-3.26	-5.49	-2.82	1.25	-2.89	-1.46	0.10	-1.02	-1.20	-2.84	-1.16	-2.66	-0.32	-6.95	-0.35	0.93	-3.73	-1.55	-2.83	-0.07	1.20	-0.94	-6.09	-100000000.00	-0.70	
PRP 	-5.15	-0.03	-1.15	-1.33	-0.86	0.00	-0.26	0.10	-2.06	-1.84	-0.97	0.26	-3.06	-0.40	-5.46	-3.45	-1.38	-3.36	-2.57	-1.94	-0.69	-2.52	-0.78	-1.22	-2.87	-0.01	-1.29	-1.83	-2.51	0.43	-0.84	-1.10	-2.68	-2.29	-2.72	-3.59	-1.22	1.57	-1.77	-4.26	-1.70	-5.93	-1.57	-4.61	-1.24	-1.24	-100000000.00	-2.46	
VB 	-2.61	-2.16	-2.24	-0.25	-2.51	-1.02	-0.66	-2.40	-1.14	-2.27	-0.94	-1.68	-1.38	-1.62	-0.34	-3.78	-0.84	-0.21	-3.07	-2.23	-2.88	-2.70	1.14	-2.27	-3.07	0.74	-0.80	-1.98	-0.65	-2.28	-2.84	-0.32	-2.05	-2.69	-0.46	-1.70	-3.79	-2.41	-1.12	-3.72	2.35	-2.32	-1.22	-1.09	-3.87	-2.98	-100000000.00	-1.65	
WRB 	-2.37	-1.07	-2.00	-1.71	-0.54	-2.07	-2.47	-2.09	-1.54	-1.52	-1.53	-0.31	-0.85	-2.41	-3.23	-0.59	0.38	-0.34	-3.10	-2.23	-0.30	-1.85	-1.81	0.16	-0.94	-0.67	-3.08	-1.32	-1.63	-0.75	-2.72	-0.99	-2.31	-3.22	-1.41	-1.26	-2.33	-0.61	0.05	-0.58	-4.57	-4.40	-2.92	-3.41	-1.67	-1.88	-100000000.00	-0.01	
CC 	-2.95	-0.43	-1.36	-1.38	0.60	-0.81	-4.40	-2.58	-3.31	0.70	-2.88	-0.76	-1.96	-1.45	-0.80	-2.88	0.33	-0.09	-2.70	-2.34	-1.67	-2.04	-3.63	-1.03	-2.91	-0.12	-1.03	-0.52	-0.96	-0.25	-5.75	-2.40	-5.50	-3.07	-1.06	-2.18	-1.05	-1.37	-1.95	-1.47	-2.97	-0.32	-1.81	-2.73	-1.19	-4.94	-100000000.00	0.30	
PDT 	-1.92	-1.69	-1.35	-1.68	-1.41	-2.86	-0.76	-1.90	-1.08	-1.87	-0.32	-1.74	-4.81	-4.37	-0.15	-2.62	-2.14	-4.05	-1.59	-1.77	-3.83	-1.10	-1.10	0.59	-2.04	-1.33	-2.95	-3.58	-3.32	-1.08	-1.56	-1.88	-2.11	-2.81	-2.34	-2.01	-2.36	-0.55	-1.41	0.84	-2.93	0.19	-1.10	-3.34	-3.33	-1.06	-100000000.00	-2.51	
RBS 	1.81	-1.79	-0.65	-5.59	-1.42	-1.53	-1.15	-1.25	-2.26	-4.64	-1.22	-1.42	0.92	-3.23	-1.99	-1.62	-1.21	-2.76	-1.41	-2.56	1.80	-0.33	-3.75	-0.69	-1.95	-2.86	-0.69	-2.89	-2.60	-1.62	-1.01	-1.79	-1.46	-1.93	-2.13	-4.48	-1.83	-1.02	-0.16	-1.11	-3.57	-2.22	-1.67	-0.64	-3.49	-3.28	-100000000.00	-5.65	
RBR 	-3.87	-1.66	-0.45	-0.90	0.16	-2.60	-1.32	-0.75	-2.29	-1.65	-4.81	0.59	-0.71	-0.17	0.49	-2.92	0.72	-2.38	-4.20	-2.40	-3.98	-2.01	-1.96	-0.82	-1.21	0.24	-2.08	0.23	0.12	0.41	-0.87	-0.65	-3.53	-2.76	-2.67	-1.02	-2.60	-0.97	-1.34	-2.55	-2.17	-3.42	-2.07	-1.19	-1.70	-1.74	-100000000.00	-1.58	
CD 	-1.07	-0.43	-0.45	-0.36	-1.03	0.34	-0.54	-1.50	-1.87	-0.82	-3.11	-0.11	0.59	0.22	-1.44	1.88	-1.08	0.06	-0.94	-1.84	-0.10	-4.04	0.35	-2.04	-5.70	-0.92	-0.20	-1.40	-2.36	-0.43	-2.01	-1.59	-3.80	-3.78	-6.31	-1.31	-7.13	-0.59	-0.36	-0.53	-5.39	-0.61	-1.18	-0.94	-0.59	-2.91	-100000000.00	-0.29	
EX 	-0.58	0.39	-1.46	-1.62	0.65	-0.90	-0.34	-0.11	-0.72	-1.57	-2.01	-2.22	-2.34	-0.48	-0.95	-0.80	-0.86	-2.62	-2.75	-1.22	-4.81	-1.31	-3.48	-0.82	-1.46	-1.45	-3.91	-2.17	-0.10	0.41	-0.93	-0.29	-0.75	-1.91	0.16	-3.12	-1.95	-0.93	-2.17	-2.93	-1.64	-1.91	-0.84	-0.86	-0.94	-0.92	-100000000.00	-2.37	
IN 	-2.99	0.42	0.00	0.35	0.47	-0.93	-1.56	-0.29	-1.18	-1.36	-3.77	0.67	-0.79	0.08	1.13	-2.43	0.95	0.46	-1.96	-4.20	-1.29	-3.57	-1.05	-2.02	-3.17	-0.53	-1.55	0.23	-0.38	-0.63	-2.07	-0.52	-2.78	-2.38	-0.16	-0.55	-1.89	-0.38	-1.37	-6.09	-2.93	-0.75	0.63	0.78	-1.13	-7.97	-100000000.00	0.50	
WP$ 	-2.38	-2.10	-2.22	-4.73	-2.04	0.11	0.36	-1.37	-1.46	-2.36	0.07	-0.74	-2.57	-1.66	0.46	-0.67	-1.33	-2.00	-1.01	-0.85	-2.80	0.24	-0.36	1.30	-1.28	-0.79	-2.29	-0.28	-3.85	-2.14	-0.42	-1.85	-0.12	-2.37	-1.05	-1.25	-0.08	0.09	-2.12	0.21	-1.48	-2.46	-1.64	0.05	-1.84	-2.70	-100000000.00	-0.69	
NN|SYM 	-1.94	-1.90	-4.11	-6.72	-3.54	-3.20	1.07	-1.86	-1.84	-3.93	-1.20	-3.11	-2.27	-4.71	-2.53	-1.04	-5.38	0.69	-2.87	-2.33	-1.72	-2.40	-3.07	-0.87	-0.19	-4.58	-2.86	-4.00	-3.83	-1.16	-1.12	-2.55	0.56	-1.37	0.01	-5.15	-1.80	-2.06	0.14	-0.56	-1.72	-2.23	-0.64	-0.72	-1.30	-2.79	-100000000.00	-5.49	
MD 	-3.08	-1.30	-1.47	-4.79	-1.80	-0.82	-0.33	-0.83	0.18	-2.50	-1.70	-2.14	-0.77	-0.67	-0.96	-3.87	-0.03	-1.25	-4.17	-2.62	-2.42	-3.67	-4.50	-0.20	-0.96	-1.32	-3.60	0.16	0.40	-2.19	-2.00	-1.55	-2.63	-2.84	-2.43	-2.27	0.10	-2.02	-1.22	-2.29	-4.62	-2.45	-2.46	-4.50	-2.54	-3.07	-100000000.00	-0.50	
NNPS 	-3.21	-1.37	-1.89	-2.01	-2.51	-2.15	-0.67	-1.20	-1.07	-1.29	-3.99	-2.55	0.23	-1.91	-2.13	-0.65	-2.10	-2.43	0.03	-5.59	-3.50	-0.70	-4.14	-1.70	-2.32	-6.73	-1.14	-3.68	-4.93	-1.61	-2.32	-1.45	-2.46	-0.67	-2.23	-0.31	-5.96	-0.66	-1.76	-1.91	-3.58	-1.57	-4.16	-5.07	-1.99	-5.33	-100000000.00	0.97	
JJS 	0.16	-5.49	-2.28	-2.36	-2.23	-1.33	-2.57	-4.44	-2.32	-2.39	-2.54	-2.53	-1.40	-2.05	-1.58	-3.38	-3.03	-3.20	-0.75	-3.64	-1.07	-1.33	-1.76	-0.12	-2.28	-4.10	-4.63	-2.57	-3.77	-2.61	-0.93	-1.47	-1.49	-1.79	-3.07	-2.48	-2.49	-0.95	-1.90	-1.33	-0.34	-2.01	-3.66	-0.51	-3.38	-4.06	-100000000.00	-3.67	
JJR 	-2.16	-0.41	-0.16	-0.67	-1.53	-2.29	-1.75	-1.30	-1.26	-1.71	-1.88	-0.15	-1.73	-2.53	-1.30	-1.11	-0.93	-3.82	0.10	-2.39	-2.86	-2.07	-1.25	-1.00	-3.03	-0.22	-2.36	-1.26	-1.26	0.45	-0.25	-1.01	-1.68	-1.46	-1.91	-1.05	-1.35	-0.09	-2.13	-2.59	-1.01	-0.89	-2.08	-2.58	-0.37	-1.87	-100000000.00	-2.10	
SYM 	-4.34	-3.45	-3.28	-0.54	-3.56	-4.83	-1.36	-0.87	-4.98	-0.23	-2.77	-4.91	-6.89	-3.08	-4.34	-2.61	-0.23	-0.59	-3.16	-4.94	-3.63	-1.42	-2.43	-1.96	-4.35	-3.61	-2.94	-0.70	-2.21	-2.74	-1.22	-1.78	-2.27	-1.73	-2.67	-0.52	-2.68	-2.60	-0.58	-1.17	-1.33	-4.35	-2.73	-4.43	-2.36	-1.76	-100000000.00	-0.28	
UH 	-3.74	-3.82	-4.26	-1.09	-3.17	0.79	-1.42	-3.24	-1.24	-7.28	-1.30	-3.50	-7.39	-0.34	-1.87	-0.14	-8.43	-4.82	-3.95	-1.05	-5.19	-0.08	-5.67	-0.78	-3.18	-4.96	-6.06	-6.02	-2.09	-5.97	-2.55	-6.57	-3.47	-2.05	-3.95	-9.83	-3.52	-2.85	-0.70	-0.56	-5.22	-4.04	-1.74	-2.38	-2.52	-1.25	-100000000.00	-4.32	
stop_tag 	-5.39	-6.28	-1.53	-0.52	-1.42	-3.97	1.47	-2.83	-7.57	-0.30	-5.23	-2.63	-1.92	-2.92	-2.55	-4.90	0.67	-2.59	-4.23	-1.76	-1.53	-1.76	-3.22	-0.86	-3.95	-2.16	-0.74	-0.36	-3.01	-2.21	-4.11	-4.31	-7.24	-2.76	-7.94	-0.96	-5.97	-2.85	-2.06	-2.75	-5.87	-0.78	-6.94	-7.23	0.16	-4.45	-100000000.00	-0.35	
NNP 	-0.82	0.25	-0.20	0.26	0.29	0.42	0.12	-0.68	-1.60	-0.17	-2.29	-0.45	0.76	0.73	-0.86	-1.69	-0.01	-0.68	-0.74	-0.17	-0.84	-3.66	0.29	-2.17	-4.16	-2.38	0.23	-1.37	-3.21	0.53	-0.89	-0.73	-7.48	-2.27	-2.48	-0.69	-6.60	-0.17	-1.65	-4.78	-1.35	-0.46	-0.75	-0.84	0.29	-1.80	-100000000.00	1.87	
Mean train loss after  0 batches of 6  epochs =0.00029182434082
Mean train loss after  100 batches of 6  epochs =0.0200978272607
Mean train loss after  200 batches of 6  epochs =0.0168677297281
Mean train loss after  300 batches of 6  epochs =0.0179246542251
Mean train loss after  400 batches of 6  epochs =0.0183766946061
Mean train loss after  500 batches of 6  epochs =0.0175910764963
Mean train loss after  600 batches of 6  epochs =0.0177795861877
Mean train loss after  700 batches of 6  epochs =0.018358597018
Mean train loss after  800 batches of 6  epochs =0.0191290564074
Mean train loss after  900 batches of 6  epochs =0.0191485342076
Mean train loss after  1000 batches of 6  epochs =0.0185838316342
Mean train loss after  1100 batches of 6  epochs =0.0192047474338
Mean train loss after  1200 batches of 6  epochs =0.0193605196887
Mean train loss after  1300 batches of 6  epochs =0.019324975783
Mean train loss after  1400 batches of 6  epochs =0.019515840438
Mean train loss after  1500 batches of 6  epochs =0.0199675443129
Mean train loss after  1600 batches of 6  epochs =0.0199908745329
Mean train loss after  1700 batches of 6  epochs =0.0208176535454
Mean train loss after  1800 batches of 6  epochs =0.0206116796787
Mean train loss after  1900 batches of 6  epochs =0.0209312306561
Mean train loss after  2000 batches of 6  epochs =0.0215642635393
Mean train loss after  2100 batches of 6  epochs =0.0216796528304
Mean train loss after  2200 batches of 6  epochs =0.0215364443217
Mean train loss after  2300 batches of 6  epochs =0.021762049091
Mean train loss after  2400 batches of 6  epochs =0.0215597074513
Mean train loss after  2500 batches of 6  epochs =0.0217702596058
Mean train loss after  2600 batches of 6  epochs =0.0216813102764
Mean train loss after  2700 batches of 6  epochs =0.0221771409922
Mean train loss after  2800 batches of 6  epochs =0.0222123327722
Mean train loss after  2900 batches of 6  epochs =0.0224815747256
Mean train loss after  3000 batches of 6  epochs =0.0223790263135
Mean train loss after  3100 batches of 6  epochs =0.0223496330665
Mean train loss after  3200 batches of 6  epochs =0.0223524781434
Mean train loss after  3300 batches of 6  epochs =0.0225745775919
Mean train loss after  3400 batches of 6  epochs =0.0227564228404
Mean train loss after  3500 batches of 6  epochs =0.0225025640434
Mean train loss after  3600 batches of 6  epochs =0.022372420191
Mean train loss after  3700 batches of 6  epochs =0.022288094534
Mean train loss after  3800 batches of 6  epochs =0.0225068050919
Mean train loss after  3900 batches of 6  epochs =0.022756092423
Mean train loss after  4000 batches of 6  epochs =0.0228063140621
Mean train loss after  4100 batches of 6  epochs =0.0227784691513
Mean train loss after  4200 batches of 6  epochs =0.0233166273357
Mean train loss after  4300 batches of 6  epochs =0.023481600123
Mean train loss after  4400 batches of 6  epochs =0.0233556188237
Mean train loss after  4500 batches of 6  epochs =0.0232280599297
Mean train loss after  4600 batches of 6  epochs =0.0231289941743
Mean train loss after  4700 batches of 6  epochs =0.0230979340469
Mean train loss after  4800 batches of 6  epochs =0.0232059284017
Mean train loss after  4900 batches of 6  epochs =0.0234004661867
Mean train loss after  5000 batches of 6  epochs =0.0233601091249
Mean train loss after  5100 batches of 6  epochs =0.0236221709158
Mean train loss after  5200 batches of 6  epochs =0.0236430180945
Mean train loss after  5300 batches of 6  epochs =0.0239570874503
Mean train loss after  5400 batches of 6  epochs =0.023923974181
Mean train loss after  5500 batches of 6  epochs =0.0242553097617
Mean train loss after  5600 batches of 6  epochs =0.0242664201155
Mean train loss after  5700 batches of 6  epochs =0.0242783155867
Mean train loss after  5800 batches of 6  epochs =0.0245607068283
Mean train loss after  5900 batches of 6  epochs =0.0244776837733
Mean train loss after  6000 batches of 6  epochs =0.0245019074614
Mean train loss after  6100 batches of 6  epochs =0.0245611408319
Mean train loss after  6200 batches of 6  epochs =0.0246188490325
Mean train loss after  6300 batches of 6  epochs =0.0246899920191
Mean train loss after  6400 batches of 6  epochs =0.0246673094443
Mean train loss after  6500 batches of 6  epochs =0.0249186620651
Mean train loss after  6600 batches of 6  epochs =0.0248728169988
Mean train loss after  6700 batches of 6  epochs =0.0249990387675
Mean train loss after  6800 batches of 6  epochs =0.0251685139496
Mean train loss after  6900 batches of 6  epochs =0.0252599859496
Mean train loss after  7000 batches of 6  epochs =0.0256027945393
Mean train loss after  7100 batches of 6  epochs =0.0257465568533
Mean train loss after  7200 batches of 6  epochs =0.0258805074485
Mean train loss after  7300 batches of 6  epochs =0.0260728033585
Mean train loss after  7400 batches of 6  epochs =0.0260222907072
Mean train loss after  7500 batches of 6  epochs =0.0261927419611
Mean train loss after  7600 batches of 6  epochs =0.0264962975517
Mean train loss after  7700 batches of 6  epochs =0.0266070752236
Mean train loss after  7800 batches of 6  epochs =0.0266340995122
Mean train loss after  7900 batches of 6  epochs =0.026571527401
Mean train loss after  8000 batches of 6  epochs =0.0267717938378
Mean train loss after  8100 batches of 6  epochs =0.0267577765412
Mean train loss after  8200 batches of 6  epochs =0.0267306587734
Mean train loss after  8300 batches of 6  epochs =0.0267623499391
Mean train loss after  8400 batches of 6  epochs =0.0269094207974
Mean train loss after  8500 batches of 6  epochs =0.0269239884582
Mean train loss after  8600 batches of 6  epochs =0.0269338444182
Mean train loss after  8700 batches of 6  epochs =0.0269121291462
Mean train loss after  8800 batches of 6  epochs =0.0270481195253
Mean train loss after  8900 batches of 6  epochs =0.0272305816135
Mean train loss after  9000 batches of 6  epochs =0.0271749191554
Mean train loss after  9100 batches of 6  epochs =0.0271812448253
Mean train loss after  9200 batches of 6  epochs =0.0272938952411
Mean train loss after  9300 batches of 6  epochs =0.0273816243088
Mean train loss after  9400 batches of 6  epochs =0.0273276254354
Mean train loss after  9500 batches of 6  epochs =0.0273375896405
Mean train loss after  9600 batches of 6  epochs =0.0273820646957
Mean train loss after  9700 batches of 6  epochs =0.0273263006481
Mean train loss after  9800 batches of 6  epochs =0.0274993797925
Mean train loss after  9900 batches of 6  epochs =0.0275787433688
Mean train loss after  10000 batches of 6  epochs =0.0277130170763
Mean train loss after  10100 batches of 6  epochs =0.0278195697179
Mean train loss after  10200 batches of 6  epochs =0.027900764412
Mean train loss after  10300 batches of 6  epochs =0.0280620248911
Mean train loss after  10400 batches of 6  epochs =0.0280472549025
Mean train loss after  10500 batches of 6  epochs =0.0282279378122
Mean train loss after  10600 batches of 6  epochs =0.0282602694181
Mean train loss after  10700 batches of 6  epochs =0.0282309601213
Mean train loss after  10800 batches of 6  epochs =0.0283218855053
Mean train loss after  10900 batches of 6  epochs =0.0284406994845
Mean train loss after  11000 batches of 6  epochs =0.0284302749549
Mean train loss after  11100 batches of 6  epochs =0.0284614962338
Mean train loss after  11200 batches of 6  epochs =0.0285682320987
Mean train loss after  11300 batches of 6  epochs =0.0286921122427
Mean train loss after  11400 batches of 6  epochs =0.0288064353977
Mean train loss after  11500 batches of 6  epochs =0.0288682758395
Mean train loss after  11600 batches of 6  epochs =0.0289640450046
Mean train loss after  11700 batches of 6  epochs =0.0291155032586
Mean train loss after  11800 batches of 6  epochs =0.0292276618349
Mean train loss after  11900 batches of 6  epochs =0.0292443040772
Mean train loss after  12000 batches of 6  epochs =0.029358475087
Mean train loss after  12100 batches of 6  epochs =0.0297861496846
Mean train loss after  12200 batches of 6  epochs =0.0299945448104
Mean train loss after  12300 batches of 6  epochs =0.0300241114789
Mean train loss after  12400 batches of 6  epochs =0.0299810402588
Mean train loss after  12500 batches of 6  epochs =0.0301025140611
Mean train loss after  12600 batches of 6  epochs =0.0301744956684
Mean train loss after  12700 batches of 6  epochs =0.0303052103038
Mean train loss after  12800 batches of 6  epochs =0.0305060894058
Mean train loss after  12900 batches of 6  epochs =0.0305210178247
Mean train loss after  13000 batches of 6  epochs =0.0307644862271
Mean train loss after  13100 batches of 6  epochs =0.0308526333765
Mean train loss after  13200 batches of 6  epochs =0.0309303938744
Mean train loss after  13300 batches of 6  epochs =0.0310554597522
Mean train loss after  13400 batches of 6  epochs =0.0310246585812
Mean train loss after  13500 batches of 6  epochs =0.0310398371295
Mean train loss after  13600 batches of 6  epochs =0.0312036389136
Mean train loss after  13700 batches of 6  epochs =0.0313306188688
Mean train loss after  13800 batches of 6  epochs =0.0313544650169
Mean train loss after  13900 batches of 6  epochs =0.031330906984
Mean train loss after  14000 batches of 6  epochs =0.0314665352301
Mean train loss after  14100 batches of 6  epochs =0.0315510926935
Mean train loss after  14200 batches of 6  epochs =0.0317355045438
Mean train loss after  14300 batches of 6  epochs =0.0318431219837
Mean train loss after  14400 batches of 6  epochs =0.0319085590008
Mean train loss after  14500 batches of 6  epochs =0.0319427476077
Mean train loss after  14600 batches of 6  epochs =0.0321049671131
Mean train loss after  14700 batches of 6  epochs =0.0321562607128
Mean train loss after  14800 batches of 6  epochs =0.032206662099
Mean train loss after  14900 batches of 6  epochs =0.0322097830548
Epoch 6 : Mean train epoch loss =0.0322719339539
Epoch 6 Epoch val loss = 17725.5482686
Epoch 6 Epoch val perplexity = 1.4354739159860759
SCORES =  (92.58, 100.0, 100.0, 100.0)
Saved Model

 ------------- Epoch = 7---------------------

=================================
fscore(z) =  [39.01158] || goldscore = [39.01158]
self.transition_potentials.data.cpu().numpy(): 
	PRP$ 	VBG 	VBD 	start_tag 	VBN 	, 	'' 	VBP 	WDT 	JJ 	WP 	VBZ 	DT 	" 	RP 	$ 	NN 	) 	( 	FW 	POS 	. 	TO 	-X- 	LS 	RB 	: 	NNS 	PRP 	VB 	WRB 	CC 	PDT 	RBS 	RBR 	CD 	EX 	IN 	WP$ 	NN|SYM 	MD 	NNPS 	JJS 	JJR 	SYM 	UH 	stop_tag 	NNP 	
PRP$ 	-5.35	0.81	-0.20	-2.75	-0.07	-1.92	-1.39	-1.13	-1.13	-1.10	-0.91	0.05	-0.26	-0.79	1.22	-4.87	-1.34	-2.72	-4.76	-1.59	-0.35	-2.74	-1.16	-2.30	-2.75	0.02	-4.90	-1.63	-0.81	1.00	-1.44	-0.48	-0.30	-2.19	-1.72	-3.02	-3.49	0.17	-1.43	-2.25	-3.82	-3.55	-2.28	-1.53	-3.19	-2.23	-100000000.00	-1.96	
VBG 	-1.87	-2.44	-0.05	0.24	-0.25	0.96	-4.39	0.43	-1.59	-2.53	-3.55	-0.59	0.02	-1.45	-0.84	-3.02	0.13	-0.54	-3.62	-6.69	-3.24	-2.34	-1.55	-1.38	-5.50	-0.55	-1.71	0.07	-3.12	0.60	-2.97	-0.05	-3.30	-1.69	-2.61	-1.68	-3.02	-0.70	-1.74	-3.97	-2.89	-1.70	-1.18	-1.65	-3.47	-4.58	-100000000.00	-1.66	
VBD 	-2.71	-2.43	-3.92	-1.78	-2.61	0.28	-2.09	-1.37	0.78	-1.66	0.62	-2.09	0.57	-1.87	-1.70	-3.46	0.43	-0.65	-1.84	-2.40	-2.33	-2.62	-3.82	-1.61	-3.30	0.02	-2.39	1.09	1.49	-1.77	-2.79	-1.37	-6.45	0.09	-1.74	-1.72	0.11	-3.09	-2.39	-3.84	-2.39	-0.68	-0.56	-1.03	-2.57	-2.78	-100000000.00	0.66	
start_tag 	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	-100000000.00	
VBN 	-2.99	-0.68	-0.92	-0.95	-1.80	-1.33	-3.76	0.18	-1.25	-1.74	-1.81	0.11	-0.09	-0.94	-0.73	-3.47	-0.28	-2.04	-0.70	-2.15	-1.32	-3.47	-2.20	-1.79	-3.71	0.71	-0.73	-0.14	-1.85	0.53	-0.83	-0.93	-4.89	-0.84	-0.17	-1.87	-3.80	-0.94	-1.06	-3.35	-4.89	-1.61	-2.80	-1.67	-0.66	-7.20	-100000000.00	-2.24	
, 	-1.94	-1.40	0.77	-3.38	-0.52	-3.13	-0.96	-0.85	-0.78	0.73	-1.99	-1.25	-1.57	-1.15	-0.74	-4.95	0.28	0.14	-2.69	-1.73	0.01	-2.63	-3.52	-1.93	-1.80	-1.25	-4.45	-0.41	-1.32	-0.68	-4.42	-0.78	-5.84	-0.50	-1.29	1.39	-1.99	-0.52	-3.95	-4.01	-1.87	0.61	-2.21	-0.90	-4.44	-1.36	-100000000.00	0.98	
'' 	-1.51	-0.87	-2.11	-1.44	-4.16	-0.30	-0.80	-3.65	-2.98	-5.11	-2.35	-2.81	-6.03	-4.80	-0.61	-1.21	0.57	-2.00	-3.20	-2.07	-3.08	0.46	-3.01	-0.36	-2.72	-0.64	-2.08	-2.82	-2.71	-1.25	-1.43	-0.54	-1.98	-1.01	-2.70	-3.85	-1.62	-0.70	-0.59	-0.53	-3.77	-3.09	-1.29	-4.00	-2.67	-3.17	-100000000.00	-1.31	
VBP 	-5.64	-2.14	-7.63	-4.34	-3.15	-0.95	-0.78	-2.04	-0.10	-3.90	0.37	-2.61	-1.73	-2.00	-2.43	-1.10	-2.03	0.41	-1.08	-5.30	-5.06	-1.75	-2.42	-3.13	-4.19	-0.34	-3.34	1.04	-0.19	-2.29	-2.62	-1.67	-3.89	-1.88	-1.70	-0.76	0.33	-5.39	-0.84	-2.26	-3.66	0.07	-4.38	-2.89	-1.98	-3.56	-100000000.00	-0.87	
WDT 	-3.87	-3.03	-3.78	-2.57	-3.78	-0.86	-2.13	-2.20	-3.53	-2.40	-2.05	-4.11	-1.73	-1.84	-1.37	-2.82	0.21	-0.53	-3.01	-3.83	-1.46	-1.86	-1.39	-0.31	-1.10	-2.39	-0.55	0.81	-3.43	-2.51	-1.85	-0.91	-1.93	-1.46	-1.99	-1.59	-3.62	-1.56	0.27	-2.01	-4.41	-2.56	-2.82	-2.49	-3.14	-2.91	-100000000.00	-0.09	
JJ 	-0.24	0.86	0.25	0.46	-0.25	-1.45	-2.60	0.13	-1.70	-0.81	-3.82	0.32	-0.06	-1.40	-0.62	-0.99	-0.90	-0.75	-1.26	-2.59	0.15	-3.54	-1.69	-1.22	-5.37	-0.08	-0.65	-1.40	-1.14	0.10	0.37	0.20	-3.22	-0.10	0.61	0.21	-4.51	0.56	-1.24	-4.09	-1.33	-2.73	-1.27	-0.26	-1.35	-2.75	-100000000.00	-0.96	
WP 	-3.60	-1.48	-0.99	-0.98	-0.70	-1.46	-2.10	-3.64	-3.24	-1.36	-4.02	-1.74	-0.93	-1.10	-1.91	-3.24	-1.51	-1.76	-1.58	-2.87	-0.61	-1.54	-1.32	-0.52	-0.85	-1.81	-3.06	1.60	-1.36	-1.51	-3.11	-2.52	-2.63	0.40	-2.04	-2.73	-0.87	-0.44	-0.52	-0.28	-1.00	-0.40	-3.17	-1.79	-3.99	-2.32	-100000000.00	0.03	
VBZ 	-2.07	-2.65	-3.82	-3.86	-2.21	0.14	-2.40	-1.12	0.65	-1.73	1.22	-2.26	-0.40	-2.54	-3.37	-3.93	0.92	-2.12	-1.27	-1.98	-2.11	-2.49	-3.18	-0.76	-4.24	-0.19	-2.11	-1.78	0.59	-3.36	-2.25	-1.11	-6.50	-2.04	-5.23	-1.07	1.72	-3.43	-1.45	-2.62	-3.21	-3.23	-1.68	-2.75	-2.09	-5.26	-100000000.00	0.30	
DT 	-3.53	0.24	0.55	0.08	-0.10	1.27	-1.62	0.43	-1.00	-0.73	-1.97	0.30	-1.85	-0.91	1.03	-4.54	-0.91	-2.05	-0.50	-2.28	-1.11	-2.34	0.77	-1.52	-4.32	-0.58	-0.92	-2.09	-0.68	0.99	-0.79	1.02	1.10	-2.52	0.88	-2.05	-5.27	0.99	-1.19	-2.06	-2.03	-3.02	-2.97	-2.66	0.17	-3.41	-100000000.00	-1.73	
" 	-2.34	-0.50	-1.68	-2.18	-0.15	-0.69	-0.80	-2.34	-2.03	-1.90	-0.38	-0.68	-2.84	-3.01	0.85	-2.08	-0.59	-1.75	-2.91	-2.34	-0.79	1.88	-1.09	0.69	-2.06	-1.56	-0.96	-1.61	-2.70	-1.28	-1.90	-2.93	-2.87	-1.95	-1.87	-2.33	-3.16	-1.75	-1.90	1.04	-1.83	-1.13	-4.36	-2.44	-3.40	-3.17	-100000000.00	-0.03	
RP 	-5.18	1.19	0.85	-3.63	0.42	-2.28	-1.83	0.35	-5.56	-2.22	-2.24	-1.13	-0.22	-4.58	-0.48	-3.30	-1.27	-1.93	-3.68	-2.36	-5.64	-0.72	-7.07	-0.95	-3.51	-0.71	-7.18	-1.87	-0.76	0.96	-3.59	-2.79	-2.51	-1.84	-4.29	-2.24	-1.44	-3.31	-0.33	-1.47	-5.08	-1.84	-1.88	-1.88	-2.48	-2.01	-100000000.00	-3.09	
$ 	-1.55	-0.04	-0.39	-5.06	-1.27	-3.56	-2.73	-2.85	-3.58	-1.19	-3.76	-0.26	-0.59	-3.59	-0.52	-1.68	-0.64	-0.96	-0.34	-0.60	-0.28	-1.12	-0.93	0.74	-2.72	-0.19	-1.14	-1.35	-1.15	-1.55	-1.39	-1.04	-2.86	-2.72	-2.95	-2.59	-0.53	-1.00	0.31	-1.17	-1.64	-2.36	-1.83	-1.63	-1.25	-1.43	-100000000.00	-1.32	
NN 	0.88	0.27	-1.29	0.25	-0.23	0.05	-1.69	-0.63	-1.53	1.25	-2.76	-0.62	-0.72	-0.76	-0.22	-2.85	-0.03	-1.37	-1.31	-0.83	0.61	-3.66	-0.61	-4.05	-4.96	-2.61	-0.00	-1.53	-1.77	0.19	-0.95	-0.32	-4.99	-3.22	-1.75	-0.33	-6.43	-0.01	-0.28	-5.40	-2.38	-1.45	1.00	-0.78	-0.24	-6.93	-100000000.00	-0.58	
) 	-4.35	-1.18	-3.03	-5.26	-0.97	-5.19	-4.05	-2.98	-4.82	-0.61	-3.73	-2.06	-2.86	-3.25	0.10	-3.99	-0.70	-3.21	-0.75	-2.19	-0.64	-2.98	-4.35	-2.44	-0.41	-2.99	-3.68	-1.31	-4.66	-0.85	-0.26	-3.09	-5.16	-2.11	-2.92	-2.73	-2.29	-3.10	-0.99	-2.33	-4.93	0.33	-2.61	-4.34	-3.72	-4.94	-100000000.00	-1.53	
( 	-1.65	-1.46	-2.56	-2.38	-1.55	-2.41	-1.20	-6.35	-2.71	-0.26	-0.20	-1.07	-1.84	-1.85	-4.62	-2.80	-0.12	-2.04	-2.73	-1.22	-1.95	-1.42	-2.58	0.33	-3.67	-3.08	-2.32	-0.81	-1.08	-1.90	-2.28	-2.44	-3.71	-2.12	-3.61	0.08	-2.47	-2.93	-2.32	-2.33	-5.06	-0.82	-0.64	-1.36	-4.62	-5.42	-100000000.00	-0.14	
FW 	-5.78	-6.11	-2.26	-2.41	-5.62	-2.25	-1.37	-0.92	-2.54	-1.48	-3.40	-6.42	-4.21	-3.53	-3.00	-1.67	-1.34	-1.49	-0.06	0.40	-4.57	-1.49	-2.37	0.44	-2.89	-4.04	-2.12	-2.84	-3.87	-1.45	-3.08	-1.48	-4.22	-0.32	-2.13	-2.16	-2.67	-4.50	-0.34	-1.48	-4.33	-2.06	-2.44	-4.15	-2.70	-3.72	-100000000.00	-0.82	
POS 	-3.28	-2.62	-2.92	-3.73	-2.13	-2.66	-0.57	-2.51	-1.85	-1.48	-3.34	-3.14	-1.10	-4.37	-2.74	-2.25	-0.70	-2.48	-1.42	-2.17	-3.31	0.21	-6.57	-1.11	-2.64	-2.76	-4.76	-0.98	-0.13	-1.54	-3.36	-3.85	-2.06	-2.06	-3.32	-2.69	-1.62	-2.90	-1.61	-2.28	-2.68	-1.66	-1.39	-4.26	-3.61	-2.70	-100000000.00	-0.96	
. 	-2.99	0.64	-0.13	-4.81	0.24	-5.10	-3.45	-1.19	-2.91	-2.40	-3.91	-1.06	-3.13	-1.52	-0.38	-4.39	-0.75	-1.33	-2.94	-4.47	-2.17	-3.74	-2.17	-0.52	0.83	0.67	-2.64	0.73	-1.71	-0.15	-4.06	-3.92	-5.27	-4.69	0.08	-0.95	-1.70	-2.29	-3.37	-4.92	-3.87	-0.67	-4.36	-0.63	-7.76	-0.50	-100000000.00	0.02	
TO 	-1.19	-1.11	1.00	-2.39	-1.04	-2.89	-4.31	0.55	-5.99	0.73	-4.33	-0.42	-0.48	-3.01	-0.09	-5.31	-0.19	-1.96	-1.87	-4.01	-5.28	-3.18	-3.51	-1.90	-5.66	-1.79	-2.37	-1.88	-1.12	0.39	-2.67	-1.75	-6.14	-2.44	0.14	-1.96	-1.36	-1.45	-3.03	-3.69	-3.20	-1.90	-1.93	-1.08	-3.65	-3.85	-100000000.00	-1.61	
-X- 	-0.85	-0.91	-1.95	-1.57	-2.18	-1.97	0.06	-0.84	1.05	-1.82	-1.07	-3.30	-2.21	-2.11	-1.35	0.11	-2.09	-0.32	-1.37	-0.51	-1.66	0.44	-1.98	0.78	-0.21	-1.71	-1.04	-0.98	0.11	-1.83	-0.50	-0.77	1.29	0.26	-0.51	-2.04	1.33	-2.29	0.74	0.37	1.39	-0.99	0.70	-0.45	-1.17	-1.44	-100000000.00	-2.10	
LS 	-2.93	-2.09	-4.60	-1.31	-2.77	-2.55	-1.61	-2.40	-1.94	-5.25	-1.96	-3.29	-6.21	-2.68	-2.37	-4.03	-3.67	-3.33	-1.60	-2.67	-2.95	-0.76	-4.11	-0.12	-2.22	-2.54	0.37	-3.82	0.50	-2.60	-2.32	-2.51	-1.41	-0.66	-2.14	-4.66	-1.83	-6.71	0.00	-2.14	-2.00	-2.19	-1.61	-2.45	-2.08	-3.82	-100000000.00	-3.42	
RB 	-1.49	0.02	-0.14	-0.43	-0.61	0.02	-3.48	-0.74	-0.77	-2.08	-2.82	0.45	0.21	-1.16	0.01	-2.42	-0.41	-0.37	-2.44	-6.55	-1.38	-3.46	-1.99	-1.34	-3.41	-1.42	-3.24	-0.23	-1.90	-0.29	-1.38	-0.78	-3.29	0.42	0.20	-0.81	-1.68	-1.02	-2.17	-2.91	0.81	-3.07	-1.65	-0.96	-1.29	-4.43	-100000000.00	-1.47	
: 	-2.98	-1.33	-1.58	-3.03	-1.04	-1.63	-4.05	-1.94	-1.88	-0.95	-2.60	0.11	-2.48	-1.39	-1.13	-2.91	1.24	-0.66	-1.30	-4.87	-1.03	-2.70	-3.02	-0.39	-1.16	-0.49	-2.94	-0.19	-2.15	-0.42	-4.67	-4.09	-5.35	-1.82	-2.99	0.84	-2.10	-2.77	-2.29	-1.71	-5.05	-2.76	-3.57	-1.51	-2.07	-5.48	-100000000.00	-2.70	
NNS 	-1.27	0.27	-0.53	0.22	0.23	-0.73	-1.79	-0.55	-0.41	1.43	-1.69	-1.11	0.28	-0.21	-0.37	-4.42	1.14	-1.17	-0.95	-0.64	0.45	-4.28	-2.83	-3.26	-5.80	-2.95	1.28	-3.11	-1.62	-0.02	-1.04	-1.27	-3.05	-1.28	-2.80	-0.32	-7.14	-0.44	0.98	-3.97	-1.85	-3.18	-0.13	1.21	-1.14	-6.46	-100000000.00	-0.74	
PRP 	-5.68	-0.02	-1.12	-1.53	-0.95	0.08	-0.31	0.08	-2.24	-1.87	-0.93	0.29	-3.15	-0.43	-5.69	-3.83	-1.56	-3.52	-2.95	-2.31	-0.76	-2.59	-0.82	-1.24	-3.13	-0.08	-1.40	-1.89	-2.86	0.40	-0.74	-1.26	-2.75	-2.45	-2.92	-3.67	-1.31	1.55	-1.81	-4.31	-1.81	-6.27	-1.68	-5.02	-1.36	-1.45	-100000000.00	-2.52	
VB 	-2.83	-2.21	-2.46	-0.20	-2.58	-0.93	-0.70	-2.46	-1.57	-2.34	-1.04	-1.97	-1.41	-1.68	-0.46	-4.02	-1.01	-0.26	-3.38	-2.32	-3.11	-2.78	1.18	-2.28	-3.40	0.64	-0.88	-2.07	-0.69	-2.45	-3.11	-0.44	-2.28	-2.93	-0.52	-1.86	-4.03	-2.60	-1.23	-3.86	2.40	-2.38	-1.23	-1.16	-4.38	-2.98	-100000000.00	-1.74	
WRB 	-2.52	-1.24	-2.07	-1.85	-0.55	-2.02	-2.56	-2.38	-1.68	-1.52	-1.74	-0.25	-1.17	-2.62	-3.35	-0.80	0.36	-0.53	-3.28	-2.41	-0.41	-1.87	-1.97	0.16	-1.14	-0.70	-3.45	-1.31	-1.76	-0.66	-2.97	-1.32	-2.45	-3.35	-1.57	-1.41	-2.33	-0.63	0.01	-0.72	-4.76	-4.58	-3.12	-3.63	-1.95	-2.04	-100000000.00	-0.03	
CC 	-2.97	-0.61	-1.59	-1.57	0.60	-0.93	-4.56	-2.80	-3.52	0.67	-3.02	-0.99	-2.22	-1.76	-0.88	-3.22	0.33	-0.32	-2.91	-2.35	-1.97	-2.15	-3.78	-1.04	-3.32	-0.13	-1.31	-0.57	-1.11	-0.23	-6.01	-2.67	-5.75	-3.39	-1.12	-2.09	-1.17	-1.43	-1.98	-1.68	-3.31	-0.31	-1.88	-2.79	-1.31	-5.21	-100000000.00	0.29	
PDT 	-2.10	-1.81	-1.43	-1.80	-1.51	-3.32	-0.89	-2.00	-1.24	-2.02	-0.48	-1.93	-5.08	-4.52	-0.42	-2.79	-2.30	-4.17	-1.78	-1.90	-3.95	-1.11	-1.29	0.59	-2.22	-1.36	-3.36	-3.58	-3.67	-1.11	-1.79	-2.09	-2.29	-2.89	-2.58	-2.17	-2.52	-0.52	-1.45	0.72	-3.23	0.08	-1.29	-3.58	-3.53	-1.21	-100000000.00	-2.48	
RBS 	1.80	-2.02	-0.86	-5.85	-1.56	-1.59	-1.20	-1.54	-2.47	-4.81	-1.43	-1.41	0.98	-3.52	-2.20	-1.81	-1.31	-2.95	-1.60	-2.75	1.83	-0.35	-4.09	-0.69	-2.03	-3.12	-1.10	-3.07	-2.91	-1.82	-1.08	-1.77	-1.70	-2.01	-2.31	-5.01	-1.95	-1.00	-0.20	-1.14	-3.75	-2.45	-1.84	-0.98	-3.65	-3.42	-100000000.00	-5.97	
RBR 	-3.93	-1.67	-0.39	-1.25	0.17	-2.71	-1.44	-0.81	-2.38	-1.92	-4.97	0.40	-0.76	-0.28	0.47	-3.30	0.63	-2.62	-4.45	-2.79	-4.34	-2.03	-1.95	-0.82	-1.38	0.17	-2.21	0.21	0.08	0.22	-1.06	-0.72	-3.80	-3.00	-2.89	-1.06	-2.79	-1.02	-1.39	-2.57	-2.24	-3.53	-2.26	-1.44	-1.88	-1.91	-100000000.00	-1.56	
CD 	-1.22	-0.39	-0.49	-0.43	-1.12	0.34	-0.52	-1.71	-1.92	-0.90	-3.56	-0.05	0.58	0.21	-1.60	2.00	-1.19	0.16	-0.89	-1.99	-0.15	-4.33	0.38	-2.18	-6.05	-0.96	-0.19	-1.42	-2.40	-0.48	-2.20	-1.59	-4.24	-3.88	-6.92	-1.41	-7.41	-0.60	-0.37	-0.50	-6.13	-0.73	-1.30	-1.08	-0.51	-2.98	-100000000.00	-0.35	
EX 	-0.81	0.32	-1.46	-1.62	0.48	-0.87	-0.44	-0.15	-0.83	-1.72	-2.10	-2.28	-2.42	-0.59	-1.10	-0.89	-0.83	-2.91	-3.00	-1.32	-4.97	-1.36	-3.71	-0.82	-1.59	-1.43	-4.11	-2.29	-0.11	0.33	-1.10	-0.14	-0.81	-1.92	0.06	-3.47	-2.08	-0.89	-2.18	-2.94	-1.86	-2.15	-0.96	-1.03	-1.10	-1.07	-100000000.00	-2.43	
IN 	-3.29	0.39	-0.06	0.23	0.44	-0.97	-1.76	-0.37	-1.24	-1.38	-3.96	0.66	-0.89	-0.05	1.16	-2.55	0.88	0.56	-1.90	-4.25	-1.71	-3.76	-1.23	-2.07	-3.41	-0.55	-1.72	0.24	-0.33	-0.57	-2.29	-0.52	-3.23	-2.39	-0.22	-0.55	-1.99	-0.41	-1.48	-6.21	-2.99	-0.76	0.53	0.82	-1.42	-8.44	-100000000.00	0.49	
WP$ 	-2.39	-2.19	-2.28	-4.97	-2.07	0.10	0.34	-1.45	-1.52	-2.47	0.04	-0.81	-2.74	-1.71	0.38	-0.73	-1.43	-2.06	-1.07	-0.92	-2.84	0.22	-0.47	1.30	-1.29	-0.93	-2.42	-0.22	-3.86	-2.22	-0.45	-1.90	-0.17	-2.39	-1.09	-1.33	-0.09	-0.16	-2.12	0.20	-1.54	-2.54	-1.65	-0.02	-1.92	-2.72	-100000000.00	-0.78	
NN|SYM 	-2.06	-2.14	-4.32	-7.24	-3.66	-3.41	1.02	-2.01	-2.01	-4.27	-1.28	-3.29	-2.50	-4.89	-2.59	-1.18	-5.59	0.71	-3.16	-2.51	-1.93	-2.40	-3.20	-0.87	-0.35	-4.85	-3.19	-4.33	-3.96	-1.63	-1.16	-2.78	0.39	-1.40	-0.21	-5.59	-1.81	-2.42	0.13	-0.58	-1.92	-2.50	-0.75	-0.96	-1.61	-2.87	-100000000.00	-5.80	
MD 	-3.16	-1.46	-1.48	-4.82	-1.96	-0.84	-0.65	-0.97	0.15	-2.67	-1.80	-2.18	-0.74	-0.94	-1.06	-4.13	-0.12	-1.35	-4.40	-2.90	-2.59	-3.71	-4.55	-0.24	-1.21	-1.51	-3.83	0.01	0.41	-2.31	-1.98	-1.46	-2.80	-3.07	-2.74	-2.44	0.10	-2.29	-1.36	-2.43	-4.69	-2.50	-2.75	-4.72	-2.76	-3.22	-100000000.00	-0.49	
NNPS 	-3.47	-1.56	-1.98	-2.16	-2.65	-2.32	-0.76	-1.46	-1.24	-1.45	-4.25	-2.68	0.12	-2.07	-2.32	-0.93	-2.20	-2.67	-0.18	-6.01	-3.72	-0.85	-4.40	-1.71	-2.60	-7.45	-1.36	-4.05	-5.33	-1.68	-2.66	-1.50	-2.79	-0.91	-2.73	-0.45	-6.10	-0.65	-1.73	-2.07	-3.83	-1.76	-4.42	-5.44	-2.21	-5.84	-100000000.00	0.95	
JJS 	0.06	-5.70	-2.37	-2.42	-2.30	-1.38	-2.74	-4.64	-2.47	-2.33	-2.77	-2.72	-1.50	-2.29	-1.76	-3.55	-3.15	-3.65	-0.86	-4.00	-1.06	-1.38	-2.15	-0.16	-2.37	-4.56	-5.08	-2.70	-4.07	-2.63	-1.05	-1.70	-1.78	-1.88	-3.36	-2.90	-2.69	-1.09	-1.98	-1.47	-0.52	-2.19	-3.81	-0.83	-3.49	-4.16	-100000000.00	-4.08	
JJR 	-2.32	-0.47	-0.15	-0.77	-1.57	-2.35	-1.92	-1.30	-1.52	-1.90	-2.16	-0.18	-1.93	-2.52	-1.40	-1.31	-1.04	-4.23	0.05	-2.61	-3.27	-2.08	-1.26	-1.01	-3.25	-0.36	-2.62	-1.27	-1.34	0.40	-0.39	-0.95	-2.02	-1.70	-2.26	-1.15	-1.60	-0.17	-2.24	-2.65	-1.11	-1.09	-2.29	-2.87	-0.48	-2.17	-100000000.00	-2.20	
SYM 	-4.62	-3.57	-3.71	-0.53	-3.78	-5.05	-1.58	-1.02	-5.21	-0.21	-3.13	-5.18	-7.33	-3.33	-4.62	-2.79	-0.27	-0.73	-3.36	-5.21	-3.98	-1.61	-2.89	-1.96	-4.54	-3.89	-3.13	-0.86	-2.22	-3.00	-1.43	-1.90	-2.64	-2.02	-2.99	-0.62	-3.09	-2.81	-0.69	-1.39	-1.55	-4.65	-2.93	-4.78	-2.63	-1.82	-100000000.00	-0.28	
UH 	-4.09	-4.26	-4.61	-1.24	-3.55	0.65	-1.64	-3.45	-1.45	-7.67	-1.51	-3.81	-7.86	-0.36	-2.04	-0.34	-8.91	-5.16	-4.10	-1.25	-5.48	-0.12	-5.94	-0.79	-3.33	-5.46	-6.41	-6.43	-2.10	-6.28	-2.64	-7.05	-3.78	-2.19	-4.19	-10.11	-3.61	-3.13	-0.76	-0.64	-5.54	-4.39	-1.85	-2.78	-2.75	-1.29	-100000000.00	-4.46	
stop_tag 	-5.87	-7.22	-1.63	-0.52	-1.81	-4.22	1.25	-3.02	-8.49	-0.22	-5.76	-2.79	-2.08	-3.11	-2.75	-5.55	0.61	-2.82	-4.62	-1.90	-1.68	-1.78	-3.68	-1.05	-4.62	-2.36	-0.99	-0.41	-3.67	-2.32	-4.65	-4.53	-8.11	-3.26	-8.61	-1.09	-6.49	-3.04	-2.33	-2.85	-6.57	-0.86	-7.81	-7.88	0.15	-5.22	-100000000.00	-0.51	
NNP 	-0.84	0.28	-0.15	0.13	0.27	0.45	-0.04	-0.81	-1.62	-0.31	-2.49	-0.51	0.87	0.74	-0.87	-1.98	-0.06	-0.71	-0.81	-0.23	-0.82	-3.92	0.21	-2.28	-4.63	-2.51	0.09	-1.32	-3.38	0.51	-0.97	-0.77	-7.97	-2.59	-2.54	-0.80	-6.96	-0.23	-1.74	-4.95	-1.40	-0.51	-0.91	-0.91	0.16	-1.81	-100000000.00	1.92	
Mean train loss after  0 batches of 7  epochs =0.0
Mean train loss after  100 batches of 7  epochs =0.00465485387704
Mean train loss after  200 batches of 7  epochs =0.0115948186928
Mean train loss after  300 batches of 7  epochs =0.0173846772514
Mean train loss after  400 batches of 7  epochs =0.0165205483344
Mean train loss after  500 batches of 7  epochs =0.0177418345532
Mean train loss after  600 batches of 7  epochs =0.0182607464801
Mean train loss after  700 batches of 7  epochs =0.0177332134185
Mean train loss after  800 batches of 7  epochs =0.0169713926401
Mean train loss after  900 batches of 7  epochs =0.0166512025586
Mean train loss after  1000 batches of 7  epochs =0.0172936351354
Mean train loss after  1100 batches of 7  epochs =0.0172698058218
Mean train loss after  1200 batches of 7  epochs =0.0176349965213
Mean train loss after  1300 batches of 7  epochs =0.0181634574709
Mean train loss after  1400 batches of 7  epochs =0.0177542256179
Mean train loss after  1500 batches of 7  epochs =0.0173111243961
Mean train loss after  1600 batches of 7  epochs =0.0172104767584
Mean train loss after  1700 batches of 7  epochs =0.0174144855322
Mean train loss after  1800 batches of 7  epochs =0.0172196065004
Mean train loss after  1900 batches of 7  epochs =0.0176373782699
Mean train loss after  2000 batches of 7  epochs =0.0175582146484
Mean train loss after  2100 batches of 7  epochs =0.0175298402557
Mean train loss after  2200 batches of 7  epochs =0.0175209804577
Mean train loss after  2300 batches of 7  epochs =0.0179082737596
Mean train loss after  2400 batches of 7  epochs =0.018420039485
Mean train loss after  2500 batches of 7  epochs =0.0185018818877
Mean train loss after  2600 batches of 7  epochs =0.0185215349158
Mean train loss after  2700 batches of 7  epochs =0.0182790584186
Mean train loss after  2800 batches of 7  epochs =0.0184279500351
Mean train loss after  2900 batches of 7  epochs =0.018407036074
Mean train loss after  3000 batches of 7  epochs =0.018113065217
Mean train loss after  3100 batches of 7  epochs =0.0180929366219
Mean train loss after  3200 batches of 7  epochs =0.0180171685589
Mean train loss after  3300 batches of 7  epochs =0.017758506889
Mean train loss after  3400 batches of 7  epochs =0.0179725805123
Mean train loss after  3500 batches of 7  epochs =0.0178232363841
Mean train loss after  3600 batches of 7  epochs =0.017732387188
Mean train loss after  3700 batches of 7  epochs =0.0180468493705
Mean train loss after  3800 batches of 7  epochs =0.0184044703801
Mean train loss after  3900 batches of 7  epochs =0.0188537750635
Mean train loss after  4000 batches of 7  epochs =0.0190380297206
Mean train loss after  4100 batches of 7  epochs =0.018886137473
Mean train loss after  4200 batches of 7  epochs =0.0187728233451
Mean train loss after  4300 batches of 7  epochs =0.0187398058141
Mean train loss after  4400 batches of 7  epochs =0.0190223168888
Mean train loss after  4500 batches of 7  epochs =0.019120945731
Mean train loss after  4600 batches of 7  epochs =0.0191017538773
Mean train loss after  4700 batches of 7  epochs =0.0190529121451
Mean train loss after  4800 batches of 7  epochs =0.0192148244755
Mean train loss after  4900 batches of 7  epochs =0.0191291242019
Mean train loss after  5000 batches of 7  epochs =0.019278235708
Mean train loss after  5100 batches of 7  epochs =0.0194414689035
Mean train loss after  5200 batches of 7  epochs =0.0197886444673
Mean train loss after  5300 batches of 7  epochs =0.019929380835
Mean train loss after  5400 batches of 7  epochs =0.0200542779145
Mean train loss after  5500 batches of 7  epochs =0.0203703234358
Mean train loss after  5600 batches of 7  epochs =0.0206799659963
Mean train loss after  5700 batches of 7  epochs =0.0211573878525
Mean train loss after  5800 batches of 7  epochs =0.021178346138
Mean train loss after  5900 batches of 7  epochs =0.0211330334074
Mean train loss after  6000 batches of 7  epochs =0.0211915591821
Mean train loss after  6100 batches of 7  epochs =0.021352272302
Mean train loss after  6200 batches of 7  epochs =0.0213660492691
Mean train loss after  6300 batches of 7  epochs =0.0213280841645
Mean train loss after  6400 batches of 7  epochs =0.0214866308435
Mean train loss after  6500 batches of 7  epochs =0.0216275277773
Mean train loss after  6600 batches of 7  epochs =0.0219079214364
Mean train loss after  6700 batches of 7  epochs =0.0218580913689
Mean train loss after  6800 batches of 7  epochs =0.0219023343409
Mean train loss after  6900 batches of 7  epochs =0.0218495175604
Mean train loss after  7000 batches of 7  epochs =0.0220061560464
Mean train loss after  7100 batches of 7  epochs =0.0219920675723
Mean train loss after  7200 batches of 7  epochs =0.0219354001825
Mean train loss after  7300 batches of 7  epochs =0.0219568126929
Mean train loss after  7400 batches of 7  epochs =0.0220009302355
Mean train loss after  7500 batches of 7  epochs =0.0219955160592
Mean train loss after  7600 batches of 7  epochs =0.0221101570672
Mean train loss after  7700 batches of 7  epochs =0.0221625620788
Mean train loss after  7800 batches of 7  epochs =0.0224358067196
Mean train loss after  7900 batches of 7  epochs =0.0223893736095
Mean train loss after  8000 batches of 7  epochs =0.022333647368
Mean train loss after  8100 batches of 7  epochs =0.0223306160685
Mean train loss after  8200 batches of 7  epochs =0.0222913779228
Mean train loss after  8300 batches of 7  epochs =0.0222584566778
Mean train loss after  8400 batches of 7  epochs =0.0222018937316
Mean train loss after  8500 batches of 7  epochs =0.0222763376624
Mean train loss after  8600 batches of 7  epochs =0.0224370005429
Mean train loss after  8700 batches of 7  epochs =0.02250970563
Mean train loss after  8800 batches of 7  epochs =0.0226245619608
Mean train loss after  8900 batches of 7  epochs =0.0226323160719
Mean train loss after  9000 batches of 7  epochs =0.0228306563128
Mean train loss after  9100 batches of 7  epochs =0.0229882659335
Mean train loss after  9200 batches of 7  epochs =0.0230714789748
Mean train loss after  9300 batches of 7  epochs =0.023114665935
Mean train loss after  9400 batches of 7  epochs =0.0231792434799
Mean train loss after  9500 batches of 7  epochs =0.023337328756
Mean train loss after  9600 batches of 7  epochs =0.02330156907
Mean train loss after  9700 batches of 7  epochs =0.0233668853748
Mean train loss after  9800 batches of 7  epochs =0.0234040010903
Mean train loss after  9900 batches of 7  epochs =0.0235087488602
Mean train loss after  10000 batches of 7  epochs =0.0234732735645
Mean train loss after  10100 batches of 7  epochs =0.0235122276923
Mean train loss after  10200 batches of 7  epochs =0.0235171110777
Mean train loss after  10300 batches of 7  epochs =0.0236225091617
Mean train loss after  10400 batches of 7  epochs =0.0236273474198
Mean train loss after  10500 batches of 7  epochs =0.023800065104
Mean train loss after  10600 batches of 7  epochs =0.0238513931851
Mean train loss after  10700 batches of 7  epochs =0.0241283468494
Mean train loss after  10800 batches of 7  epochs =0.0241426766234
Mean train loss after  10900 batches of 7  epochs =0.0242398908352
Mean train loss after  11000 batches of 7  epochs =0.0243700006849
Mean train loss after  11100 batches of 7  epochs =0.0244710665928
Mean train loss after  11200 batches of 7  epochs =0.0244874245028
Mean train loss after  11300 batches of 7  epochs =0.0244902084286
Mean train loss after  11400 batches of 7  epochs =0.024551439702
Mean train loss after  11500 batches of 7  epochs =0.0246344602629
Mean train loss after  11600 batches of 7  epochs =0.0247747569285
Mean train loss after  11700 batches of 7  epochs =0.0247993790185
Mean train loss after  11800 batches of 7  epochs =0.0248650926649
Mean train loss after  11900 batches of 7  epochs =0.0249368239121
Mean train loss after  12000 batches of 7  epochs =0.0249830798578
Mean train loss after  12100 batches of 7  epochs =0.0250444192816
Mean train loss after  12200 batches of 7  epochs =0.0252257921668
Mean train loss after  12300 batches of 7  epochs =0.0253882362069
Mean train loss after  12400 batches of 7  epochs =0.0255003364349
Mean train loss after  12500 batches of 7  epochs =0.0256093645428
Mean train loss after  12600 batches of 7  epochs =0.0257507500438
Mean train loss after  12700 batches of 7  epochs =0.0257582403591
Mean train loss after  12800 batches of 7  epochs =0.0259898039815
